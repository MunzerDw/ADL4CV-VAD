{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | Name         | Type             | Params  \n",
      "-----------------------------------------------------\n",
      "0  | bottleneck   | Sequential       | 197376  \n",
      "1  | bottleneck.0 | Linear           | 65792   \n",
      "2  | bottleneck.1 | ReLU             | 0       \n",
      "3  | bottleneck.2 | Linear           | 131584  \n",
      "4  | bottleneck.3 | ReLU             | 0       \n",
      "5  | decoder1     | Sequential       | 8389376 \n",
      "6  | decoder1.0   | ConvTranspose3d  | 8388864 \n",
      "7  | decoder1.1   | BatchNorm3d      | 512     \n",
      "8  | decoder1.2   | ReLU             | 0       \n",
      "9  | decoder2     | Sequential       | 2097536 \n",
      "10 | decoder2.0   | ConvTranspose3d  | 2097280 \n",
      "11 | decoder2.1   | BatchNorm3d      | 256     \n",
      "12 | decoder2.2   | ReLU             | 0       \n",
      "13 | decoder3     | Sequential       | 524480  \n",
      "14 | decoder3.0   | ConvTranspose3d  | 524352  \n",
      "15 | decoder3.1   | BatchNorm3d      | 128     \n",
      "16 | decoder3.2   | ReLU             | 0       \n",
      "17 | decoder4     | Sequential       | 4097    \n",
      "18 | decoder4.0   | ConvTranspose3d  | 4097    \n",
      "19 | TOTAL        | ThreeDEPNDecoder | 11212865\n"
     ]
    }
   ],
   "source": [
    "from model.threedepn import ThreeDEPNDecoder\n",
    "from util.model import summarize_model\n",
    "\n",
    "threedepn = ThreeDEPNDecoder()\n",
    "print(summarize_model(threedepn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train set: 1854\n",
      "Length of val set: 232\n",
      "Length of test set: 232\n"
     ]
    }
   ],
   "source": [
    "from data.shapenet import ShapeNet\n",
    "\n",
    "# Create a dataset with train split\n",
    "train_dataset = ShapeNet('train', filter_class='lamp')\n",
    "val_dataset = ShapeNet('val', filter_class='lamp')\n",
    "test_dataset = ShapeNet('test', filter_class='lamp')\n",
    "\n",
    "print(f'Length of train set: {len(train_dataset)}')  # expected output: 153540\n",
    "print(f'Length of val set: {len(val_dataset)}')  # expected output: 153540\n",
    "print(f'Length of test set: {len(test_dataset)}')  # expected output: 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target DF: (32, 32, 32)\n",
      "Target DF: <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be8986754fb4504b13533f665f03a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from util.visualization import visualize_mesh\n",
    "from skimage.measure import marching_cubes\n",
    "\n",
    "sample = test_dataset[231]\n",
    "print(f'Target DF: {sample[\"target_df\"].shape}')  # expected output: (32, 32, 32)\n",
    "print(f'Target DF: {type(sample[\"target_df\"])}')  # expected output: <class 'numpy.ndarray'>\n",
    "\n",
    "input_mesh = marching_cubes(sample['target_df'], level=1)\n",
    "visualize_mesh(input_mesh[0], input_mesh[1], flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "#                #\n",
    "#    TRAINING    #\n",
    "#                #\n",
    "##################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Data length 3236\n",
      "Training params: 2\n",
      "[001/00048] train_loss: 0.106201 kl_loss: 0.000000 normal_loss: 0.106201\n",
      "[003/00046] train_loss: 0.042423 kl_loss: 0.000000 normal_loss: 0.042423\n",
      "[005/00044] train_loss: 0.035614 kl_loss: 0.000000 normal_loss: 0.035614\n",
      "[007/00042] train_loss: 0.031330 kl_loss: 0.000000 normal_loss: 0.031330\n",
      "[009/00040] train_loss: 0.029408 kl_loss: 0.000000 normal_loss: 0.029408\n",
      "[011/00038] train_loss: 0.028273 kl_loss: 0.000000 normal_loss: 0.028273\n",
      "[013/00036] train_loss: 0.025522 kl_loss: 0.000000 normal_loss: 0.025522\n",
      "[015/00034] train_loss: 0.024653 kl_loss: 0.000000 normal_loss: 0.024653\n",
      "[017/00032] train_loss: 0.025657 kl_loss: 0.000000 normal_loss: 0.025657\n",
      "[019/00030] train_loss: 0.022715 kl_loss: 0.000000 normal_loss: 0.022715\n",
      "[021/00028] train_loss: 0.021348 kl_loss: 0.000000 normal_loss: 0.021348\n",
      "[023/00026] train_loss: 0.020369 kl_loss: 0.000000 normal_loss: 0.020369\n",
      "[025/00024] train_loss: 0.024364 kl_loss: 0.000000 normal_loss: 0.024364\n",
      "[027/00022] train_loss: 0.022951 kl_loss: 0.000000 normal_loss: 0.022951\n",
      "[029/00020] train_loss: 0.021597 kl_loss: 0.000000 normal_loss: 0.021597\n",
      "[031/00018] train_loss: 0.020342 kl_loss: 0.000000 normal_loss: 0.020342\n",
      "[033/00016] train_loss: 0.019189 kl_loss: 0.000000 normal_loss: 0.019189\n",
      "[035/00014] train_loss: 0.018313 kl_loss: 0.000000 normal_loss: 0.018313\n",
      "[037/00012] train_loss: 0.017717 kl_loss: 0.000000 normal_loss: 0.017717\n",
      "[039/00010] train_loss: 0.017121 kl_loss: 0.000000 normal_loss: 0.017121\n",
      "[041/00008] train_loss: 0.016550 kl_loss: 0.000000 normal_loss: 0.016550\n",
      "[043/00006] train_loss: 0.016037 kl_loss: 0.000000 normal_loss: 0.016037\n",
      "[045/00004] train_loss: 0.014177 kl_loss: 0.000000 normal_loss: 0.014177\n",
      "[047/00002] train_loss: 0.015520 kl_loss: 0.000000 normal_loss: 0.015520\n",
      "[049/00000] train_loss: 0.015192 kl_loss: 0.000000 normal_loss: 0.015192\n",
      "[049/00050] IOU 0.8063006274567914\n",
      "[050/00049] train_loss: 0.014601 kl_loss: 0.000000 normal_loss: 0.014601\n",
      "[052/00047] train_loss: 0.014220 kl_loss: 0.000000 normal_loss: 0.014220\n",
      "[054/00045] train_loss: 0.013703 kl_loss: 0.000000 normal_loss: 0.013703\n",
      "[056/00043] train_loss: 0.013695 kl_loss: 0.000000 normal_loss: 0.013695\n",
      "[058/00041] train_loss: 0.012883 kl_loss: 0.000000 normal_loss: 0.012883\n",
      "[060/00039] train_loss: 0.012819 kl_loss: 0.000000 normal_loss: 0.012819\n",
      "[062/00037] train_loss: 0.012836 kl_loss: 0.000000 normal_loss: 0.012836\n",
      "[064/00035] train_loss: 0.012791 kl_loss: 0.000000 normal_loss: 0.012791\n",
      "[066/00033] train_loss: 0.012476 kl_loss: 0.000000 normal_loss: 0.012476\n",
      "[068/00031] train_loss: 0.012316 kl_loss: 0.000000 normal_loss: 0.012316\n",
      "[070/00029] train_loss: 0.011803 kl_loss: 0.000000 normal_loss: 0.011803\n",
      "[072/00027] train_loss: 0.011014 kl_loss: 0.000000 normal_loss: 0.011014\n",
      "[074/00025] train_loss: 0.011772 kl_loss: 0.000000 normal_loss: 0.011772\n",
      "[076/00023] train_loss: 0.011582 kl_loss: 0.000000 normal_loss: 0.011582\n",
      "[078/00021] train_loss: 0.011229 kl_loss: 0.000000 normal_loss: 0.011229\n",
      "[080/00019] train_loss: 0.011229 kl_loss: 0.000000 normal_loss: 0.011229\n",
      "[082/00017] train_loss: 0.010978 kl_loss: 0.000000 normal_loss: 0.010978\n",
      "[084/00015] train_loss: 0.010512 kl_loss: 0.000000 normal_loss: 0.010512\n",
      "[086/00013] train_loss: 0.010199 kl_loss: 0.000000 normal_loss: 0.010199\n",
      "[088/00011] train_loss: 0.010301 kl_loss: 0.000000 normal_loss: 0.010301\n",
      "[090/00009] train_loss: 0.010272 kl_loss: 0.000000 normal_loss: 0.010272\n",
      "[092/00007] train_loss: 0.010392 kl_loss: 0.000000 normal_loss: 0.010392\n",
      "[094/00005] train_loss: 0.010156 kl_loss: 0.000000 normal_loss: 0.010156\n",
      "[096/00003] train_loss: 0.010084 kl_loss: 0.000000 normal_loss: 0.010084\n",
      "[098/00001] train_loss: 0.009890 kl_loss: 0.000000 normal_loss: 0.009890\n",
      "[099/00050] train_loss: 0.009625 kl_loss: 0.000000 normal_loss: 0.009625\n",
      "[099/00050] IOU 0.8885892022341232\n",
      "[101/00048] train_loss: 0.006687 kl_loss: 0.000000 normal_loss: 0.006687\n",
      "[103/00046] train_loss: 0.006355 kl_loss: 0.000000 normal_loss: 0.006355\n",
      "[105/00044] train_loss: 0.006316 kl_loss: 0.000000 normal_loss: 0.006316\n",
      "[107/00042] train_loss: 0.006515 kl_loss: 0.000000 normal_loss: 0.006515\n",
      "[109/00040] train_loss: 0.006439 kl_loss: 0.000000 normal_loss: 0.006439\n",
      "[111/00038] train_loss: 0.006445 kl_loss: 0.000000 normal_loss: 0.006445\n",
      "[113/00036] train_loss: 0.006852 kl_loss: 0.000000 normal_loss: 0.006852\n",
      "[115/00034] train_loss: 0.006719 kl_loss: 0.000000 normal_loss: 0.006719\n",
      "[117/00032] train_loss: 0.006506 kl_loss: 0.000000 normal_loss: 0.006506\n",
      "[119/00030] train_loss: 0.006467 kl_loss: 0.000000 normal_loss: 0.006467\n",
      "[121/00028] train_loss: 0.006596 kl_loss: 0.000000 normal_loss: 0.006596\n",
      "[123/00026] train_loss: 0.006502 kl_loss: 0.000000 normal_loss: 0.006502\n",
      "[125/00024] train_loss: 0.006630 kl_loss: 0.000000 normal_loss: 0.006630\n",
      "[127/00022] train_loss: 0.006474 kl_loss: 0.000000 normal_loss: 0.006474\n",
      "[129/00020] train_loss: 0.006653 kl_loss: 0.000000 normal_loss: 0.006653\n",
      "[131/00018] train_loss: 0.006524 kl_loss: 0.000000 normal_loss: 0.006524\n",
      "[133/00016] train_loss: 0.006183 kl_loss: 0.000000 normal_loss: 0.006183\n",
      "[135/00014] train_loss: 0.005946 kl_loss: 0.000000 normal_loss: 0.005946\n",
      "[137/00012] train_loss: 0.006370 kl_loss: 0.000000 normal_loss: 0.006370\n",
      "[139/00010] train_loss: 0.006504 kl_loss: 0.000000 normal_loss: 0.006504\n",
      "[141/00008] train_loss: 0.006158 kl_loss: 0.000000 normal_loss: 0.006158\n",
      "[143/00006] train_loss: 0.006420 kl_loss: 0.000000 normal_loss: 0.006420\n",
      "[145/00004] train_loss: 0.006318 kl_loss: 0.000000 normal_loss: 0.006318\n",
      "[147/00002] train_loss: 0.005959 kl_loss: 0.000000 normal_loss: 0.005959\n",
      "[149/00000] train_loss: 0.006167 kl_loss: 0.000000 normal_loss: 0.006167\n",
      "[149/00050] IOU 0.9118488400400937\n",
      "[150/00049] train_loss: 0.006267 kl_loss: 0.000000 normal_loss: 0.006267\n",
      "[152/00047] train_loss: 0.005839 kl_loss: 0.000000 normal_loss: 0.005839\n",
      "[154/00045] train_loss: 0.005782 kl_loss: 0.000000 normal_loss: 0.005782\n",
      "[156/00043] train_loss: 0.005699 kl_loss: 0.000000 normal_loss: 0.005699\n",
      "[158/00041] train_loss: 0.006232 kl_loss: 0.000000 normal_loss: 0.006232\n",
      "[160/00039] train_loss: 0.006133 kl_loss: 0.000000 normal_loss: 0.006133\n",
      "[162/00037] train_loss: 0.005951 kl_loss: 0.000000 normal_loss: 0.005951\n",
      "[164/00035] train_loss: 0.005979 kl_loss: 0.000000 normal_loss: 0.005979\n",
      "[166/00033] train_loss: 0.005948 kl_loss: 0.000000 normal_loss: 0.005948\n",
      "[168/00031] train_loss: 0.005905 kl_loss: 0.000000 normal_loss: 0.005905\n",
      "[170/00029] train_loss: 0.005624 kl_loss: 0.000000 normal_loss: 0.005624\n",
      "[172/00027] train_loss: 0.005861 kl_loss: 0.000000 normal_loss: 0.005861\n",
      "[174/00025] train_loss: 0.005777 kl_loss: 0.000000 normal_loss: 0.005777\n",
      "[176/00023] train_loss: 0.005548 kl_loss: 0.000000 normal_loss: 0.005548\n",
      "[178/00021] train_loss: 0.005477 kl_loss: 0.000000 normal_loss: 0.005477\n",
      "[180/00019] train_loss: 0.005532 kl_loss: 0.000000 normal_loss: 0.005532\n",
      "[182/00017] train_loss: 0.005863 kl_loss: 0.000000 normal_loss: 0.005863\n",
      "[184/00015] train_loss: 0.005802 kl_loss: 0.000000 normal_loss: 0.005802\n",
      "[186/00013] train_loss: 0.005245 kl_loss: 0.000000 normal_loss: 0.005245\n",
      "[188/00011] train_loss: 0.005779 kl_loss: 0.000000 normal_loss: 0.005779\n",
      "[190/00009] train_loss: 0.005693 kl_loss: 0.000000 normal_loss: 0.005693\n",
      "[192/00007] train_loss: 0.005587 kl_loss: 0.000000 normal_loss: 0.005587\n",
      "[194/00005] train_loss: 0.005504 kl_loss: 0.000000 normal_loss: 0.005504\n",
      "[196/00003] train_loss: 0.005209 kl_loss: 0.000000 normal_loss: 0.005209\n",
      "[198/00001] train_loss: 0.005176 kl_loss: 0.000000 normal_loss: 0.005176\n",
      "[199/00050] train_loss: 0.005617 kl_loss: 0.000000 normal_loss: 0.005617\n",
      "[199/00050] IOU 0.9256172117458286\n",
      "[201/00048] train_loss: 0.004190 kl_loss: 0.000000 normal_loss: 0.004190\n",
      "[203/00046] train_loss: 0.004088 kl_loss: 0.000000 normal_loss: 0.004088\n",
      "[205/00044] train_loss: 0.004151 kl_loss: 0.000000 normal_loss: 0.004151\n",
      "[207/00042] train_loss: 0.003992 kl_loss: 0.000000 normal_loss: 0.003992\n",
      "[209/00040] train_loss: 0.003967 kl_loss: 0.000000 normal_loss: 0.003967\n",
      "[211/00038] train_loss: 0.004063 kl_loss: 0.000000 normal_loss: 0.004063\n",
      "[213/00036] train_loss: 0.003931 kl_loss: 0.000000 normal_loss: 0.003931\n",
      "[215/00034] train_loss: 0.004004 kl_loss: 0.000000 normal_loss: 0.004004\n",
      "[217/00032] train_loss: 0.003941 kl_loss: 0.000000 normal_loss: 0.003941\n",
      "[219/00030] train_loss: 0.004066 kl_loss: 0.000000 normal_loss: 0.004066\n",
      "[221/00028] train_loss: 0.003951 kl_loss: 0.000000 normal_loss: 0.003951\n",
      "[223/00026] train_loss: 0.004050 kl_loss: 0.000000 normal_loss: 0.004050\n",
      "[225/00024] train_loss: 0.003784 kl_loss: 0.000000 normal_loss: 0.003784\n",
      "[227/00022] train_loss: 0.004005 kl_loss: 0.000000 normal_loss: 0.004005\n",
      "[229/00020] train_loss: 0.003875 kl_loss: 0.000000 normal_loss: 0.003875\n",
      "[231/00018] train_loss: 0.004033 kl_loss: 0.000000 normal_loss: 0.004033\n",
      "[233/00016] train_loss: 0.003944 kl_loss: 0.000000 normal_loss: 0.003944\n",
      "[235/00014] train_loss: 0.003814 kl_loss: 0.000000 normal_loss: 0.003814\n",
      "[237/00012] train_loss: 0.003859 kl_loss: 0.000000 normal_loss: 0.003859\n",
      "[239/00010] train_loss: 0.003986 kl_loss: 0.000000 normal_loss: 0.003986\n",
      "[241/00008] train_loss: 0.004073 kl_loss: 0.000000 normal_loss: 0.004073\n",
      "[243/00006] train_loss: 0.004000 kl_loss: 0.000000 normal_loss: 0.004000\n",
      "[245/00004] train_loss: 0.003843 kl_loss: 0.000000 normal_loss: 0.003843\n",
      "[247/00002] train_loss: 0.004078 kl_loss: 0.000000 normal_loss: 0.004078\n",
      "[249/00000] train_loss: 0.003961 kl_loss: 0.000000 normal_loss: 0.003961\n",
      "[249/00050] IOU 0.9346959705111123\n",
      "[250/00049] train_loss: 0.003924 kl_loss: 0.000000 normal_loss: 0.003924\n",
      "[252/00047] train_loss: 0.003846 kl_loss: 0.000000 normal_loss: 0.003846\n",
      "[254/00045] train_loss: 0.003735 kl_loss: 0.000000 normal_loss: 0.003735\n",
      "[256/00043] train_loss: 0.003948 kl_loss: 0.000000 normal_loss: 0.003948\n",
      "[258/00041] train_loss: 0.003995 kl_loss: 0.000000 normal_loss: 0.003995\n",
      "[260/00039] train_loss: 0.003818 kl_loss: 0.000000 normal_loss: 0.003818\n",
      "[262/00037] train_loss: 0.003759 kl_loss: 0.000000 normal_loss: 0.003759\n",
      "[264/00035] train_loss: 0.003703 kl_loss: 0.000000 normal_loss: 0.003703\n",
      "[266/00033] train_loss: 0.003788 kl_loss: 0.000000 normal_loss: 0.003788\n",
      "[268/00031] train_loss: 0.003723 kl_loss: 0.000000 normal_loss: 0.003723\n",
      "[270/00029] train_loss: 0.003873 kl_loss: 0.000000 normal_loss: 0.003873\n",
      "[272/00027] train_loss: 0.003660 kl_loss: 0.000000 normal_loss: 0.003660\n",
      "[274/00025] train_loss: 0.003853 kl_loss: 0.000000 normal_loss: 0.003853\n",
      "[276/00023] train_loss: 0.003877 kl_loss: 0.000000 normal_loss: 0.003877\n",
      "[278/00021] train_loss: 0.003803 kl_loss: 0.000000 normal_loss: 0.003803\n",
      "[280/00019] train_loss: 0.003703 kl_loss: 0.000000 normal_loss: 0.003703\n",
      "[282/00017] train_loss: 0.003841 kl_loss: 0.000000 normal_loss: 0.003841\n",
      "[284/00015] train_loss: 0.003895 kl_loss: 0.000000 normal_loss: 0.003895\n",
      "[286/00013] train_loss: 0.003555 kl_loss: 0.000000 normal_loss: 0.003555\n",
      "[288/00011] train_loss: 0.003735 kl_loss: 0.000000 normal_loss: 0.003735\n",
      "[290/00009] train_loss: 0.003763 kl_loss: 0.000000 normal_loss: 0.003763\n",
      "[292/00007] train_loss: 0.003704 kl_loss: 0.000000 normal_loss: 0.003704\n",
      "[294/00005] train_loss: 0.003652 kl_loss: 0.000000 normal_loss: 0.003652\n",
      "[296/00003] train_loss: 0.003586 kl_loss: 0.000000 normal_loss: 0.003586\n",
      "[298/00001] train_loss: 0.003862 kl_loss: 0.000000 normal_loss: 0.003862\n",
      "[299/00050] train_loss: 0.003801 kl_loss: 0.000000 normal_loss: 0.003801\n",
      "[299/00050] IOU 0.9409190300294878\n",
      "[301/00048] train_loss: 0.003255 kl_loss: 0.000000 normal_loss: 0.003255\n",
      "[303/00046] train_loss: 0.003081 kl_loss: 0.000000 normal_loss: 0.003081\n",
      "[305/00044] train_loss: 0.003031 kl_loss: 0.000000 normal_loss: 0.003031\n",
      "[307/00042] train_loss: 0.003017 kl_loss: 0.000000 normal_loss: 0.003017\n",
      "[309/00040] train_loss: 0.003090 kl_loss: 0.000000 normal_loss: 0.003090\n",
      "[311/00038] train_loss: 0.003025 kl_loss: 0.000000 normal_loss: 0.003025\n",
      "[313/00036] train_loss: 0.003138 kl_loss: 0.000000 normal_loss: 0.003138\n",
      "[315/00034] train_loss: 0.003145 kl_loss: 0.000000 normal_loss: 0.003145\n",
      "[317/00032] train_loss: 0.003234 kl_loss: 0.000000 normal_loss: 0.003234\n",
      "[319/00030] train_loss: 0.003039 kl_loss: 0.000000 normal_loss: 0.003039\n",
      "[321/00028] train_loss: 0.003081 kl_loss: 0.000000 normal_loss: 0.003081\n",
      "[323/00026] train_loss: 0.003025 kl_loss: 0.000000 normal_loss: 0.003025\n",
      "[325/00024] train_loss: 0.003036 kl_loss: 0.000000 normal_loss: 0.003036\n",
      "[327/00022] train_loss: 0.002954 kl_loss: 0.000000 normal_loss: 0.002954\n",
      "[329/00020] train_loss: 0.003022 kl_loss: 0.000000 normal_loss: 0.003022\n",
      "[331/00018] train_loss: 0.003104 kl_loss: 0.000000 normal_loss: 0.003104\n",
      "[333/00016] train_loss: 0.003053 kl_loss: 0.000000 normal_loss: 0.003053\n",
      "[335/00014] train_loss: 0.003131 kl_loss: 0.000000 normal_loss: 0.003131\n",
      "[337/00012] train_loss: 0.002940 kl_loss: 0.000000 normal_loss: 0.002940\n",
      "[339/00010] train_loss: 0.003013 kl_loss: 0.000000 normal_loss: 0.003013\n",
      "[341/00008] train_loss: 0.003054 kl_loss: 0.000000 normal_loss: 0.003054\n",
      "[343/00006] train_loss: 0.003020 kl_loss: 0.000000 normal_loss: 0.003020\n",
      "[345/00004] train_loss: 0.003072 kl_loss: 0.000000 normal_loss: 0.003072\n",
      "[347/00002] train_loss: 0.003019 kl_loss: 0.000000 normal_loss: 0.003019\n",
      "[349/00000] train_loss: 0.002970 kl_loss: 0.000000 normal_loss: 0.002970\n",
      "[349/00050] IOU 0.9448994673300438\n",
      "[350/00049] train_loss: 0.002997 kl_loss: 0.000000 normal_loss: 0.002997\n",
      "[352/00047] train_loss: 0.003048 kl_loss: 0.000000 normal_loss: 0.003048\n",
      "[354/00045] train_loss: 0.003040 kl_loss: 0.000000 normal_loss: 0.003040\n",
      "[356/00043] train_loss: 0.002957 kl_loss: 0.000000 normal_loss: 0.002957\n",
      "[358/00041] train_loss: 0.003000 kl_loss: 0.000000 normal_loss: 0.003000\n",
      "[360/00039] train_loss: 0.002947 kl_loss: 0.000000 normal_loss: 0.002947\n",
      "[362/00037] train_loss: 0.002954 kl_loss: 0.000000 normal_loss: 0.002954\n",
      "[364/00035] train_loss: 0.002963 kl_loss: 0.000000 normal_loss: 0.002963\n",
      "[366/00033] train_loss: 0.002984 kl_loss: 0.000000 normal_loss: 0.002984\n",
      "[368/00031] train_loss: 0.003052 kl_loss: 0.000000 normal_loss: 0.003052\n",
      "[370/00029] train_loss: 0.002905 kl_loss: 0.000000 normal_loss: 0.002905\n",
      "[372/00027] train_loss: 0.002975 kl_loss: 0.000000 normal_loss: 0.002975\n",
      "[374/00025] train_loss: 0.002945 kl_loss: 0.000000 normal_loss: 0.002945\n",
      "[376/00023] train_loss: 0.002922 kl_loss: 0.000000 normal_loss: 0.002922\n",
      "[378/00021] train_loss: 0.002909 kl_loss: 0.000000 normal_loss: 0.002909\n",
      "[380/00019] train_loss: 0.002939 kl_loss: 0.000000 normal_loss: 0.002939\n",
      "[382/00017] train_loss: 0.002971 kl_loss: 0.000000 normal_loss: 0.002971\n",
      "[384/00015] train_loss: 0.002892 kl_loss: 0.000000 normal_loss: 0.002892\n",
      "[386/00013] train_loss: 0.002953 kl_loss: 0.000000 normal_loss: 0.002953\n",
      "[388/00011] train_loss: 0.002892 kl_loss: 0.000000 normal_loss: 0.002892\n",
      "[390/00009] train_loss: 0.002880 kl_loss: 0.000000 normal_loss: 0.002880\n",
      "[392/00007] train_loss: 0.002916 kl_loss: 0.000000 normal_loss: 0.002916\n",
      "[394/00005] train_loss: 0.002930 kl_loss: 0.000000 normal_loss: 0.002930\n",
      "[396/00003] train_loss: 0.002926 kl_loss: 0.000000 normal_loss: 0.002926\n",
      "[398/00001] train_loss: 0.002911 kl_loss: 0.000000 normal_loss: 0.002911\n",
      "[399/00050] train_loss: 0.002905 kl_loss: 0.000000 normal_loss: 0.002905\n",
      "[399/00050] IOU 0.9468951126922046\n",
      "[401/00048] train_loss: 0.002722 kl_loss: 0.000000 normal_loss: 0.002722\n",
      "[403/00046] train_loss: 0.002626 kl_loss: 0.000000 normal_loss: 0.002626\n",
      "[405/00044] train_loss: 0.002706 kl_loss: 0.000000 normal_loss: 0.002706\n",
      "[407/00042] train_loss: 0.002621 kl_loss: 0.000000 normal_loss: 0.002621\n",
      "[409/00040] train_loss: 0.002653 kl_loss: 0.000000 normal_loss: 0.002653\n",
      "[411/00038] train_loss: 0.002629 kl_loss: 0.000000 normal_loss: 0.002629\n",
      "[413/00036] train_loss: 0.002617 kl_loss: 0.000000 normal_loss: 0.002617\n",
      "[415/00034] train_loss: 0.002619 kl_loss: 0.000000 normal_loss: 0.002619\n",
      "[417/00032] train_loss: 0.002685 kl_loss: 0.000000 normal_loss: 0.002685\n",
      "[419/00030] train_loss: 0.002677 kl_loss: 0.000000 normal_loss: 0.002677\n",
      "[421/00028] train_loss: 0.002639 kl_loss: 0.000000 normal_loss: 0.002639\n",
      "[423/00026] train_loss: 0.002647 kl_loss: 0.000000 normal_loss: 0.002647\n",
      "[425/00024] train_loss: 0.002607 kl_loss: 0.000000 normal_loss: 0.002607\n",
      "[427/00022] train_loss: 0.002590 kl_loss: 0.000000 normal_loss: 0.002590\n",
      "[429/00020] train_loss: 0.002619 kl_loss: 0.000000 normal_loss: 0.002619\n",
      "[431/00018] train_loss: 0.002590 kl_loss: 0.000000 normal_loss: 0.002590\n",
      "[433/00016] train_loss: 0.002600 kl_loss: 0.000000 normal_loss: 0.002600\n",
      "[435/00014] train_loss: 0.002608 kl_loss: 0.000000 normal_loss: 0.002608\n",
      "[437/00012] train_loss: 0.002611 kl_loss: 0.000000 normal_loss: 0.002611\n",
      "[439/00010] train_loss: 0.002590 kl_loss: 0.000000 normal_loss: 0.002590\n",
      "[441/00008] train_loss: 0.002608 kl_loss: 0.000000 normal_loss: 0.002608\n",
      "[443/00006] train_loss: 0.002603 kl_loss: 0.000000 normal_loss: 0.002603\n",
      "[445/00004] train_loss: 0.002616 kl_loss: 0.000000 normal_loss: 0.002616\n",
      "[447/00002] train_loss: 0.002620 kl_loss: 0.000000 normal_loss: 0.002620\n",
      "[449/00000] train_loss: 0.002606 kl_loss: 0.000000 normal_loss: 0.002606\n",
      "[449/00050] IOU 0.9495383341910665\n",
      "[450/00049] train_loss: 0.002602 kl_loss: 0.000000 normal_loss: 0.002602\n",
      "[452/00047] train_loss: 0.002635 kl_loss: 0.000000 normal_loss: 0.002635\n",
      "[454/00045] train_loss: 0.002679 kl_loss: 0.000000 normal_loss: 0.002679\n",
      "[456/00043] train_loss: 0.002605 kl_loss: 0.000000 normal_loss: 0.002605\n",
      "[458/00041] train_loss: 0.002596 kl_loss: 0.000000 normal_loss: 0.002596\n",
      "[460/00039] train_loss: 0.002581 kl_loss: 0.000000 normal_loss: 0.002581\n",
      "[462/00037] train_loss: 0.002634 kl_loss: 0.000000 normal_loss: 0.002634\n",
      "[464/00035] train_loss: 0.002574 kl_loss: 0.000000 normal_loss: 0.002574\n",
      "[466/00033] train_loss: 0.002574 kl_loss: 0.000000 normal_loss: 0.002574\n",
      "[468/00031] train_loss: 0.002642 kl_loss: 0.000000 normal_loss: 0.002642\n",
      "[470/00029] train_loss: 0.002573 kl_loss: 0.000000 normal_loss: 0.002573\n",
      "[472/00027] train_loss: 0.002558 kl_loss: 0.000000 normal_loss: 0.002558\n",
      "[474/00025] train_loss: 0.002524 kl_loss: 0.000000 normal_loss: 0.002524\n",
      "[476/00023] train_loss: 0.002595 kl_loss: 0.000000 normal_loss: 0.002595\n",
      "[478/00021] train_loss: 0.002551 kl_loss: 0.000000 normal_loss: 0.002551\n",
      "[480/00019] train_loss: 0.002536 kl_loss: 0.000000 normal_loss: 0.002536\n",
      "[482/00017] train_loss: 0.002541 kl_loss: 0.000000 normal_loss: 0.002541\n",
      "[484/00015] train_loss: 0.002522 kl_loss: 0.000000 normal_loss: 0.002522\n",
      "[486/00013] train_loss: 0.002624 kl_loss: 0.000000 normal_loss: 0.002624\n",
      "[488/00011] train_loss: 0.002531 kl_loss: 0.000000 normal_loss: 0.002531\n",
      "[490/00009] train_loss: 0.002525 kl_loss: 0.000000 normal_loss: 0.002525\n",
      "[492/00007] train_loss: 0.002606 kl_loss: 0.000000 normal_loss: 0.002606\n",
      "[494/00005] train_loss: 0.002620 kl_loss: 0.000000 normal_loss: 0.002620\n",
      "[496/00003] train_loss: 0.002541 kl_loss: 0.000000 normal_loss: 0.002541\n",
      "[498/00001] train_loss: 0.002546 kl_loss: 0.000000 normal_loss: 0.002546\n",
      "[499/00050] train_loss: 0.002573 kl_loss: 0.000000 normal_loss: 0.002573\n",
      "[499/00050] IOU 0.9503749401777135\n",
      "[501/00048] train_loss: 0.002475 kl_loss: 0.000000 normal_loss: 0.002475\n",
      "[503/00046] train_loss: 0.002424 kl_loss: 0.000000 normal_loss: 0.002424\n",
      "[505/00044] train_loss: 0.002428 kl_loss: 0.000000 normal_loss: 0.002428\n",
      "[507/00042] train_loss: 0.002423 kl_loss: 0.000000 normal_loss: 0.002423\n",
      "[509/00040] train_loss: 0.002429 kl_loss: 0.000000 normal_loss: 0.002429\n",
      "[511/00038] train_loss: 0.002437 kl_loss: 0.000000 normal_loss: 0.002437\n",
      "[513/00036] train_loss: 0.002428 kl_loss: 0.000000 normal_loss: 0.002428\n",
      "[515/00034] train_loss: 0.002434 kl_loss: 0.000000 normal_loss: 0.002434\n",
      "[517/00032] train_loss: 0.002470 kl_loss: 0.000000 normal_loss: 0.002470\n",
      "[519/00030] train_loss: 0.002429 kl_loss: 0.000000 normal_loss: 0.002429\n",
      "[521/00028] train_loss: 0.002435 kl_loss: 0.000000 normal_loss: 0.002435\n",
      "[523/00026] train_loss: 0.002443 kl_loss: 0.000000 normal_loss: 0.002443\n",
      "[525/00024] train_loss: 0.002432 kl_loss: 0.000000 normal_loss: 0.002432\n",
      "[527/00022] train_loss: 0.002453 kl_loss: 0.000000 normal_loss: 0.002453\n",
      "[529/00020] train_loss: 0.002408 kl_loss: 0.000000 normal_loss: 0.002408\n",
      "[531/00018] train_loss: 0.002432 kl_loss: 0.000000 normal_loss: 0.002432\n",
      "[533/00016] train_loss: 0.002431 kl_loss: 0.000000 normal_loss: 0.002431\n",
      "[535/00014] train_loss: 0.002428 kl_loss: 0.000000 normal_loss: 0.002428\n",
      "[537/00012] train_loss: 0.002444 kl_loss: 0.000000 normal_loss: 0.002444\n",
      "[539/00010] train_loss: 0.002421 kl_loss: 0.000000 normal_loss: 0.002421\n",
      "[541/00008] train_loss: 0.002461 kl_loss: 0.000000 normal_loss: 0.002461\n",
      "[543/00006] train_loss: 0.002450 kl_loss: 0.000000 normal_loss: 0.002450\n",
      "[545/00004] train_loss: 0.002411 kl_loss: 0.000000 normal_loss: 0.002411\n",
      "[547/00002] train_loss: 0.002439 kl_loss: 0.000000 normal_loss: 0.002439\n",
      "[549/00000] train_loss: 0.002399 kl_loss: 0.000000 normal_loss: 0.002399\n",
      "[549/00050] IOU 0.9521024298977351\n",
      "[550/00049] train_loss: 0.002439 kl_loss: 0.000000 normal_loss: 0.002439\n",
      "[552/00047] train_loss: 0.002406 kl_loss: 0.000000 normal_loss: 0.002406\n",
      "[554/00045] train_loss: 0.002416 kl_loss: 0.000000 normal_loss: 0.002416\n",
      "[556/00043] train_loss: 0.002406 kl_loss: 0.000000 normal_loss: 0.002406\n",
      "[558/00041] train_loss: 0.002396 kl_loss: 0.000000 normal_loss: 0.002396\n",
      "[560/00039] train_loss: 0.002409 kl_loss: 0.000000 normal_loss: 0.002409\n",
      "[562/00037] train_loss: 0.002398 kl_loss: 0.000000 normal_loss: 0.002398\n",
      "[564/00035] train_loss: 0.002433 kl_loss: 0.000000 normal_loss: 0.002433\n",
      "[566/00033] train_loss: 0.002401 kl_loss: 0.000000 normal_loss: 0.002401\n",
      "[568/00031] train_loss: 0.002402 kl_loss: 0.000000 normal_loss: 0.002402\n",
      "[570/00029] train_loss: 0.002395 kl_loss: 0.000000 normal_loss: 0.002395\n",
      "[572/00027] train_loss: 0.002397 kl_loss: 0.000000 normal_loss: 0.002397\n",
      "[574/00025] train_loss: 0.002431 kl_loss: 0.000000 normal_loss: 0.002431\n",
      "[576/00023] train_loss: 0.002410 kl_loss: 0.000000 normal_loss: 0.002410\n",
      "[578/00021] train_loss: 0.002402 kl_loss: 0.000000 normal_loss: 0.002402\n",
      "[580/00019] train_loss: 0.002373 kl_loss: 0.000000 normal_loss: 0.002373\n",
      "[582/00017] train_loss: 0.002418 kl_loss: 0.000000 normal_loss: 0.002418\n",
      "[584/00015] train_loss: 0.002380 kl_loss: 0.000000 normal_loss: 0.002380\n",
      "[586/00013] train_loss: 0.002376 kl_loss: 0.000000 normal_loss: 0.002376\n",
      "[588/00011] train_loss: 0.002387 kl_loss: 0.000000 normal_loss: 0.002387\n",
      "[590/00009] train_loss: 0.002386 kl_loss: 0.000000 normal_loss: 0.002386\n",
      "[592/00007] train_loss: 0.002387 kl_loss: 0.000000 normal_loss: 0.002387\n",
      "[594/00005] train_loss: 0.002383 kl_loss: 0.000000 normal_loss: 0.002383\n",
      "[596/00003] train_loss: 0.002383 kl_loss: 0.000000 normal_loss: 0.002383\n",
      "[598/00001] train_loss: 0.002381 kl_loss: 0.000000 normal_loss: 0.002381\n",
      "[599/00050] train_loss: 0.002367 kl_loss: 0.000000 normal_loss: 0.002367\n",
      "[599/00050] IOU 0.9526207224916027\n",
      "[601/00048] train_loss: 0.002342 kl_loss: 0.000000 normal_loss: 0.002342\n",
      "[603/00046] train_loss: 0.002340 kl_loss: 0.000000 normal_loss: 0.002340\n",
      "[605/00044] train_loss: 0.002341 kl_loss: 0.000000 normal_loss: 0.002341\n",
      "[607/00042] train_loss: 0.002323 kl_loss: 0.000000 normal_loss: 0.002323\n",
      "[609/00040] train_loss: 0.002339 kl_loss: 0.000000 normal_loss: 0.002339\n",
      "[611/00038] train_loss: 0.002327 kl_loss: 0.000000 normal_loss: 0.002327\n",
      "[613/00036] train_loss: 0.002320 kl_loss: 0.000000 normal_loss: 0.002320\n",
      "[615/00034] train_loss: 0.002334 kl_loss: 0.000000 normal_loss: 0.002334\n",
      "[617/00032] train_loss: 0.002341 kl_loss: 0.000000 normal_loss: 0.002341\n",
      "[619/00030] train_loss: 0.002330 kl_loss: 0.000000 normal_loss: 0.002330\n",
      "[621/00028] train_loss: 0.002361 kl_loss: 0.000000 normal_loss: 0.002361\n",
      "[623/00026] train_loss: 0.002335 kl_loss: 0.000000 normal_loss: 0.002335\n",
      "[625/00024] train_loss: 0.002327 kl_loss: 0.000000 normal_loss: 0.002327\n",
      "[627/00022] train_loss: 0.002332 kl_loss: 0.000000 normal_loss: 0.002332\n",
      "[629/00020] train_loss: 0.002319 kl_loss: 0.000000 normal_loss: 0.002319\n",
      "[631/00018] train_loss: 0.002322 kl_loss: 0.000000 normal_loss: 0.002322\n",
      "[633/00016] train_loss: 0.002344 kl_loss: 0.000000 normal_loss: 0.002344\n",
      "[635/00014] train_loss: 0.002336 kl_loss: 0.000000 normal_loss: 0.002336\n",
      "[637/00012] train_loss: 0.002314 kl_loss: 0.000000 normal_loss: 0.002314\n",
      "[639/00010] train_loss: 0.002334 kl_loss: 0.000000 normal_loss: 0.002334\n",
      "[641/00008] train_loss: 0.002338 kl_loss: 0.000000 normal_loss: 0.002338\n",
      "[643/00006] train_loss: 0.002299 kl_loss: 0.000000 normal_loss: 0.002299\n",
      "[645/00004] train_loss: 0.002320 kl_loss: 0.000000 normal_loss: 0.002320\n",
      "[647/00002] train_loss: 0.002352 kl_loss: 0.000000 normal_loss: 0.002352\n",
      "[649/00000] train_loss: 0.002341 kl_loss: 0.000000 normal_loss: 0.002341\n",
      "[649/00050] IOU 0.9529927011915427\n",
      "[650/00049] train_loss: 0.002325 kl_loss: 0.000000 normal_loss: 0.002325\n",
      "[652/00047] train_loss: 0.002331 kl_loss: 0.000000 normal_loss: 0.002331\n",
      "[654/00045] train_loss: 0.002317 kl_loss: 0.000000 normal_loss: 0.002317\n",
      "[656/00043] train_loss: 0.002316 kl_loss: 0.000000 normal_loss: 0.002316\n",
      "[658/00041] train_loss: 0.002320 kl_loss: 0.000000 normal_loss: 0.002320\n",
      "[660/00039] train_loss: 0.002321 kl_loss: 0.000000 normal_loss: 0.002321\n",
      "[662/00037] train_loss: 0.002316 kl_loss: 0.000000 normal_loss: 0.002316\n",
      "[664/00035] train_loss: 0.002335 kl_loss: 0.000000 normal_loss: 0.002335\n",
      "[666/00033] train_loss: 0.002310 kl_loss: 0.000000 normal_loss: 0.002310\n",
      "[668/00031] train_loss: 0.002309 kl_loss: 0.000000 normal_loss: 0.002309\n",
      "[670/00029] train_loss: 0.002299 kl_loss: 0.000000 normal_loss: 0.002299\n",
      "[672/00027] train_loss: 0.002338 kl_loss: 0.000000 normal_loss: 0.002338\n",
      "[674/00025] train_loss: 0.002312 kl_loss: 0.000000 normal_loss: 0.002312\n",
      "[676/00023] train_loss: 0.002328 kl_loss: 0.000000 normal_loss: 0.002328\n",
      "[678/00021] train_loss: 0.002328 kl_loss: 0.000000 normal_loss: 0.002328\n",
      "[680/00019] train_loss: 0.002296 kl_loss: 0.000000 normal_loss: 0.002296\n",
      "[682/00017] train_loss: 0.002320 kl_loss: 0.000000 normal_loss: 0.002320\n",
      "[684/00015] train_loss: 0.002309 kl_loss: 0.000000 normal_loss: 0.002309\n",
      "[686/00013] train_loss: 0.002308 kl_loss: 0.000000 normal_loss: 0.002308\n",
      "[688/00011] train_loss: 0.002327 kl_loss: 0.000000 normal_loss: 0.002327\n",
      "[690/00009] train_loss: 0.002322 kl_loss: 0.000000 normal_loss: 0.002322\n",
      "[692/00007] train_loss: 0.002306 kl_loss: 0.000000 normal_loss: 0.002306\n",
      "[694/00005] train_loss: 0.002316 kl_loss: 0.000000 normal_loss: 0.002316\n",
      "[696/00003] train_loss: 0.002305 kl_loss: 0.000000 normal_loss: 0.002305\n",
      "[698/00001] train_loss: 0.002288 kl_loss: 0.000000 normal_loss: 0.002288\n",
      "[699/00050] train_loss: 0.002295 kl_loss: 0.000000 normal_loss: 0.002295\n",
      "[699/00050] IOU 0.9531763271694572\n",
      "[701/00048] train_loss: 0.002288 kl_loss: 0.000000 normal_loss: 0.002288\n",
      "[703/00046] train_loss: 0.002288 kl_loss: 0.000000 normal_loss: 0.002288\n",
      "[705/00044] train_loss: 0.002282 kl_loss: 0.000000 normal_loss: 0.002282\n",
      "[707/00042] train_loss: 0.002268 kl_loss: 0.000000 normal_loss: 0.002268\n",
      "[709/00040] train_loss: 0.002296 kl_loss: 0.000000 normal_loss: 0.002296\n",
      "[711/00038] train_loss: 0.002284 kl_loss: 0.000000 normal_loss: 0.002284\n",
      "[713/00036] train_loss: 0.002287 kl_loss: 0.000000 normal_loss: 0.002287\n",
      "[715/00034] train_loss: 0.002267 kl_loss: 0.000000 normal_loss: 0.002267\n",
      "[717/00032] train_loss: 0.002283 kl_loss: 0.000000 normal_loss: 0.002283\n",
      "[719/00030] train_loss: 0.002273 kl_loss: 0.000000 normal_loss: 0.002273\n",
      "[721/00028] train_loss: 0.002288 kl_loss: 0.000000 normal_loss: 0.002288\n",
      "[723/00026] train_loss: 0.002270 kl_loss: 0.000000 normal_loss: 0.002270\n",
      "[725/00024] train_loss: 0.002286 kl_loss: 0.000000 normal_loss: 0.002286\n",
      "[727/00022] train_loss: 0.002278 kl_loss: 0.000000 normal_loss: 0.002278\n",
      "[729/00020] train_loss: 0.002288 kl_loss: 0.000000 normal_loss: 0.002288\n",
      "[731/00018] train_loss: 0.002272 kl_loss: 0.000000 normal_loss: 0.002272\n",
      "[733/00016] train_loss: 0.002286 kl_loss: 0.000000 normal_loss: 0.002286\n",
      "[735/00014] train_loss: 0.002277 kl_loss: 0.000000 normal_loss: 0.002277\n",
      "[737/00012] train_loss: 0.002294 kl_loss: 0.000000 normal_loss: 0.002294\n",
      "[739/00010] train_loss: 0.002266 kl_loss: 0.000000 normal_loss: 0.002266\n",
      "[741/00008] train_loss: 0.002275 kl_loss: 0.000000 normal_loss: 0.002275\n",
      "[743/00006] train_loss: 0.002277 kl_loss: 0.000000 normal_loss: 0.002277\n",
      "[745/00004] train_loss: 0.002281 kl_loss: 0.000000 normal_loss: 0.002281\n",
      "[747/00002] train_loss: 0.002273 kl_loss: 0.000000 normal_loss: 0.002273\n",
      "[749/00000] train_loss: 0.002277 kl_loss: 0.000000 normal_loss: 0.002277\n",
      "[749/00050] IOU 0.9535995807098075\n",
      "[750/00049] train_loss: 0.002268 kl_loss: 0.000000 normal_loss: 0.002268\n",
      "[752/00047] train_loss: 0.002282 kl_loss: 0.000000 normal_loss: 0.002282\n",
      "[754/00045] train_loss: 0.002279 kl_loss: 0.000000 normal_loss: 0.002279\n",
      "[756/00043] train_loss: 0.002270 kl_loss: 0.000000 normal_loss: 0.002270\n",
      "[758/00041] train_loss: 0.002273 kl_loss: 0.000000 normal_loss: 0.002273\n",
      "[760/00039] train_loss: 0.002280 kl_loss: 0.000000 normal_loss: 0.002280\n",
      "[762/00037] train_loss: 0.002285 kl_loss: 0.000000 normal_loss: 0.002285\n",
      "[764/00035] train_loss: 0.002268 kl_loss: 0.000000 normal_loss: 0.002268\n",
      "[766/00033] train_loss: 0.002265 kl_loss: 0.000000 normal_loss: 0.002265\n",
      "[768/00031] train_loss: 0.002272 kl_loss: 0.000000 normal_loss: 0.002272\n",
      "[770/00029] train_loss: 0.002267 kl_loss: 0.000000 normal_loss: 0.002267\n",
      "[772/00027] train_loss: 0.002270 kl_loss: 0.000000 normal_loss: 0.002270\n",
      "[774/00025] train_loss: 0.002271 kl_loss: 0.000000 normal_loss: 0.002271\n",
      "[776/00023] train_loss: 0.002276 kl_loss: 0.000000 normal_loss: 0.002276\n",
      "[778/00021] train_loss: 0.002266 kl_loss: 0.000000 normal_loss: 0.002266\n",
      "[780/00019] train_loss: 0.002262 kl_loss: 0.000000 normal_loss: 0.002262\n",
      "[782/00017] train_loss: 0.002263 kl_loss: 0.000000 normal_loss: 0.002263\n",
      "[784/00015] train_loss: 0.002270 kl_loss: 0.000000 normal_loss: 0.002270\n",
      "[786/00013] train_loss: 0.002262 kl_loss: 0.000000 normal_loss: 0.002262\n",
      "[788/00011] train_loss: 0.002269 kl_loss: 0.000000 normal_loss: 0.002269\n",
      "[790/00009] train_loss: 0.002265 kl_loss: 0.000000 normal_loss: 0.002265\n",
      "[792/00007] train_loss: 0.002261 kl_loss: 0.000000 normal_loss: 0.002261\n",
      "[794/00005] train_loss: 0.002270 kl_loss: 0.000000 normal_loss: 0.002270\n",
      "[796/00003] train_loss: 0.002255 kl_loss: 0.000000 normal_loss: 0.002255\n",
      "[798/00001] train_loss: 0.002266 kl_loss: 0.000000 normal_loss: 0.002266\n",
      "[799/00050] train_loss: 0.002266 kl_loss: 0.000000 normal_loss: 0.002266\n",
      "[799/00050] IOU 0.9538687331272734\n",
      "[801/00048] train_loss: 0.002250 kl_loss: 0.000000 normal_loss: 0.002250\n",
      "[803/00046] train_loss: 0.002257 kl_loss: 0.000000 normal_loss: 0.002257\n",
      "[805/00044] train_loss: 0.002251 kl_loss: 0.000000 normal_loss: 0.002251\n",
      "[807/00042] train_loss: 0.002244 kl_loss: 0.000000 normal_loss: 0.002244\n",
      "[809/00040] train_loss: 0.002251 kl_loss: 0.000000 normal_loss: 0.002251\n",
      "[811/00038] train_loss: 0.002250 kl_loss: 0.000000 normal_loss: 0.002250\n",
      "[813/00036] train_loss: 0.002259 kl_loss: 0.000000 normal_loss: 0.002259\n",
      "[815/00034] train_loss: 0.002253 kl_loss: 0.000000 normal_loss: 0.002253\n",
      "[817/00032] train_loss: 0.002257 kl_loss: 0.000000 normal_loss: 0.002257\n",
      "[819/00030] train_loss: 0.002242 kl_loss: 0.000000 normal_loss: 0.002242\n",
      "[821/00028] train_loss: 0.002260 kl_loss: 0.000000 normal_loss: 0.002260\n",
      "[823/00026] train_loss: 0.002243 kl_loss: 0.000000 normal_loss: 0.002243\n",
      "[825/00024] train_loss: 0.002261 kl_loss: 0.000000 normal_loss: 0.002261\n",
      "[827/00022] train_loss: 0.002256 kl_loss: 0.000000 normal_loss: 0.002256\n",
      "[829/00020] train_loss: 0.002241 kl_loss: 0.000000 normal_loss: 0.002241\n",
      "[831/00018] train_loss: 0.002257 kl_loss: 0.000000 normal_loss: 0.002257\n",
      "[833/00016] train_loss: 0.002249 kl_loss: 0.000000 normal_loss: 0.002249\n",
      "[835/00014] train_loss: 0.002245 kl_loss: 0.000000 normal_loss: 0.002245\n",
      "[837/00012] train_loss: 0.002250 kl_loss: 0.000000 normal_loss: 0.002250\n",
      "[839/00010] train_loss: 0.002246 kl_loss: 0.000000 normal_loss: 0.002246\n",
      "[841/00008] train_loss: 0.002246 kl_loss: 0.000000 normal_loss: 0.002246\n",
      "[843/00006] train_loss: 0.002241 kl_loss: 0.000000 normal_loss: 0.002241\n",
      "[845/00004] train_loss: 0.002256 kl_loss: 0.000000 normal_loss: 0.002256\n",
      "[847/00002] train_loss: 0.002244 kl_loss: 0.000000 normal_loss: 0.002244\n",
      "[849/00000] train_loss: 0.002255 kl_loss: 0.000000 normal_loss: 0.002255\n",
      "[849/00050] IOU 0.9540121351427436\n",
      "[850/00049] train_loss: 0.002252 kl_loss: 0.000000 normal_loss: 0.002252\n",
      "[852/00047] train_loss: 0.002254 kl_loss: 0.000000 normal_loss: 0.002254\n",
      "[854/00045] train_loss: 0.002251 kl_loss: 0.000000 normal_loss: 0.002251\n",
      "[856/00043] train_loss: 0.002239 kl_loss: 0.000000 normal_loss: 0.002239\n",
      "[858/00041] train_loss: 0.002243 kl_loss: 0.000000 normal_loss: 0.002243\n",
      "[860/00039] train_loss: 0.002257 kl_loss: 0.000000 normal_loss: 0.002257\n",
      "[862/00037] train_loss: 0.002234 kl_loss: 0.000000 normal_loss: 0.002234\n",
      "[864/00035] train_loss: 0.002263 kl_loss: 0.000000 normal_loss: 0.002263\n",
      "[866/00033] train_loss: 0.002239 kl_loss: 0.000000 normal_loss: 0.002239\n",
      "[868/00031] train_loss: 0.002250 kl_loss: 0.000000 normal_loss: 0.002250\n",
      "[870/00029] train_loss: 0.002243 kl_loss: 0.000000 normal_loss: 0.002243\n",
      "[872/00027] train_loss: 0.002244 kl_loss: 0.000000 normal_loss: 0.002244\n",
      "[874/00025] train_loss: 0.002234 kl_loss: 0.000000 normal_loss: 0.002234\n",
      "[876/00023] train_loss: 0.002235 kl_loss: 0.000000 normal_loss: 0.002235\n",
      "[878/00021] train_loss: 0.002252 kl_loss: 0.000000 normal_loss: 0.002252\n",
      "[880/00019] train_loss: 0.002249 kl_loss: 0.000000 normal_loss: 0.002249\n",
      "[882/00017] train_loss: 0.002230 kl_loss: 0.000000 normal_loss: 0.002230\n",
      "[884/00015] train_loss: 0.002256 kl_loss: 0.000000 normal_loss: 0.002256\n",
      "[886/00013] train_loss: 0.002238 kl_loss: 0.000000 normal_loss: 0.002238\n",
      "[888/00011] train_loss: 0.002251 kl_loss: 0.000000 normal_loss: 0.002251\n",
      "[890/00009] train_loss: 0.002238 kl_loss: 0.000000 normal_loss: 0.002238\n",
      "[892/00007] train_loss: 0.002241 kl_loss: 0.000000 normal_loss: 0.002241\n",
      "[894/00005] train_loss: 0.002245 kl_loss: 0.000000 normal_loss: 0.002245\n",
      "[896/00003] train_loss: 0.002248 kl_loss: 0.000000 normal_loss: 0.002248\n",
      "[898/00001] train_loss: 0.002242 kl_loss: 0.000000 normal_loss: 0.002242\n",
      "[899/00050] train_loss: 0.002242 kl_loss: 0.000000 normal_loss: 0.002242\n",
      "[899/00050] IOU 0.954000507337496\n",
      "[901/00048] train_loss: 0.002234 kl_loss: 0.000000 normal_loss: 0.002234\n",
      "[903/00046] train_loss: 0.002244 kl_loss: 0.000000 normal_loss: 0.002244\n",
      "[905/00044] train_loss: 0.002232 kl_loss: 0.000000 normal_loss: 0.002232\n",
      "[907/00042] train_loss: 0.002230 kl_loss: 0.000000 normal_loss: 0.002230\n",
      "[909/00040] train_loss: 0.002236 kl_loss: 0.000000 normal_loss: 0.002236\n",
      "[911/00038] train_loss: 0.002227 kl_loss: 0.000000 normal_loss: 0.002227\n",
      "[913/00036] train_loss: 0.002231 kl_loss: 0.000000 normal_loss: 0.002231\n",
      "[915/00034] train_loss: 0.002243 kl_loss: 0.000000 normal_loss: 0.002243\n",
      "[917/00032] train_loss: 0.002234 kl_loss: 0.000000 normal_loss: 0.002234\n",
      "[919/00030] train_loss: 0.002235 kl_loss: 0.000000 normal_loss: 0.002235\n",
      "[921/00028] train_loss: 0.002223 kl_loss: 0.000000 normal_loss: 0.002223\n",
      "[923/00026] train_loss: 0.002249 kl_loss: 0.000000 normal_loss: 0.002249\n",
      "[925/00024] train_loss: 0.002227 kl_loss: 0.000000 normal_loss: 0.002227\n",
      "[927/00022] train_loss: 0.002234 kl_loss: 0.000000 normal_loss: 0.002234\n",
      "[929/00020] train_loss: 0.002241 kl_loss: 0.000000 normal_loss: 0.002241\n",
      "[931/00018] train_loss: 0.002243 kl_loss: 0.000000 normal_loss: 0.002243\n",
      "[933/00016] train_loss: 0.002236 kl_loss: 0.000000 normal_loss: 0.002236\n",
      "[935/00014] train_loss: 0.002225 kl_loss: 0.000000 normal_loss: 0.002225\n",
      "[937/00012] train_loss: 0.002230 kl_loss: 0.000000 normal_loss: 0.002230\n",
      "[939/00010] train_loss: 0.002234 kl_loss: 0.000000 normal_loss: 0.002234\n",
      "[941/00008] train_loss: 0.002235 kl_loss: 0.000000 normal_loss: 0.002235\n",
      "[943/00006] train_loss: 0.002232 kl_loss: 0.000000 normal_loss: 0.002232\n",
      "[945/00004] train_loss: 0.002229 kl_loss: 0.000000 normal_loss: 0.002229\n",
      "[947/00002] train_loss: 0.002235 kl_loss: 0.000000 normal_loss: 0.002235\n",
      "[949/00000] train_loss: 0.002240 kl_loss: 0.000000 normal_loss: 0.002240\n",
      "[949/00050] IOU 0.9540956982944451\n",
      "[950/00049] train_loss: 0.002231 kl_loss: 0.000000 normal_loss: 0.002231\n",
      "[952/00047] train_loss: 0.002230 kl_loss: 0.000000 normal_loss: 0.002230\n",
      "[954/00045] train_loss: 0.002235 kl_loss: 0.000000 normal_loss: 0.002235\n",
      "[956/00043] train_loss: 0.002227 kl_loss: 0.000000 normal_loss: 0.002227\n",
      "[958/00041] train_loss: 0.002240 kl_loss: 0.000000 normal_loss: 0.002240\n",
      "[960/00039] train_loss: 0.002229 kl_loss: 0.000000 normal_loss: 0.002229\n",
      "[962/00037] train_loss: 0.002232 kl_loss: 0.000000 normal_loss: 0.002232\n",
      "[964/00035] train_loss: 0.002237 kl_loss: 0.000000 normal_loss: 0.002237\n",
      "[966/00033] train_loss: 0.002227 kl_loss: 0.000000 normal_loss: 0.002227\n",
      "[968/00031] train_loss: 0.002230 kl_loss: 0.000000 normal_loss: 0.002230\n",
      "[970/00029] train_loss: 0.002240 kl_loss: 0.000000 normal_loss: 0.002240\n",
      "[972/00027] train_loss: 0.002231 kl_loss: 0.000000 normal_loss: 0.002231\n",
      "[974/00025] train_loss: 0.002229 kl_loss: 0.000000 normal_loss: 0.002229\n",
      "[976/00023] train_loss: 0.002246 kl_loss: 0.000000 normal_loss: 0.002246\n",
      "[978/00021] train_loss: 0.002238 kl_loss: 0.000000 normal_loss: 0.002238\n",
      "[980/00019] train_loss: 0.002237 kl_loss: 0.000000 normal_loss: 0.002237\n",
      "[982/00017] train_loss: 0.002220 kl_loss: 0.000000 normal_loss: 0.002220\n",
      "[984/00015] train_loss: 0.002242 kl_loss: 0.000000 normal_loss: 0.002242\n",
      "[986/00013] train_loss: 0.002223 kl_loss: 0.000000 normal_loss: 0.002223\n",
      "[988/00011] train_loss: 0.002238 kl_loss: 0.000000 normal_loss: 0.002238\n",
      "[990/00009] train_loss: 0.002227 kl_loss: 0.000000 normal_loss: 0.002227\n",
      "[992/00007] train_loss: 0.002235 kl_loss: 0.000000 normal_loss: 0.002235\n",
      "[994/00005] train_loss: 0.002234 kl_loss: 0.000000 normal_loss: 0.002234\n",
      "[996/00003] train_loss: 0.002226 kl_loss: 0.000000 normal_loss: 0.002226\n",
      "[998/00001] train_loss: 0.002232 kl_loss: 0.000000 normal_loss: 0.002232\n",
      "[999/00050] train_loss: 0.002235 kl_loss: 0.000000 normal_loss: 0.002235\n",
      "[999/00050] IOU 0.9541702348421177\n"
     ]
    }
   ],
   "source": [
    "# AIRPLANE AD\n",
    "from scripts import train\n",
    "config = {\n",
    "    'experiment_name': 'airplane_ad',\n",
    "    'device': 'cuda:0',\n",
    "    'is_overfit': False,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate_model': 0.01,\n",
    "    'learning_rate_code': 0.01,\n",
    "    'learning_rate_log_var':0.01,\n",
    "    'max_epochs': 1000,\n",
    "    'print_every_n': 100,\n",
    "    'latent_code_length' : 256,\n",
    "    'scheduler_step_size': 100,\n",
    "    'vad_free' : False,\n",
    "    'test': False,\n",
    "    'kl_weight': 0.03,\n",
    "    'kl_weight_increase_every_epochs': 100,\n",
    "    'kl_weight_increase_value': 0.0,\n",
    "    'iou_every_epoch': 50,\n",
    "    'resume_ckpt': None,\n",
    "    'filter_class': 'airplane',\n",
    "    'decoder_var' : False\n",
    "}\n",
    "train.main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Data length 4800\n",
      "Training params: 2\n",
      "[001/00024] train_loss: 0.168495 kl_loss: 0.000000 normal_loss: 0.168495\n",
      "[002/00049] train_loss: 0.117954 kl_loss: 0.000000 normal_loss: 0.117954\n",
      "[003/00074] train_loss: 0.109562 kl_loss: 0.000000 normal_loss: 0.109562\n",
      "[005/00024] train_loss: 0.105227 kl_loss: 0.000000 normal_loss: 0.105227\n",
      "[006/00049] train_loss: 0.097987 kl_loss: 0.000000 normal_loss: 0.097987\n",
      "[007/00074] train_loss: 0.095581 kl_loss: 0.000000 normal_loss: 0.095581\n",
      "[009/00024] train_loss: 0.091399 kl_loss: 0.000000 normal_loss: 0.091399\n",
      "[010/00049] train_loss: 0.086116 kl_loss: 0.000000 normal_loss: 0.086116\n",
      "[011/00074] train_loss: 0.082822 kl_loss: 0.000000 normal_loss: 0.082822\n",
      "[013/00024] train_loss: 0.076092 kl_loss: 0.000000 normal_loss: 0.076092\n",
      "[014/00049] train_loss: 0.073706 kl_loss: 0.000000 normal_loss: 0.073706\n",
      "[015/00074] train_loss: 0.068664 kl_loss: 0.000000 normal_loss: 0.068664\n",
      "[017/00024] train_loss: 0.065321 kl_loss: 0.000000 normal_loss: 0.065321\n",
      "[018/00049] train_loss: 0.063247 kl_loss: 0.000000 normal_loss: 0.063247\n",
      "[019/00074] train_loss: 0.060584 kl_loss: 0.000000 normal_loss: 0.060584\n",
      "[021/00024] train_loss: 0.057878 kl_loss: 0.000000 normal_loss: 0.057878\n",
      "[022/00049] train_loss: 0.056367 kl_loss: 0.000000 normal_loss: 0.056367\n",
      "[023/00074] train_loss: 0.053790 kl_loss: 0.000000 normal_loss: 0.053790\n",
      "[025/00024] train_loss: 0.051930 kl_loss: 0.000000 normal_loss: 0.051930\n",
      "[026/00049] train_loss: 0.049985 kl_loss: 0.000000 normal_loss: 0.049985\n",
      "[027/00074] train_loss: 0.047572 kl_loss: 0.000000 normal_loss: 0.047572\n",
      "[029/00024] train_loss: 0.047217 kl_loss: 0.000000 normal_loss: 0.047217\n",
      "[030/00049] train_loss: 0.044996 kl_loss: 0.000000 normal_loss: 0.044996\n",
      "[031/00074] train_loss: 0.044526 kl_loss: 0.000000 normal_loss: 0.044526\n",
      "[033/00024] train_loss: 0.042396 kl_loss: 0.000000 normal_loss: 0.042396\n",
      "[034/00049] train_loss: 0.041516 kl_loss: 0.000000 normal_loss: 0.041516\n",
      "[035/00074] train_loss: 0.040286 kl_loss: 0.000000 normal_loss: 0.040286\n",
      "[037/00024] train_loss: 0.039482 kl_loss: 0.000000 normal_loss: 0.039482\n",
      "[038/00049] train_loss: 0.039414 kl_loss: 0.000000 normal_loss: 0.039414\n",
      "[039/00074] train_loss: 0.038704 kl_loss: 0.000000 normal_loss: 0.038704\n",
      "[041/00024] train_loss: 0.037147 kl_loss: 0.000000 normal_loss: 0.037147\n",
      "[042/00049] train_loss: 0.036394 kl_loss: 0.000000 normal_loss: 0.036394\n",
      "[043/00074] train_loss: 0.035746 kl_loss: 0.000000 normal_loss: 0.035746\n",
      "[045/00024] train_loss: 0.034762 kl_loss: 0.000000 normal_loss: 0.034762\n",
      "[046/00049] train_loss: 0.033424 kl_loss: 0.000000 normal_loss: 0.033424\n",
      "[047/00074] train_loss: 0.033722 kl_loss: 0.000000 normal_loss: 0.033722\n",
      "[049/00024] train_loss: 0.033844 kl_loss: 0.000000 normal_loss: 0.033844\n",
      "[049/00074] IOU 0.7622530335048213\n",
      "[050/00049] train_loss: 0.032229 kl_loss: 0.000000 normal_loss: 0.032229\n",
      "[051/00074] train_loss: 0.030781 kl_loss: 0.000000 normal_loss: 0.030781\n",
      "[053/00024] train_loss: 0.030600 kl_loss: 0.000000 normal_loss: 0.030600\n",
      "[054/00049] train_loss: 0.029736 kl_loss: 0.000000 normal_loss: 0.029736\n",
      "[055/00074] train_loss: 0.030456 kl_loss: 0.000000 normal_loss: 0.030456\n",
      "[057/00024] train_loss: 0.029372 kl_loss: 0.000000 normal_loss: 0.029372\n",
      "[058/00049] train_loss: 0.028534 kl_loss: 0.000000 normal_loss: 0.028534\n",
      "[059/00074] train_loss: 0.027996 kl_loss: 0.000000 normal_loss: 0.027996\n",
      "[061/00024] train_loss: 0.027135 kl_loss: 0.000000 normal_loss: 0.027135\n",
      "[062/00049] train_loss: 0.027203 kl_loss: 0.000000 normal_loss: 0.027203\n",
      "[063/00074] train_loss: 0.026554 kl_loss: 0.000000 normal_loss: 0.026554\n",
      "[065/00024] train_loss: 0.026542 kl_loss: 0.000000 normal_loss: 0.026542\n",
      "[066/00049] train_loss: 0.025803 kl_loss: 0.000000 normal_loss: 0.025803\n",
      "[067/00074] train_loss: 0.025319 kl_loss: 0.000000 normal_loss: 0.025319\n",
      "[069/00024] train_loss: 0.025430 kl_loss: 0.000000 normal_loss: 0.025430\n",
      "[070/00049] train_loss: 0.024336 kl_loss: 0.000000 normal_loss: 0.024336\n",
      "[071/00074] train_loss: 0.024208 kl_loss: 0.000000 normal_loss: 0.024208\n",
      "[073/00024] train_loss: 0.023858 kl_loss: 0.000000 normal_loss: 0.023858\n",
      "[074/00049] train_loss: 0.023339 kl_loss: 0.000000 normal_loss: 0.023339\n",
      "[075/00074] train_loss: 0.023397 kl_loss: 0.000000 normal_loss: 0.023397\n",
      "[077/00024] train_loss: 0.022137 kl_loss: 0.000000 normal_loss: 0.022137\n",
      "[078/00049] train_loss: 0.023627 kl_loss: 0.000000 normal_loss: 0.023627\n",
      "[079/00074] train_loss: 0.022821 kl_loss: 0.000000 normal_loss: 0.022821\n",
      "[081/00024] train_loss: 0.021747 kl_loss: 0.000000 normal_loss: 0.021747\n",
      "[082/00049] train_loss: 0.021771 kl_loss: 0.000000 normal_loss: 0.021771\n",
      "[083/00074] train_loss: 0.021447 kl_loss: 0.000000 normal_loss: 0.021447\n",
      "[085/00024] train_loss: 0.021570 kl_loss: 0.000000 normal_loss: 0.021570\n",
      "[086/00049] train_loss: 0.023595 kl_loss: 0.000000 normal_loss: 0.023595\n",
      "[087/00074] train_loss: 0.021081 kl_loss: 0.000000 normal_loss: 0.021081\n",
      "[089/00024] train_loss: 0.021024 kl_loss: 0.000000 normal_loss: 0.021024\n",
      "[090/00049] train_loss: 0.020293 kl_loss: 0.000000 normal_loss: 0.020293\n",
      "[091/00074] train_loss: 0.020695 kl_loss: 0.000000 normal_loss: 0.020695\n",
      "[093/00024] train_loss: 0.020079 kl_loss: 0.000000 normal_loss: 0.020079\n",
      "[094/00049] train_loss: 0.019900 kl_loss: 0.000000 normal_loss: 0.019900\n",
      "[095/00074] train_loss: 0.019607 kl_loss: 0.000000 normal_loss: 0.019607\n",
      "[097/00024] train_loss: 0.019325 kl_loss: 0.000000 normal_loss: 0.019325\n",
      "[098/00049] train_loss: 0.019085 kl_loss: 0.000000 normal_loss: 0.019085\n",
      "[099/00074] train_loss: 0.019873 kl_loss: 0.000000 normal_loss: 0.019873\n",
      "[099/00074] IOU 0.8655713971207539\n",
      "[101/00024] train_loss: 0.016658 kl_loss: 0.000000 normal_loss: 0.016658\n",
      "[102/00049] train_loss: 0.015480 kl_loss: 0.000000 normal_loss: 0.015480\n",
      "[103/00074] train_loss: 0.014648 kl_loss: 0.000000 normal_loss: 0.014648\n",
      "[105/00024] train_loss: 0.014769 kl_loss: 0.000000 normal_loss: 0.014769\n",
      "[106/00049] train_loss: 0.016084 kl_loss: 0.000000 normal_loss: 0.016084\n",
      "[107/00074] train_loss: 0.014534 kl_loss: 0.000000 normal_loss: 0.014534\n",
      "[109/00024] train_loss: 0.014817 kl_loss: 0.000000 normal_loss: 0.014817\n",
      "[110/00049] train_loss: 0.014652 kl_loss: 0.000000 normal_loss: 0.014652\n",
      "[111/00074] train_loss: 0.014367 kl_loss: 0.000000 normal_loss: 0.014367\n",
      "[113/00024] train_loss: 0.014340 kl_loss: 0.000000 normal_loss: 0.014340\n",
      "[114/00049] train_loss: 0.015159 kl_loss: 0.000000 normal_loss: 0.015159\n",
      "[115/00074] train_loss: 0.014448 kl_loss: 0.000000 normal_loss: 0.014448\n",
      "[117/00024] train_loss: 0.014429 kl_loss: 0.000000 normal_loss: 0.014429\n",
      "[118/00049] train_loss: 0.014190 kl_loss: 0.000000 normal_loss: 0.014190\n",
      "[119/00074] train_loss: 0.014278 kl_loss: 0.000000 normal_loss: 0.014278\n",
      "[121/00024] train_loss: 0.014228 kl_loss: 0.000000 normal_loss: 0.014228\n",
      "[122/00049] train_loss: 0.014223 kl_loss: 0.000000 normal_loss: 0.014223\n",
      "[123/00074] train_loss: 0.013981 kl_loss: 0.000000 normal_loss: 0.013981\n",
      "[125/00024] train_loss: 0.013909 kl_loss: 0.000000 normal_loss: 0.013909\n",
      "[126/00049] train_loss: 0.014281 kl_loss: 0.000000 normal_loss: 0.014281\n",
      "[127/00074] train_loss: 0.013830 kl_loss: 0.000000 normal_loss: 0.013830\n",
      "[129/00024] train_loss: 0.014006 kl_loss: 0.000000 normal_loss: 0.014006\n",
      "[130/00049] train_loss: 0.014121 kl_loss: 0.000000 normal_loss: 0.014121\n",
      "[131/00074] train_loss: 0.013807 kl_loss: 0.000000 normal_loss: 0.013807\n",
      "[133/00024] train_loss: 0.013787 kl_loss: 0.000000 normal_loss: 0.013787\n",
      "[134/00049] train_loss: 0.013484 kl_loss: 0.000000 normal_loss: 0.013484\n",
      "[135/00074] train_loss: 0.013499 kl_loss: 0.000000 normal_loss: 0.013499\n",
      "[137/00024] train_loss: 0.013692 kl_loss: 0.000000 normal_loss: 0.013692\n",
      "[138/00049] train_loss: 0.013088 kl_loss: 0.000000 normal_loss: 0.013088\n",
      "[139/00074] train_loss: 0.013704 kl_loss: 0.000000 normal_loss: 0.013704\n",
      "[141/00024] train_loss: 0.013468 kl_loss: 0.000000 normal_loss: 0.013468\n",
      "[142/00049] train_loss: 0.013239 kl_loss: 0.000000 normal_loss: 0.013239\n",
      "[143/00074] train_loss: 0.013199 kl_loss: 0.000000 normal_loss: 0.013199\n",
      "[145/00024] train_loss: 0.013233 kl_loss: 0.000000 normal_loss: 0.013233\n",
      "[146/00049] train_loss: 0.013188 kl_loss: 0.000000 normal_loss: 0.013188\n",
      "[147/00074] train_loss: 0.013026 kl_loss: 0.000000 normal_loss: 0.013026\n",
      "[149/00024] train_loss: 0.013072 kl_loss: 0.000000 normal_loss: 0.013072\n",
      "[149/00074] IOU 0.8918958876344065\n",
      "[150/00049] train_loss: 0.012995 kl_loss: 0.000000 normal_loss: 0.012995\n",
      "[151/00074] train_loss: 0.012918 kl_loss: 0.000000 normal_loss: 0.012918\n",
      "[153/00024] train_loss: 0.013256 kl_loss: 0.000000 normal_loss: 0.013256\n",
      "[154/00049] train_loss: 0.012769 kl_loss: 0.000000 normal_loss: 0.012769\n",
      "[155/00074] train_loss: 0.012903 kl_loss: 0.000000 normal_loss: 0.012903\n",
      "[157/00024] train_loss: 0.012863 kl_loss: 0.000000 normal_loss: 0.012863\n",
      "[158/00049] train_loss: 0.012738 kl_loss: 0.000000 normal_loss: 0.012738\n",
      "[159/00074] train_loss: 0.013069 kl_loss: 0.000000 normal_loss: 0.013069\n",
      "[161/00024] train_loss: 0.012759 kl_loss: 0.000000 normal_loss: 0.012759\n",
      "[162/00049] train_loss: 0.012512 kl_loss: 0.000000 normal_loss: 0.012512\n",
      "[163/00074] train_loss: 0.012702 kl_loss: 0.000000 normal_loss: 0.012702\n",
      "[165/00024] train_loss: 0.012281 kl_loss: 0.000000 normal_loss: 0.012281\n",
      "[166/00049] train_loss: 0.012643 kl_loss: 0.000000 normal_loss: 0.012643\n",
      "[167/00074] train_loss: 0.012493 kl_loss: 0.000000 normal_loss: 0.012493\n",
      "[169/00024] train_loss: 0.012528 kl_loss: 0.000000 normal_loss: 0.012528\n",
      "[170/00049] train_loss: 0.012374 kl_loss: 0.000000 normal_loss: 0.012374\n",
      "[171/00074] train_loss: 0.012414 kl_loss: 0.000000 normal_loss: 0.012414\n",
      "[173/00024] train_loss: 0.012233 kl_loss: 0.000000 normal_loss: 0.012233\n",
      "[174/00049] train_loss: 0.012403 kl_loss: 0.000000 normal_loss: 0.012403\n",
      "[175/00074] train_loss: 0.012256 kl_loss: 0.000000 normal_loss: 0.012256\n",
      "[177/00024] train_loss: 0.012279 kl_loss: 0.000000 normal_loss: 0.012279\n",
      "[178/00049] train_loss: 0.011979 kl_loss: 0.000000 normal_loss: 0.011979\n",
      "[179/00074] train_loss: 0.011892 kl_loss: 0.000000 normal_loss: 0.011892\n",
      "[181/00024] train_loss: 0.012069 kl_loss: 0.000000 normal_loss: 0.012069\n",
      "[182/00049] train_loss: 0.011950 kl_loss: 0.000000 normal_loss: 0.011950\n",
      "[183/00074] train_loss: 0.012135 kl_loss: 0.000000 normal_loss: 0.012135\n",
      "[185/00024] train_loss: 0.012050 kl_loss: 0.000000 normal_loss: 0.012050\n",
      "[186/00049] train_loss: 0.012243 kl_loss: 0.000000 normal_loss: 0.012243\n",
      "[187/00074] train_loss: 0.012127 kl_loss: 0.000000 normal_loss: 0.012127\n",
      "[189/00024] train_loss: 0.011887 kl_loss: 0.000000 normal_loss: 0.011887\n",
      "[190/00049] train_loss: 0.011886 kl_loss: 0.000000 normal_loss: 0.011886\n",
      "[191/00074] train_loss: 0.011742 kl_loss: 0.000000 normal_loss: 0.011742\n",
      "[193/00024] train_loss: 0.011814 kl_loss: 0.000000 normal_loss: 0.011814\n",
      "[194/00049] train_loss: 0.011699 kl_loss: 0.000000 normal_loss: 0.011699\n",
      "[195/00074] train_loss: 0.011788 kl_loss: 0.000000 normal_loss: 0.011788\n",
      "[197/00024] train_loss: 0.011886 kl_loss: 0.000000 normal_loss: 0.011886\n",
      "[198/00049] train_loss: 0.011643 kl_loss: 0.000000 normal_loss: 0.011643\n",
      "[199/00074] train_loss: 0.011573 kl_loss: 0.000000 normal_loss: 0.011573\n",
      "[199/00074] IOU 0.905182747785002\n",
      "[201/00024] train_loss: 0.010377 kl_loss: 0.000000 normal_loss: 0.010377\n",
      "[202/00049] train_loss: 0.009947 kl_loss: 0.000000 normal_loss: 0.009947\n",
      "[203/00074] train_loss: 0.009725 kl_loss: 0.000000 normal_loss: 0.009725\n",
      "[205/00024] train_loss: 0.009883 kl_loss: 0.000000 normal_loss: 0.009883\n",
      "[206/00049] train_loss: 0.009887 kl_loss: 0.000000 normal_loss: 0.009887\n",
      "[207/00074] train_loss: 0.009953 kl_loss: 0.000000 normal_loss: 0.009953\n",
      "[209/00024] train_loss: 0.009872 kl_loss: 0.000000 normal_loss: 0.009872\n",
      "[210/00049] train_loss: 0.010071 kl_loss: 0.000000 normal_loss: 0.010071\n",
      "[211/00074] train_loss: 0.009833 kl_loss: 0.000000 normal_loss: 0.009833\n",
      "[213/00024] train_loss: 0.009793 kl_loss: 0.000000 normal_loss: 0.009793\n",
      "[214/00049] train_loss: 0.009823 kl_loss: 0.000000 normal_loss: 0.009823\n",
      "[215/00074] train_loss: 0.009684 kl_loss: 0.000000 normal_loss: 0.009684\n",
      "[217/00024] train_loss: 0.009797 kl_loss: 0.000000 normal_loss: 0.009797\n",
      "[218/00049] train_loss: 0.009706 kl_loss: 0.000000 normal_loss: 0.009706\n",
      "[219/00074] train_loss: 0.009859 kl_loss: 0.000000 normal_loss: 0.009859\n",
      "[221/00024] train_loss: 0.009833 kl_loss: 0.000000 normal_loss: 0.009833\n",
      "[222/00049] train_loss: 0.009789 kl_loss: 0.000000 normal_loss: 0.009789\n",
      "[223/00074] train_loss: 0.009782 kl_loss: 0.000000 normal_loss: 0.009782\n",
      "[225/00024] train_loss: 0.009711 kl_loss: 0.000000 normal_loss: 0.009711\n",
      "[226/00049] train_loss: 0.009779 kl_loss: 0.000000 normal_loss: 0.009779\n",
      "[227/00074] train_loss: 0.009647 kl_loss: 0.000000 normal_loss: 0.009647\n",
      "[229/00024] train_loss: 0.009610 kl_loss: 0.000000 normal_loss: 0.009610\n",
      "[230/00049] train_loss: 0.009632 kl_loss: 0.000000 normal_loss: 0.009632\n",
      "[231/00074] train_loss: 0.009604 kl_loss: 0.000000 normal_loss: 0.009604\n",
      "[233/00024] train_loss: 0.009519 kl_loss: 0.000000 normal_loss: 0.009519\n",
      "[234/00049] train_loss: 0.009646 kl_loss: 0.000000 normal_loss: 0.009646\n",
      "[235/00074] train_loss: 0.009728 kl_loss: 0.000000 normal_loss: 0.009728\n",
      "[237/00024] train_loss: 0.009822 kl_loss: 0.000000 normal_loss: 0.009822\n",
      "[238/00049] train_loss: 0.009763 kl_loss: 0.000000 normal_loss: 0.009763\n",
      "[239/00074] train_loss: 0.009536 kl_loss: 0.000000 normal_loss: 0.009536\n",
      "[241/00024] train_loss: 0.009630 kl_loss: 0.000000 normal_loss: 0.009630\n",
      "[242/00049] train_loss: 0.009532 kl_loss: 0.000000 normal_loss: 0.009532\n",
      "[243/00074] train_loss: 0.009560 kl_loss: 0.000000 normal_loss: 0.009560\n",
      "[245/00024] train_loss: 0.009768 kl_loss: 0.000000 normal_loss: 0.009768\n",
      "[246/00049] train_loss: 0.009695 kl_loss: 0.000000 normal_loss: 0.009695\n",
      "[247/00074] train_loss: 0.009559 kl_loss: 0.000000 normal_loss: 0.009559\n",
      "[249/00024] train_loss: 0.009581 kl_loss: 0.000000 normal_loss: 0.009581\n",
      "[249/00074] IOU 0.9117270767937103\n",
      "[250/00049] train_loss: 0.009403 kl_loss: 0.000000 normal_loss: 0.009403\n",
      "[251/00074] train_loss: 0.009483 kl_loss: 0.000000 normal_loss: 0.009483\n",
      "[253/00024] train_loss: 0.009401 kl_loss: 0.000000 normal_loss: 0.009401\n",
      "[254/00049] train_loss: 0.009466 kl_loss: 0.000000 normal_loss: 0.009466\n",
      "[255/00074] train_loss: 0.009541 kl_loss: 0.000000 normal_loss: 0.009541\n",
      "[257/00024] train_loss: 0.009438 kl_loss: 0.000000 normal_loss: 0.009438\n",
      "[258/00049] train_loss: 0.009436 kl_loss: 0.000000 normal_loss: 0.009436\n",
      "[259/00074] train_loss: 0.009550 kl_loss: 0.000000 normal_loss: 0.009550\n",
      "[261/00024] train_loss: 0.009406 kl_loss: 0.000000 normal_loss: 0.009406\n",
      "[262/00049] train_loss: 0.009444 kl_loss: 0.000000 normal_loss: 0.009444\n",
      "[263/00074] train_loss: 0.009470 kl_loss: 0.000000 normal_loss: 0.009470\n",
      "[265/00024] train_loss: 0.009471 kl_loss: 0.000000 normal_loss: 0.009471\n",
      "[266/00049] train_loss: 0.009330 kl_loss: 0.000000 normal_loss: 0.009330\n",
      "[267/00074] train_loss: 0.009408 kl_loss: 0.000000 normal_loss: 0.009408\n",
      "[269/00024] train_loss: 0.009331 kl_loss: 0.000000 normal_loss: 0.009331\n",
      "[270/00049] train_loss: 0.009181 kl_loss: 0.000000 normal_loss: 0.009181\n",
      "[271/00074] train_loss: 0.009260 kl_loss: 0.000000 normal_loss: 0.009260\n",
      "[273/00024] train_loss: 0.009280 kl_loss: 0.000000 normal_loss: 0.009280\n",
      "[274/00049] train_loss: 0.009348 kl_loss: 0.000000 normal_loss: 0.009348\n",
      "[275/00074] train_loss: 0.009229 kl_loss: 0.000000 normal_loss: 0.009229\n",
      "[277/00024] train_loss: 0.009139 kl_loss: 0.000000 normal_loss: 0.009139\n",
      "[278/00049] train_loss: 0.009318 kl_loss: 0.000000 normal_loss: 0.009318\n",
      "[279/00074] train_loss: 0.009370 kl_loss: 0.000000 normal_loss: 0.009370\n",
      "[281/00024] train_loss: 0.009266 kl_loss: 0.000000 normal_loss: 0.009266\n",
      "[282/00049] train_loss: 0.009135 kl_loss: 0.000000 normal_loss: 0.009135\n",
      "[283/00074] train_loss: 0.009251 kl_loss: 0.000000 normal_loss: 0.009251\n",
      "[285/00024] train_loss: 0.009162 kl_loss: 0.000000 normal_loss: 0.009162\n",
      "[286/00049] train_loss: 0.009173 kl_loss: 0.000000 normal_loss: 0.009173\n",
      "[287/00074] train_loss: 0.009311 kl_loss: 0.000000 normal_loss: 0.009311\n",
      "[289/00024] train_loss: 0.009150 kl_loss: 0.000000 normal_loss: 0.009150\n",
      "[290/00049] train_loss: 0.009117 kl_loss: 0.000000 normal_loss: 0.009117\n",
      "[291/00074] train_loss: 0.009457 kl_loss: 0.000000 normal_loss: 0.009457\n",
      "[293/00024] train_loss: 0.009151 kl_loss: 0.000000 normal_loss: 0.009151\n",
      "[294/00049] train_loss: 0.009170 kl_loss: 0.000000 normal_loss: 0.009170\n",
      "[295/00074] train_loss: 0.009162 kl_loss: 0.000000 normal_loss: 0.009162\n",
      "[297/00024] train_loss: 0.009070 kl_loss: 0.000000 normal_loss: 0.009070\n",
      "[298/00049] train_loss: 0.009079 kl_loss: 0.000000 normal_loss: 0.009079\n",
      "[299/00074] train_loss: 0.009035 kl_loss: 0.000000 normal_loss: 0.009035\n",
      "[299/00074] IOU 0.918188418423136\n",
      "[301/00024] train_loss: 0.008645 kl_loss: 0.000000 normal_loss: 0.008645\n",
      "[302/00049] train_loss: 0.008626 kl_loss: 0.000000 normal_loss: 0.008626\n",
      "[303/00074] train_loss: 0.008374 kl_loss: 0.000000 normal_loss: 0.008374\n",
      "[305/00024] train_loss: 0.008354 kl_loss: 0.000000 normal_loss: 0.008354\n",
      "[306/00049] train_loss: 0.008309 kl_loss: 0.000000 normal_loss: 0.008309\n",
      "[307/00074] train_loss: 0.008409 kl_loss: 0.000000 normal_loss: 0.008409\n",
      "[309/00024] train_loss: 0.008408 kl_loss: 0.000000 normal_loss: 0.008408\n",
      "[310/00049] train_loss: 0.008270 kl_loss: 0.000000 normal_loss: 0.008270\n",
      "[311/00074] train_loss: 0.008391 kl_loss: 0.000000 normal_loss: 0.008391\n",
      "[313/00024] train_loss: 0.008340 kl_loss: 0.000000 normal_loss: 0.008340\n",
      "[314/00049] train_loss: 0.008402 kl_loss: 0.000000 normal_loss: 0.008402\n",
      "[315/00074] train_loss: 0.008339 kl_loss: 0.000000 normal_loss: 0.008339\n",
      "[317/00024] train_loss: 0.008278 kl_loss: 0.000000 normal_loss: 0.008278\n",
      "[318/00049] train_loss: 0.008322 kl_loss: 0.000000 normal_loss: 0.008322\n",
      "[319/00074] train_loss: 0.008336 kl_loss: 0.000000 normal_loss: 0.008336\n",
      "[321/00024] train_loss: 0.008316 kl_loss: 0.000000 normal_loss: 0.008316\n",
      "[322/00049] train_loss: 0.008351 kl_loss: 0.000000 normal_loss: 0.008351\n",
      "[323/00074] train_loss: 0.008341 kl_loss: 0.000000 normal_loss: 0.008341\n",
      "[325/00024] train_loss: 0.008288 kl_loss: 0.000000 normal_loss: 0.008288\n",
      "[326/00049] train_loss: 0.008339 kl_loss: 0.000000 normal_loss: 0.008339\n",
      "[327/00074] train_loss: 0.008353 kl_loss: 0.000000 normal_loss: 0.008353\n",
      "[329/00024] train_loss: 0.008343 kl_loss: 0.000000 normal_loss: 0.008343\n",
      "[330/00049] train_loss: 0.008359 kl_loss: 0.000000 normal_loss: 0.008359\n",
      "[331/00074] train_loss: 0.008310 kl_loss: 0.000000 normal_loss: 0.008310\n",
      "[333/00024] train_loss: 0.008287 kl_loss: 0.000000 normal_loss: 0.008287\n",
      "[334/00049] train_loss: 0.008249 kl_loss: 0.000000 normal_loss: 0.008249\n",
      "[335/00074] train_loss: 0.008330 kl_loss: 0.000000 normal_loss: 0.008330\n",
      "[337/00024] train_loss: 0.008247 kl_loss: 0.000000 normal_loss: 0.008247\n",
      "[338/00049] train_loss: 0.008313 kl_loss: 0.000000 normal_loss: 0.008313\n",
      "[339/00074] train_loss: 0.008270 kl_loss: 0.000000 normal_loss: 0.008270\n",
      "[341/00024] train_loss: 0.008267 kl_loss: 0.000000 normal_loss: 0.008267\n",
      "[342/00049] train_loss: 0.008220 kl_loss: 0.000000 normal_loss: 0.008220\n",
      "[343/00074] train_loss: 0.008186 kl_loss: 0.000000 normal_loss: 0.008186\n",
      "[345/00024] train_loss: 0.008237 kl_loss: 0.000000 normal_loss: 0.008237\n",
      "[346/00049] train_loss: 0.008186 kl_loss: 0.000000 normal_loss: 0.008186\n",
      "[347/00074] train_loss: 0.008210 kl_loss: 0.000000 normal_loss: 0.008210\n",
      "[349/00024] train_loss: 0.008151 kl_loss: 0.000000 normal_loss: 0.008151\n",
      "[349/00074] IOU 0.9216015450966855\n",
      "[350/00049] train_loss: 0.008175 kl_loss: 0.000000 normal_loss: 0.008175\n",
      "[351/00074] train_loss: 0.008192 kl_loss: 0.000000 normal_loss: 0.008192\n",
      "[353/00024] train_loss: 0.008168 kl_loss: 0.000000 normal_loss: 0.008168\n",
      "[354/00049] train_loss: 0.008103 kl_loss: 0.000000 normal_loss: 0.008103\n",
      "[355/00074] train_loss: 0.008230 kl_loss: 0.000000 normal_loss: 0.008230\n",
      "[357/00024] train_loss: 0.008196 kl_loss: 0.000000 normal_loss: 0.008196\n",
      "[358/00049] train_loss: 0.008185 kl_loss: 0.000000 normal_loss: 0.008185\n",
      "[359/00074] train_loss: 0.008179 kl_loss: 0.000000 normal_loss: 0.008179\n",
      "[361/00024] train_loss: 0.008169 kl_loss: 0.000000 normal_loss: 0.008169\n",
      "[362/00049] train_loss: 0.008159 kl_loss: 0.000000 normal_loss: 0.008159\n",
      "[363/00074] train_loss: 0.008145 kl_loss: 0.000000 normal_loss: 0.008145\n",
      "[365/00024] train_loss: 0.008176 kl_loss: 0.000000 normal_loss: 0.008176\n",
      "[366/00049] train_loss: 0.008138 kl_loss: 0.000000 normal_loss: 0.008138\n",
      "[367/00074] train_loss: 0.008125 kl_loss: 0.000000 normal_loss: 0.008125\n",
      "[369/00024] train_loss: 0.008222 kl_loss: 0.000000 normal_loss: 0.008222\n",
      "[370/00049] train_loss: 0.008111 kl_loss: 0.000000 normal_loss: 0.008111\n",
      "[371/00074] train_loss: 0.008109 kl_loss: 0.000000 normal_loss: 0.008109\n",
      "[373/00024] train_loss: 0.008090 kl_loss: 0.000000 normal_loss: 0.008090\n",
      "[374/00049] train_loss: 0.008116 kl_loss: 0.000000 normal_loss: 0.008116\n",
      "[375/00074] train_loss: 0.008121 kl_loss: 0.000000 normal_loss: 0.008121\n",
      "[377/00024] train_loss: 0.008143 kl_loss: 0.000000 normal_loss: 0.008143\n",
      "[378/00049] train_loss: 0.008087 kl_loss: 0.000000 normal_loss: 0.008087\n",
      "[379/00074] train_loss: 0.008109 kl_loss: 0.000000 normal_loss: 0.008109\n",
      "[381/00024] train_loss: 0.008032 kl_loss: 0.000000 normal_loss: 0.008032\n",
      "[382/00049] train_loss: 0.008130 kl_loss: 0.000000 normal_loss: 0.008130\n",
      "[383/00074] train_loss: 0.008082 kl_loss: 0.000000 normal_loss: 0.008082\n",
      "[385/00024] train_loss: 0.008399 kl_loss: 0.000000 normal_loss: 0.008399\n",
      "[386/00049] train_loss: 0.008161 kl_loss: 0.000000 normal_loss: 0.008161\n",
      "[387/00074] train_loss: 0.008120 kl_loss: 0.000000 normal_loss: 0.008120\n",
      "[389/00024] train_loss: 0.007964 kl_loss: 0.000000 normal_loss: 0.007964\n",
      "[390/00049] train_loss: 0.008060 kl_loss: 0.000000 normal_loss: 0.008060\n",
      "[391/00074] train_loss: 0.008054 kl_loss: 0.000000 normal_loss: 0.008054\n",
      "[393/00024] train_loss: 0.008057 kl_loss: 0.000000 normal_loss: 0.008057\n",
      "[394/00049] train_loss: 0.007999 kl_loss: 0.000000 normal_loss: 0.007999\n",
      "[395/00074] train_loss: 0.008074 kl_loss: 0.000000 normal_loss: 0.008074\n",
      "[397/00024] train_loss: 0.007996 kl_loss: 0.000000 normal_loss: 0.007996\n",
      "[398/00049] train_loss: 0.007980 kl_loss: 0.000000 normal_loss: 0.007980\n",
      "[399/00074] train_loss: 0.007986 kl_loss: 0.000000 normal_loss: 0.007986\n",
      "[399/00074] IOU 0.9229857251731058\n",
      "[401/00024] train_loss: 0.007774 kl_loss: 0.000000 normal_loss: 0.007774\n",
      "[402/00049] train_loss: 0.007787 kl_loss: 0.000000 normal_loss: 0.007787\n",
      "[403/00074] train_loss: 0.007738 kl_loss: 0.000000 normal_loss: 0.007738\n",
      "[405/00024] train_loss: 0.007694 kl_loss: 0.000000 normal_loss: 0.007694\n",
      "[406/00049] train_loss: 0.007777 kl_loss: 0.000000 normal_loss: 0.007777\n",
      "[407/00074] train_loss: 0.007658 kl_loss: 0.000000 normal_loss: 0.007658\n",
      "[409/00024] train_loss: 0.007714 kl_loss: 0.000000 normal_loss: 0.007714\n",
      "[410/00049] train_loss: 0.007657 kl_loss: 0.000000 normal_loss: 0.007657\n",
      "[411/00074] train_loss: 0.007752 kl_loss: 0.000000 normal_loss: 0.007752\n",
      "[413/00024] train_loss: 0.007709 kl_loss: 0.000000 normal_loss: 0.007709\n",
      "[414/00049] train_loss: 0.007831 kl_loss: 0.000000 normal_loss: 0.007831\n",
      "[415/00074] train_loss: 0.007738 kl_loss: 0.000000 normal_loss: 0.007738\n",
      "[417/00024] train_loss: 0.007736 kl_loss: 0.000000 normal_loss: 0.007736\n",
      "[418/00049] train_loss: 0.007679 kl_loss: 0.000000 normal_loss: 0.007679\n",
      "[419/00074] train_loss: 0.007703 kl_loss: 0.000000 normal_loss: 0.007703\n",
      "[421/00024] train_loss: 0.007694 kl_loss: 0.000000 normal_loss: 0.007694\n",
      "[422/00049] train_loss: 0.007706 kl_loss: 0.000000 normal_loss: 0.007706\n",
      "[423/00074] train_loss: 0.007672 kl_loss: 0.000000 normal_loss: 0.007672\n",
      "[425/00024] train_loss: 0.007741 kl_loss: 0.000000 normal_loss: 0.007741\n",
      "[426/00049] train_loss: 0.007712 kl_loss: 0.000000 normal_loss: 0.007712\n",
      "[427/00074] train_loss: 0.007709 kl_loss: 0.000000 normal_loss: 0.007709\n",
      "[429/00024] train_loss: 0.007665 kl_loss: 0.000000 normal_loss: 0.007665\n",
      "[430/00049] train_loss: 0.007666 kl_loss: 0.000000 normal_loss: 0.007666\n",
      "[431/00074] train_loss: 0.007667 kl_loss: 0.000000 normal_loss: 0.007667\n",
      "[433/00024] train_loss: 0.007704 kl_loss: 0.000000 normal_loss: 0.007704\n",
      "[434/00049] train_loss: 0.007652 kl_loss: 0.000000 normal_loss: 0.007652\n",
      "[435/00074] train_loss: 0.007652 kl_loss: 0.000000 normal_loss: 0.007652\n",
      "[437/00024] train_loss: 0.007715 kl_loss: 0.000000 normal_loss: 0.007715\n",
      "[438/00049] train_loss: 0.007689 kl_loss: 0.000000 normal_loss: 0.007689\n",
      "[439/00074] train_loss: 0.007709 kl_loss: 0.000000 normal_loss: 0.007709\n",
      "[441/00024] train_loss: 0.007662 kl_loss: 0.000000 normal_loss: 0.007662\n",
      "[442/00049] train_loss: 0.007702 kl_loss: 0.000000 normal_loss: 0.007702\n",
      "[443/00074] train_loss: 0.007661 kl_loss: 0.000000 normal_loss: 0.007661\n",
      "[445/00024] train_loss: 0.007714 kl_loss: 0.000000 normal_loss: 0.007714\n",
      "[446/00049] train_loss: 0.007593 kl_loss: 0.000000 normal_loss: 0.007593\n",
      "[447/00074] train_loss: 0.007666 kl_loss: 0.000000 normal_loss: 0.007666\n",
      "[449/00024] train_loss: 0.007611 kl_loss: 0.000000 normal_loss: 0.007611\n",
      "[449/00074] IOU 0.9239503654030462\n",
      "[450/00049] train_loss: 0.007604 kl_loss: 0.000000 normal_loss: 0.007604\n",
      "[451/00074] train_loss: 0.007650 kl_loss: 0.000000 normal_loss: 0.007650\n",
      "[453/00024] train_loss: 0.007750 kl_loss: 0.000000 normal_loss: 0.007750\n",
      "[454/00049] train_loss: 0.007654 kl_loss: 0.000000 normal_loss: 0.007654\n",
      "[455/00074] train_loss: 0.007612 kl_loss: 0.000000 normal_loss: 0.007612\n",
      "[457/00024] train_loss: 0.007651 kl_loss: 0.000000 normal_loss: 0.007651\n",
      "[458/00049] train_loss: 0.007642 kl_loss: 0.000000 normal_loss: 0.007642\n",
      "[459/00074] train_loss: 0.007595 kl_loss: 0.000000 normal_loss: 0.007595\n",
      "[461/00024] train_loss: 0.007605 kl_loss: 0.000000 normal_loss: 0.007605\n",
      "[462/00049] train_loss: 0.007568 kl_loss: 0.000000 normal_loss: 0.007568\n",
      "[463/00074] train_loss: 0.007596 kl_loss: 0.000000 normal_loss: 0.007596\n",
      "[465/00024] train_loss: 0.007601 kl_loss: 0.000000 normal_loss: 0.007601\n",
      "[466/00049] train_loss: 0.007634 kl_loss: 0.000000 normal_loss: 0.007634\n",
      "[467/00074] train_loss: 0.007598 kl_loss: 0.000000 normal_loss: 0.007598\n",
      "[469/00024] train_loss: 0.007605 kl_loss: 0.000000 normal_loss: 0.007605\n",
      "[470/00049] train_loss: 0.007650 kl_loss: 0.000000 normal_loss: 0.007650\n",
      "[471/00074] train_loss: 0.007589 kl_loss: 0.000000 normal_loss: 0.007589\n",
      "[473/00024] train_loss: 0.007680 kl_loss: 0.000000 normal_loss: 0.007680\n",
      "[474/00049] train_loss: 0.007506 kl_loss: 0.000000 normal_loss: 0.007506\n",
      "[475/00074] train_loss: 0.007719 kl_loss: 0.000000 normal_loss: 0.007719\n",
      "[477/00024] train_loss: 0.007574 kl_loss: 0.000000 normal_loss: 0.007574\n",
      "[478/00049] train_loss: 0.007602 kl_loss: 0.000000 normal_loss: 0.007602\n",
      "[479/00074] train_loss: 0.007552 kl_loss: 0.000000 normal_loss: 0.007552\n",
      "[481/00024] train_loss: 0.007595 kl_loss: 0.000000 normal_loss: 0.007595\n",
      "[482/00049] train_loss: 0.007643 kl_loss: 0.000000 normal_loss: 0.007643\n",
      "[483/00074] train_loss: 0.007583 kl_loss: 0.000000 normal_loss: 0.007583\n",
      "[485/00024] train_loss: 0.007576 kl_loss: 0.000000 normal_loss: 0.007576\n",
      "[486/00049] train_loss: 0.007607 kl_loss: 0.000000 normal_loss: 0.007607\n",
      "[487/00074] train_loss: 0.007605 kl_loss: 0.000000 normal_loss: 0.007605\n",
      "[489/00024] train_loss: 0.007563 kl_loss: 0.000000 normal_loss: 0.007563\n",
      "[490/00049] train_loss: 0.007519 kl_loss: 0.000000 normal_loss: 0.007519\n",
      "[491/00074] train_loss: 0.007551 kl_loss: 0.000000 normal_loss: 0.007551\n",
      "[493/00024] train_loss: 0.007536 kl_loss: 0.000000 normal_loss: 0.007536\n",
      "[494/00049] train_loss: 0.007555 kl_loss: 0.000000 normal_loss: 0.007555\n",
      "[495/00074] train_loss: 0.007599 kl_loss: 0.000000 normal_loss: 0.007599\n",
      "[497/00024] train_loss: 0.007508 kl_loss: 0.000000 normal_loss: 0.007508\n",
      "[498/00049] train_loss: 0.007557 kl_loss: 0.000000 normal_loss: 0.007557\n",
      "[499/00074] train_loss: 0.007536 kl_loss: 0.000000 normal_loss: 0.007536\n",
      "[499/00074] IOU 0.9246742397360503\n",
      "[501/00024] train_loss: 0.007434 kl_loss: 0.000000 normal_loss: 0.007434\n",
      "[502/00049] train_loss: 0.007427 kl_loss: 0.000000 normal_loss: 0.007427\n",
      "[503/00074] train_loss: 0.007451 kl_loss: 0.000000 normal_loss: 0.007451\n",
      "[505/00024] train_loss: 0.007393 kl_loss: 0.000000 normal_loss: 0.007393\n",
      "[506/00049] train_loss: 0.007461 kl_loss: 0.000000 normal_loss: 0.007461\n",
      "[507/00074] train_loss: 0.007396 kl_loss: 0.000000 normal_loss: 0.007396\n",
      "[509/00024] train_loss: 0.007435 kl_loss: 0.000000 normal_loss: 0.007435\n",
      "[510/00049] train_loss: 0.007399 kl_loss: 0.000000 normal_loss: 0.007399\n",
      "[511/00074] train_loss: 0.007397 kl_loss: 0.000000 normal_loss: 0.007397\n",
      "[513/00024] train_loss: 0.007392 kl_loss: 0.000000 normal_loss: 0.007392\n",
      "[514/00049] train_loss: 0.007383 kl_loss: 0.000000 normal_loss: 0.007383\n",
      "[515/00074] train_loss: 0.007414 kl_loss: 0.000000 normal_loss: 0.007414\n",
      "[517/00024] train_loss: 0.007451 kl_loss: 0.000000 normal_loss: 0.007451\n",
      "[518/00049] train_loss: 0.007426 kl_loss: 0.000000 normal_loss: 0.007426\n",
      "[519/00074] train_loss: 0.007383 kl_loss: 0.000000 normal_loss: 0.007383\n",
      "[521/00024] train_loss: 0.007374 kl_loss: 0.000000 normal_loss: 0.007374\n",
      "[522/00049] train_loss: 0.007368 kl_loss: 0.000000 normal_loss: 0.007368\n",
      "[523/00074] train_loss: 0.007395 kl_loss: 0.000000 normal_loss: 0.007395\n",
      "[525/00024] train_loss: 0.007411 kl_loss: 0.000000 normal_loss: 0.007411\n",
      "[526/00049] train_loss: 0.007370 kl_loss: 0.000000 normal_loss: 0.007370\n",
      "[527/00074] train_loss: 0.007391 kl_loss: 0.000000 normal_loss: 0.007391\n",
      "[529/00024] train_loss: 0.007445 kl_loss: 0.000000 normal_loss: 0.007445\n",
      "[530/00049] train_loss: 0.007336 kl_loss: 0.000000 normal_loss: 0.007336\n",
      "[531/00074] train_loss: 0.007395 kl_loss: 0.000000 normal_loss: 0.007395\n",
      "[533/00024] train_loss: 0.007419 kl_loss: 0.000000 normal_loss: 0.007419\n",
      "[534/00049] train_loss: 0.007384 kl_loss: 0.000000 normal_loss: 0.007384\n",
      "[535/00074] train_loss: 0.007372 kl_loss: 0.000000 normal_loss: 0.007372\n",
      "[537/00024] train_loss: 0.007379 kl_loss: 0.000000 normal_loss: 0.007379\n",
      "[538/00049] train_loss: 0.007354 kl_loss: 0.000000 normal_loss: 0.007354\n",
      "[539/00074] train_loss: 0.007384 kl_loss: 0.000000 normal_loss: 0.007384\n",
      "[541/00024] train_loss: 0.007398 kl_loss: 0.000000 normal_loss: 0.007398\n",
      "[542/00049] train_loss: 0.007352 kl_loss: 0.000000 normal_loss: 0.007352\n",
      "[543/00074] train_loss: 0.007407 kl_loss: 0.000000 normal_loss: 0.007407\n",
      "[545/00024] train_loss: 0.007361 kl_loss: 0.000000 normal_loss: 0.007361\n",
      "[546/00049] train_loss: 0.007383 kl_loss: 0.000000 normal_loss: 0.007383\n",
      "[547/00074] train_loss: 0.007347 kl_loss: 0.000000 normal_loss: 0.007347\n",
      "[549/00024] train_loss: 0.007396 kl_loss: 0.000000 normal_loss: 0.007396\n",
      "[549/00074] IOU 0.9263209449810287\n",
      "[550/00049] train_loss: 0.007383 kl_loss: 0.000000 normal_loss: 0.007383\n",
      "[551/00074] train_loss: 0.007368 kl_loss: 0.000000 normal_loss: 0.007368\n",
      "[553/00024] train_loss: 0.007386 kl_loss: 0.000000 normal_loss: 0.007386\n",
      "[554/00049] train_loss: 0.007384 kl_loss: 0.000000 normal_loss: 0.007384\n",
      "[555/00074] train_loss: 0.007351 kl_loss: 0.000000 normal_loss: 0.007351\n",
      "[557/00024] train_loss: 0.007321 kl_loss: 0.000000 normal_loss: 0.007321\n",
      "[558/00049] train_loss: 0.007414 kl_loss: 0.000000 normal_loss: 0.007414\n",
      "[559/00074] train_loss: 0.007342 kl_loss: 0.000000 normal_loss: 0.007342\n",
      "[561/00024] train_loss: 0.007379 kl_loss: 0.000000 normal_loss: 0.007379\n",
      "[562/00049] train_loss: 0.007362 kl_loss: 0.000000 normal_loss: 0.007362\n",
      "[563/00074] train_loss: 0.007373 kl_loss: 0.000000 normal_loss: 0.007373\n",
      "[565/00024] train_loss: 0.007366 kl_loss: 0.000000 normal_loss: 0.007366\n",
      "[566/00049] train_loss: 0.007343 kl_loss: 0.000000 normal_loss: 0.007343\n",
      "[567/00074] train_loss: 0.007324 kl_loss: 0.000000 normal_loss: 0.007324\n",
      "[569/00024] train_loss: 0.007333 kl_loss: 0.000000 normal_loss: 0.007333\n",
      "[570/00049] train_loss: 0.007323 kl_loss: 0.000000 normal_loss: 0.007323\n",
      "[571/00074] train_loss: 0.007354 kl_loss: 0.000000 normal_loss: 0.007354\n",
      "[573/00024] train_loss: 0.007307 kl_loss: 0.000000 normal_loss: 0.007307\n",
      "[574/00049] train_loss: 0.007354 kl_loss: 0.000000 normal_loss: 0.007354\n",
      "[575/00074] train_loss: 0.007339 kl_loss: 0.000000 normal_loss: 0.007339\n",
      "[577/00024] train_loss: 0.007347 kl_loss: 0.000000 normal_loss: 0.007347\n",
      "[578/00049] train_loss: 0.007352 kl_loss: 0.000000 normal_loss: 0.007352\n",
      "[579/00074] train_loss: 0.007356 kl_loss: 0.000000 normal_loss: 0.007356\n",
      "[581/00024] train_loss: 0.007323 kl_loss: 0.000000 normal_loss: 0.007323\n",
      "[582/00049] train_loss: 0.007302 kl_loss: 0.000000 normal_loss: 0.007302\n",
      "[583/00074] train_loss: 0.007347 kl_loss: 0.000000 normal_loss: 0.007347\n",
      "[585/00024] train_loss: 0.007364 kl_loss: 0.000000 normal_loss: 0.007364\n",
      "[586/00049] train_loss: 0.007350 kl_loss: 0.000000 normal_loss: 0.007350\n",
      "[587/00074] train_loss: 0.007331 kl_loss: 0.000000 normal_loss: 0.007331\n",
      "[589/00024] train_loss: 0.007362 kl_loss: 0.000000 normal_loss: 0.007362\n",
      "[590/00049] train_loss: 0.007291 kl_loss: 0.000000 normal_loss: 0.007291\n",
      "[591/00074] train_loss: 0.007343 kl_loss: 0.000000 normal_loss: 0.007343\n",
      "[593/00024] train_loss: 0.007328 kl_loss: 0.000000 normal_loss: 0.007328\n",
      "[594/00049] train_loss: 0.007301 kl_loss: 0.000000 normal_loss: 0.007301\n",
      "[595/00074] train_loss: 0.007308 kl_loss: 0.000000 normal_loss: 0.007308\n",
      "[597/00024] train_loss: 0.007264 kl_loss: 0.000000 normal_loss: 0.007264\n",
      "[598/00049] train_loss: 0.007352 kl_loss: 0.000000 normal_loss: 0.007352\n",
      "[599/00074] train_loss: 0.007317 kl_loss: 0.000000 normal_loss: 0.007317\n",
      "[599/00074] IOU 0.9263666389447948\n",
      "[601/00024] train_loss: 0.007286 kl_loss: 0.000000 normal_loss: 0.007286\n",
      "[602/00049] train_loss: 0.007254 kl_loss: 0.000000 normal_loss: 0.007254\n",
      "[603/00074] train_loss: 0.007248 kl_loss: 0.000000 normal_loss: 0.007248\n",
      "[605/00024] train_loss: 0.007230 kl_loss: 0.000000 normal_loss: 0.007230\n",
      "[606/00049] train_loss: 0.007265 kl_loss: 0.000000 normal_loss: 0.007265\n",
      "[607/00074] train_loss: 0.007258 kl_loss: 0.000000 normal_loss: 0.007258\n",
      "[609/00024] train_loss: 0.007254 kl_loss: 0.000000 normal_loss: 0.007254\n",
      "[610/00049] train_loss: 0.007280 kl_loss: 0.000000 normal_loss: 0.007280\n",
      "[611/00074] train_loss: 0.007224 kl_loss: 0.000000 normal_loss: 0.007224\n",
      "[613/00024] train_loss: 0.007263 kl_loss: 0.000000 normal_loss: 0.007263\n",
      "[614/00049] train_loss: 0.007219 kl_loss: 0.000000 normal_loss: 0.007219\n",
      "[615/00074] train_loss: 0.007283 kl_loss: 0.000000 normal_loss: 0.007283\n",
      "[617/00024] train_loss: 0.007239 kl_loss: 0.000000 normal_loss: 0.007239\n",
      "[618/00049] train_loss: 0.007256 kl_loss: 0.000000 normal_loss: 0.007256\n",
      "[619/00074] train_loss: 0.007247 kl_loss: 0.000000 normal_loss: 0.007247\n",
      "[621/00024] train_loss: 0.007257 kl_loss: 0.000000 normal_loss: 0.007257\n",
      "[622/00049] train_loss: 0.007282 kl_loss: 0.000000 normal_loss: 0.007282\n",
      "[623/00074] train_loss: 0.007188 kl_loss: 0.000000 normal_loss: 0.007188\n",
      "[625/00024] train_loss: 0.007239 kl_loss: 0.000000 normal_loss: 0.007239\n",
      "[626/00049] train_loss: 0.007256 kl_loss: 0.000000 normal_loss: 0.007256\n",
      "[627/00074] train_loss: 0.007222 kl_loss: 0.000000 normal_loss: 0.007222\n",
      "[629/00024] train_loss: 0.007269 kl_loss: 0.000000 normal_loss: 0.007269\n",
      "[630/00049] train_loss: 0.007226 kl_loss: 0.000000 normal_loss: 0.007226\n",
      "[631/00074] train_loss: 0.007234 kl_loss: 0.000000 normal_loss: 0.007234\n",
      "[633/00024] train_loss: 0.007239 kl_loss: 0.000000 normal_loss: 0.007239\n",
      "[634/00049] train_loss: 0.007219 kl_loss: 0.000000 normal_loss: 0.007219\n",
      "[635/00074] train_loss: 0.007259 kl_loss: 0.000000 normal_loss: 0.007259\n",
      "[637/00024] train_loss: 0.007246 kl_loss: 0.000000 normal_loss: 0.007246\n",
      "[638/00049] train_loss: 0.007253 kl_loss: 0.000000 normal_loss: 0.007253\n",
      "[639/00074] train_loss: 0.007205 kl_loss: 0.000000 normal_loss: 0.007205\n",
      "[641/00024] train_loss: 0.007216 kl_loss: 0.000000 normal_loss: 0.007216\n",
      "[642/00049] train_loss: 0.007246 kl_loss: 0.000000 normal_loss: 0.007246\n",
      "[643/00074] train_loss: 0.007217 kl_loss: 0.000000 normal_loss: 0.007217\n",
      "[645/00024] train_loss: 0.007301 kl_loss: 0.000000 normal_loss: 0.007301\n",
      "[646/00049] train_loss: 0.007160 kl_loss: 0.000000 normal_loss: 0.007160\n",
      "[647/00074] train_loss: 0.007253 kl_loss: 0.000000 normal_loss: 0.007253\n",
      "[649/00024] train_loss: 0.007237 kl_loss: 0.000000 normal_loss: 0.007237\n",
      "[649/00074] IOU 0.9272706339942912\n",
      "[650/00049] train_loss: 0.007217 kl_loss: 0.000000 normal_loss: 0.007217\n",
      "[651/00074] train_loss: 0.007246 kl_loss: 0.000000 normal_loss: 0.007246\n",
      "[653/00024] train_loss: 0.007237 kl_loss: 0.000000 normal_loss: 0.007237\n",
      "[654/00049] train_loss: 0.007201 kl_loss: 0.000000 normal_loss: 0.007201\n",
      "[655/00074] train_loss: 0.007228 kl_loss: 0.000000 normal_loss: 0.007228\n",
      "[657/00024] train_loss: 0.007245 kl_loss: 0.000000 normal_loss: 0.007245\n",
      "[658/00049] train_loss: 0.007193 kl_loss: 0.000000 normal_loss: 0.007193\n",
      "[659/00074] train_loss: 0.007256 kl_loss: 0.000000 normal_loss: 0.007256\n",
      "[661/00024] train_loss: 0.007233 kl_loss: 0.000000 normal_loss: 0.007233\n",
      "[662/00049] train_loss: 0.007232 kl_loss: 0.000000 normal_loss: 0.007232\n",
      "[663/00074] train_loss: 0.007186 kl_loss: 0.000000 normal_loss: 0.007186\n",
      "[665/00024] train_loss: 0.007236 kl_loss: 0.000000 normal_loss: 0.007236\n",
      "[666/00049] train_loss: 0.007266 kl_loss: 0.000000 normal_loss: 0.007266\n",
      "[667/00074] train_loss: 0.007185 kl_loss: 0.000000 normal_loss: 0.007185\n",
      "[669/00024] train_loss: 0.007198 kl_loss: 0.000000 normal_loss: 0.007198\n",
      "[670/00049] train_loss: 0.007224 kl_loss: 0.000000 normal_loss: 0.007224\n",
      "[671/00074] train_loss: 0.007239 kl_loss: 0.000000 normal_loss: 0.007239\n",
      "[673/00024] train_loss: 0.007196 kl_loss: 0.000000 normal_loss: 0.007196\n",
      "[674/00049] train_loss: 0.007254 kl_loss: 0.000000 normal_loss: 0.007254\n",
      "[675/00074] train_loss: 0.007178 kl_loss: 0.000000 normal_loss: 0.007178\n",
      "[677/00024] train_loss: 0.007219 kl_loss: 0.000000 normal_loss: 0.007219\n",
      "[678/00049] train_loss: 0.007209 kl_loss: 0.000000 normal_loss: 0.007209\n",
      "[679/00074] train_loss: 0.007236 kl_loss: 0.000000 normal_loss: 0.007236\n",
      "[681/00024] train_loss: 0.007212 kl_loss: 0.000000 normal_loss: 0.007212\n",
      "[682/00049] train_loss: 0.007176 kl_loss: 0.000000 normal_loss: 0.007176\n",
      "[683/00074] train_loss: 0.007217 kl_loss: 0.000000 normal_loss: 0.007217\n",
      "[685/00024] train_loss: 0.007218 kl_loss: 0.000000 normal_loss: 0.007218\n",
      "[686/00049] train_loss: 0.007216 kl_loss: 0.000000 normal_loss: 0.007216\n",
      "[687/00074] train_loss: 0.007208 kl_loss: 0.000000 normal_loss: 0.007208\n",
      "[689/00024] train_loss: 0.007226 kl_loss: 0.000000 normal_loss: 0.007226\n",
      "[690/00049] train_loss: 0.007194 kl_loss: 0.000000 normal_loss: 0.007194\n",
      "[691/00074] train_loss: 0.007245 kl_loss: 0.000000 normal_loss: 0.007245\n",
      "[693/00024] train_loss: 0.007257 kl_loss: 0.000000 normal_loss: 0.007257\n",
      "[694/00049] train_loss: 0.007140 kl_loss: 0.000000 normal_loss: 0.007140\n",
      "[695/00074] train_loss: 0.007188 kl_loss: 0.000000 normal_loss: 0.007188\n",
      "[697/00024] train_loss: 0.007218 kl_loss: 0.000000 normal_loss: 0.007218\n",
      "[698/00049] train_loss: 0.007209 kl_loss: 0.000000 normal_loss: 0.007209\n",
      "[699/00074] train_loss: 0.007198 kl_loss: 0.000000 normal_loss: 0.007198\n",
      "[699/00074] IOU 0.9275575063253443\n",
      "[701/00024] train_loss: 0.007197 kl_loss: 0.000000 normal_loss: 0.007197\n",
      "[702/00049] train_loss: 0.007110 kl_loss: 0.000000 normal_loss: 0.007110\n",
      "[703/00074] train_loss: 0.007209 kl_loss: 0.000000 normal_loss: 0.007209\n",
      "[705/00024] train_loss: 0.007179 kl_loss: 0.000000 normal_loss: 0.007179\n",
      "[706/00049] train_loss: 0.007147 kl_loss: 0.000000 normal_loss: 0.007147\n",
      "[707/00074] train_loss: 0.007166 kl_loss: 0.000000 normal_loss: 0.007166\n",
      "[709/00024] train_loss: 0.007143 kl_loss: 0.000000 normal_loss: 0.007143\n",
      "[710/00049] train_loss: 0.007157 kl_loss: 0.000000 normal_loss: 0.007157\n",
      "[711/00074] train_loss: 0.007195 kl_loss: 0.000000 normal_loss: 0.007195\n",
      "[713/00024] train_loss: 0.007158 kl_loss: 0.000000 normal_loss: 0.007158\n",
      "[714/00049] train_loss: 0.007186 kl_loss: 0.000000 normal_loss: 0.007186\n",
      "[715/00074] train_loss: 0.007153 kl_loss: 0.000000 normal_loss: 0.007153\n",
      "[717/00024] train_loss: 0.007174 kl_loss: 0.000000 normal_loss: 0.007174\n",
      "[718/00049] train_loss: 0.007123 kl_loss: 0.000000 normal_loss: 0.007123\n",
      "[719/00074] train_loss: 0.007186 kl_loss: 0.000000 normal_loss: 0.007186\n",
      "[721/00024] train_loss: 0.007171 kl_loss: 0.000000 normal_loss: 0.007171\n",
      "[722/00049] train_loss: 0.007155 kl_loss: 0.000000 normal_loss: 0.007155\n",
      "[723/00074] train_loss: 0.007176 kl_loss: 0.000000 normal_loss: 0.007176\n",
      "[725/00024] train_loss: 0.007141 kl_loss: 0.000000 normal_loss: 0.007141\n",
      "[726/00049] train_loss: 0.007173 kl_loss: 0.000000 normal_loss: 0.007173\n",
      "[727/00074] train_loss: 0.007193 kl_loss: 0.000000 normal_loss: 0.007193\n",
      "[729/00024] train_loss: 0.007154 kl_loss: 0.000000 normal_loss: 0.007154\n",
      "[730/00049] train_loss: 0.007188 kl_loss: 0.000000 normal_loss: 0.007188\n",
      "[731/00074] train_loss: 0.007152 kl_loss: 0.000000 normal_loss: 0.007152\n",
      "[733/00024] train_loss: 0.007128 kl_loss: 0.000000 normal_loss: 0.007128\n",
      "[734/00049] train_loss: 0.007203 kl_loss: 0.000000 normal_loss: 0.007203\n",
      "[735/00074] train_loss: 0.007149 kl_loss: 0.000000 normal_loss: 0.007149\n",
      "[737/00024] train_loss: 0.007132 kl_loss: 0.000000 normal_loss: 0.007132\n",
      "[738/00049] train_loss: 0.007196 kl_loss: 0.000000 normal_loss: 0.007196\n",
      "[739/00074] train_loss: 0.007152 kl_loss: 0.000000 normal_loss: 0.007152\n",
      "[741/00024] train_loss: 0.007159 kl_loss: 0.000000 normal_loss: 0.007159\n",
      "[742/00049] train_loss: 0.007177 kl_loss: 0.000000 normal_loss: 0.007177\n",
      "[743/00074] train_loss: 0.007160 kl_loss: 0.000000 normal_loss: 0.007160\n",
      "[745/00024] train_loss: 0.007150 kl_loss: 0.000000 normal_loss: 0.007150\n",
      "[746/00049] train_loss: 0.007154 kl_loss: 0.000000 normal_loss: 0.007154\n",
      "[747/00074] train_loss: 0.007176 kl_loss: 0.000000 normal_loss: 0.007176\n",
      "[749/00024] train_loss: 0.007144 kl_loss: 0.000000 normal_loss: 0.007144\n",
      "[749/00074] IOU 0.9276946818456053\n",
      "[750/00049] train_loss: 0.007147 kl_loss: 0.000000 normal_loss: 0.007147\n",
      "[751/00074] train_loss: 0.007175 kl_loss: 0.000000 normal_loss: 0.007175\n",
      "[753/00024] train_loss: 0.007150 kl_loss: 0.000000 normal_loss: 0.007150\n",
      "[754/00049] train_loss: 0.007184 kl_loss: 0.000000 normal_loss: 0.007184\n",
      "[755/00074] train_loss: 0.007156 kl_loss: 0.000000 normal_loss: 0.007156\n",
      "[757/00024] train_loss: 0.007161 kl_loss: 0.000000 normal_loss: 0.007161\n",
      "[758/00049] train_loss: 0.007139 kl_loss: 0.000000 normal_loss: 0.007139\n",
      "[759/00074] train_loss: 0.007170 kl_loss: 0.000000 normal_loss: 0.007170\n",
      "[761/00024] train_loss: 0.007202 kl_loss: 0.000000 normal_loss: 0.007202\n",
      "[762/00049] train_loss: 0.007122 kl_loss: 0.000000 normal_loss: 0.007122\n",
      "[763/00074] train_loss: 0.007149 kl_loss: 0.000000 normal_loss: 0.007149\n",
      "[765/00024] train_loss: 0.007152 kl_loss: 0.000000 normal_loss: 0.007152\n",
      "[766/00049] train_loss: 0.007146 kl_loss: 0.000000 normal_loss: 0.007146\n",
      "[767/00074] train_loss: 0.007151 kl_loss: 0.000000 normal_loss: 0.007151\n",
      "[769/00024] train_loss: 0.007163 kl_loss: 0.000000 normal_loss: 0.007163\n",
      "[770/00049] train_loss: 0.007175 kl_loss: 0.000000 normal_loss: 0.007175\n",
      "[771/00074] train_loss: 0.007128 kl_loss: 0.000000 normal_loss: 0.007128\n",
      "[773/00024] train_loss: 0.007127 kl_loss: 0.000000 normal_loss: 0.007127\n",
      "[774/00049] train_loss: 0.007169 kl_loss: 0.000000 normal_loss: 0.007169\n",
      "[775/00074] train_loss: 0.007155 kl_loss: 0.000000 normal_loss: 0.007155\n",
      "[777/00024] train_loss: 0.007157 kl_loss: 0.000000 normal_loss: 0.007157\n",
      "[778/00049] train_loss: 0.007163 kl_loss: 0.000000 normal_loss: 0.007163\n",
      "[779/00074] train_loss: 0.007132 kl_loss: 0.000000 normal_loss: 0.007132\n",
      "[781/00024] train_loss: 0.007150 kl_loss: 0.000000 normal_loss: 0.007150\n",
      "[782/00049] train_loss: 0.007141 kl_loss: 0.000000 normal_loss: 0.007141\n",
      "[783/00074] train_loss: 0.007136 kl_loss: 0.000000 normal_loss: 0.007136\n",
      "[785/00024] train_loss: 0.007149 kl_loss: 0.000000 normal_loss: 0.007149\n",
      "[786/00049] train_loss: 0.007129 kl_loss: 0.000000 normal_loss: 0.007129\n",
      "[787/00074] train_loss: 0.007152 kl_loss: 0.000000 normal_loss: 0.007152\n",
      "[789/00024] train_loss: 0.007137 kl_loss: 0.000000 normal_loss: 0.007137\n",
      "[790/00049] train_loss: 0.007197 kl_loss: 0.000000 normal_loss: 0.007197\n",
      "[791/00074] train_loss: 0.007119 kl_loss: 0.000000 normal_loss: 0.007119\n",
      "[793/00024] train_loss: 0.007129 kl_loss: 0.000000 normal_loss: 0.007129\n",
      "[794/00049] train_loss: 0.007191 kl_loss: 0.000000 normal_loss: 0.007191\n",
      "[795/00074] train_loss: 0.007124 kl_loss: 0.000000 normal_loss: 0.007124\n",
      "[797/00024] train_loss: 0.007143 kl_loss: 0.000000 normal_loss: 0.007143\n",
      "[798/00049] train_loss: 0.007144 kl_loss: 0.000000 normal_loss: 0.007144\n",
      "[799/00074] train_loss: 0.007158 kl_loss: 0.000000 normal_loss: 0.007158\n",
      "[799/00074] IOU 0.927694671265781\n",
      "[801/00024] train_loss: 0.007139 kl_loss: 0.000000 normal_loss: 0.007139\n",
      "[802/00049] train_loss: 0.007132 kl_loss: 0.000000 normal_loss: 0.007132\n",
      "[803/00074] train_loss: 0.007102 kl_loss: 0.000000 normal_loss: 0.007102\n",
      "[805/00024] train_loss: 0.007113 kl_loss: 0.000000 normal_loss: 0.007113\n",
      "[806/00049] train_loss: 0.007144 kl_loss: 0.000000 normal_loss: 0.007144\n",
      "[807/00074] train_loss: 0.007125 kl_loss: 0.000000 normal_loss: 0.007125\n",
      "[809/00024] train_loss: 0.007122 kl_loss: 0.000000 normal_loss: 0.007122\n",
      "[810/00049] train_loss: 0.007106 kl_loss: 0.000000 normal_loss: 0.007106\n",
      "[811/00074] train_loss: 0.007134 kl_loss: 0.000000 normal_loss: 0.007134\n",
      "[813/00024] train_loss: 0.007111 kl_loss: 0.000000 normal_loss: 0.007111\n",
      "[814/00049] train_loss: 0.007136 kl_loss: 0.000000 normal_loss: 0.007136\n",
      "[815/00074] train_loss: 0.007112 kl_loss: 0.000000 normal_loss: 0.007112\n",
      "[817/00024] train_loss: 0.007137 kl_loss: 0.000000 normal_loss: 0.007137\n",
      "[818/00049] train_loss: 0.007094 kl_loss: 0.000000 normal_loss: 0.007094\n",
      "[819/00074] train_loss: 0.007149 kl_loss: 0.000000 normal_loss: 0.007149\n",
      "[821/00024] train_loss: 0.007132 kl_loss: 0.000000 normal_loss: 0.007132\n",
      "[822/00049] train_loss: 0.007130 kl_loss: 0.000000 normal_loss: 0.007130\n",
      "[823/00074] train_loss: 0.007136 kl_loss: 0.000000 normal_loss: 0.007136\n",
      "[825/00024] train_loss: 0.007115 kl_loss: 0.000000 normal_loss: 0.007115\n",
      "[826/00049] train_loss: 0.007140 kl_loss: 0.000000 normal_loss: 0.007140\n",
      "[827/00074] train_loss: 0.007091 kl_loss: 0.000000 normal_loss: 0.007091\n",
      "[829/00024] train_loss: 0.007117 kl_loss: 0.000000 normal_loss: 0.007117\n",
      "[830/00049] train_loss: 0.007109 kl_loss: 0.000000 normal_loss: 0.007109\n",
      "[831/00074] train_loss: 0.007138 kl_loss: 0.000000 normal_loss: 0.007138\n",
      "[833/00024] train_loss: 0.007095 kl_loss: 0.000000 normal_loss: 0.007095\n",
      "[834/00049] train_loss: 0.007161 kl_loss: 0.000000 normal_loss: 0.007161\n",
      "[835/00074] train_loss: 0.007124 kl_loss: 0.000000 normal_loss: 0.007124\n",
      "[837/00024] train_loss: 0.007131 kl_loss: 0.000000 normal_loss: 0.007131\n",
      "[838/00049] train_loss: 0.007098 kl_loss: 0.000000 normal_loss: 0.007098\n",
      "[839/00074] train_loss: 0.007124 kl_loss: 0.000000 normal_loss: 0.007124\n",
      "[841/00024] train_loss: 0.007127 kl_loss: 0.000000 normal_loss: 0.007127\n",
      "[842/00049] train_loss: 0.007117 kl_loss: 0.000000 normal_loss: 0.007117\n",
      "[843/00074] train_loss: 0.007112 kl_loss: 0.000000 normal_loss: 0.007112\n",
      "[845/00024] train_loss: 0.007125 kl_loss: 0.000000 normal_loss: 0.007125\n",
      "[846/00049] train_loss: 0.007089 kl_loss: 0.000000 normal_loss: 0.007089\n",
      "[847/00074] train_loss: 0.007136 kl_loss: 0.000000 normal_loss: 0.007136\n",
      "[849/00024] train_loss: 0.007087 kl_loss: 0.000000 normal_loss: 0.007087\n",
      "[849/00074] IOU 0.9279553627471129\n",
      "[850/00049] train_loss: 0.007167 kl_loss: 0.000000 normal_loss: 0.007167\n",
      "[851/00074] train_loss: 0.007110 kl_loss: 0.000000 normal_loss: 0.007110\n",
      "[853/00024] train_loss: 0.007117 kl_loss: 0.000000 normal_loss: 0.007117\n",
      "[854/00049] train_loss: 0.007135 kl_loss: 0.000000 normal_loss: 0.007135\n",
      "[855/00074] train_loss: 0.007108 kl_loss: 0.000000 normal_loss: 0.007108\n",
      "[857/00024] train_loss: 0.007126 kl_loss: 0.000000 normal_loss: 0.007126\n",
      "[858/00049] train_loss: 0.007116 kl_loss: 0.000000 normal_loss: 0.007116\n",
      "[859/00074] train_loss: 0.007101 kl_loss: 0.000000 normal_loss: 0.007101\n",
      "[861/00024] train_loss: 0.007134 kl_loss: 0.000000 normal_loss: 0.007134\n",
      "[862/00049] train_loss: 0.007105 kl_loss: 0.000000 normal_loss: 0.007105\n",
      "[863/00074] train_loss: 0.007096 kl_loss: 0.000000 normal_loss: 0.007096\n",
      "[865/00024] train_loss: 0.007107 kl_loss: 0.000000 normal_loss: 0.007107\n",
      "[866/00049] train_loss: 0.007134 kl_loss: 0.000000 normal_loss: 0.007134\n",
      "[867/00074] train_loss: 0.007116 kl_loss: 0.000000 normal_loss: 0.007116\n",
      "[869/00024] train_loss: 0.007073 kl_loss: 0.000000 normal_loss: 0.007073\n",
      "[870/00049] train_loss: 0.007152 kl_loss: 0.000000 normal_loss: 0.007152\n",
      "[871/00074] train_loss: 0.007114 kl_loss: 0.000000 normal_loss: 0.007114\n",
      "[873/00024] train_loss: 0.007111 kl_loss: 0.000000 normal_loss: 0.007111\n",
      "[874/00049] train_loss: 0.007131 kl_loss: 0.000000 normal_loss: 0.007131\n",
      "[875/00074] train_loss: 0.007132 kl_loss: 0.000000 normal_loss: 0.007132\n",
      "[877/00024] train_loss: 0.007109 kl_loss: 0.000000 normal_loss: 0.007109\n",
      "[878/00049] train_loss: 0.007112 kl_loss: 0.000000 normal_loss: 0.007112\n",
      "[879/00074] train_loss: 0.007132 kl_loss: 0.000000 normal_loss: 0.007132\n",
      "[881/00024] train_loss: 0.007114 kl_loss: 0.000000 normal_loss: 0.007114\n",
      "[882/00049] train_loss: 0.007116 kl_loss: 0.000000 normal_loss: 0.007116\n",
      "[883/00074] train_loss: 0.007122 kl_loss: 0.000000 normal_loss: 0.007122\n",
      "[885/00024] train_loss: 0.007133 kl_loss: 0.000000 normal_loss: 0.007133\n",
      "[886/00049] train_loss: 0.007099 kl_loss: 0.000000 normal_loss: 0.007099\n",
      "[887/00074] train_loss: 0.007109 kl_loss: 0.000000 normal_loss: 0.007109\n",
      "[889/00024] train_loss: 0.007099 kl_loss: 0.000000 normal_loss: 0.007099\n",
      "[890/00049] train_loss: 0.007119 kl_loss: 0.000000 normal_loss: 0.007119\n",
      "[891/00074] train_loss: 0.007108 kl_loss: 0.000000 normal_loss: 0.007108\n",
      "[893/00024] train_loss: 0.007116 kl_loss: 0.000000 normal_loss: 0.007116\n",
      "[894/00049] train_loss: 0.007112 kl_loss: 0.000000 normal_loss: 0.007112\n",
      "[895/00074] train_loss: 0.007110 kl_loss: 0.000000 normal_loss: 0.007110\n",
      "[897/00024] train_loss: 0.007111 kl_loss: 0.000000 normal_loss: 0.007111\n",
      "[898/00049] train_loss: 0.007138 kl_loss: 0.000000 normal_loss: 0.007138\n",
      "[899/00074] train_loss: 0.007094 kl_loss: 0.000000 normal_loss: 0.007094\n",
      "[899/00074] IOU 0.9280677935667336\n",
      "[901/00024] train_loss: 0.007085 kl_loss: 0.000000 normal_loss: 0.007085\n",
      "[902/00049] train_loss: 0.007107 kl_loss: 0.000000 normal_loss: 0.007107\n",
      "[903/00074] train_loss: 0.007112 kl_loss: 0.000000 normal_loss: 0.007112\n",
      "[905/00024] train_loss: 0.007090 kl_loss: 0.000000 normal_loss: 0.007090\n",
      "[906/00049] train_loss: 0.007121 kl_loss: 0.000000 normal_loss: 0.007121\n",
      "[907/00074] train_loss: 0.007096 kl_loss: 0.000000 normal_loss: 0.007096\n",
      "[909/00024] train_loss: 0.007116 kl_loss: 0.000000 normal_loss: 0.007116\n",
      "[910/00049] train_loss: 0.007074 kl_loss: 0.000000 normal_loss: 0.007074\n",
      "[911/00074] train_loss: 0.007118 kl_loss: 0.000000 normal_loss: 0.007118\n",
      "[913/00024] train_loss: 0.007102 kl_loss: 0.000000 normal_loss: 0.007102\n",
      "[914/00049] train_loss: 0.007091 kl_loss: 0.000000 normal_loss: 0.007091\n",
      "[915/00074] train_loss: 0.007105 kl_loss: 0.000000 normal_loss: 0.007105\n",
      "[917/00024] train_loss: 0.007085 kl_loss: 0.000000 normal_loss: 0.007085\n",
      "[918/00049] train_loss: 0.007091 kl_loss: 0.000000 normal_loss: 0.007091\n",
      "[919/00074] train_loss: 0.007129 kl_loss: 0.000000 normal_loss: 0.007129\n",
      "[921/00024] train_loss: 0.007074 kl_loss: 0.000000 normal_loss: 0.007074\n",
      "[922/00049] train_loss: 0.007101 kl_loss: 0.000000 normal_loss: 0.007101\n",
      "[923/00074] train_loss: 0.007127 kl_loss: 0.000000 normal_loss: 0.007127\n",
      "[925/00024] train_loss: 0.007107 kl_loss: 0.000000 normal_loss: 0.007107\n",
      "[926/00049] train_loss: 0.007103 kl_loss: 0.000000 normal_loss: 0.007103\n",
      "[927/00074] train_loss: 0.007088 kl_loss: 0.000000 normal_loss: 0.007088\n",
      "[929/00024] train_loss: 0.007075 kl_loss: 0.000000 normal_loss: 0.007075\n",
      "[930/00049] train_loss: 0.007123 kl_loss: 0.000000 normal_loss: 0.007123\n",
      "[931/00074] train_loss: 0.007108 kl_loss: 0.000000 normal_loss: 0.007108\n",
      "[933/00024] train_loss: 0.007118 kl_loss: 0.000000 normal_loss: 0.007118\n",
      "[934/00049] train_loss: 0.007085 kl_loss: 0.000000 normal_loss: 0.007085\n",
      "[935/00074] train_loss: 0.007096 kl_loss: 0.000000 normal_loss: 0.007096\n",
      "[937/00024] train_loss: 0.007094 kl_loss: 0.000000 normal_loss: 0.007094\n",
      "[938/00049] train_loss: 0.007088 kl_loss: 0.000000 normal_loss: 0.007088\n",
      "[939/00074] train_loss: 0.007106 kl_loss: 0.000000 normal_loss: 0.007106\n",
      "[941/00024] train_loss: 0.007097 kl_loss: 0.000000 normal_loss: 0.007097\n",
      "[942/00049] train_loss: 0.007104 kl_loss: 0.000000 normal_loss: 0.007104\n",
      "[943/00074] train_loss: 0.007086 kl_loss: 0.000000 normal_loss: 0.007086\n",
      "[945/00024] train_loss: 0.007087 kl_loss: 0.000000 normal_loss: 0.007087\n",
      "[946/00049] train_loss: 0.007130 kl_loss: 0.000000 normal_loss: 0.007130\n",
      "[947/00074] train_loss: 0.007092 kl_loss: 0.000000 normal_loss: 0.007092\n",
      "[949/00024] train_loss: 0.007082 kl_loss: 0.000000 normal_loss: 0.007082\n",
      "[949/00074] IOU 0.9280678423928718\n",
      "[950/00049] train_loss: 0.007075 kl_loss: 0.000000 normal_loss: 0.007075\n",
      "[951/00074] train_loss: 0.007134 kl_loss: 0.000000 normal_loss: 0.007134\n",
      "[953/00024] train_loss: 0.007093 kl_loss: 0.000000 normal_loss: 0.007093\n",
      "[954/00049] train_loss: 0.007099 kl_loss: 0.000000 normal_loss: 0.007099\n",
      "[955/00074] train_loss: 0.007108 kl_loss: 0.000000 normal_loss: 0.007108\n",
      "[957/00024] train_loss: 0.007111 kl_loss: 0.000000 normal_loss: 0.007111\n",
      "[958/00049] train_loss: 0.007074 kl_loss: 0.000000 normal_loss: 0.007074\n",
      "[959/00074] train_loss: 0.007098 kl_loss: 0.000000 normal_loss: 0.007098\n",
      "[961/00024] train_loss: 0.007080 kl_loss: 0.000000 normal_loss: 0.007080\n",
      "[962/00049] train_loss: 0.007126 kl_loss: 0.000000 normal_loss: 0.007126\n",
      "[963/00074] train_loss: 0.007079 kl_loss: 0.000000 normal_loss: 0.007079\n",
      "[965/00024] train_loss: 0.007088 kl_loss: 0.000000 normal_loss: 0.007088\n",
      "[966/00049] train_loss: 0.007100 kl_loss: 0.000000 normal_loss: 0.007100\n",
      "[967/00074] train_loss: 0.007113 kl_loss: 0.000000 normal_loss: 0.007113\n",
      "[969/00024] train_loss: 0.007089 kl_loss: 0.000000 normal_loss: 0.007089\n",
      "[970/00049] train_loss: 0.007104 kl_loss: 0.000000 normal_loss: 0.007104\n",
      "[971/00074] train_loss: 0.007089 kl_loss: 0.000000 normal_loss: 0.007089\n",
      "[973/00024] train_loss: 0.007092 kl_loss: 0.000000 normal_loss: 0.007092\n",
      "[974/00049] train_loss: 0.007093 kl_loss: 0.000000 normal_loss: 0.007093\n",
      "[975/00074] train_loss: 0.007088 kl_loss: 0.000000 normal_loss: 0.007088\n",
      "[977/00024] train_loss: 0.007105 kl_loss: 0.000000 normal_loss: 0.007105\n",
      "[978/00049] train_loss: 0.007074 kl_loss: 0.000000 normal_loss: 0.007074\n",
      "[979/00074] train_loss: 0.007100 kl_loss: 0.000000 normal_loss: 0.007100\n",
      "[981/00024] train_loss: 0.007094 kl_loss: 0.000000 normal_loss: 0.007094\n",
      "[982/00049] train_loss: 0.007081 kl_loss: 0.000000 normal_loss: 0.007081\n",
      "[983/00074] train_loss: 0.007102 kl_loss: 0.000000 normal_loss: 0.007102\n",
      "[985/00024] train_loss: 0.007093 kl_loss: 0.000000 normal_loss: 0.007093\n",
      "[986/00049] train_loss: 0.007119 kl_loss: 0.000000 normal_loss: 0.007119\n",
      "[987/00074] train_loss: 0.007078 kl_loss: 0.000000 normal_loss: 0.007078\n",
      "[989/00024] train_loss: 0.007069 kl_loss: 0.000000 normal_loss: 0.007069\n",
      "[990/00049] train_loss: 0.007095 kl_loss: 0.000000 normal_loss: 0.007095\n",
      "[991/00074] train_loss: 0.007117 kl_loss: 0.000000 normal_loss: 0.007117\n",
      "[993/00024] train_loss: 0.007079 kl_loss: 0.000000 normal_loss: 0.007079\n",
      "[994/00049] train_loss: 0.007115 kl_loss: 0.000000 normal_loss: 0.007115\n",
      "[995/00074] train_loss: 0.007091 kl_loss: 0.000000 normal_loss: 0.007091\n",
      "[997/00024] train_loss: 0.007060 kl_loss: 0.000000 normal_loss: 0.007060\n",
      "[998/00049] train_loss: 0.007135 kl_loss: 0.000000 normal_loss: 0.007135\n",
      "[999/00074] train_loss: 0.007098 kl_loss: 0.000000 normal_loss: 0.007098\n",
      "[999/00074] IOU 0.9280581993671755\n"
     ]
    }
   ],
   "source": [
    "# TABLE AD\n",
    "from scripts import train\n",
    "config = {\n",
    "    'experiment_name': 'table_ad',\n",
    "    'device': 'cuda:0',\n",
    "    'is_overfit': False,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate_model': 0.01,\n",
    "    'learning_rate_code': 0.01,\n",
    "    'learning_rate_log_var':0.01,\n",
    "    'max_epochs': 1000,\n",
    "    'print_every_n': 100,\n",
    "    'latent_code_length' : 256,\n",
    "    'scheduler_step_size': 100,\n",
    "    'vad_free' : False,\n",
    "    'test': False,\n",
    "    'kl_weight': 0.03,\n",
    "    'kl_weight_increase_every_epochs': 100,\n",
    "    'kl_weight_increase_value': 0.0,\n",
    "    'iou_every_epoch': 50,\n",
    "    'resume_ckpt': None,\n",
    "    'filter_class': 'table',\n",
    "    'decoder_var' : False\n",
    "}\n",
    "train.main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Data length 4800\n",
      "Training params: 2\n",
      "[001/00024] train_loss: 0.164451 kl_loss: 0.000000 normal_loss: 0.164451\n",
      "[002/00049] train_loss: 0.116169 kl_loss: 0.000000 normal_loss: 0.116169\n",
      "[003/00074] train_loss: 0.113166 kl_loss: 0.000000 normal_loss: 0.113166\n",
      "[005/00024] train_loss: 0.106087 kl_loss: 0.000000 normal_loss: 0.106087\n",
      "[006/00049] train_loss: 0.100100 kl_loss: 0.000000 normal_loss: 0.100100\n",
      "[007/00074] train_loss: 0.095202 kl_loss: 0.000000 normal_loss: 0.095202\n",
      "[009/00024] train_loss: 0.089955 kl_loss: 0.000000 normal_loss: 0.089955\n",
      "[010/00049] train_loss: 0.085373 kl_loss: 0.000000 normal_loss: 0.085373\n",
      "[011/00074] train_loss: 0.082074 kl_loss: 0.000000 normal_loss: 0.082074\n",
      "[013/00024] train_loss: 0.077538 kl_loss: 0.000000 normal_loss: 0.077538\n",
      "[014/00049] train_loss: 0.075404 kl_loss: 0.000000 normal_loss: 0.075404\n",
      "[015/00074] train_loss: 0.071963 kl_loss: 0.000000 normal_loss: 0.071963\n",
      "[017/00024] train_loss: 0.069499 kl_loss: 0.000000 normal_loss: 0.069499\n",
      "[018/00049] train_loss: 0.066746 kl_loss: 0.000000 normal_loss: 0.066746\n",
      "[019/00074] train_loss: 0.064414 kl_loss: 0.000000 normal_loss: 0.064414\n",
      "[021/00024] train_loss: 0.061414 kl_loss: 0.000000 normal_loss: 0.061414\n",
      "[022/00049] train_loss: 0.058761 kl_loss: 0.000000 normal_loss: 0.058761\n",
      "[023/00074] train_loss: 0.057564 kl_loss: 0.000000 normal_loss: 0.057564\n",
      "[025/00024] train_loss: 0.054771 kl_loss: 0.000000 normal_loss: 0.054771\n",
      "[026/00049] train_loss: 0.052876 kl_loss: 0.000000 normal_loss: 0.052876\n",
      "[027/00074] train_loss: 0.051078 kl_loss: 0.000000 normal_loss: 0.051078\n",
      "[029/00024] train_loss: 0.050608 kl_loss: 0.000000 normal_loss: 0.050608\n",
      "[030/00049] train_loss: 0.048213 kl_loss: 0.000000 normal_loss: 0.048213\n",
      "[031/00074] train_loss: 0.046769 kl_loss: 0.000000 normal_loss: 0.046769\n",
      "[033/00024] train_loss: 0.045782 kl_loss: 0.000000 normal_loss: 0.045782\n",
      "[034/00049] train_loss: 0.043948 kl_loss: 0.000000 normal_loss: 0.043948\n",
      "[035/00074] train_loss: 0.044078 kl_loss: 0.000000 normal_loss: 0.044078\n",
      "[037/00024] train_loss: 0.043027 kl_loss: 0.000000 normal_loss: 0.043027\n",
      "[038/00049] train_loss: 0.041322 kl_loss: 0.000000 normal_loss: 0.041322\n",
      "[039/00074] train_loss: 0.040937 kl_loss: 0.000000 normal_loss: 0.040937\n",
      "[041/00024] train_loss: 0.039977 kl_loss: 0.000000 normal_loss: 0.039977\n",
      "[042/00049] train_loss: 0.039429 kl_loss: 0.000000 normal_loss: 0.039429\n",
      "[043/00074] train_loss: 0.037095 kl_loss: 0.000000 normal_loss: 0.037095\n",
      "[045/00024] train_loss: 0.036566 kl_loss: 0.000000 normal_loss: 0.036566\n",
      "[046/00049] train_loss: 0.035893 kl_loss: 0.000000 normal_loss: 0.035893\n",
      "[047/00074] train_loss: 0.034910 kl_loss: 0.000000 normal_loss: 0.034910\n",
      "[049/00024] train_loss: 0.033562 kl_loss: 0.000000 normal_loss: 0.033562\n",
      "[049/00074] IOU 0.7890190244900683\n",
      "[050/00049] train_loss: 0.034636 kl_loss: 0.000000 normal_loss: 0.034636\n",
      "[051/00074] train_loss: 0.032916 kl_loss: 0.000000 normal_loss: 0.032916\n",
      "[053/00024] train_loss: 0.031271 kl_loss: 0.000000 normal_loss: 0.031271\n",
      "[054/00049] train_loss: 0.032771 kl_loss: 0.000000 normal_loss: 0.032771\n",
      "[055/00074] train_loss: 0.030839 kl_loss: 0.000000 normal_loss: 0.030839\n",
      "[057/00024] train_loss: 0.030091 kl_loss: 0.000000 normal_loss: 0.030091\n",
      "[058/00049] train_loss: 0.029720 kl_loss: 0.000000 normal_loss: 0.029720\n",
      "[059/00074] train_loss: 0.028828 kl_loss: 0.000000 normal_loss: 0.028828\n",
      "[061/00024] train_loss: 0.028370 kl_loss: 0.000000 normal_loss: 0.028370\n",
      "[062/00049] train_loss: 0.028777 kl_loss: 0.000000 normal_loss: 0.028777\n",
      "[063/00074] train_loss: 0.027703 kl_loss: 0.000000 normal_loss: 0.027703\n",
      "[065/00024] train_loss: 0.027142 kl_loss: 0.000000 normal_loss: 0.027142\n",
      "[066/00049] train_loss: 0.026743 kl_loss: 0.000000 normal_loss: 0.026743\n",
      "[067/00074] train_loss: 0.026170 kl_loss: 0.000000 normal_loss: 0.026170\n",
      "[069/00024] train_loss: 0.025965 kl_loss: 0.000000 normal_loss: 0.025965\n",
      "[070/00049] train_loss: 0.025977 kl_loss: 0.000000 normal_loss: 0.025977\n",
      "[071/00074] train_loss: 0.025848 kl_loss: 0.000000 normal_loss: 0.025848\n",
      "[073/00024] train_loss: 0.025788 kl_loss: 0.000000 normal_loss: 0.025788\n",
      "[074/00049] train_loss: 0.024837 kl_loss: 0.000000 normal_loss: 0.024837\n",
      "[075/00074] train_loss: 0.025637 kl_loss: 0.000000 normal_loss: 0.025637\n",
      "[077/00024] train_loss: 0.024126 kl_loss: 0.000000 normal_loss: 0.024126\n",
      "[078/00049] train_loss: 0.024836 kl_loss: 0.000000 normal_loss: 0.024836\n",
      "[079/00074] train_loss: 0.023747 kl_loss: 0.000000 normal_loss: 0.023747\n",
      "[081/00024] train_loss: 0.023330 kl_loss: 0.000000 normal_loss: 0.023330\n",
      "[082/00049] train_loss: 0.024536 kl_loss: 0.000000 normal_loss: 0.024536\n",
      "[083/00074] train_loss: 0.023570 kl_loss: 0.000000 normal_loss: 0.023570\n",
      "[085/00024] train_loss: 0.023637 kl_loss: 0.000000 normal_loss: 0.023637\n",
      "[086/00049] train_loss: 0.022628 kl_loss: 0.000000 normal_loss: 0.022628\n",
      "[087/00074] train_loss: 0.022251 kl_loss: 0.000000 normal_loss: 0.022251\n",
      "[089/00024] train_loss: 0.022363 kl_loss: 0.000000 normal_loss: 0.022363\n",
      "[090/00049] train_loss: 0.022950 kl_loss: 0.000000 normal_loss: 0.022950\n",
      "[091/00074] train_loss: 0.022131 kl_loss: 0.000000 normal_loss: 0.022131\n",
      "[093/00024] train_loss: 0.021984 kl_loss: 0.000000 normal_loss: 0.021984\n",
      "[094/00049] train_loss: 0.022061 kl_loss: 0.000000 normal_loss: 0.022061\n",
      "[095/00074] train_loss: 0.021452 kl_loss: 0.000000 normal_loss: 0.021452\n",
      "[097/00024] train_loss: 0.021802 kl_loss: 0.000000 normal_loss: 0.021802\n",
      "[098/00049] train_loss: 0.021225 kl_loss: 0.000000 normal_loss: 0.021225\n",
      "[099/00074] train_loss: 0.020889 kl_loss: 0.000000 normal_loss: 0.020889\n",
      "[099/00074] IOU 0.8662025389696161\n",
      "[101/00024] train_loss: 0.018751 kl_loss: 0.000000 normal_loss: 0.018751\n",
      "[102/00049] train_loss: 0.016807 kl_loss: 0.000000 normal_loss: 0.016807\n",
      "[103/00074] train_loss: 0.016106 kl_loss: 0.000000 normal_loss: 0.016106\n",
      "[105/00024] train_loss: 0.015961 kl_loss: 0.000000 normal_loss: 0.015961\n",
      "[106/00049] train_loss: 0.016184 kl_loss: 0.000000 normal_loss: 0.016184\n",
      "[107/00074] train_loss: 0.015720 kl_loss: 0.000000 normal_loss: 0.015720\n",
      "[109/00024] train_loss: 0.015845 kl_loss: 0.000000 normal_loss: 0.015845\n",
      "[110/00049] train_loss: 0.015781 kl_loss: 0.000000 normal_loss: 0.015781\n",
      "[111/00074] train_loss: 0.016113 kl_loss: 0.000000 normal_loss: 0.016113\n",
      "[113/00024] train_loss: 0.016199 kl_loss: 0.000000 normal_loss: 0.016199\n",
      "[114/00049] train_loss: 0.016084 kl_loss: 0.000000 normal_loss: 0.016084\n",
      "[115/00074] train_loss: 0.015986 kl_loss: 0.000000 normal_loss: 0.015986\n",
      "[117/00024] train_loss: 0.015418 kl_loss: 0.000000 normal_loss: 0.015418\n",
      "[118/00049] train_loss: 0.016162 kl_loss: 0.000000 normal_loss: 0.016162\n",
      "[119/00074] train_loss: 0.016461 kl_loss: 0.000000 normal_loss: 0.016461\n",
      "[121/00024] train_loss: 0.015995 kl_loss: 0.000000 normal_loss: 0.015995\n",
      "[122/00049] train_loss: 0.015734 kl_loss: 0.000000 normal_loss: 0.015734\n",
      "[123/00074] train_loss: 0.015335 kl_loss: 0.000000 normal_loss: 0.015335\n",
      "[125/00024] train_loss: 0.015976 kl_loss: 0.000000 normal_loss: 0.015976\n",
      "[126/00049] train_loss: 0.015941 kl_loss: 0.000000 normal_loss: 0.015941\n",
      "[127/00074] train_loss: 0.015573 kl_loss: 0.000000 normal_loss: 0.015573\n",
      "[129/00024] train_loss: 0.015858 kl_loss: 0.000000 normal_loss: 0.015858\n",
      "[130/00049] train_loss: 0.015334 kl_loss: 0.000000 normal_loss: 0.015334\n",
      "[131/00074] train_loss: 0.015677 kl_loss: 0.000000 normal_loss: 0.015677\n",
      "[133/00024] train_loss: 0.015271 kl_loss: 0.000000 normal_loss: 0.015271\n",
      "[134/00049] train_loss: 0.015364 kl_loss: 0.000000 normal_loss: 0.015364\n",
      "[135/00074] train_loss: 0.015314 kl_loss: 0.000000 normal_loss: 0.015314\n",
      "[137/00024] train_loss: 0.015494 kl_loss: 0.000000 normal_loss: 0.015494\n",
      "[138/00049] train_loss: 0.015551 kl_loss: 0.000000 normal_loss: 0.015551\n",
      "[139/00074] train_loss: 0.015190 kl_loss: 0.000000 normal_loss: 0.015190\n",
      "[141/00024] train_loss: 0.014862 kl_loss: 0.000000 normal_loss: 0.014862\n",
      "[142/00049] train_loss: 0.015344 kl_loss: 0.000000 normal_loss: 0.015344\n",
      "[143/00074] train_loss: 0.015097 kl_loss: 0.000000 normal_loss: 0.015097\n",
      "[145/00024] train_loss: 0.015198 kl_loss: 0.000000 normal_loss: 0.015198\n",
      "[146/00049] train_loss: 0.015145 kl_loss: 0.000000 normal_loss: 0.015145\n",
      "[147/00074] train_loss: 0.014797 kl_loss: 0.000000 normal_loss: 0.014797\n",
      "[149/00024] train_loss: 0.015085 kl_loss: 0.000000 normal_loss: 0.015085\n",
      "[149/00074] IOU 0.8902636351746818\n",
      "[150/00049] train_loss: 0.015042 kl_loss: 0.000000 normal_loss: 0.015042\n",
      "[151/00074] train_loss: 0.014795 kl_loss: 0.000000 normal_loss: 0.014795\n",
      "[153/00024] train_loss: 0.014889 kl_loss: 0.000000 normal_loss: 0.014889\n",
      "[154/00049] train_loss: 0.014328 kl_loss: 0.000000 normal_loss: 0.014328\n",
      "[155/00074] train_loss: 0.014663 kl_loss: 0.000000 normal_loss: 0.014663\n",
      "[157/00024] train_loss: 0.014570 kl_loss: 0.000000 normal_loss: 0.014570\n",
      "[158/00049] train_loss: 0.014872 kl_loss: 0.000000 normal_loss: 0.014872\n",
      "[159/00074] train_loss: 0.014569 kl_loss: 0.000000 normal_loss: 0.014569\n",
      "[161/00024] train_loss: 0.014658 kl_loss: 0.000000 normal_loss: 0.014658\n",
      "[162/00049] train_loss: 0.014701 kl_loss: 0.000000 normal_loss: 0.014701\n",
      "[163/00074] train_loss: 0.014564 kl_loss: 0.000000 normal_loss: 0.014564\n",
      "[165/00024] train_loss: 0.014121 kl_loss: 0.000000 normal_loss: 0.014121\n",
      "[166/00049] train_loss: 0.014525 kl_loss: 0.000000 normal_loss: 0.014525\n",
      "[167/00074] train_loss: 0.014238 kl_loss: 0.000000 normal_loss: 0.014238\n",
      "[169/00024] train_loss: 0.014586 kl_loss: 0.000000 normal_loss: 0.014586\n",
      "[170/00049] train_loss: 0.014109 kl_loss: 0.000000 normal_loss: 0.014109\n",
      "[171/00074] train_loss: 0.014192 kl_loss: 0.000000 normal_loss: 0.014192\n",
      "[173/00024] train_loss: 0.014367 kl_loss: 0.000000 normal_loss: 0.014367\n",
      "[174/00049] train_loss: 0.014173 kl_loss: 0.000000 normal_loss: 0.014173\n",
      "[175/00074] train_loss: 0.014156 kl_loss: 0.000000 normal_loss: 0.014156\n",
      "[177/00024] train_loss: 0.014205 kl_loss: 0.000000 normal_loss: 0.014205\n",
      "[178/00049] train_loss: 0.014131 kl_loss: 0.000000 normal_loss: 0.014131\n",
      "[179/00074] train_loss: 0.014310 kl_loss: 0.000000 normal_loss: 0.014310\n",
      "[181/00024] train_loss: 0.013722 kl_loss: 0.000000 normal_loss: 0.013722\n",
      "[182/00049] train_loss: 0.013985 kl_loss: 0.000000 normal_loss: 0.013985\n",
      "[183/00074] train_loss: 0.014210 kl_loss: 0.000000 normal_loss: 0.014210\n",
      "[185/00024] train_loss: 0.013881 kl_loss: 0.000000 normal_loss: 0.013881\n",
      "[186/00049] train_loss: 0.013712 kl_loss: 0.000000 normal_loss: 0.013712\n",
      "[187/00074] train_loss: 0.013481 kl_loss: 0.000000 normal_loss: 0.013481\n",
      "[189/00024] train_loss: 0.014046 kl_loss: 0.000000 normal_loss: 0.014046\n",
      "[190/00049] train_loss: 0.014026 kl_loss: 0.000000 normal_loss: 0.014026\n",
      "[191/00074] train_loss: 0.014068 kl_loss: 0.000000 normal_loss: 0.014068\n",
      "[193/00024] train_loss: 0.013848 kl_loss: 0.000000 normal_loss: 0.013848\n",
      "[194/00049] train_loss: 0.013905 kl_loss: 0.000000 normal_loss: 0.013905\n",
      "[195/00074] train_loss: 0.013573 kl_loss: 0.000000 normal_loss: 0.013573\n",
      "[197/00024] train_loss: 0.013619 kl_loss: 0.000000 normal_loss: 0.013619\n",
      "[198/00049] train_loss: 0.013699 kl_loss: 0.000000 normal_loss: 0.013699\n",
      "[199/00074] train_loss: 0.013374 kl_loss: 0.000000 normal_loss: 0.013374\n",
      "[199/00074] IOU 0.8991929771751166\n",
      "[201/00024] train_loss: 0.012351 kl_loss: 0.000000 normal_loss: 0.012351\n",
      "[202/00049] train_loss: 0.011701 kl_loss: 0.000000 normal_loss: 0.011701\n",
      "[203/00074] train_loss: 0.011644 kl_loss: 0.000000 normal_loss: 0.011644\n",
      "[205/00024] train_loss: 0.011500 kl_loss: 0.000000 normal_loss: 0.011500\n",
      "[206/00049] train_loss: 0.011616 kl_loss: 0.000000 normal_loss: 0.011616\n",
      "[207/00074] train_loss: 0.011539 kl_loss: 0.000000 normal_loss: 0.011539\n",
      "[209/00024] train_loss: 0.011481 kl_loss: 0.000000 normal_loss: 0.011481\n",
      "[210/00049] train_loss: 0.011602 kl_loss: 0.000000 normal_loss: 0.011602\n",
      "[211/00074] train_loss: 0.011510 kl_loss: 0.000000 normal_loss: 0.011510\n",
      "[213/00024] train_loss: 0.011490 kl_loss: 0.000000 normal_loss: 0.011490\n",
      "[214/00049] train_loss: 0.011511 kl_loss: 0.000000 normal_loss: 0.011511\n",
      "[215/00074] train_loss: 0.011491 kl_loss: 0.000000 normal_loss: 0.011491\n",
      "[217/00024] train_loss: 0.011423 kl_loss: 0.000000 normal_loss: 0.011423\n",
      "[218/00049] train_loss: 0.011675 kl_loss: 0.000000 normal_loss: 0.011675\n",
      "[219/00074] train_loss: 0.011741 kl_loss: 0.000000 normal_loss: 0.011741\n",
      "[221/00024] train_loss: 0.011548 kl_loss: 0.000000 normal_loss: 0.011548\n",
      "[222/00049] train_loss: 0.011584 kl_loss: 0.000000 normal_loss: 0.011584\n",
      "[223/00074] train_loss: 0.011517 kl_loss: 0.000000 normal_loss: 0.011517\n",
      "[225/00024] train_loss: 0.011517 kl_loss: 0.000000 normal_loss: 0.011517\n",
      "[226/00049] train_loss: 0.011440 kl_loss: 0.000000 normal_loss: 0.011440\n",
      "[227/00074] train_loss: 0.011536 kl_loss: 0.000000 normal_loss: 0.011536\n",
      "[229/00024] train_loss: 0.011458 kl_loss: 0.000000 normal_loss: 0.011458\n",
      "[230/00049] train_loss: 0.011424 kl_loss: 0.000000 normal_loss: 0.011424\n",
      "[231/00074] train_loss: 0.011441 kl_loss: 0.000000 normal_loss: 0.011441\n",
      "[233/00024] train_loss: 0.011437 kl_loss: 0.000000 normal_loss: 0.011437\n",
      "[234/00049] train_loss: 0.011520 kl_loss: 0.000000 normal_loss: 0.011520\n",
      "[235/00074] train_loss: 0.011382 kl_loss: 0.000000 normal_loss: 0.011382\n",
      "[237/00024] train_loss: 0.011432 kl_loss: 0.000000 normal_loss: 0.011432\n",
      "[238/00049] train_loss: 0.011508 kl_loss: 0.000000 normal_loss: 0.011508\n",
      "[239/00074] train_loss: 0.011330 kl_loss: 0.000000 normal_loss: 0.011330\n",
      "[241/00024] train_loss: 0.011474 kl_loss: 0.000000 normal_loss: 0.011474\n",
      "[242/00049] train_loss: 0.011459 kl_loss: 0.000000 normal_loss: 0.011459\n",
      "[243/00074] train_loss: 0.011282 kl_loss: 0.000000 normal_loss: 0.011282\n",
      "[245/00024] train_loss: 0.011403 kl_loss: 0.000000 normal_loss: 0.011403\n",
      "[246/00049] train_loss: 0.011354 kl_loss: 0.000000 normal_loss: 0.011354\n",
      "[247/00074] train_loss: 0.011400 kl_loss: 0.000000 normal_loss: 0.011400\n",
      "[249/00024] train_loss: 0.011352 kl_loss: 0.000000 normal_loss: 0.011352\n",
      "[249/00074] IOU 0.9097692750145991\n",
      "[250/00049] train_loss: 0.011393 kl_loss: 0.000000 normal_loss: 0.011393\n",
      "[251/00074] train_loss: 0.011180 kl_loss: 0.000000 normal_loss: 0.011180\n",
      "[253/00024] train_loss: 0.011163 kl_loss: 0.000000 normal_loss: 0.011163\n",
      "[254/00049] train_loss: 0.011223 kl_loss: 0.000000 normal_loss: 0.011223\n",
      "[255/00074] train_loss: 0.011185 kl_loss: 0.000000 normal_loss: 0.011185\n",
      "[257/00024] train_loss: 0.011283 kl_loss: 0.000000 normal_loss: 0.011283\n",
      "[258/00049] train_loss: 0.011216 kl_loss: 0.000000 normal_loss: 0.011216\n",
      "[259/00074] train_loss: 0.011251 kl_loss: 0.000000 normal_loss: 0.011251\n",
      "[261/00024] train_loss: 0.011064 kl_loss: 0.000000 normal_loss: 0.011064\n",
      "[262/00049] train_loss: 0.011278 kl_loss: 0.000000 normal_loss: 0.011278\n",
      "[263/00074] train_loss: 0.011164 kl_loss: 0.000000 normal_loss: 0.011164\n",
      "[265/00024] train_loss: 0.011301 kl_loss: 0.000000 normal_loss: 0.011301\n",
      "[266/00049] train_loss: 0.011068 kl_loss: 0.000000 normal_loss: 0.011068\n",
      "[267/00074] train_loss: 0.011145 kl_loss: 0.000000 normal_loss: 0.011145\n",
      "[269/00024] train_loss: 0.011347 kl_loss: 0.000000 normal_loss: 0.011347\n",
      "[270/00049] train_loss: 0.011098 kl_loss: 0.000000 normal_loss: 0.011098\n",
      "[271/00074] train_loss: 0.011144 kl_loss: 0.000000 normal_loss: 0.011144\n",
      "[273/00024] train_loss: 0.010963 kl_loss: 0.000000 normal_loss: 0.010963\n",
      "[274/00049] train_loss: 0.011172 kl_loss: 0.000000 normal_loss: 0.011172\n",
      "[275/00074] train_loss: 0.011058 kl_loss: 0.000000 normal_loss: 0.011058\n",
      "[277/00024] train_loss: 0.011133 kl_loss: 0.000000 normal_loss: 0.011133\n",
      "[278/00049] train_loss: 0.011219 kl_loss: 0.000000 normal_loss: 0.011219\n",
      "[279/00074] train_loss: 0.011025 kl_loss: 0.000000 normal_loss: 0.011025\n",
      "[281/00024] train_loss: 0.011000 kl_loss: 0.000000 normal_loss: 0.011000\n",
      "[282/00049] train_loss: 0.011118 kl_loss: 0.000000 normal_loss: 0.011118\n",
      "[283/00074] train_loss: 0.011107 kl_loss: 0.000000 normal_loss: 0.011107\n",
      "[285/00024] train_loss: 0.010989 kl_loss: 0.000000 normal_loss: 0.010989\n",
      "[286/00049] train_loss: 0.011106 kl_loss: 0.000000 normal_loss: 0.011106\n",
      "[287/00074] train_loss: 0.010985 kl_loss: 0.000000 normal_loss: 0.010985\n",
      "[289/00024] train_loss: 0.011186 kl_loss: 0.000000 normal_loss: 0.011186\n",
      "[290/00049] train_loss: 0.010873 kl_loss: 0.000000 normal_loss: 0.010873\n",
      "[291/00074] train_loss: 0.010929 kl_loss: 0.000000 normal_loss: 0.010929\n",
      "[293/00024] train_loss: 0.010951 kl_loss: 0.000000 normal_loss: 0.010951\n",
      "[294/00049] train_loss: 0.011059 kl_loss: 0.000000 normal_loss: 0.011059\n",
      "[295/00074] train_loss: 0.011040 kl_loss: 0.000000 normal_loss: 0.011040\n",
      "[297/00024] train_loss: 0.010972 kl_loss: 0.000000 normal_loss: 0.010972\n",
      "[298/00049] train_loss: 0.010871 kl_loss: 0.000000 normal_loss: 0.010871\n",
      "[299/00074] train_loss: 0.010959 kl_loss: 0.000000 normal_loss: 0.010959\n",
      "[299/00074] IOU 0.9090687726127604\n",
      "[301/00024] train_loss: 0.010345 kl_loss: 0.000000 normal_loss: 0.010345\n",
      "[302/00049] train_loss: 0.010154 kl_loss: 0.000000 normal_loss: 0.010154\n",
      "[303/00074] train_loss: 0.010115 kl_loss: 0.000000 normal_loss: 0.010115\n",
      "[305/00024] train_loss: 0.010201 kl_loss: 0.000000 normal_loss: 0.010201\n",
      "[306/00049] train_loss: 0.010100 kl_loss: 0.000000 normal_loss: 0.010100\n",
      "[307/00074] train_loss: 0.010107 kl_loss: 0.000000 normal_loss: 0.010107\n",
      "[309/00024] train_loss: 0.010163 kl_loss: 0.000000 normal_loss: 0.010163\n",
      "[310/00049] train_loss: 0.010034 kl_loss: 0.000000 normal_loss: 0.010034\n",
      "[311/00074] train_loss: 0.010108 kl_loss: 0.000000 normal_loss: 0.010108\n",
      "[313/00024] train_loss: 0.010115 kl_loss: 0.000000 normal_loss: 0.010115\n",
      "[314/00049] train_loss: 0.010149 kl_loss: 0.000000 normal_loss: 0.010149\n",
      "[315/00074] train_loss: 0.010075 kl_loss: 0.000000 normal_loss: 0.010075\n",
      "[317/00024] train_loss: 0.010188 kl_loss: 0.000000 normal_loss: 0.010188\n",
      "[318/00049] train_loss: 0.010170 kl_loss: 0.000000 normal_loss: 0.010170\n",
      "[319/00074] train_loss: 0.010041 kl_loss: 0.000000 normal_loss: 0.010041\n",
      "[321/00024] train_loss: 0.010063 kl_loss: 0.000000 normal_loss: 0.010063\n",
      "[322/00049] train_loss: 0.009991 kl_loss: 0.000000 normal_loss: 0.009991\n",
      "[323/00074] train_loss: 0.010043 kl_loss: 0.000000 normal_loss: 0.010043\n",
      "[325/00024] train_loss: 0.010064 kl_loss: 0.000000 normal_loss: 0.010064\n",
      "[326/00049] train_loss: 0.010069 kl_loss: 0.000000 normal_loss: 0.010069\n",
      "[327/00074] train_loss: 0.010033 kl_loss: 0.000000 normal_loss: 0.010033\n",
      "[329/00024] train_loss: 0.010040 kl_loss: 0.000000 normal_loss: 0.010040\n",
      "[330/00049] train_loss: 0.010082 kl_loss: 0.000000 normal_loss: 0.010082\n",
      "[331/00074] train_loss: 0.010083 kl_loss: 0.000000 normal_loss: 0.010083\n",
      "[333/00024] train_loss: 0.010194 kl_loss: 0.000000 normal_loss: 0.010194\n",
      "[334/00049] train_loss: 0.009973 kl_loss: 0.000000 normal_loss: 0.009973\n",
      "[335/00074] train_loss: 0.010036 kl_loss: 0.000000 normal_loss: 0.010036\n",
      "[337/00024] train_loss: 0.010017 kl_loss: 0.000000 normal_loss: 0.010017\n",
      "[338/00049] train_loss: 0.009979 kl_loss: 0.000000 normal_loss: 0.009979\n",
      "[339/00074] train_loss: 0.010012 kl_loss: 0.000000 normal_loss: 0.010012\n",
      "[341/00024] train_loss: 0.009935 kl_loss: 0.000000 normal_loss: 0.009935\n",
      "[342/00049] train_loss: 0.010071 kl_loss: 0.000000 normal_loss: 0.010071\n",
      "[343/00074] train_loss: 0.009963 kl_loss: 0.000000 normal_loss: 0.009963\n",
      "[345/00024] train_loss: 0.009981 kl_loss: 0.000000 normal_loss: 0.009981\n",
      "[346/00049] train_loss: 0.009955 kl_loss: 0.000000 normal_loss: 0.009955\n",
      "[347/00074] train_loss: 0.009958 kl_loss: 0.000000 normal_loss: 0.009958\n",
      "[349/00024] train_loss: 0.010044 kl_loss: 0.000000 normal_loss: 0.010044\n",
      "[349/00074] IOU 0.9136460893414915\n",
      "[350/00049] train_loss: 0.009924 kl_loss: 0.000000 normal_loss: 0.009924\n",
      "[351/00074] train_loss: 0.009981 kl_loss: 0.000000 normal_loss: 0.009981\n",
      "[353/00024] train_loss: 0.009933 kl_loss: 0.000000 normal_loss: 0.009933\n",
      "[354/00049] train_loss: 0.009890 kl_loss: 0.000000 normal_loss: 0.009890\n",
      "[355/00074] train_loss: 0.009957 kl_loss: 0.000000 normal_loss: 0.009957\n",
      "[357/00024] train_loss: 0.009963 kl_loss: 0.000000 normal_loss: 0.009963\n",
      "[358/00049] train_loss: 0.009960 kl_loss: 0.000000 normal_loss: 0.009960\n",
      "[359/00074] train_loss: 0.009859 kl_loss: 0.000000 normal_loss: 0.009859\n",
      "[361/00024] train_loss: 0.009998 kl_loss: 0.000000 normal_loss: 0.009998\n",
      "[362/00049] train_loss: 0.009995 kl_loss: 0.000000 normal_loss: 0.009995\n",
      "[363/00074] train_loss: 0.009922 kl_loss: 0.000000 normal_loss: 0.009922\n",
      "[365/00024] train_loss: 0.009864 kl_loss: 0.000000 normal_loss: 0.009864\n",
      "[366/00049] train_loss: 0.009954 kl_loss: 0.000000 normal_loss: 0.009954\n",
      "[367/00074] train_loss: 0.009985 kl_loss: 0.000000 normal_loss: 0.009985\n",
      "[369/00024] train_loss: 0.009921 kl_loss: 0.000000 normal_loss: 0.009921\n",
      "[370/00049] train_loss: 0.009901 kl_loss: 0.000000 normal_loss: 0.009901\n",
      "[371/00074] train_loss: 0.009925 kl_loss: 0.000000 normal_loss: 0.009925\n",
      "[373/00024] train_loss: 0.009891 kl_loss: 0.000000 normal_loss: 0.009891\n",
      "[374/00049] train_loss: 0.009865 kl_loss: 0.000000 normal_loss: 0.009865\n",
      "[375/00074] train_loss: 0.009865 kl_loss: 0.000000 normal_loss: 0.009865\n",
      "[377/00024] train_loss: 0.009924 kl_loss: 0.000000 normal_loss: 0.009924\n",
      "[378/00049] train_loss: 0.009788 kl_loss: 0.000000 normal_loss: 0.009788\n",
      "[379/00074] train_loss: 0.009802 kl_loss: 0.000000 normal_loss: 0.009802\n",
      "[381/00024] train_loss: 0.009820 kl_loss: 0.000000 normal_loss: 0.009820\n",
      "[382/00049] train_loss: 0.009806 kl_loss: 0.000000 normal_loss: 0.009806\n",
      "[383/00074] train_loss: 0.009812 kl_loss: 0.000000 normal_loss: 0.009812\n",
      "[385/00024] train_loss: 0.009851 kl_loss: 0.000000 normal_loss: 0.009851\n",
      "[386/00049] train_loss: 0.009822 kl_loss: 0.000000 normal_loss: 0.009822\n",
      "[387/00074] train_loss: 0.009862 kl_loss: 0.000000 normal_loss: 0.009862\n",
      "[389/00024] train_loss: 0.009803 kl_loss: 0.000000 normal_loss: 0.009803\n",
      "[390/00049] train_loss: 0.009755 kl_loss: 0.000000 normal_loss: 0.009755\n",
      "[391/00074] train_loss: 0.009870 kl_loss: 0.000000 normal_loss: 0.009870\n",
      "[393/00024] train_loss: 0.009904 kl_loss: 0.000000 normal_loss: 0.009904\n",
      "[394/00049] train_loss: 0.009875 kl_loss: 0.000000 normal_loss: 0.009875\n",
      "[395/00074] train_loss: 0.009751 kl_loss: 0.000000 normal_loss: 0.009751\n",
      "[397/00024] train_loss: 0.009760 kl_loss: 0.000000 normal_loss: 0.009760\n",
      "[398/00049] train_loss: 0.009743 kl_loss: 0.000000 normal_loss: 0.009743\n",
      "[399/00074] train_loss: 0.009700 kl_loss: 0.000000 normal_loss: 0.009700\n",
      "[399/00074] IOU 0.9167061796349784\n",
      "[401/00024] train_loss: 0.009582 kl_loss: 0.000000 normal_loss: 0.009582\n",
      "[402/00049] train_loss: 0.009484 kl_loss: 0.000000 normal_loss: 0.009484\n",
      "[403/00074] train_loss: 0.009537 kl_loss: 0.000000 normal_loss: 0.009537\n",
      "[405/00024] train_loss: 0.009503 kl_loss: 0.000000 normal_loss: 0.009503\n",
      "[406/00049] train_loss: 0.009487 kl_loss: 0.000000 normal_loss: 0.009487\n",
      "[407/00074] train_loss: 0.009437 kl_loss: 0.000000 normal_loss: 0.009437\n",
      "[409/00024] train_loss: 0.009476 kl_loss: 0.000000 normal_loss: 0.009476\n",
      "[410/00049] train_loss: 0.009451 kl_loss: 0.000000 normal_loss: 0.009451\n",
      "[411/00074] train_loss: 0.009444 kl_loss: 0.000000 normal_loss: 0.009444\n",
      "[413/00024] train_loss: 0.009420 kl_loss: 0.000000 normal_loss: 0.009420\n",
      "[414/00049] train_loss: 0.009469 kl_loss: 0.000000 normal_loss: 0.009469\n",
      "[415/00074] train_loss: 0.009595 kl_loss: 0.000000 normal_loss: 0.009595\n",
      "[417/00024] train_loss: 0.009462 kl_loss: 0.000000 normal_loss: 0.009462\n",
      "[418/00049] train_loss: 0.009431 kl_loss: 0.000000 normal_loss: 0.009431\n",
      "[419/00074] train_loss: 0.009461 kl_loss: 0.000000 normal_loss: 0.009461\n",
      "[421/00024] train_loss: 0.009500 kl_loss: 0.000000 normal_loss: 0.009500\n",
      "[422/00049] train_loss: 0.009395 kl_loss: 0.000000 normal_loss: 0.009395\n",
      "[423/00074] train_loss: 0.009445 kl_loss: 0.000000 normal_loss: 0.009445\n",
      "[425/00024] train_loss: 0.009456 kl_loss: 0.000000 normal_loss: 0.009456\n",
      "[426/00049] train_loss: 0.009399 kl_loss: 0.000000 normal_loss: 0.009399\n",
      "[427/00074] train_loss: 0.009494 kl_loss: 0.000000 normal_loss: 0.009494\n",
      "[429/00024] train_loss: 0.009382 kl_loss: 0.000000 normal_loss: 0.009382\n",
      "[430/00049] train_loss: 0.009525 kl_loss: 0.000000 normal_loss: 0.009525\n",
      "[431/00074] train_loss: 0.009366 kl_loss: 0.000000 normal_loss: 0.009366\n",
      "[433/00024] train_loss: 0.009379 kl_loss: 0.000000 normal_loss: 0.009379\n",
      "[434/00049] train_loss: 0.009400 kl_loss: 0.000000 normal_loss: 0.009400\n",
      "[435/00074] train_loss: 0.009426 kl_loss: 0.000000 normal_loss: 0.009426\n",
      "[437/00024] train_loss: 0.009387 kl_loss: 0.000000 normal_loss: 0.009387\n",
      "[438/00049] train_loss: 0.009469 kl_loss: 0.000000 normal_loss: 0.009469\n",
      "[439/00074] train_loss: 0.009370 kl_loss: 0.000000 normal_loss: 0.009370\n",
      "[441/00024] train_loss: 0.009428 kl_loss: 0.000000 normal_loss: 0.009428\n",
      "[442/00049] train_loss: 0.009426 kl_loss: 0.000000 normal_loss: 0.009426\n",
      "[443/00074] train_loss: 0.009386 kl_loss: 0.000000 normal_loss: 0.009386\n",
      "[445/00024] train_loss: 0.009415 kl_loss: 0.000000 normal_loss: 0.009415\n",
      "[446/00049] train_loss: 0.009388 kl_loss: 0.000000 normal_loss: 0.009388\n",
      "[447/00074] train_loss: 0.009373 kl_loss: 0.000000 normal_loss: 0.009373\n",
      "[449/00024] train_loss: 0.009362 kl_loss: 0.000000 normal_loss: 0.009362\n",
      "[449/00074] IOU 0.9176198591167728\n",
      "[450/00049] train_loss: 0.009342 kl_loss: 0.000000 normal_loss: 0.009342\n",
      "[451/00074] train_loss: 0.009419 kl_loss: 0.000000 normal_loss: 0.009419\n",
      "[453/00024] train_loss: 0.009396 kl_loss: 0.000000 normal_loss: 0.009396\n",
      "[454/00049] train_loss: 0.009279 kl_loss: 0.000000 normal_loss: 0.009279\n",
      "[455/00074] train_loss: 0.009350 kl_loss: 0.000000 normal_loss: 0.009350\n",
      "[457/00024] train_loss: 0.009387 kl_loss: 0.000000 normal_loss: 0.009387\n",
      "[458/00049] train_loss: 0.009380 kl_loss: 0.000000 normal_loss: 0.009380\n",
      "[459/00074] train_loss: 0.009369 kl_loss: 0.000000 normal_loss: 0.009369\n",
      "[461/00024] train_loss: 0.009380 kl_loss: 0.000000 normal_loss: 0.009380\n",
      "[462/00049] train_loss: 0.009346 kl_loss: 0.000000 normal_loss: 0.009346\n",
      "[463/00074] train_loss: 0.009486 kl_loss: 0.000000 normal_loss: 0.009486\n",
      "[465/00024] train_loss: 0.009400 kl_loss: 0.000000 normal_loss: 0.009400\n",
      "[466/00049] train_loss: 0.009361 kl_loss: 0.000000 normal_loss: 0.009361\n",
      "[467/00074] train_loss: 0.009257 kl_loss: 0.000000 normal_loss: 0.009257\n",
      "[469/00024] train_loss: 0.009341 kl_loss: 0.000000 normal_loss: 0.009341\n",
      "[470/00049] train_loss: 0.009389 kl_loss: 0.000000 normal_loss: 0.009389\n",
      "[471/00074] train_loss: 0.009313 kl_loss: 0.000000 normal_loss: 0.009313\n",
      "[473/00024] train_loss: 0.009314 kl_loss: 0.000000 normal_loss: 0.009314\n",
      "[474/00049] train_loss: 0.009491 kl_loss: 0.000000 normal_loss: 0.009491\n",
      "[475/00074] train_loss: 0.009285 kl_loss: 0.000000 normal_loss: 0.009285\n",
      "[477/00024] train_loss: 0.009291 kl_loss: 0.000000 normal_loss: 0.009291\n",
      "[478/00049] train_loss: 0.009256 kl_loss: 0.000000 normal_loss: 0.009256\n",
      "[479/00074] train_loss: 0.009355 kl_loss: 0.000000 normal_loss: 0.009355\n",
      "[481/00024] train_loss: 0.009277 kl_loss: 0.000000 normal_loss: 0.009277\n",
      "[482/00049] train_loss: 0.009281 kl_loss: 0.000000 normal_loss: 0.009281\n",
      "[483/00074] train_loss: 0.009314 kl_loss: 0.000000 normal_loss: 0.009314\n",
      "[485/00024] train_loss: 0.009307 kl_loss: 0.000000 normal_loss: 0.009307\n",
      "[486/00049] train_loss: 0.009324 kl_loss: 0.000000 normal_loss: 0.009324\n",
      "[487/00074] train_loss: 0.009298 kl_loss: 0.000000 normal_loss: 0.009298\n",
      "[489/00024] train_loss: 0.009349 kl_loss: 0.000000 normal_loss: 0.009349\n",
      "[490/00049] train_loss: 0.009310 kl_loss: 0.000000 normal_loss: 0.009310\n",
      "[491/00074] train_loss: 0.009278 kl_loss: 0.000000 normal_loss: 0.009278\n",
      "[493/00024] train_loss: 0.009312 kl_loss: 0.000000 normal_loss: 0.009312\n",
      "[494/00049] train_loss: 0.009280 kl_loss: 0.000000 normal_loss: 0.009280\n",
      "[495/00074] train_loss: 0.009283 kl_loss: 0.000000 normal_loss: 0.009283\n",
      "[497/00024] train_loss: 0.009348 kl_loss: 0.000000 normal_loss: 0.009348\n",
      "[498/00049] train_loss: 0.009276 kl_loss: 0.000000 normal_loss: 0.009276\n",
      "[499/00074] train_loss: 0.009316 kl_loss: 0.000000 normal_loss: 0.009316\n",
      "[499/00074] IOU 0.9187757863290608\n",
      "[501/00024] train_loss: 0.009178 kl_loss: 0.000000 normal_loss: 0.009178\n",
      "[502/00049] train_loss: 0.009143 kl_loss: 0.000000 normal_loss: 0.009143\n",
      "[503/00074] train_loss: 0.009154 kl_loss: 0.000000 normal_loss: 0.009154\n",
      "[505/00024] train_loss: 0.009155 kl_loss: 0.000000 normal_loss: 0.009155\n",
      "[506/00049] train_loss: 0.009105 kl_loss: 0.000000 normal_loss: 0.009105\n",
      "[507/00074] train_loss: 0.009165 kl_loss: 0.000000 normal_loss: 0.009165\n",
      "[509/00024] train_loss: 0.009148 kl_loss: 0.000000 normal_loss: 0.009148\n",
      "[510/00049] train_loss: 0.009087 kl_loss: 0.000000 normal_loss: 0.009087\n",
      "[511/00074] train_loss: 0.009185 kl_loss: 0.000000 normal_loss: 0.009185\n",
      "[513/00024] train_loss: 0.009153 kl_loss: 0.000000 normal_loss: 0.009153\n",
      "[514/00049] train_loss: 0.009177 kl_loss: 0.000000 normal_loss: 0.009177\n",
      "[515/00074] train_loss: 0.009111 kl_loss: 0.000000 normal_loss: 0.009111\n",
      "[517/00024] train_loss: 0.009079 kl_loss: 0.000000 normal_loss: 0.009079\n",
      "[518/00049] train_loss: 0.009156 kl_loss: 0.000000 normal_loss: 0.009156\n",
      "[519/00074] train_loss: 0.009155 kl_loss: 0.000000 normal_loss: 0.009155\n",
      "[521/00024] train_loss: 0.009109 kl_loss: 0.000000 normal_loss: 0.009109\n",
      "[522/00049] train_loss: 0.009177 kl_loss: 0.000000 normal_loss: 0.009177\n",
      "[523/00074] train_loss: 0.009139 kl_loss: 0.000000 normal_loss: 0.009139\n",
      "[525/00024] train_loss: 0.009088 kl_loss: 0.000000 normal_loss: 0.009088\n",
      "[526/00049] train_loss: 0.009088 kl_loss: 0.000000 normal_loss: 0.009088\n",
      "[527/00074] train_loss: 0.009167 kl_loss: 0.000000 normal_loss: 0.009167\n",
      "[529/00024] train_loss: 0.009094 kl_loss: 0.000000 normal_loss: 0.009094\n",
      "[530/00049] train_loss: 0.009168 kl_loss: 0.000000 normal_loss: 0.009168\n",
      "[531/00074] train_loss: 0.009083 kl_loss: 0.000000 normal_loss: 0.009083\n",
      "[533/00024] train_loss: 0.009093 kl_loss: 0.000000 normal_loss: 0.009093\n",
      "[534/00049] train_loss: 0.009144 kl_loss: 0.000000 normal_loss: 0.009144\n",
      "[535/00074] train_loss: 0.009079 kl_loss: 0.000000 normal_loss: 0.009079\n",
      "[537/00024] train_loss: 0.009097 kl_loss: 0.000000 normal_loss: 0.009097\n",
      "[538/00049] train_loss: 0.009092 kl_loss: 0.000000 normal_loss: 0.009092\n",
      "[539/00074] train_loss: 0.009147 kl_loss: 0.000000 normal_loss: 0.009147\n",
      "[541/00024] train_loss: 0.009102 kl_loss: 0.000000 normal_loss: 0.009102\n",
      "[542/00049] train_loss: 0.009146 kl_loss: 0.000000 normal_loss: 0.009146\n",
      "[543/00074] train_loss: 0.009091 kl_loss: 0.000000 normal_loss: 0.009091\n",
      "[545/00024] train_loss: 0.009117 kl_loss: 0.000000 normal_loss: 0.009117\n",
      "[546/00049] train_loss: 0.009158 kl_loss: 0.000000 normal_loss: 0.009158\n",
      "[547/00074] train_loss: 0.009088 kl_loss: 0.000000 normal_loss: 0.009088\n",
      "[549/00024] train_loss: 0.009081 kl_loss: 0.000000 normal_loss: 0.009081\n",
      "[549/00074] IOU 0.9194678045560917\n",
      "[550/00049] train_loss: 0.009057 kl_loss: 0.000000 normal_loss: 0.009057\n",
      "[551/00074] train_loss: 0.009121 kl_loss: 0.000000 normal_loss: 0.009121\n",
      "[553/00024] train_loss: 0.009082 kl_loss: 0.000000 normal_loss: 0.009082\n",
      "[554/00049] train_loss: 0.009158 kl_loss: 0.000000 normal_loss: 0.009158\n",
      "[555/00074] train_loss: 0.009105 kl_loss: 0.000000 normal_loss: 0.009105\n",
      "[557/00024] train_loss: 0.009068 kl_loss: 0.000000 normal_loss: 0.009068\n",
      "[558/00049] train_loss: 0.009112 kl_loss: 0.000000 normal_loss: 0.009112\n",
      "[559/00074] train_loss: 0.009099 kl_loss: 0.000000 normal_loss: 0.009099\n",
      "[561/00024] train_loss: 0.009077 kl_loss: 0.000000 normal_loss: 0.009077\n",
      "[562/00049] train_loss: 0.009059 kl_loss: 0.000000 normal_loss: 0.009059\n",
      "[563/00074] train_loss: 0.009095 kl_loss: 0.000000 normal_loss: 0.009095\n",
      "[565/00024] train_loss: 0.009057 kl_loss: 0.000000 normal_loss: 0.009057\n",
      "[566/00049] train_loss: 0.009075 kl_loss: 0.000000 normal_loss: 0.009075\n",
      "[567/00074] train_loss: 0.009095 kl_loss: 0.000000 normal_loss: 0.009095\n",
      "[569/00024] train_loss: 0.009080 kl_loss: 0.000000 normal_loss: 0.009080\n",
      "[570/00049] train_loss: 0.009121 kl_loss: 0.000000 normal_loss: 0.009121\n",
      "[571/00074] train_loss: 0.009088 kl_loss: 0.000000 normal_loss: 0.009088\n",
      "[573/00024] train_loss: 0.009042 kl_loss: 0.000000 normal_loss: 0.009042\n",
      "[574/00049] train_loss: 0.009119 kl_loss: 0.000000 normal_loss: 0.009119\n",
      "[575/00074] train_loss: 0.009072 kl_loss: 0.000000 normal_loss: 0.009072\n",
      "[577/00024] train_loss: 0.009044 kl_loss: 0.000000 normal_loss: 0.009044\n",
      "[578/00049] train_loss: 0.009084 kl_loss: 0.000000 normal_loss: 0.009084\n",
      "[579/00074] train_loss: 0.009063 kl_loss: 0.000000 normal_loss: 0.009063\n",
      "[581/00024] train_loss: 0.009070 kl_loss: 0.000000 normal_loss: 0.009070\n",
      "[582/00049] train_loss: 0.009110 kl_loss: 0.000000 normal_loss: 0.009110\n",
      "[583/00074] train_loss: 0.009051 kl_loss: 0.000000 normal_loss: 0.009051\n",
      "[585/00024] train_loss: 0.009094 kl_loss: 0.000000 normal_loss: 0.009094\n",
      "[586/00049] train_loss: 0.009072 kl_loss: 0.000000 normal_loss: 0.009072\n",
      "[587/00074] train_loss: 0.009042 kl_loss: 0.000000 normal_loss: 0.009042\n",
      "[589/00024] train_loss: 0.009039 kl_loss: 0.000000 normal_loss: 0.009039\n",
      "[590/00049] train_loss: 0.009043 kl_loss: 0.000000 normal_loss: 0.009043\n",
      "[591/00074] train_loss: 0.009093 kl_loss: 0.000000 normal_loss: 0.009093\n",
      "[593/00024] train_loss: 0.009024 kl_loss: 0.000000 normal_loss: 0.009024\n",
      "[594/00049] train_loss: 0.009068 kl_loss: 0.000000 normal_loss: 0.009068\n",
      "[595/00074] train_loss: 0.009055 kl_loss: 0.000000 normal_loss: 0.009055\n",
      "[597/00024] train_loss: 0.009086 kl_loss: 0.000000 normal_loss: 0.009086\n",
      "[598/00049] train_loss: 0.009089 kl_loss: 0.000000 normal_loss: 0.009089\n",
      "[599/00074] train_loss: 0.009002 kl_loss: 0.000000 normal_loss: 0.009002\n",
      "[599/00074] IOU 0.9207689363136887\n",
      "[601/00024] train_loss: 0.008974 kl_loss: 0.000000 normal_loss: 0.008974\n",
      "[602/00049] train_loss: 0.008986 kl_loss: 0.000000 normal_loss: 0.008986\n",
      "[603/00074] train_loss: 0.009004 kl_loss: 0.000000 normal_loss: 0.009004\n",
      "[605/00024] train_loss: 0.008993 kl_loss: 0.000000 normal_loss: 0.008993\n",
      "[606/00049] train_loss: 0.008920 kl_loss: 0.000000 normal_loss: 0.008920\n",
      "[607/00074] train_loss: 0.008993 kl_loss: 0.000000 normal_loss: 0.008993\n",
      "[609/00024] train_loss: 0.008979 kl_loss: 0.000000 normal_loss: 0.008979\n",
      "[610/00049] train_loss: 0.008967 kl_loss: 0.000000 normal_loss: 0.008967\n",
      "[611/00074] train_loss: 0.008987 kl_loss: 0.000000 normal_loss: 0.008987\n",
      "[613/00024] train_loss: 0.008939 kl_loss: 0.000000 normal_loss: 0.008939\n",
      "[614/00049] train_loss: 0.009030 kl_loss: 0.000000 normal_loss: 0.009030\n",
      "[615/00074] train_loss: 0.008957 kl_loss: 0.000000 normal_loss: 0.008957\n",
      "[617/00024] train_loss: 0.008989 kl_loss: 0.000000 normal_loss: 0.008989\n",
      "[618/00049] train_loss: 0.008979 kl_loss: 0.000000 normal_loss: 0.008979\n",
      "[619/00074] train_loss: 0.008958 kl_loss: 0.000000 normal_loss: 0.008958\n",
      "[621/00024] train_loss: 0.008922 kl_loss: 0.000000 normal_loss: 0.008922\n",
      "[622/00049] train_loss: 0.008992 kl_loss: 0.000000 normal_loss: 0.008992\n",
      "[623/00074] train_loss: 0.008990 kl_loss: 0.000000 normal_loss: 0.008990\n",
      "[625/00024] train_loss: 0.008965 kl_loss: 0.000000 normal_loss: 0.008965\n",
      "[626/00049] train_loss: 0.008937 kl_loss: 0.000000 normal_loss: 0.008937\n",
      "[627/00074] train_loss: 0.008999 kl_loss: 0.000000 normal_loss: 0.008999\n",
      "[629/00024] train_loss: 0.008934 kl_loss: 0.000000 normal_loss: 0.008934\n",
      "[630/00049] train_loss: 0.009042 kl_loss: 0.000000 normal_loss: 0.009042\n",
      "[631/00074] train_loss: 0.008947 kl_loss: 0.000000 normal_loss: 0.008947\n",
      "[633/00024] train_loss: 0.008940 kl_loss: 0.000000 normal_loss: 0.008940\n",
      "[634/00049] train_loss: 0.008986 kl_loss: 0.000000 normal_loss: 0.008986\n",
      "[635/00074] train_loss: 0.008986 kl_loss: 0.000000 normal_loss: 0.008986\n",
      "[637/00024] train_loss: 0.008987 kl_loss: 0.000000 normal_loss: 0.008987\n",
      "[638/00049] train_loss: 0.008953 kl_loss: 0.000000 normal_loss: 0.008953\n",
      "[639/00074] train_loss: 0.008958 kl_loss: 0.000000 normal_loss: 0.008958\n",
      "[641/00024] train_loss: 0.008921 kl_loss: 0.000000 normal_loss: 0.008921\n",
      "[642/00049] train_loss: 0.008987 kl_loss: 0.000000 normal_loss: 0.008987\n",
      "[643/00074] train_loss: 0.008983 kl_loss: 0.000000 normal_loss: 0.008983\n",
      "[645/00024] train_loss: 0.008982 kl_loss: 0.000000 normal_loss: 0.008982\n",
      "[646/00049] train_loss: 0.008947 kl_loss: 0.000000 normal_loss: 0.008947\n",
      "[647/00074] train_loss: 0.008970 kl_loss: 0.000000 normal_loss: 0.008970\n",
      "[649/00024] train_loss: 0.008954 kl_loss: 0.000000 normal_loss: 0.008954\n",
      "[649/00074] IOU 0.9200765140975515\n",
      "[650/00049] train_loss: 0.008913 kl_loss: 0.000000 normal_loss: 0.008913\n",
      "[651/00074] train_loss: 0.008990 kl_loss: 0.000000 normal_loss: 0.008990\n",
      "[653/00024] train_loss: 0.008923 kl_loss: 0.000000 normal_loss: 0.008923\n",
      "[654/00049] train_loss: 0.008993 kl_loss: 0.000000 normal_loss: 0.008993\n",
      "[655/00074] train_loss: 0.008922 kl_loss: 0.000000 normal_loss: 0.008922\n",
      "[657/00024] train_loss: 0.008969 kl_loss: 0.000000 normal_loss: 0.008969\n",
      "[658/00049] train_loss: 0.008977 kl_loss: 0.000000 normal_loss: 0.008977\n",
      "[659/00074] train_loss: 0.008952 kl_loss: 0.000000 normal_loss: 0.008952\n",
      "[661/00024] train_loss: 0.008921 kl_loss: 0.000000 normal_loss: 0.008921\n",
      "[662/00049] train_loss: 0.008931 kl_loss: 0.000000 normal_loss: 0.008931\n",
      "[663/00074] train_loss: 0.008972 kl_loss: 0.000000 normal_loss: 0.008972\n",
      "[665/00024] train_loss: 0.008936 kl_loss: 0.000000 normal_loss: 0.008936\n",
      "[666/00049] train_loss: 0.009000 kl_loss: 0.000000 normal_loss: 0.009000\n",
      "[667/00074] train_loss: 0.008916 kl_loss: 0.000000 normal_loss: 0.008916\n",
      "[669/00024] train_loss: 0.008925 kl_loss: 0.000000 normal_loss: 0.008925\n",
      "[670/00049] train_loss: 0.008915 kl_loss: 0.000000 normal_loss: 0.008915\n",
      "[671/00074] train_loss: 0.008993 kl_loss: 0.000000 normal_loss: 0.008993\n",
      "[673/00024] train_loss: 0.008948 kl_loss: 0.000000 normal_loss: 0.008948\n",
      "[674/00049] train_loss: 0.008964 kl_loss: 0.000000 normal_loss: 0.008964\n",
      "[675/00074] train_loss: 0.008935 kl_loss: 0.000000 normal_loss: 0.008935\n",
      "[677/00024] train_loss: 0.008906 kl_loss: 0.000000 normal_loss: 0.008906\n",
      "[678/00049] train_loss: 0.008982 kl_loss: 0.000000 normal_loss: 0.008982\n",
      "[679/00074] train_loss: 0.008942 kl_loss: 0.000000 normal_loss: 0.008942\n",
      "[681/00024] train_loss: 0.008948 kl_loss: 0.000000 normal_loss: 0.008948\n",
      "[682/00049] train_loss: 0.008919 kl_loss: 0.000000 normal_loss: 0.008919\n",
      "[683/00074] train_loss: 0.008972 kl_loss: 0.000000 normal_loss: 0.008972\n",
      "[685/00024] train_loss: 0.008942 kl_loss: 0.000000 normal_loss: 0.008942\n",
      "[686/00049] train_loss: 0.008912 kl_loss: 0.000000 normal_loss: 0.008912\n",
      "[687/00074] train_loss: 0.008972 kl_loss: 0.000000 normal_loss: 0.008972\n",
      "[689/00024] train_loss: 0.008890 kl_loss: 0.000000 normal_loss: 0.008890\n",
      "[690/00049] train_loss: 0.008965 kl_loss: 0.000000 normal_loss: 0.008965\n",
      "[691/00074] train_loss: 0.008940 kl_loss: 0.000000 normal_loss: 0.008940\n",
      "[693/00024] train_loss: 0.008908 kl_loss: 0.000000 normal_loss: 0.008908\n",
      "[694/00049] train_loss: 0.008959 kl_loss: 0.000000 normal_loss: 0.008959\n",
      "[695/00074] train_loss: 0.008904 kl_loss: 0.000000 normal_loss: 0.008904\n",
      "[697/00024] train_loss: 0.008909 kl_loss: 0.000000 normal_loss: 0.008909\n",
      "[698/00049] train_loss: 0.008904 kl_loss: 0.000000 normal_loss: 0.008904\n",
      "[699/00074] train_loss: 0.008957 kl_loss: 0.000000 normal_loss: 0.008957\n",
      "[699/00074] IOU 0.9203456947021187\n",
      "[701/00024] train_loss: 0.008897 kl_loss: 0.000000 normal_loss: 0.008897\n",
      "[702/00049] train_loss: 0.008879 kl_loss: 0.000000 normal_loss: 0.008879\n",
      "[703/00074] train_loss: 0.008902 kl_loss: 0.000000 normal_loss: 0.008902\n",
      "[705/00024] train_loss: 0.008885 kl_loss: 0.000000 normal_loss: 0.008885\n",
      "[706/00049] train_loss: 0.008929 kl_loss: 0.000000 normal_loss: 0.008929\n",
      "[707/00074] train_loss: 0.008870 kl_loss: 0.000000 normal_loss: 0.008870\n",
      "[709/00024] train_loss: 0.008878 kl_loss: 0.000000 normal_loss: 0.008878\n",
      "[710/00049] train_loss: 0.008897 kl_loss: 0.000000 normal_loss: 0.008897\n",
      "[711/00074] train_loss: 0.008915 kl_loss: 0.000000 normal_loss: 0.008915\n",
      "[713/00024] train_loss: 0.008842 kl_loss: 0.000000 normal_loss: 0.008842\n",
      "[714/00049] train_loss: 0.008908 kl_loss: 0.000000 normal_loss: 0.008908\n",
      "[715/00074] train_loss: 0.008912 kl_loss: 0.000000 normal_loss: 0.008912\n",
      "[717/00024] train_loss: 0.008860 kl_loss: 0.000000 normal_loss: 0.008860\n",
      "[718/00049] train_loss: 0.008933 kl_loss: 0.000000 normal_loss: 0.008933\n",
      "[719/00074] train_loss: 0.008890 kl_loss: 0.000000 normal_loss: 0.008890\n",
      "[721/00024] train_loss: 0.008871 kl_loss: 0.000000 normal_loss: 0.008871\n",
      "[722/00049] train_loss: 0.008932 kl_loss: 0.000000 normal_loss: 0.008932\n",
      "[723/00074] train_loss: 0.008848 kl_loss: 0.000000 normal_loss: 0.008848\n",
      "[725/00024] train_loss: 0.008893 kl_loss: 0.000000 normal_loss: 0.008893\n",
      "[726/00049] train_loss: 0.008910 kl_loss: 0.000000 normal_loss: 0.008910\n",
      "[727/00074] train_loss: 0.008876 kl_loss: 0.000000 normal_loss: 0.008876\n",
      "[729/00024] train_loss: 0.008910 kl_loss: 0.000000 normal_loss: 0.008910\n",
      "[730/00049] train_loss: 0.008856 kl_loss: 0.000000 normal_loss: 0.008856\n",
      "[731/00074] train_loss: 0.008893 kl_loss: 0.000000 normal_loss: 0.008893\n",
      "[733/00024] train_loss: 0.008882 kl_loss: 0.000000 normal_loss: 0.008882\n",
      "[734/00049] train_loss: 0.008915 kl_loss: 0.000000 normal_loss: 0.008915\n",
      "[735/00074] train_loss: 0.008858 kl_loss: 0.000000 normal_loss: 0.008858\n",
      "[737/00024] train_loss: 0.008913 kl_loss: 0.000000 normal_loss: 0.008913\n",
      "[738/00049] train_loss: 0.008847 kl_loss: 0.000000 normal_loss: 0.008847\n",
      "[739/00074] train_loss: 0.008891 kl_loss: 0.000000 normal_loss: 0.008891\n",
      "[741/00024] train_loss: 0.008855 kl_loss: 0.000000 normal_loss: 0.008855\n",
      "[742/00049] train_loss: 0.008925 kl_loss: 0.000000 normal_loss: 0.008925\n",
      "[743/00074] train_loss: 0.008869 kl_loss: 0.000000 normal_loss: 0.008869\n",
      "[745/00024] train_loss: 0.008864 kl_loss: 0.000000 normal_loss: 0.008864\n",
      "[746/00049] train_loss: 0.008849 kl_loss: 0.000000 normal_loss: 0.008849\n",
      "[747/00074] train_loss: 0.008954 kl_loss: 0.000000 normal_loss: 0.008954\n",
      "[749/00024] train_loss: 0.008868 kl_loss: 0.000000 normal_loss: 0.008868\n",
      "[749/00074] IOU 0.9206733241987725\n",
      "[750/00049] train_loss: 0.008890 kl_loss: 0.000000 normal_loss: 0.008890\n",
      "[751/00074] train_loss: 0.008913 kl_loss: 0.000000 normal_loss: 0.008913\n",
      "[753/00024] train_loss: 0.008889 kl_loss: 0.000000 normal_loss: 0.008889\n",
      "[754/00049] train_loss: 0.008861 kl_loss: 0.000000 normal_loss: 0.008861\n",
      "[755/00074] train_loss: 0.008901 kl_loss: 0.000000 normal_loss: 0.008901\n",
      "[757/00024] train_loss: 0.008864 kl_loss: 0.000000 normal_loss: 0.008864\n",
      "[758/00049] train_loss: 0.008924 kl_loss: 0.000000 normal_loss: 0.008924\n",
      "[759/00074] train_loss: 0.008848 kl_loss: 0.000000 normal_loss: 0.008848\n",
      "[761/00024] train_loss: 0.008893 kl_loss: 0.000000 normal_loss: 0.008893\n",
      "[762/00049] train_loss: 0.008885 kl_loss: 0.000000 normal_loss: 0.008885\n",
      "[763/00074] train_loss: 0.008865 kl_loss: 0.000000 normal_loss: 0.008865\n",
      "[765/00024] train_loss: 0.008838 kl_loss: 0.000000 normal_loss: 0.008838\n",
      "[766/00049] train_loss: 0.008929 kl_loss: 0.000000 normal_loss: 0.008929\n",
      "[767/00074] train_loss: 0.008846 kl_loss: 0.000000 normal_loss: 0.008846\n",
      "[769/00024] train_loss: 0.008891 kl_loss: 0.000000 normal_loss: 0.008891\n",
      "[770/00049] train_loss: 0.008853 kl_loss: 0.000000 normal_loss: 0.008853\n",
      "[771/00074] train_loss: 0.008862 kl_loss: 0.000000 normal_loss: 0.008862\n",
      "[773/00024] train_loss: 0.008867 kl_loss: 0.000000 normal_loss: 0.008867\n",
      "[774/00049] train_loss: 0.008847 kl_loss: 0.000000 normal_loss: 0.008847\n",
      "[775/00074] train_loss: 0.008913 kl_loss: 0.000000 normal_loss: 0.008913\n",
      "[777/00024] train_loss: 0.008846 kl_loss: 0.000000 normal_loss: 0.008846\n",
      "[778/00049] train_loss: 0.008896 kl_loss: 0.000000 normal_loss: 0.008896\n",
      "[779/00074] train_loss: 0.008870 kl_loss: 0.000000 normal_loss: 0.008870\n",
      "[781/00024] train_loss: 0.008844 kl_loss: 0.000000 normal_loss: 0.008844\n",
      "[782/00049] train_loss: 0.008896 kl_loss: 0.000000 normal_loss: 0.008896\n",
      "[783/00074] train_loss: 0.008865 kl_loss: 0.000000 normal_loss: 0.008865\n",
      "[785/00024] train_loss: 0.008866 kl_loss: 0.000000 normal_loss: 0.008866\n",
      "[786/00049] train_loss: 0.008879 kl_loss: 0.000000 normal_loss: 0.008879\n",
      "[787/00074] train_loss: 0.008874 kl_loss: 0.000000 normal_loss: 0.008874\n",
      "[789/00024] train_loss: 0.008821 kl_loss: 0.000000 normal_loss: 0.008821\n",
      "[790/00049] train_loss: 0.008920 kl_loss: 0.000000 normal_loss: 0.008920\n",
      "[791/00074] train_loss: 0.008867 kl_loss: 0.000000 normal_loss: 0.008867\n",
      "[793/00024] train_loss: 0.008870 kl_loss: 0.000000 normal_loss: 0.008870\n",
      "[794/00049] train_loss: 0.008847 kl_loss: 0.000000 normal_loss: 0.008847\n",
      "[795/00074] train_loss: 0.008875 kl_loss: 0.000000 normal_loss: 0.008875\n",
      "[797/00024] train_loss: 0.008860 kl_loss: 0.000000 normal_loss: 0.008860\n",
      "[798/00049] train_loss: 0.008857 kl_loss: 0.000000 normal_loss: 0.008857\n",
      "[799/00074] train_loss: 0.008879 kl_loss: 0.000000 normal_loss: 0.008879\n",
      "[799/00074] IOU 0.9212639772891998\n",
      "[801/00024] train_loss: 0.008889 kl_loss: 0.000000 normal_loss: 0.008889\n",
      "[802/00049] train_loss: 0.008834 kl_loss: 0.000000 normal_loss: 0.008834\n",
      "[803/00074] train_loss: 0.008850 kl_loss: 0.000000 normal_loss: 0.008850\n",
      "[805/00024] train_loss: 0.008861 kl_loss: 0.000000 normal_loss: 0.008861\n",
      "[806/00049] train_loss: 0.008835 kl_loss: 0.000000 normal_loss: 0.008835\n",
      "[807/00074] train_loss: 0.008834 kl_loss: 0.000000 normal_loss: 0.008834\n",
      "[809/00024] train_loss: 0.008861 kl_loss: 0.000000 normal_loss: 0.008861\n",
      "[810/00049] train_loss: 0.008841 kl_loss: 0.000000 normal_loss: 0.008841\n",
      "[811/00074] train_loss: 0.008848 kl_loss: 0.000000 normal_loss: 0.008848\n",
      "[813/00024] train_loss: 0.008859 kl_loss: 0.000000 normal_loss: 0.008859\n",
      "[814/00049] train_loss: 0.008855 kl_loss: 0.000000 normal_loss: 0.008855\n",
      "[815/00074] train_loss: 0.008856 kl_loss: 0.000000 normal_loss: 0.008856\n",
      "[817/00024] train_loss: 0.008859 kl_loss: 0.000000 normal_loss: 0.008859\n",
      "[818/00049] train_loss: 0.008881 kl_loss: 0.000000 normal_loss: 0.008881\n",
      "[819/00074] train_loss: 0.008811 kl_loss: 0.000000 normal_loss: 0.008811\n",
      "[821/00024] train_loss: 0.008852 kl_loss: 0.000000 normal_loss: 0.008852\n",
      "[822/00049] train_loss: 0.008847 kl_loss: 0.000000 normal_loss: 0.008847\n",
      "[823/00074] train_loss: 0.008841 kl_loss: 0.000000 normal_loss: 0.008841\n",
      "[825/00024] train_loss: 0.008850 kl_loss: 0.000000 normal_loss: 0.008850\n",
      "[826/00049] train_loss: 0.008864 kl_loss: 0.000000 normal_loss: 0.008864\n",
      "[827/00074] train_loss: 0.008829 kl_loss: 0.000000 normal_loss: 0.008829\n",
      "[829/00024] train_loss: 0.008869 kl_loss: 0.000000 normal_loss: 0.008869\n",
      "[830/00049] train_loss: 0.008801 kl_loss: 0.000000 normal_loss: 0.008801\n",
      "[831/00074] train_loss: 0.008871 kl_loss: 0.000000 normal_loss: 0.008871\n",
      "[833/00024] train_loss: 0.008859 kl_loss: 0.000000 normal_loss: 0.008859\n",
      "[834/00049] train_loss: 0.008835 kl_loss: 0.000000 normal_loss: 0.008835\n",
      "[835/00074] train_loss: 0.008843 kl_loss: 0.000000 normal_loss: 0.008843\n",
      "[837/00024] train_loss: 0.008864 kl_loss: 0.000000 normal_loss: 0.008864\n",
      "[838/00049] train_loss: 0.008798 kl_loss: 0.000000 normal_loss: 0.008798\n",
      "[839/00074] train_loss: 0.008880 kl_loss: 0.000000 normal_loss: 0.008880\n",
      "[841/00024] train_loss: 0.008864 kl_loss: 0.000000 normal_loss: 0.008864\n",
      "[842/00049] train_loss: 0.008808 kl_loss: 0.000000 normal_loss: 0.008808\n",
      "[843/00074] train_loss: 0.008853 kl_loss: 0.000000 normal_loss: 0.008853\n",
      "[845/00024] train_loss: 0.008864 kl_loss: 0.000000 normal_loss: 0.008864\n",
      "[846/00049] train_loss: 0.008835 kl_loss: 0.000000 normal_loss: 0.008835\n",
      "[847/00074] train_loss: 0.008820 kl_loss: 0.000000 normal_loss: 0.008820\n",
      "[849/00024] train_loss: 0.008864 kl_loss: 0.000000 normal_loss: 0.008864\n",
      "[849/00074] IOU 0.9209131120455761\n",
      "[850/00049] train_loss: 0.008826 kl_loss: 0.000000 normal_loss: 0.008826\n",
      "[851/00074] train_loss: 0.008846 kl_loss: 0.000000 normal_loss: 0.008846\n",
      "[853/00024] train_loss: 0.008839 kl_loss: 0.000000 normal_loss: 0.008839\n",
      "[854/00049] train_loss: 0.008852 kl_loss: 0.000000 normal_loss: 0.008852\n",
      "[855/00074] train_loss: 0.008835 kl_loss: 0.000000 normal_loss: 0.008835\n",
      "[857/00024] train_loss: 0.008852 kl_loss: 0.000000 normal_loss: 0.008852\n",
      "[858/00049] train_loss: 0.008877 kl_loss: 0.000000 normal_loss: 0.008877\n",
      "[859/00074] train_loss: 0.008828 kl_loss: 0.000000 normal_loss: 0.008828\n",
      "[861/00024] train_loss: 0.008839 kl_loss: 0.000000 normal_loss: 0.008839\n",
      "[862/00049] train_loss: 0.008820 kl_loss: 0.000000 normal_loss: 0.008820\n",
      "[863/00074] train_loss: 0.008895 kl_loss: 0.000000 normal_loss: 0.008895\n",
      "[865/00024] train_loss: 0.008860 kl_loss: 0.000000 normal_loss: 0.008860\n",
      "[866/00049] train_loss: 0.008825 kl_loss: 0.000000 normal_loss: 0.008825\n",
      "[867/00074] train_loss: 0.008839 kl_loss: 0.000000 normal_loss: 0.008839\n",
      "[869/00024] train_loss: 0.008843 kl_loss: 0.000000 normal_loss: 0.008843\n",
      "[870/00049] train_loss: 0.008852 kl_loss: 0.000000 normal_loss: 0.008852\n",
      "[871/00074] train_loss: 0.008830 kl_loss: 0.000000 normal_loss: 0.008830\n",
      "[873/00024] train_loss: 0.008818 kl_loss: 0.000000 normal_loss: 0.008818\n",
      "[874/00049] train_loss: 0.008880 kl_loss: 0.000000 normal_loss: 0.008880\n",
      "[875/00074] train_loss: 0.008827 kl_loss: 0.000000 normal_loss: 0.008827\n",
      "[877/00024] train_loss: 0.008828 kl_loss: 0.000000 normal_loss: 0.008828\n",
      "[878/00049] train_loss: 0.008855 kl_loss: 0.000000 normal_loss: 0.008855\n",
      "[879/00074] train_loss: 0.008834 kl_loss: 0.000000 normal_loss: 0.008834\n",
      "[881/00024] train_loss: 0.008890 kl_loss: 0.000000 normal_loss: 0.008890\n",
      "[882/00049] train_loss: 0.008822 kl_loss: 0.000000 normal_loss: 0.008822\n",
      "[883/00074] train_loss: 0.008796 kl_loss: 0.000000 normal_loss: 0.008796\n",
      "[885/00024] train_loss: 0.008867 kl_loss: 0.000000 normal_loss: 0.008867\n",
      "[886/00049] train_loss: 0.008846 kl_loss: 0.000000 normal_loss: 0.008846\n",
      "[887/00074] train_loss: 0.008789 kl_loss: 0.000000 normal_loss: 0.008789\n",
      "[889/00024] train_loss: 0.008839 kl_loss: 0.000000 normal_loss: 0.008839\n",
      "[890/00049] train_loss: 0.008831 kl_loss: 0.000000 normal_loss: 0.008831\n",
      "[891/00074] train_loss: 0.008844 kl_loss: 0.000000 normal_loss: 0.008844\n",
      "[893/00024] train_loss: 0.008832 kl_loss: 0.000000 normal_loss: 0.008832\n",
      "[894/00049] train_loss: 0.008781 kl_loss: 0.000000 normal_loss: 0.008781\n",
      "[895/00074] train_loss: 0.008888 kl_loss: 0.000000 normal_loss: 0.008888\n",
      "[897/00024] train_loss: 0.008863 kl_loss: 0.000000 normal_loss: 0.008863\n",
      "[898/00049] train_loss: 0.008773 kl_loss: 0.000000 normal_loss: 0.008773\n",
      "[899/00074] train_loss: 0.008882 kl_loss: 0.000000 normal_loss: 0.008882\n",
      "[899/00074] IOU 0.920868968218565\n",
      "[901/00024] train_loss: 0.008815 kl_loss: 0.000000 normal_loss: 0.008815\n",
      "[902/00049] train_loss: 0.008821 kl_loss: 0.000000 normal_loss: 0.008821\n",
      "[903/00074] train_loss: 0.008823 kl_loss: 0.000000 normal_loss: 0.008823\n",
      "[905/00024] train_loss: 0.008846 kl_loss: 0.000000 normal_loss: 0.008846\n",
      "[906/00049] train_loss: 0.008785 kl_loss: 0.000000 normal_loss: 0.008785\n",
      "[907/00074] train_loss: 0.008859 kl_loss: 0.000000 normal_loss: 0.008859\n",
      "[909/00024] train_loss: 0.008804 kl_loss: 0.000000 normal_loss: 0.008804\n",
      "[910/00049] train_loss: 0.008860 kl_loss: 0.000000 normal_loss: 0.008860\n",
      "[911/00074] train_loss: 0.008784 kl_loss: 0.000000 normal_loss: 0.008784\n",
      "[913/00024] train_loss: 0.008809 kl_loss: 0.000000 normal_loss: 0.008809\n",
      "[914/00049] train_loss: 0.008815 kl_loss: 0.000000 normal_loss: 0.008815\n",
      "[915/00074] train_loss: 0.008861 kl_loss: 0.000000 normal_loss: 0.008861\n",
      "[917/00024] train_loss: 0.008834 kl_loss: 0.000000 normal_loss: 0.008834\n",
      "[918/00049] train_loss: 0.008780 kl_loss: 0.000000 normal_loss: 0.008780\n",
      "[919/00074] train_loss: 0.008858 kl_loss: 0.000000 normal_loss: 0.008858\n",
      "[921/00024] train_loss: 0.008825 kl_loss: 0.000000 normal_loss: 0.008825\n",
      "[922/00049] train_loss: 0.008843 kl_loss: 0.000000 normal_loss: 0.008843\n",
      "[923/00074] train_loss: 0.008824 kl_loss: 0.000000 normal_loss: 0.008824\n",
      "[925/00024] train_loss: 0.008837 kl_loss: 0.000000 normal_loss: 0.008837\n",
      "[926/00049] train_loss: 0.008758 kl_loss: 0.000000 normal_loss: 0.008758\n",
      "[927/00074] train_loss: 0.008868 kl_loss: 0.000000 normal_loss: 0.008868\n",
      "[929/00024] train_loss: 0.008844 kl_loss: 0.000000 normal_loss: 0.008844\n",
      "[930/00049] train_loss: 0.008777 kl_loss: 0.000000 normal_loss: 0.008777\n",
      "[931/00074] train_loss: 0.008839 kl_loss: 0.000000 normal_loss: 0.008839\n",
      "[933/00024] train_loss: 0.008813 kl_loss: 0.000000 normal_loss: 0.008813\n",
      "[934/00049] train_loss: 0.008866 kl_loss: 0.000000 normal_loss: 0.008866\n",
      "[935/00074] train_loss: 0.008775 kl_loss: 0.000000 normal_loss: 0.008775\n",
      "[937/00024] train_loss: 0.008839 kl_loss: 0.000000 normal_loss: 0.008839\n",
      "[938/00049] train_loss: 0.008792 kl_loss: 0.000000 normal_loss: 0.008792\n",
      "[939/00074] train_loss: 0.008833 kl_loss: 0.000000 normal_loss: 0.008833\n",
      "[941/00024] train_loss: 0.008806 kl_loss: 0.000000 normal_loss: 0.008806\n",
      "[942/00049] train_loss: 0.008847 kl_loss: 0.000000 normal_loss: 0.008847\n",
      "[943/00074] train_loss: 0.008811 kl_loss: 0.000000 normal_loss: 0.008811\n",
      "[945/00024] train_loss: 0.008791 kl_loss: 0.000000 normal_loss: 0.008791\n",
      "[946/00049] train_loss: 0.008838 kl_loss: 0.000000 normal_loss: 0.008838\n",
      "[947/00074] train_loss: 0.008817 kl_loss: 0.000000 normal_loss: 0.008817\n",
      "[949/00024] train_loss: 0.008826 kl_loss: 0.000000 normal_loss: 0.008826\n",
      "[949/00074] IOU 0.9210172387460868\n",
      "[950/00049] train_loss: 0.008805 kl_loss: 0.000000 normal_loss: 0.008805\n",
      "[951/00074] train_loss: 0.008831 kl_loss: 0.000000 normal_loss: 0.008831\n",
      "[953/00024] train_loss: 0.008813 kl_loss: 0.000000 normal_loss: 0.008813\n",
      "[954/00049] train_loss: 0.008855 kl_loss: 0.000000 normal_loss: 0.008855\n",
      "[955/00074] train_loss: 0.008788 kl_loss: 0.000000 normal_loss: 0.008788\n",
      "[957/00024] train_loss: 0.008814 kl_loss: 0.000000 normal_loss: 0.008814\n",
      "[958/00049] train_loss: 0.008825 kl_loss: 0.000000 normal_loss: 0.008825\n",
      "[959/00074] train_loss: 0.008822 kl_loss: 0.000000 normal_loss: 0.008822\n",
      "[961/00024] train_loss: 0.008824 kl_loss: 0.000000 normal_loss: 0.008824\n",
      "[962/00049] train_loss: 0.008787 kl_loss: 0.000000 normal_loss: 0.008787\n",
      "[963/00074] train_loss: 0.008850 kl_loss: 0.000000 normal_loss: 0.008850\n",
      "[965/00024] train_loss: 0.008786 kl_loss: 0.000000 normal_loss: 0.008786\n",
      "[966/00049] train_loss: 0.008848 kl_loss: 0.000000 normal_loss: 0.008848\n",
      "[967/00074] train_loss: 0.008827 kl_loss: 0.000000 normal_loss: 0.008827\n",
      "[969/00024] train_loss: 0.008783 kl_loss: 0.000000 normal_loss: 0.008783\n",
      "[970/00049] train_loss: 0.008854 kl_loss: 0.000000 normal_loss: 0.008854\n",
      "[971/00074] train_loss: 0.008793 kl_loss: 0.000000 normal_loss: 0.008793\n",
      "[973/00024] train_loss: 0.008816 kl_loss: 0.000000 normal_loss: 0.008816\n",
      "[974/00049] train_loss: 0.008807 kl_loss: 0.000000 normal_loss: 0.008807\n",
      "[975/00074] train_loss: 0.008841 kl_loss: 0.000000 normal_loss: 0.008841\n",
      "[977/00024] train_loss: 0.008831 kl_loss: 0.000000 normal_loss: 0.008831\n",
      "[978/00049] train_loss: 0.008759 kl_loss: 0.000000 normal_loss: 0.008759\n",
      "[979/00074] train_loss: 0.008853 kl_loss: 0.000000 normal_loss: 0.008853\n",
      "[981/00024] train_loss: 0.008830 kl_loss: 0.000000 normal_loss: 0.008830\n",
      "[982/00049] train_loss: 0.008862 kl_loss: 0.000000 normal_loss: 0.008862\n",
      "[983/00074] train_loss: 0.008783 kl_loss: 0.000000 normal_loss: 0.008783\n",
      "[985/00024] train_loss: 0.008787 kl_loss: 0.000000 normal_loss: 0.008787\n",
      "[986/00049] train_loss: 0.008811 kl_loss: 0.000000 normal_loss: 0.008811\n",
      "[987/00074] train_loss: 0.008839 kl_loss: 0.000000 normal_loss: 0.008839\n",
      "[989/00024] train_loss: 0.008858 kl_loss: 0.000000 normal_loss: 0.008858\n",
      "[990/00049] train_loss: 0.008791 kl_loss: 0.000000 normal_loss: 0.008791\n",
      "[991/00074] train_loss: 0.008812 kl_loss: 0.000000 normal_loss: 0.008812\n",
      "[993/00024] train_loss: 0.008866 kl_loss: 0.000000 normal_loss: 0.008866\n",
      "[994/00049] train_loss: 0.008793 kl_loss: 0.000000 normal_loss: 0.008793\n",
      "[995/00074] train_loss: 0.008821 kl_loss: 0.000000 normal_loss: 0.008821\n",
      "[997/00024] train_loss: 0.008815 kl_loss: 0.000000 normal_loss: 0.008815\n",
      "[998/00049] train_loss: 0.008824 kl_loss: 0.000000 normal_loss: 0.008824\n",
      "[999/00074] train_loss: 0.008800 kl_loss: 0.000000 normal_loss: 0.008800\n",
      "[999/00074] IOU 0.9210172180334727\n"
     ]
    }
   ],
   "source": [
    "# CHAIR AD\n",
    "from scripts import train\n",
    "config = {\n",
    "    'experiment_name': 'chair_ad',\n",
    "    'device': 'cuda:0',\n",
    "    'is_overfit': False,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate_model': 0.01,\n",
    "    'learning_rate_code': 0.01,\n",
    "    'learning_rate_log_var':0.01,\n",
    "    'max_epochs': 1000,\n",
    "    'print_every_n': 100,\n",
    "    'latent_code_length' : 256,\n",
    "    'scheduler_step_size': 100,\n",
    "    'vad_free' : False,\n",
    "    'test': False,\n",
    "    'kl_weight': 0.03,\n",
    "    'kl_weight_increase_every_epochs': 100,\n",
    "    'kl_weight_increase_value': 0.0,\n",
    "    'iou_every_epoch': 50,\n",
    "    'resume_ckpt': None,\n",
    "    'filter_class': 'chair',\n",
    "    'decoder_var' : False\n",
    "}\n",
    "train.main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TABLE VAD\n",
    "from scripts import train\n",
    "config = {\n",
    "    'experiment_name': 'table_vad',\n",
    "    'device': 'cuda:0',\n",
    "    'is_overfit': False,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate_model': 0.01,\n",
    "    'learning_rate_code': 0.01,\n",
    "    'learning_rate_log_var':0.01,\n",
    "    'max_epochs': 1000,\n",
    "    'print_every_n': 100,\n",
    "    'latent_code_length' : 256,\n",
    "    'scheduler_step_size': 100,\n",
    "    'vad_free' : True,\n",
    "    'test': False,\n",
    "    'kl_weight': 0.03,\n",
    "    'kl_weight_increase_every_epochs': 100,\n",
    "    'kl_weight_increase_value': 0.01,\n",
    "    'resume_ckpt': 'table_vad',\n",
    "    'filter_class': 'table',\n",
    "    'decoder_var' : True\n",
    "}\n",
    "train.main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIRPLANE VAD\n",
    "from scripts import train\n",
    "config = {\n",
    "    'experiment_name': 'airplane_vad',\n",
    "    'device': 'cuda:0',\n",
    "    'is_overfit': False,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate_model': 0.01,\n",
    "    'learning_rate_code': 0.01,\n",
    "    'learning_rate_log_var':0.01,\n",
    "    'max_epochs': 1000,\n",
    "    'print_every_n': 100,\n",
    "    'latent_code_length' : 256,\n",
    "    'scheduler_step_size': 100,\n",
    "    'vad_free' : True,\n",
    "    'test': False,\n",
    "    'kl_weight': 0.03,\n",
    "    'kl_weight_increase_every_epochs': 100,\n",
    "    'kl_weight_increase_value': 0.0,\n",
    "    'resume_ckpt': 'airplane_vad',\n",
    "    'filter_class': 'airplane',\n",
    "    'decoder_var' : True\n",
    "}\n",
    "train.main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Data length 4800\n",
      "Training params: 3\n",
      "[001/00024] train_loss: 0.178638 kl_loss: 0.492069 normal_loss: 0.163876\n",
      "[002/00049] train_loss: 0.133184 kl_loss: 0.440588 normal_loss: 0.119966\n",
      "[003/00074] train_loss: 0.126972 kl_loss: 0.387870 normal_loss: 0.115336\n",
      "[005/00024] train_loss: 0.122300 kl_loss: 0.344194 normal_loss: 0.111974\n",
      "[006/00049] train_loss: 0.117572 kl_loss: 0.326850 normal_loss: 0.107766\n",
      "[007/00074] train_loss: 0.114495 kl_loss: 0.316428 normal_loss: 0.105002\n",
      "[009/00024] train_loss: 0.109007 kl_loss: 0.302268 normal_loss: 0.099939\n",
      "[010/00049] train_loss: 0.107026 kl_loss: 0.290253 normal_loss: 0.098318\n",
      "[011/00074] train_loss: 0.105014 kl_loss: 0.278051 normal_loss: 0.096672\n",
      "[013/00024] train_loss: 0.103401 kl_loss: 0.266038 normal_loss: 0.095420\n",
      "[014/00049] train_loss: 0.099887 kl_loss: 0.255598 normal_loss: 0.092219\n",
      "[015/00074] train_loss: 0.098646 kl_loss: 0.247489 normal_loss: 0.091221\n",
      "[017/00024] train_loss: 0.097429 kl_loss: 0.241518 normal_loss: 0.090184\n",
      "[018/00049] train_loss: 0.094537 kl_loss: 0.240299 normal_loss: 0.087328\n",
      "[019/00074] train_loss: 0.092248 kl_loss: 0.237083 normal_loss: 0.085135\n",
      "[021/00024] train_loss: 0.090566 kl_loss: 0.233879 normal_loss: 0.083550\n",
      "[022/00049] train_loss: 0.088628 kl_loss: 0.230393 normal_loss: 0.081716\n",
      "[023/00074] train_loss: 0.087367 kl_loss: 0.229643 normal_loss: 0.080477\n",
      "[025/00024] train_loss: 0.085515 kl_loss: 0.227364 normal_loss: 0.078694\n",
      "[026/00049] train_loss: 0.084186 kl_loss: 0.225406 normal_loss: 0.077423\n",
      "[027/00074] train_loss: 0.082387 kl_loss: 0.224574 normal_loss: 0.075650\n",
      "[029/00024] train_loss: 0.080859 kl_loss: 0.223576 normal_loss: 0.074151\n",
      "[030/00049] train_loss: 0.080671 kl_loss: 0.225389 normal_loss: 0.073910\n",
      "[031/00074] train_loss: 0.078297 kl_loss: 0.224095 normal_loss: 0.071574\n",
      "[033/00024] train_loss: 0.077416 kl_loss: 0.225772 normal_loss: 0.070643\n",
      "[034/00049] train_loss: 0.076505 kl_loss: 0.226039 normal_loss: 0.069724\n",
      "[035/00074] train_loss: 0.076279 kl_loss: 0.226972 normal_loss: 0.069470\n",
      "[037/00024] train_loss: 0.073701 kl_loss: 0.227346 normal_loss: 0.066881\n",
      "[038/00049] train_loss: 0.072637 kl_loss: 0.227411 normal_loss: 0.065814\n",
      "[039/00074] train_loss: 0.071753 kl_loss: 0.228318 normal_loss: 0.064904\n",
      "[041/00024] train_loss: 0.071381 kl_loss: 0.229485 normal_loss: 0.064497\n",
      "[042/00049] train_loss: 0.070086 kl_loss: 0.228875 normal_loss: 0.063220\n",
      "[043/00074] train_loss: 0.068728 kl_loss: 0.229004 normal_loss: 0.061858\n",
      "[045/00024] train_loss: 0.068534 kl_loss: 0.230920 normal_loss: 0.061606\n",
      "[046/00049] train_loss: 0.068384 kl_loss: 0.230847 normal_loss: 0.061459\n",
      "[047/00074] train_loss: 0.066707 kl_loss: 0.232220 normal_loss: 0.059740\n",
      "[049/00024] train_loss: 0.067064 kl_loss: 0.232719 normal_loss: 0.060082\n",
      "[049/00074] MMD 0.00483490526676178\n",
      "[049/00074] TMD 0.058382462710142136\n",
      "[050/00049] train_loss: 0.066090 kl_loss: 0.233780 normal_loss: 0.059077\n",
      "[051/00074] train_loss: 0.065735 kl_loss: 0.235657 normal_loss: 0.058665\n",
      "[053/00024] train_loss: 0.064367 kl_loss: 0.235278 normal_loss: 0.057309\n",
      "[054/00049] train_loss: 0.064141 kl_loss: 0.238040 normal_loss: 0.057000\n",
      "[055/00074] train_loss: 0.064249 kl_loss: 0.238480 normal_loss: 0.057094\n",
      "[057/00024] train_loss: 0.062686 kl_loss: 0.239607 normal_loss: 0.055498\n",
      "[058/00049] train_loss: 0.062306 kl_loss: 0.240559 normal_loss: 0.055089\n",
      "[059/00074] train_loss: 0.062390 kl_loss: 0.242489 normal_loss: 0.055115\n",
      "[061/00024] train_loss: 0.061092 kl_loss: 0.244442 normal_loss: 0.053759\n",
      "[062/00049] train_loss: 0.060578 kl_loss: 0.243492 normal_loss: 0.053273\n",
      "[063/00074] train_loss: 0.060285 kl_loss: 0.247513 normal_loss: 0.052859\n",
      "[065/00024] train_loss: 0.059986 kl_loss: 0.248322 normal_loss: 0.052536\n",
      "[066/00049] train_loss: 0.059700 kl_loss: 0.249850 normal_loss: 0.052205\n",
      "[067/00074] train_loss: 0.058685 kl_loss: 0.250920 normal_loss: 0.051158\n",
      "[069/00024] train_loss: 0.058846 kl_loss: 0.252642 normal_loss: 0.051267\n",
      "[070/00049] train_loss: 0.056994 kl_loss: 0.253884 normal_loss: 0.049377\n",
      "[071/00074] train_loss: 0.058436 kl_loss: 0.255965 normal_loss: 0.050757\n",
      "[073/00024] train_loss: 0.057254 kl_loss: 0.257246 normal_loss: 0.049537\n",
      "[074/00049] train_loss: 0.057324 kl_loss: 0.258666 normal_loss: 0.049564\n",
      "[075/00074] train_loss: 0.056233 kl_loss: 0.259782 normal_loss: 0.048440\n",
      "[077/00024] train_loss: 0.055803 kl_loss: 0.261438 normal_loss: 0.047960\n",
      "[078/00049] train_loss: 0.055530 kl_loss: 0.262924 normal_loss: 0.047642\n",
      "[079/00074] train_loss: 0.055365 kl_loss: 0.263876 normal_loss: 0.047448\n",
      "[081/00024] train_loss: 0.054437 kl_loss: 0.265252 normal_loss: 0.046479\n",
      "[082/00049] train_loss: 0.053687 kl_loss: 0.267364 normal_loss: 0.045666\n",
      "[083/00074] train_loss: 0.053845 kl_loss: 0.268546 normal_loss: 0.045789\n",
      "[085/00024] train_loss: 0.053205 kl_loss: 0.268384 normal_loss: 0.045153\n",
      "[086/00049] train_loss: 0.053422 kl_loss: 0.273187 normal_loss: 0.045226\n",
      "[087/00074] train_loss: 0.052590 kl_loss: 0.270658 normal_loss: 0.044470\n",
      "[089/00024] train_loss: 0.051889 kl_loss: 0.272924 normal_loss: 0.043702\n",
      "[090/00049] train_loss: 0.051732 kl_loss: 0.274924 normal_loss: 0.043484\n",
      "[091/00074] train_loss: 0.051126 kl_loss: 0.275591 normal_loss: 0.042858\n",
      "[093/00024] train_loss: 0.050967 kl_loss: 0.276019 normal_loss: 0.042686\n",
      "[094/00049] train_loss: 0.049827 kl_loss: 0.278587 normal_loss: 0.041469\n",
      "[095/00074] train_loss: 0.050372 kl_loss: 0.277962 normal_loss: 0.042033\n",
      "[097/00024] train_loss: 0.049956 kl_loss: 0.279586 normal_loss: 0.041569\n",
      "[098/00049] train_loss: 0.049669 kl_loss: 0.281057 normal_loss: 0.041237\n",
      "[099/00000] updated kl_weight: 0.03\n",
      "[099/00001] updated kl_weight: 0.03\n",
      "[099/00002] updated kl_weight: 0.03\n",
      "[099/00003] updated kl_weight: 0.03\n",
      "[099/00004] updated kl_weight: 0.03\n",
      "[099/00005] updated kl_weight: 0.03\n",
      "[099/00006] updated kl_weight: 0.03\n",
      "[099/00007] updated kl_weight: 0.03\n",
      "[099/00008] updated kl_weight: 0.03\n",
      "[099/00009] updated kl_weight: 0.03\n",
      "[099/00010] updated kl_weight: 0.03\n",
      "[099/00011] updated kl_weight: 0.03\n",
      "[099/00012] updated kl_weight: 0.03\n",
      "[099/00013] updated kl_weight: 0.03\n",
      "[099/00014] updated kl_weight: 0.03\n",
      "[099/00015] updated kl_weight: 0.03\n",
      "[099/00016] updated kl_weight: 0.03\n",
      "[099/00017] updated kl_weight: 0.03\n",
      "[099/00018] updated kl_weight: 0.03\n",
      "[099/00019] updated kl_weight: 0.03\n",
      "[099/00020] updated kl_weight: 0.03\n",
      "[099/00021] updated kl_weight: 0.03\n",
      "[099/00022] updated kl_weight: 0.03\n",
      "[099/00023] updated kl_weight: 0.03\n",
      "[099/00024] updated kl_weight: 0.03\n",
      "[099/00025] updated kl_weight: 0.03\n",
      "[099/00026] updated kl_weight: 0.03\n",
      "[099/00027] updated kl_weight: 0.03\n",
      "[099/00028] updated kl_weight: 0.03\n",
      "[099/00029] updated kl_weight: 0.03\n",
      "[099/00030] updated kl_weight: 0.03\n",
      "[099/00031] updated kl_weight: 0.03\n",
      "[099/00032] updated kl_weight: 0.03\n",
      "[099/00033] updated kl_weight: 0.03\n",
      "[099/00034] updated kl_weight: 0.03\n",
      "[099/00035] updated kl_weight: 0.03\n",
      "[099/00036] updated kl_weight: 0.03\n",
      "[099/00037] updated kl_weight: 0.03\n",
      "[099/00038] updated kl_weight: 0.03\n",
      "[099/00039] updated kl_weight: 0.03\n",
      "[099/00040] updated kl_weight: 0.03\n",
      "[099/00041] updated kl_weight: 0.03\n",
      "[099/00042] updated kl_weight: 0.03\n",
      "[099/00043] updated kl_weight: 0.03\n",
      "[099/00044] updated kl_weight: 0.03\n",
      "[099/00045] updated kl_weight: 0.03\n",
      "[099/00046] updated kl_weight: 0.03\n",
      "[099/00047] updated kl_weight: 0.03\n",
      "[099/00048] updated kl_weight: 0.03\n",
      "[099/00049] updated kl_weight: 0.03\n",
      "[099/00050] updated kl_weight: 0.03\n",
      "[099/00051] updated kl_weight: 0.03\n",
      "[099/00052] updated kl_weight: 0.03\n",
      "[099/00053] updated kl_weight: 0.03\n",
      "[099/00054] updated kl_weight: 0.03\n",
      "[099/00055] updated kl_weight: 0.03\n",
      "[099/00056] updated kl_weight: 0.03\n",
      "[099/00057] updated kl_weight: 0.03\n",
      "[099/00058] updated kl_weight: 0.03\n",
      "[099/00059] updated kl_weight: 0.03\n",
      "[099/00060] updated kl_weight: 0.03\n",
      "[099/00061] updated kl_weight: 0.03\n",
      "[099/00062] updated kl_weight: 0.03\n",
      "[099/00063] updated kl_weight: 0.03\n",
      "[099/00064] updated kl_weight: 0.03\n",
      "[099/00065] updated kl_weight: 0.03\n",
      "[099/00066] updated kl_weight: 0.03\n",
      "[099/00067] updated kl_weight: 0.03\n",
      "[099/00068] updated kl_weight: 0.03\n",
      "[099/00069] updated kl_weight: 0.03\n",
      "[099/00070] updated kl_weight: 0.03\n",
      "[099/00071] updated kl_weight: 0.03\n",
      "[099/00072] updated kl_weight: 0.03\n",
      "[099/00073] updated kl_weight: 0.03\n",
      "[099/00074] updated kl_weight: 0.03\n",
      "[099/00074] train_loss: 0.049135 kl_loss: 0.282469 normal_loss: 0.040661\n",
      "[099/00074] MMD 0.005458594299852848\n",
      "[099/00074] TMD 0.07454124838113785\n",
      "[101/00024] train_loss: 0.045897 kl_loss: 0.283105 normal_loss: 0.037404\n",
      "[102/00049] train_loss: 0.044594 kl_loss: 0.280281 normal_loss: 0.036186\n",
      "[103/00074] train_loss: 0.044643 kl_loss: 0.278864 normal_loss: 0.036277\n",
      "[105/00024] train_loss: 0.043844 kl_loss: 0.278227 normal_loss: 0.035497\n",
      "[106/00049] train_loss: 0.043249 kl_loss: 0.275947 normal_loss: 0.034970\n",
      "[107/00074] train_loss: 0.043278 kl_loss: 0.273650 normal_loss: 0.035069\n",
      "[109/00024] train_loss: 0.042940 kl_loss: 0.273073 normal_loss: 0.034748\n",
      "[110/00049] train_loss: 0.042730 kl_loss: 0.272346 normal_loss: 0.034560\n",
      "[111/00074] train_loss: 0.042597 kl_loss: 0.271824 normal_loss: 0.034442\n",
      "[113/00024] train_loss: 0.041805 kl_loss: 0.270188 normal_loss: 0.033699\n",
      "[114/00049] train_loss: 0.041912 kl_loss: 0.270082 normal_loss: 0.033810\n",
      "[115/00074] train_loss: 0.041798 kl_loss: 0.269676 normal_loss: 0.033708\n",
      "[117/00024] train_loss: 0.041288 kl_loss: 0.268114 normal_loss: 0.033244\n",
      "[118/00049] train_loss: 0.041133 kl_loss: 0.268787 normal_loss: 0.033069\n",
      "[119/00074] train_loss: 0.040812 kl_loss: 0.267440 normal_loss: 0.032789\n",
      "[121/00024] train_loss: 0.040566 kl_loss: 0.267458 normal_loss: 0.032542\n",
      "[122/00049] train_loss: 0.040457 kl_loss: 0.266486 normal_loss: 0.032462\n",
      "[123/00074] train_loss: 0.040162 kl_loss: 0.267135 normal_loss: 0.032148\n",
      "[125/00024] train_loss: 0.039990 kl_loss: 0.265269 normal_loss: 0.032032\n",
      "[126/00049] train_loss: 0.040169 kl_loss: 0.267219 normal_loss: 0.032152\n",
      "[127/00074] train_loss: 0.039488 kl_loss: 0.266125 normal_loss: 0.031504\n",
      "[129/00024] train_loss: 0.039476 kl_loss: 0.265784 normal_loss: 0.031502\n",
      "[130/00049] train_loss: 0.039218 kl_loss: 0.265952 normal_loss: 0.031240\n",
      "[131/00074] train_loss: 0.039199 kl_loss: 0.265835 normal_loss: 0.031224\n",
      "[133/00024] train_loss: 0.038480 kl_loss: 0.265401 normal_loss: 0.030518\n",
      "[134/00049] train_loss: 0.038635 kl_loss: 0.265674 normal_loss: 0.030665\n",
      "[135/00074] train_loss: 0.038567 kl_loss: 0.265379 normal_loss: 0.030605\n",
      "[137/00024] train_loss: 0.037968 kl_loss: 0.263610 normal_loss: 0.030060\n",
      "[138/00049] train_loss: 0.038265 kl_loss: 0.266732 normal_loss: 0.030263\n",
      "[139/00074] train_loss: 0.038121 kl_loss: 0.266179 normal_loss: 0.030135\n",
      "[141/00024] train_loss: 0.037794 kl_loss: 0.265885 normal_loss: 0.029818\n",
      "[142/00049] train_loss: 0.037855 kl_loss: 0.264694 normal_loss: 0.029914\n",
      "[143/00074] train_loss: 0.037912 kl_loss: 0.266056 normal_loss: 0.029930\n",
      "[145/00024] train_loss: 0.037566 kl_loss: 0.265422 normal_loss: 0.029603\n",
      "[146/00049] train_loss: 0.037347 kl_loss: 0.265990 normal_loss: 0.029367\n",
      "[147/00074] train_loss: 0.037070 kl_loss: 0.266142 normal_loss: 0.029085\n",
      "[149/00024] train_loss: 0.037022 kl_loss: 0.264675 normal_loss: 0.029082\n",
      "[149/00074] MMD 0.005198840983211994\n",
      "[149/00074] TMD 0.06507346779108047\n",
      "[150/00049] train_loss: 0.036466 kl_loss: 0.266540 normal_loss: 0.028470\n",
      "[151/00074] train_loss: 0.036551 kl_loss: 0.266324 normal_loss: 0.028562\n",
      "[153/00024] train_loss: 0.036595 kl_loss: 0.266010 normal_loss: 0.028615\n",
      "[154/00049] train_loss: 0.035992 kl_loss: 0.264564 normal_loss: 0.028055\n",
      "[155/00074] train_loss: 0.036044 kl_loss: 0.266370 normal_loss: 0.028053\n",
      "[157/00024] train_loss: 0.035807 kl_loss: 0.265795 normal_loss: 0.027833\n",
      "[158/00049] train_loss: 0.036194 kl_loss: 0.265590 normal_loss: 0.028226\n",
      "[159/00074] train_loss: 0.035838 kl_loss: 0.265665 normal_loss: 0.027868\n",
      "[161/00024] train_loss: 0.035929 kl_loss: 0.265387 normal_loss: 0.027967\n",
      "[162/00049] train_loss: 0.035451 kl_loss: 0.266251 normal_loss: 0.027463\n",
      "[163/00074] train_loss: 0.035457 kl_loss: 0.265121 normal_loss: 0.027504\n",
      "[165/00024] train_loss: 0.035308 kl_loss: 0.265390 normal_loss: 0.027347\n",
      "[166/00049] train_loss: 0.035376 kl_loss: 0.265349 normal_loss: 0.027416\n",
      "[167/00074] train_loss: 0.034914 kl_loss: 0.265276 normal_loss: 0.026956\n",
      "[169/00024] train_loss: 0.035041 kl_loss: 0.264930 normal_loss: 0.027093\n",
      "[170/00049] train_loss: 0.034796 kl_loss: 0.266332 normal_loss: 0.026806\n",
      "[171/00074] train_loss: 0.034633 kl_loss: 0.264469 normal_loss: 0.026699\n",
      "[173/00024] train_loss: 0.034528 kl_loss: 0.265171 normal_loss: 0.026573\n",
      "[174/00049] train_loss: 0.034311 kl_loss: 0.264892 normal_loss: 0.026365\n",
      "[175/00074] train_loss: 0.034277 kl_loss: 0.264508 normal_loss: 0.026342\n",
      "[177/00024] train_loss: 0.033872 kl_loss: 0.264346 normal_loss: 0.025941\n",
      "[178/00049] train_loss: 0.034102 kl_loss: 0.264509 normal_loss: 0.026167\n",
      "[179/00074] train_loss: 0.034085 kl_loss: 0.264219 normal_loss: 0.026158\n",
      "[181/00024] train_loss: 0.033979 kl_loss: 0.263673 normal_loss: 0.026068\n",
      "[182/00049] train_loss: 0.033731 kl_loss: 0.264715 normal_loss: 0.025790\n",
      "[183/00074] train_loss: 0.033665 kl_loss: 0.263269 normal_loss: 0.025767\n",
      "[185/00024] train_loss: 0.033684 kl_loss: 0.264140 normal_loss: 0.025759\n",
      "[186/00049] train_loss: 0.033647 kl_loss: 0.263288 normal_loss: 0.025748\n",
      "[187/00074] train_loss: 0.033153 kl_loss: 0.262563 normal_loss: 0.025276\n",
      "[189/00024] train_loss: 0.033020 kl_loss: 0.263619 normal_loss: 0.025111\n",
      "[190/00049] train_loss: 0.032779 kl_loss: 0.261699 normal_loss: 0.024928\n",
      "[191/00074] train_loss: 0.033452 kl_loss: 0.263479 normal_loss: 0.025548\n",
      "[193/00024] train_loss: 0.033161 kl_loss: 0.262318 normal_loss: 0.025291\n",
      "[194/00049] train_loss: 0.032559 kl_loss: 0.262425 normal_loss: 0.024686\n",
      "[195/00074] train_loss: 0.032742 kl_loss: 0.262129 normal_loss: 0.024878\n",
      "[197/00024] train_loss: 0.032592 kl_loss: 0.261776 normal_loss: 0.024738\n",
      "[198/00049] train_loss: 0.032493 kl_loss: 0.261043 normal_loss: 0.024662\n",
      "[199/00000] updated kl_weight: 0.03\n",
      "[199/00001] updated kl_weight: 0.03\n",
      "[199/00002] updated kl_weight: 0.03\n",
      "[199/00003] updated kl_weight: 0.03\n",
      "[199/00004] updated kl_weight: 0.03\n",
      "[199/00005] updated kl_weight: 0.03\n",
      "[199/00006] updated kl_weight: 0.03\n",
      "[199/00007] updated kl_weight: 0.03\n",
      "[199/00008] updated kl_weight: 0.03\n",
      "[199/00009] updated kl_weight: 0.03\n",
      "[199/00010] updated kl_weight: 0.03\n",
      "[199/00011] updated kl_weight: 0.03\n",
      "[199/00012] updated kl_weight: 0.03\n",
      "[199/00013] updated kl_weight: 0.03\n",
      "[199/00014] updated kl_weight: 0.03\n",
      "[199/00015] updated kl_weight: 0.03\n",
      "[199/00016] updated kl_weight: 0.03\n",
      "[199/00017] updated kl_weight: 0.03\n",
      "[199/00018] updated kl_weight: 0.03\n",
      "[199/00019] updated kl_weight: 0.03\n",
      "[199/00020] updated kl_weight: 0.03\n",
      "[199/00021] updated kl_weight: 0.03\n",
      "[199/00022] updated kl_weight: 0.03\n",
      "[199/00023] updated kl_weight: 0.03\n",
      "[199/00024] updated kl_weight: 0.03\n",
      "[199/00025] updated kl_weight: 0.03\n",
      "[199/00026] updated kl_weight: 0.03\n",
      "[199/00027] updated kl_weight: 0.03\n",
      "[199/00028] updated kl_weight: 0.03\n",
      "[199/00029] updated kl_weight: 0.03\n",
      "[199/00030] updated kl_weight: 0.03\n",
      "[199/00031] updated kl_weight: 0.03\n",
      "[199/00032] updated kl_weight: 0.03\n",
      "[199/00033] updated kl_weight: 0.03\n",
      "[199/00034] updated kl_weight: 0.03\n",
      "[199/00035] updated kl_weight: 0.03\n",
      "[199/00036] updated kl_weight: 0.03\n",
      "[199/00037] updated kl_weight: 0.03\n",
      "[199/00038] updated kl_weight: 0.03\n",
      "[199/00039] updated kl_weight: 0.03\n",
      "[199/00040] updated kl_weight: 0.03\n",
      "[199/00041] updated kl_weight: 0.03\n",
      "[199/00042] updated kl_weight: 0.03\n",
      "[199/00043] updated kl_weight: 0.03\n",
      "[199/00044] updated kl_weight: 0.03\n",
      "[199/00045] updated kl_weight: 0.03\n",
      "[199/00046] updated kl_weight: 0.03\n",
      "[199/00047] updated kl_weight: 0.03\n",
      "[199/00048] updated kl_weight: 0.03\n",
      "[199/00049] updated kl_weight: 0.03\n",
      "[199/00050] updated kl_weight: 0.03\n",
      "[199/00051] updated kl_weight: 0.03\n",
      "[199/00052] updated kl_weight: 0.03\n",
      "[199/00053] updated kl_weight: 0.03\n",
      "[199/00054] updated kl_weight: 0.03\n",
      "[199/00055] updated kl_weight: 0.03\n",
      "[199/00056] updated kl_weight: 0.03\n",
      "[199/00057] updated kl_weight: 0.03\n",
      "[199/00058] updated kl_weight: 0.03\n",
      "[199/00059] updated kl_weight: 0.03\n",
      "[199/00060] updated kl_weight: 0.03\n",
      "[199/00061] updated kl_weight: 0.03\n",
      "[199/00062] updated kl_weight: 0.03\n",
      "[199/00063] updated kl_weight: 0.03\n",
      "[199/00064] updated kl_weight: 0.03\n",
      "[199/00065] updated kl_weight: 0.03\n",
      "[199/00066] updated kl_weight: 0.03\n",
      "[199/00067] updated kl_weight: 0.03\n",
      "[199/00068] updated kl_weight: 0.03\n",
      "[199/00069] updated kl_weight: 0.03\n",
      "[199/00070] updated kl_weight: 0.03\n",
      "[199/00071] updated kl_weight: 0.03\n",
      "[199/00072] updated kl_weight: 0.03\n",
      "[199/00073] updated kl_weight: 0.03\n",
      "[199/00074] updated kl_weight: 0.03\n",
      "[199/00074] train_loss: 0.032708 kl_loss: 0.261414 normal_loss: 0.024865\n",
      "[199/00074] MMD 0.005202102940529585\n",
      "[199/00074] TMD 0.05481155216693878\n",
      "[201/00024] train_loss: 0.031082 kl_loss: 0.261171 normal_loss: 0.023247\n",
      "[202/00049] train_loss: 0.030734 kl_loss: 0.259696 normal_loss: 0.022943\n",
      "[203/00074] train_loss: 0.030549 kl_loss: 0.259764 normal_loss: 0.022756\n",
      "[205/00024] train_loss: 0.030134 kl_loss: 0.257910 normal_loss: 0.022397\n",
      "[206/00049] train_loss: 0.030215 kl_loss: 0.258801 normal_loss: 0.022451\n",
      "[207/00074] train_loss: 0.030172 kl_loss: 0.258132 normal_loss: 0.022428\n",
      "[209/00024] train_loss: 0.030000 kl_loss: 0.257421 normal_loss: 0.022278\n",
      "[210/00049] train_loss: 0.029797 kl_loss: 0.255861 normal_loss: 0.022121\n",
      "[211/00074] train_loss: 0.029880 kl_loss: 0.255749 normal_loss: 0.022207\n",
      "[213/00024] train_loss: 0.029612 kl_loss: 0.254567 normal_loss: 0.021975\n",
      "[214/00049] train_loss: 0.029673 kl_loss: 0.254710 normal_loss: 0.022031\n",
      "[215/00074] train_loss: 0.029650 kl_loss: 0.254181 normal_loss: 0.022025\n",
      "[217/00024] train_loss: 0.029368 kl_loss: 0.252701 normal_loss: 0.021787\n",
      "[218/00049] train_loss: 0.029619 kl_loss: 0.253140 normal_loss: 0.022024\n",
      "[219/00074] train_loss: 0.029515 kl_loss: 0.252472 normal_loss: 0.021941\n",
      "[221/00024] train_loss: 0.029300 kl_loss: 0.251730 normal_loss: 0.021748\n",
      "[222/00049] train_loss: 0.029453 kl_loss: 0.251196 normal_loss: 0.021917\n",
      "[223/00074] train_loss: 0.029344 kl_loss: 0.250903 normal_loss: 0.021817\n",
      "[225/00024] train_loss: 0.029219 kl_loss: 0.249470 normal_loss: 0.021735\n",
      "[226/00049] train_loss: 0.029164 kl_loss: 0.250925 normal_loss: 0.021636\n",
      "[227/00074] train_loss: 0.029236 kl_loss: 0.249009 normal_loss: 0.021766\n",
      "[229/00024] train_loss: 0.029181 kl_loss: 0.249691 normal_loss: 0.021691\n",
      "[230/00049] train_loss: 0.029030 kl_loss: 0.247650 normal_loss: 0.021600\n",
      "[231/00074] train_loss: 0.028946 kl_loss: 0.248279 normal_loss: 0.021498\n",
      "[233/00024] train_loss: 0.028774 kl_loss: 0.247810 normal_loss: 0.021340\n",
      "[234/00049] train_loss: 0.028894 kl_loss: 0.247338 normal_loss: 0.021474\n",
      "[235/00074] train_loss: 0.028843 kl_loss: 0.246467 normal_loss: 0.021449\n",
      "[237/00024] train_loss: 0.028683 kl_loss: 0.246519 normal_loss: 0.021288\n",
      "[238/00049] train_loss: 0.028816 kl_loss: 0.246357 normal_loss: 0.021426\n",
      "[239/00074] train_loss: 0.028430 kl_loss: 0.245068 normal_loss: 0.021078\n",
      "[241/00024] train_loss: 0.028649 kl_loss: 0.245898 normal_loss: 0.021272\n",
      "[242/00049] train_loss: 0.028471 kl_loss: 0.244009 normal_loss: 0.021150\n",
      "[243/00074] train_loss: 0.028465 kl_loss: 0.244498 normal_loss: 0.021130\n",
      "[245/00024] train_loss: 0.028347 kl_loss: 0.243593 normal_loss: 0.021039\n",
      "[246/00049] train_loss: 0.028472 kl_loss: 0.244354 normal_loss: 0.021142\n",
      "[247/00074] train_loss: 0.028335 kl_loss: 0.243542 normal_loss: 0.021029\n",
      "[249/00024] train_loss: 0.028080 kl_loss: 0.243219 normal_loss: 0.020783\n",
      "[249/00074] MMD 0.005108760204166174\n",
      "[249/00074] TMD 0.05944669991731644\n",
      "[250/00049] train_loss: 0.028192 kl_loss: 0.242270 normal_loss: 0.020924\n",
      "[251/00074] train_loss: 0.028320 kl_loss: 0.242823 normal_loss: 0.021035\n",
      "[253/00024] train_loss: 0.028004 kl_loss: 0.241568 normal_loss: 0.020757\n",
      "[254/00049] train_loss: 0.028353 kl_loss: 0.242681 normal_loss: 0.021072\n",
      "[255/00074] train_loss: 0.028117 kl_loss: 0.241256 normal_loss: 0.020879\n",
      "[257/00024] train_loss: 0.028050 kl_loss: 0.241570 normal_loss: 0.020803\n",
      "[258/00049] train_loss: 0.028076 kl_loss: 0.240221 normal_loss: 0.020870\n",
      "[259/00074] train_loss: 0.027945 kl_loss: 0.241189 normal_loss: 0.020710\n",
      "[261/00024] train_loss: 0.027854 kl_loss: 0.240548 normal_loss: 0.020638\n",
      "[262/00049] train_loss: 0.027956 kl_loss: 0.239937 normal_loss: 0.020758\n",
      "[263/00074] train_loss: 0.027776 kl_loss: 0.239979 normal_loss: 0.020577\n",
      "[265/00024] train_loss: 0.027635 kl_loss: 0.239121 normal_loss: 0.020462\n",
      "[266/00049] train_loss: 0.027725 kl_loss: 0.239911 normal_loss: 0.020527\n",
      "[267/00074] train_loss: 0.027668 kl_loss: 0.238846 normal_loss: 0.020502\n",
      "[269/00024] train_loss: 0.027640 kl_loss: 0.238325 normal_loss: 0.020490\n",
      "[270/00049] train_loss: 0.027602 kl_loss: 0.238505 normal_loss: 0.020447\n",
      "[271/00074] train_loss: 0.027660 kl_loss: 0.238499 normal_loss: 0.020505\n",
      "[273/00024] train_loss: 0.027560 kl_loss: 0.237732 normal_loss: 0.020428\n",
      "[274/00049] train_loss: 0.027600 kl_loss: 0.237858 normal_loss: 0.020464\n",
      "[275/00074] train_loss: 0.027393 kl_loss: 0.237333 normal_loss: 0.020273\n",
      "[277/00024] train_loss: 0.027403 kl_loss: 0.237212 normal_loss: 0.020287\n",
      "[278/00049] train_loss: 0.027360 kl_loss: 0.236706 normal_loss: 0.020259\n",
      "[279/00074] train_loss: 0.027432 kl_loss: 0.236556 normal_loss: 0.020336\n",
      "[281/00024] train_loss: 0.027384 kl_loss: 0.236702 normal_loss: 0.020282\n",
      "[282/00049] train_loss: 0.027254 kl_loss: 0.235805 normal_loss: 0.020180\n",
      "[283/00074] train_loss: 0.026988 kl_loss: 0.235773 normal_loss: 0.019914\n",
      "[285/00024] train_loss: 0.026883 kl_loss: 0.234735 normal_loss: 0.019841\n",
      "[286/00049] train_loss: 0.027239 kl_loss: 0.235838 normal_loss: 0.020164\n",
      "[287/00074] train_loss: 0.027067 kl_loss: 0.235262 normal_loss: 0.020009\n",
      "[289/00024] train_loss: 0.026977 kl_loss: 0.234286 normal_loss: 0.019948\n",
      "[290/00049] train_loss: 0.027222 kl_loss: 0.235221 normal_loss: 0.020166\n",
      "[291/00074] train_loss: 0.026977 kl_loss: 0.234017 normal_loss: 0.019956\n",
      "[293/00024] train_loss: 0.026720 kl_loss: 0.233526 normal_loss: 0.019715\n",
      "[294/00049] train_loss: 0.026898 kl_loss: 0.234191 normal_loss: 0.019872\n",
      "[295/00074] train_loss: 0.026777 kl_loss: 0.233500 normal_loss: 0.019772\n",
      "[297/00024] train_loss: 0.026791 kl_loss: 0.233492 normal_loss: 0.019786\n",
      "[298/00049] train_loss: 0.026856 kl_loss: 0.232661 normal_loss: 0.019876\n",
      "[299/00000] updated kl_weight: 0.03\n",
      "[299/00001] updated kl_weight: 0.03\n",
      "[299/00002] updated kl_weight: 0.03\n",
      "[299/00003] updated kl_weight: 0.03\n",
      "[299/00004] updated kl_weight: 0.03\n",
      "[299/00005] updated kl_weight: 0.03\n",
      "[299/00006] updated kl_weight: 0.03\n",
      "[299/00007] updated kl_weight: 0.03\n",
      "[299/00008] updated kl_weight: 0.03\n",
      "[299/00009] updated kl_weight: 0.03\n",
      "[299/00010] updated kl_weight: 0.03\n",
      "[299/00011] updated kl_weight: 0.03\n",
      "[299/00012] updated kl_weight: 0.03\n",
      "[299/00013] updated kl_weight: 0.03\n",
      "[299/00014] updated kl_weight: 0.03\n",
      "[299/00015] updated kl_weight: 0.03\n",
      "[299/00016] updated kl_weight: 0.03\n",
      "[299/00017] updated kl_weight: 0.03\n",
      "[299/00018] updated kl_weight: 0.03\n",
      "[299/00019] updated kl_weight: 0.03\n",
      "[299/00020] updated kl_weight: 0.03\n",
      "[299/00021] updated kl_weight: 0.03\n",
      "[299/00022] updated kl_weight: 0.03\n",
      "[299/00023] updated kl_weight: 0.03\n",
      "[299/00024] updated kl_weight: 0.03\n",
      "[299/00025] updated kl_weight: 0.03\n",
      "[299/00026] updated kl_weight: 0.03\n",
      "[299/00027] updated kl_weight: 0.03\n",
      "[299/00028] updated kl_weight: 0.03\n",
      "[299/00029] updated kl_weight: 0.03\n",
      "[299/00030] updated kl_weight: 0.03\n",
      "[299/00031] updated kl_weight: 0.03\n",
      "[299/00032] updated kl_weight: 0.03\n",
      "[299/00033] updated kl_weight: 0.03\n",
      "[299/00034] updated kl_weight: 0.03\n",
      "[299/00035] updated kl_weight: 0.03\n",
      "[299/00036] updated kl_weight: 0.03\n",
      "[299/00037] updated kl_weight: 0.03\n",
      "[299/00038] updated kl_weight: 0.03\n",
      "[299/00039] updated kl_weight: 0.03\n",
      "[299/00040] updated kl_weight: 0.03\n",
      "[299/00041] updated kl_weight: 0.03\n",
      "[299/00042] updated kl_weight: 0.03\n",
      "[299/00043] updated kl_weight: 0.03\n",
      "[299/00044] updated kl_weight: 0.03\n",
      "[299/00045] updated kl_weight: 0.03\n",
      "[299/00046] updated kl_weight: 0.03\n",
      "[299/00047] updated kl_weight: 0.03\n",
      "[299/00048] updated kl_weight: 0.03\n",
      "[299/00049] updated kl_weight: 0.03\n",
      "[299/00050] updated kl_weight: 0.03\n",
      "[299/00051] updated kl_weight: 0.03\n",
      "[299/00052] updated kl_weight: 0.03\n",
      "[299/00053] updated kl_weight: 0.03\n",
      "[299/00054] updated kl_weight: 0.03\n",
      "[299/00055] updated kl_weight: 0.03\n",
      "[299/00056] updated kl_weight: 0.03\n",
      "[299/00057] updated kl_weight: 0.03\n",
      "[299/00058] updated kl_weight: 0.03\n",
      "[299/00059] updated kl_weight: 0.03\n",
      "[299/00060] updated kl_weight: 0.03\n",
      "[299/00061] updated kl_weight: 0.03\n",
      "[299/00062] updated kl_weight: 0.03\n",
      "[299/00063] updated kl_weight: 0.03\n",
      "[299/00064] updated kl_weight: 0.03\n",
      "[299/00065] updated kl_weight: 0.03\n",
      "[299/00066] updated kl_weight: 0.03\n",
      "[299/00067] updated kl_weight: 0.03\n",
      "[299/00068] updated kl_weight: 0.03\n",
      "[299/00069] updated kl_weight: 0.03\n",
      "[299/00070] updated kl_weight: 0.03\n",
      "[299/00071] updated kl_weight: 0.03\n",
      "[299/00072] updated kl_weight: 0.03\n",
      "[299/00073] updated kl_weight: 0.03\n",
      "[299/00074] updated kl_weight: 0.03\n",
      "[299/00074] train_loss: 0.026658 kl_loss: 0.232660 normal_loss: 0.019678\n",
      "[299/00074] MMD 0.005370283965021372\n",
      "[299/00074] TMD 0.05886409431695938\n",
      "[301/00024] train_loss: 0.026104 kl_loss: 0.232139 normal_loss: 0.019140\n",
      "[302/00049] train_loss: 0.026049 kl_loss: 0.232662 normal_loss: 0.019069\n",
      "[303/00074] train_loss: 0.025857 kl_loss: 0.231675 normal_loss: 0.018906\n",
      "[305/00024] train_loss: 0.025756 kl_loss: 0.231592 normal_loss: 0.018808\n",
      "[306/00049] train_loss: 0.025864 kl_loss: 0.231065 normal_loss: 0.018932\n",
      "[307/00074] train_loss: 0.025805 kl_loss: 0.231397 normal_loss: 0.018864\n",
      "[309/00024] train_loss: 0.025632 kl_loss: 0.230762 normal_loss: 0.018709\n",
      "[310/00049] train_loss: 0.025700 kl_loss: 0.230884 normal_loss: 0.018773\n",
      "[311/00074] train_loss: 0.025656 kl_loss: 0.230178 normal_loss: 0.018751\n",
      "[313/00024] train_loss: 0.025582 kl_loss: 0.229850 normal_loss: 0.018686\n",
      "[314/00049] train_loss: 0.025607 kl_loss: 0.230137 normal_loss: 0.018702\n",
      "[315/00074] train_loss: 0.025604 kl_loss: 0.229590 normal_loss: 0.018716\n",
      "[317/00024] train_loss: 0.025460 kl_loss: 0.229220 normal_loss: 0.018584\n",
      "[318/00049] train_loss: 0.025527 kl_loss: 0.229412 normal_loss: 0.018645\n",
      "[319/00074] train_loss: 0.025453 kl_loss: 0.228766 normal_loss: 0.018590\n",
      "[321/00024] train_loss: 0.025341 kl_loss: 0.227929 normal_loss: 0.018503\n",
      "[322/00049] train_loss: 0.025472 kl_loss: 0.229070 normal_loss: 0.018600\n",
      "[323/00074] train_loss: 0.025384 kl_loss: 0.228138 normal_loss: 0.018539\n",
      "[325/00024] train_loss: 0.025283 kl_loss: 0.227579 normal_loss: 0.018456\n",
      "[326/00049] train_loss: 0.025400 kl_loss: 0.227878 normal_loss: 0.018564\n",
      "[327/00074] train_loss: 0.025249 kl_loss: 0.227310 normal_loss: 0.018429\n",
      "[329/00024] train_loss: 0.025218 kl_loss: 0.227143 normal_loss: 0.018403\n",
      "[330/00049] train_loss: 0.025257 kl_loss: 0.227026 normal_loss: 0.018446\n",
      "[331/00074] train_loss: 0.025295 kl_loss: 0.226313 normal_loss: 0.018506\n",
      "[333/00024] train_loss: 0.025277 kl_loss: 0.226529 normal_loss: 0.018481\n",
      "[334/00049] train_loss: 0.025153 kl_loss: 0.225826 normal_loss: 0.018379\n",
      "[335/00074] train_loss: 0.025143 kl_loss: 0.226152 normal_loss: 0.018359\n",
      "[337/00024] train_loss: 0.025159 kl_loss: 0.225821 normal_loss: 0.018384\n",
      "[338/00049] train_loss: 0.025207 kl_loss: 0.225659 normal_loss: 0.018438\n",
      "[339/00074] train_loss: 0.025123 kl_loss: 0.224956 normal_loss: 0.018375\n",
      "[341/00024] train_loss: 0.025064 kl_loss: 0.224799 normal_loss: 0.018320\n",
      "[342/00049] train_loss: 0.025139 kl_loss: 0.225702 normal_loss: 0.018368\n",
      "[343/00074] train_loss: 0.024966 kl_loss: 0.224101 normal_loss: 0.018243\n",
      "[345/00024] train_loss: 0.024880 kl_loss: 0.224277 normal_loss: 0.018151\n",
      "[346/00049] train_loss: 0.025045 kl_loss: 0.224640 normal_loss: 0.018306\n",
      "[347/00074] train_loss: 0.024892 kl_loss: 0.223764 normal_loss: 0.018179\n",
      "[349/00024] train_loss: 0.024955 kl_loss: 0.223719 normal_loss: 0.018244\n",
      "[349/00074] MMD 0.004884112626314163\n",
      "[349/00074] TMD 0.0640522688627243\n",
      "[350/00049] train_loss: 0.024894 kl_loss: 0.223650 normal_loss: 0.018184\n",
      "[351/00074] train_loss: 0.024909 kl_loss: 0.223482 normal_loss: 0.018205\n",
      "[353/00024] train_loss: 0.024888 kl_loss: 0.223474 normal_loss: 0.018184\n",
      "[354/00049] train_loss: 0.024730 kl_loss: 0.222558 normal_loss: 0.018053\n",
      "[355/00074] train_loss: 0.024869 kl_loss: 0.222944 normal_loss: 0.018181\n",
      "[357/00024] train_loss: 0.024795 kl_loss: 0.222451 normal_loss: 0.018121\n",
      "[358/00049] train_loss: 0.024850 kl_loss: 0.222371 normal_loss: 0.018179\n",
      "[359/00074] train_loss: 0.024881 kl_loss: 0.222427 normal_loss: 0.018208\n",
      "[361/00024] train_loss: 0.024795 kl_loss: 0.222391 normal_loss: 0.018123\n",
      "[362/00049] train_loss: 0.024721 kl_loss: 0.222334 normal_loss: 0.018051\n",
      "[363/00074] train_loss: 0.024555 kl_loss: 0.220793 normal_loss: 0.017932\n",
      "[365/00024] train_loss: 0.024670 kl_loss: 0.221668 normal_loss: 0.018020\n",
      "[366/00049] train_loss: 0.024615 kl_loss: 0.220942 normal_loss: 0.017987\n",
      "[367/00074] train_loss: 0.024638 kl_loss: 0.221064 normal_loss: 0.018006\n",
      "[369/00024] train_loss: 0.024634 kl_loss: 0.220812 normal_loss: 0.018009\n",
      "[370/00049] train_loss: 0.024548 kl_loss: 0.220429 normal_loss: 0.017935\n",
      "[371/00074] train_loss: 0.024547 kl_loss: 0.220769 normal_loss: 0.017924\n",
      "[373/00024] train_loss: 0.024592 kl_loss: 0.220504 normal_loss: 0.017977\n",
      "[374/00049] train_loss: 0.024534 kl_loss: 0.219897 normal_loss: 0.017937\n",
      "[375/00074] train_loss: 0.024524 kl_loss: 0.219849 normal_loss: 0.017929\n",
      "[377/00024] train_loss: 0.024513 kl_loss: 0.219344 normal_loss: 0.017933\n",
      "[378/00049] train_loss: 0.024515 kl_loss: 0.220105 normal_loss: 0.017912\n",
      "[379/00074] train_loss: 0.024400 kl_loss: 0.219199 normal_loss: 0.017824\n",
      "[381/00024] train_loss: 0.024417 kl_loss: 0.219015 normal_loss: 0.017847\n",
      "[382/00049] train_loss: 0.024427 kl_loss: 0.219013 normal_loss: 0.017856\n",
      "[383/00074] train_loss: 0.024390 kl_loss: 0.219008 normal_loss: 0.017820\n",
      "[385/00024] train_loss: 0.024346 kl_loss: 0.218221 normal_loss: 0.017799\n",
      "[386/00049] train_loss: 0.024354 kl_loss: 0.219091 normal_loss: 0.017781\n",
      "[387/00074] train_loss: 0.024382 kl_loss: 0.218194 normal_loss: 0.017836\n",
      "[389/00024] train_loss: 0.024300 kl_loss: 0.217866 normal_loss: 0.017764\n",
      "[390/00049] train_loss: 0.024410 kl_loss: 0.218435 normal_loss: 0.017857\n",
      "[391/00074] train_loss: 0.024219 kl_loss: 0.217742 normal_loss: 0.017687\n",
      "[393/00024] train_loss: 0.024268 kl_loss: 0.217946 normal_loss: 0.017730\n",
      "[394/00049] train_loss: 0.024216 kl_loss: 0.217171 normal_loss: 0.017701\n",
      "[395/00074] train_loss: 0.024148 kl_loss: 0.217513 normal_loss: 0.017623\n",
      "[397/00024] train_loss: 0.024178 kl_loss: 0.216754 normal_loss: 0.017676\n",
      "[398/00049] train_loss: 0.024324 kl_loss: 0.217747 normal_loss: 0.017791\n",
      "[399/00000] updated kl_weight: 0.03\n",
      "[399/00001] updated kl_weight: 0.03\n",
      "[399/00002] updated kl_weight: 0.03\n",
      "[399/00003] updated kl_weight: 0.03\n",
      "[399/00004] updated kl_weight: 0.03\n",
      "[399/00005] updated kl_weight: 0.03\n",
      "[399/00006] updated kl_weight: 0.03\n",
      "[399/00007] updated kl_weight: 0.03\n",
      "[399/00008] updated kl_weight: 0.03\n",
      "[399/00009] updated kl_weight: 0.03\n",
      "[399/00010] updated kl_weight: 0.03\n",
      "[399/00011] updated kl_weight: 0.03\n",
      "[399/00012] updated kl_weight: 0.03\n",
      "[399/00013] updated kl_weight: 0.03\n",
      "[399/00014] updated kl_weight: 0.03\n",
      "[399/00015] updated kl_weight: 0.03\n",
      "[399/00016] updated kl_weight: 0.03\n",
      "[399/00017] updated kl_weight: 0.03\n",
      "[399/00018] updated kl_weight: 0.03\n",
      "[399/00019] updated kl_weight: 0.03\n",
      "[399/00020] updated kl_weight: 0.03\n",
      "[399/00021] updated kl_weight: 0.03\n",
      "[399/00022] updated kl_weight: 0.03\n",
      "[399/00023] updated kl_weight: 0.03\n",
      "[399/00024] updated kl_weight: 0.03\n",
      "[399/00025] updated kl_weight: 0.03\n",
      "[399/00026] updated kl_weight: 0.03\n",
      "[399/00027] updated kl_weight: 0.03\n",
      "[399/00028] updated kl_weight: 0.03\n",
      "[399/00029] updated kl_weight: 0.03\n",
      "[399/00030] updated kl_weight: 0.03\n",
      "[399/00031] updated kl_weight: 0.03\n",
      "[399/00032] updated kl_weight: 0.03\n",
      "[399/00033] updated kl_weight: 0.03\n",
      "[399/00034] updated kl_weight: 0.03\n",
      "[399/00035] updated kl_weight: 0.03\n",
      "[399/00036] updated kl_weight: 0.03\n",
      "[399/00037] updated kl_weight: 0.03\n",
      "[399/00038] updated kl_weight: 0.03\n",
      "[399/00039] updated kl_weight: 0.03\n",
      "[399/00040] updated kl_weight: 0.03\n",
      "[399/00041] updated kl_weight: 0.03\n",
      "[399/00042] updated kl_weight: 0.03\n",
      "[399/00043] updated kl_weight: 0.03\n",
      "[399/00044] updated kl_weight: 0.03\n",
      "[399/00045] updated kl_weight: 0.03\n",
      "[399/00046] updated kl_weight: 0.03\n",
      "[399/00047] updated kl_weight: 0.03\n",
      "[399/00048] updated kl_weight: 0.03\n",
      "[399/00049] updated kl_weight: 0.03\n",
      "[399/00050] updated kl_weight: 0.03\n",
      "[399/00051] updated kl_weight: 0.03\n",
      "[399/00052] updated kl_weight: 0.03\n",
      "[399/00053] updated kl_weight: 0.03\n",
      "[399/00054] updated kl_weight: 0.03\n",
      "[399/00055] updated kl_weight: 0.03\n",
      "[399/00056] updated kl_weight: 0.03\n",
      "[399/00057] updated kl_weight: 0.03\n",
      "[399/00058] updated kl_weight: 0.03\n",
      "[399/00059] updated kl_weight: 0.03\n",
      "[399/00060] updated kl_weight: 0.03\n",
      "[399/00061] updated kl_weight: 0.03\n",
      "[399/00062] updated kl_weight: 0.03\n",
      "[399/00063] updated kl_weight: 0.03\n",
      "[399/00064] updated kl_weight: 0.03\n",
      "[399/00065] updated kl_weight: 0.03\n",
      "[399/00066] updated kl_weight: 0.03\n",
      "[399/00067] updated kl_weight: 0.03\n",
      "[399/00068] updated kl_weight: 0.03\n",
      "[399/00069] updated kl_weight: 0.03\n",
      "[399/00070] updated kl_weight: 0.03\n",
      "[399/00071] updated kl_weight: 0.03\n",
      "[399/00072] updated kl_weight: 0.03\n",
      "[399/00073] updated kl_weight: 0.03\n",
      "[399/00074] updated kl_weight: 0.03\n",
      "[399/00074] train_loss: 0.024137 kl_loss: 0.216698 normal_loss: 0.017636\n",
      "[399/00074] MMD 0.004945943597704172\n",
      "[399/00074] TMD 0.05976533144712448\n",
      "[401/00024] train_loss: 0.023902 kl_loss: 0.216592 normal_loss: 0.017404\n",
      "[402/00049] train_loss: 0.023836 kl_loss: 0.216462 normal_loss: 0.017342\n",
      "[403/00074] train_loss: 0.023851 kl_loss: 0.216892 normal_loss: 0.017345\n",
      "[405/00024] train_loss: 0.023707 kl_loss: 0.216410 normal_loss: 0.017215\n",
      "[406/00049] train_loss: 0.023811 kl_loss: 0.216322 normal_loss: 0.017322\n",
      "[407/00074] train_loss: 0.023798 kl_loss: 0.216137 normal_loss: 0.017314\n",
      "[409/00024] train_loss: 0.023782 kl_loss: 0.215486 normal_loss: 0.017317\n",
      "[410/00049] train_loss: 0.023729 kl_loss: 0.216108 normal_loss: 0.017246\n",
      "[411/00074] train_loss: 0.023697 kl_loss: 0.216238 normal_loss: 0.017210\n",
      "[413/00024] train_loss: 0.023715 kl_loss: 0.215715 normal_loss: 0.017244\n",
      "[414/00049] train_loss: 0.023708 kl_loss: 0.215934 normal_loss: 0.017230\n",
      "[415/00074] train_loss: 0.023721 kl_loss: 0.215099 normal_loss: 0.017268\n",
      "[417/00024] train_loss: 0.023641 kl_loss: 0.214911 normal_loss: 0.017193\n",
      "[418/00049] train_loss: 0.023709 kl_loss: 0.215611 normal_loss: 0.017241\n",
      "[419/00074] train_loss: 0.023622 kl_loss: 0.215224 normal_loss: 0.017165\n",
      "[421/00024] train_loss: 0.023551 kl_loss: 0.214741 normal_loss: 0.017109\n",
      "[422/00049] train_loss: 0.023616 kl_loss: 0.215133 normal_loss: 0.017162\n",
      "[423/00074] train_loss: 0.023586 kl_loss: 0.214868 normal_loss: 0.017140\n",
      "[425/00024] train_loss: 0.023529 kl_loss: 0.214673 normal_loss: 0.017089\n",
      "[426/00049] train_loss: 0.023609 kl_loss: 0.214655 normal_loss: 0.017169\n",
      "[427/00074] train_loss: 0.023583 kl_loss: 0.214332 normal_loss: 0.017153\n",
      "[429/00024] train_loss: 0.023464 kl_loss: 0.213837 normal_loss: 0.017049\n",
      "[430/00049] train_loss: 0.023629 kl_loss: 0.214824 normal_loss: 0.017184\n",
      "[431/00074] train_loss: 0.023534 kl_loss: 0.214015 normal_loss: 0.017113\n",
      "[433/00024] train_loss: 0.023463 kl_loss: 0.213575 normal_loss: 0.017056\n",
      "[434/00049] train_loss: 0.023476 kl_loss: 0.214047 normal_loss: 0.017055\n",
      "[435/00074] train_loss: 0.023517 kl_loss: 0.214040 normal_loss: 0.017096\n",
      "[437/00024] train_loss: 0.023471 kl_loss: 0.213425 normal_loss: 0.017068\n",
      "[438/00049] train_loss: 0.023464 kl_loss: 0.213490 normal_loss: 0.017059\n",
      "[439/00074] train_loss: 0.023468 kl_loss: 0.213732 normal_loss: 0.017056\n",
      "[441/00024] train_loss: 0.023467 kl_loss: 0.213502 normal_loss: 0.017062\n",
      "[442/00049] train_loss: 0.023451 kl_loss: 0.213459 normal_loss: 0.017048\n",
      "[443/00074] train_loss: 0.023413 kl_loss: 0.212742 normal_loss: 0.017031\n",
      "[445/00024] train_loss: 0.023313 kl_loss: 0.212825 normal_loss: 0.016929\n",
      "[446/00049] train_loss: 0.023376 kl_loss: 0.212580 normal_loss: 0.016999\n",
      "[447/00074] train_loss: 0.023450 kl_loss: 0.213320 normal_loss: 0.017050\n",
      "[449/00024] train_loss: 0.023344 kl_loss: 0.212856 normal_loss: 0.016959\n",
      "[449/00074] MMD 0.005230878945440054\n",
      "[449/00074] TMD 0.0789671465754509\n",
      "[450/00049] train_loss: 0.023429 kl_loss: 0.212711 normal_loss: 0.017048\n",
      "[451/00074] train_loss: 0.023323 kl_loss: 0.212227 normal_loss: 0.016956\n",
      "[453/00024] train_loss: 0.023287 kl_loss: 0.212451 normal_loss: 0.016914\n",
      "[454/00049] train_loss: 0.023258 kl_loss: 0.211959 normal_loss: 0.016899\n",
      "[455/00074] train_loss: 0.023361 kl_loss: 0.212424 normal_loss: 0.016988\n",
      "[457/00024] train_loss: 0.023279 kl_loss: 0.212252 normal_loss: 0.016912\n",
      "[458/00049] train_loss: 0.023238 kl_loss: 0.211582 normal_loss: 0.016891\n",
      "[459/00074] train_loss: 0.023291 kl_loss: 0.212044 normal_loss: 0.016930\n",
      "[461/00024] train_loss: 0.023162 kl_loss: 0.211218 normal_loss: 0.016825\n",
      "[462/00049] train_loss: 0.023320 kl_loss: 0.212132 normal_loss: 0.016956\n",
      "[463/00074] train_loss: 0.023269 kl_loss: 0.211598 normal_loss: 0.016921\n",
      "[465/00024] train_loss: 0.023213 kl_loss: 0.211234 normal_loss: 0.016876\n",
      "[466/00049] train_loss: 0.023281 kl_loss: 0.211361 normal_loss: 0.016940\n",
      "[467/00074] train_loss: 0.023199 kl_loss: 0.211447 normal_loss: 0.016856\n",
      "[469/00024] train_loss: 0.023339 kl_loss: 0.211660 normal_loss: 0.016989\n",
      "[470/00049] train_loss: 0.023043 kl_loss: 0.209940 normal_loss: 0.016745\n",
      "[471/00074] train_loss: 0.023265 kl_loss: 0.211571 normal_loss: 0.016918\n",
      "[473/00024] train_loss: 0.023102 kl_loss: 0.210651 normal_loss: 0.016782\n",
      "[474/00049] train_loss: 0.023238 kl_loss: 0.210973 normal_loss: 0.016909\n",
      "[475/00074] train_loss: 0.023221 kl_loss: 0.210702 normal_loss: 0.016900\n",
      "[477/00024] train_loss: 0.023042 kl_loss: 0.209973 normal_loss: 0.016743\n",
      "[478/00049] train_loss: 0.023196 kl_loss: 0.210898 normal_loss: 0.016869\n",
      "[479/00074] train_loss: 0.023195 kl_loss: 0.210594 normal_loss: 0.016877\n",
      "[481/00024] train_loss: 0.023095 kl_loss: 0.210207 normal_loss: 0.016789\n",
      "[482/00049] train_loss: 0.023120 kl_loss: 0.210594 normal_loss: 0.016802\n",
      "[483/00074] train_loss: 0.023111 kl_loss: 0.209805 normal_loss: 0.016817\n",
      "[485/00024] train_loss: 0.023049 kl_loss: 0.210037 normal_loss: 0.016748\n",
      "[486/00049] train_loss: 0.023150 kl_loss: 0.210125 normal_loss: 0.016846\n",
      "[487/00074] train_loss: 0.023101 kl_loss: 0.209611 normal_loss: 0.016813\n",
      "[489/00024] train_loss: 0.023083 kl_loss: 0.209893 normal_loss: 0.016786\n",
      "[490/00049] train_loss: 0.022924 kl_loss: 0.208981 normal_loss: 0.016655\n",
      "[491/00074] train_loss: 0.023134 kl_loss: 0.210077 normal_loss: 0.016831\n",
      "[493/00024] train_loss: 0.023033 kl_loss: 0.209375 normal_loss: 0.016752\n",
      "[494/00049] train_loss: 0.023081 kl_loss: 0.210094 normal_loss: 0.016778\n",
      "[495/00074] train_loss: 0.022992 kl_loss: 0.208677 normal_loss: 0.016732\n",
      "[497/00024] train_loss: 0.022966 kl_loss: 0.209233 normal_loss: 0.016689\n",
      "[498/00049] train_loss: 0.022955 kl_loss: 0.209501 normal_loss: 0.016669\n",
      "[499/00000] updated kl_weight: 0.03\n",
      "[499/00001] updated kl_weight: 0.03\n",
      "[499/00002] updated kl_weight: 0.03\n",
      "[499/00003] updated kl_weight: 0.03\n",
      "[499/00004] updated kl_weight: 0.03\n",
      "[499/00005] updated kl_weight: 0.03\n",
      "[499/00006] updated kl_weight: 0.03\n",
      "[499/00007] updated kl_weight: 0.03\n",
      "[499/00008] updated kl_weight: 0.03\n",
      "[499/00009] updated kl_weight: 0.03\n",
      "[499/00010] updated kl_weight: 0.03\n",
      "[499/00011] updated kl_weight: 0.03\n",
      "[499/00012] updated kl_weight: 0.03\n",
      "[499/00013] updated kl_weight: 0.03\n",
      "[499/00014] updated kl_weight: 0.03\n",
      "[499/00015] updated kl_weight: 0.03\n",
      "[499/00016] updated kl_weight: 0.03\n",
      "[499/00017] updated kl_weight: 0.03\n",
      "[499/00018] updated kl_weight: 0.03\n",
      "[499/00019] updated kl_weight: 0.03\n",
      "[499/00020] updated kl_weight: 0.03\n",
      "[499/00021] updated kl_weight: 0.03\n",
      "[499/00022] updated kl_weight: 0.03\n",
      "[499/00023] updated kl_weight: 0.03\n",
      "[499/00024] updated kl_weight: 0.03\n",
      "[499/00025] updated kl_weight: 0.03\n",
      "[499/00026] updated kl_weight: 0.03\n",
      "[499/00027] updated kl_weight: 0.03\n",
      "[499/00028] updated kl_weight: 0.03\n",
      "[499/00029] updated kl_weight: 0.03\n",
      "[499/00030] updated kl_weight: 0.03\n",
      "[499/00031] updated kl_weight: 0.03\n",
      "[499/00032] updated kl_weight: 0.03\n",
      "[499/00033] updated kl_weight: 0.03\n",
      "[499/00034] updated kl_weight: 0.03\n",
      "[499/00035] updated kl_weight: 0.03\n",
      "[499/00036] updated kl_weight: 0.03\n",
      "[499/00037] updated kl_weight: 0.03\n",
      "[499/00038] updated kl_weight: 0.03\n",
      "[499/00039] updated kl_weight: 0.03\n",
      "[499/00040] updated kl_weight: 0.03\n",
      "[499/00041] updated kl_weight: 0.03\n",
      "[499/00042] updated kl_weight: 0.03\n",
      "[499/00043] updated kl_weight: 0.03\n",
      "[499/00044] updated kl_weight: 0.03\n",
      "[499/00045] updated kl_weight: 0.03\n",
      "[499/00046] updated kl_weight: 0.03\n",
      "[499/00047] updated kl_weight: 0.03\n",
      "[499/00048] updated kl_weight: 0.03\n",
      "[499/00049] updated kl_weight: 0.03\n",
      "[499/00050] updated kl_weight: 0.03\n",
      "[499/00051] updated kl_weight: 0.03\n",
      "[499/00052] updated kl_weight: 0.03\n",
      "[499/00053] updated kl_weight: 0.03\n",
      "[499/00054] updated kl_weight: 0.03\n",
      "[499/00055] updated kl_weight: 0.03\n",
      "[499/00056] updated kl_weight: 0.03\n",
      "[499/00057] updated kl_weight: 0.03\n",
      "[499/00058] updated kl_weight: 0.03\n",
      "[499/00059] updated kl_weight: 0.03\n",
      "[499/00060] updated kl_weight: 0.03\n",
      "[499/00061] updated kl_weight: 0.03\n",
      "[499/00062] updated kl_weight: 0.03\n",
      "[499/00063] updated kl_weight: 0.03\n",
      "[499/00064] updated kl_weight: 0.03\n",
      "[499/00065] updated kl_weight: 0.03\n",
      "[499/00066] updated kl_weight: 0.03\n",
      "[499/00067] updated kl_weight: 0.03\n",
      "[499/00068] updated kl_weight: 0.03\n",
      "[499/00069] updated kl_weight: 0.03\n",
      "[499/00070] updated kl_weight: 0.03\n",
      "[499/00071] updated kl_weight: 0.03\n",
      "[499/00072] updated kl_weight: 0.03\n",
      "[499/00073] updated kl_weight: 0.03\n",
      "[499/00074] updated kl_weight: 0.03\n",
      "[499/00074] train_loss: 0.022958 kl_loss: 0.208578 normal_loss: 0.016701\n",
      "[499/00074] MMD 0.0050292606465518475\n",
      "[499/00074] TMD 0.07114793360233307\n",
      "[501/00024] train_loss: 0.022878 kl_loss: 0.208997 normal_loss: 0.016609\n",
      "[502/00049] train_loss: 0.022843 kl_loss: 0.208846 normal_loss: 0.016578\n",
      "[503/00074] train_loss: 0.022865 kl_loss: 0.208797 normal_loss: 0.016601\n",
      "[505/00024] train_loss: 0.022783 kl_loss: 0.208710 normal_loss: 0.016522\n",
      "[506/00049] train_loss: 0.022810 kl_loss: 0.208573 normal_loss: 0.016553\n",
      "[507/00074] train_loss: 0.022861 kl_loss: 0.208903 normal_loss: 0.016594\n",
      "[509/00024] train_loss: 0.022796 kl_loss: 0.208205 normal_loss: 0.016550\n",
      "[510/00049] train_loss: 0.022792 kl_loss: 0.209191 normal_loss: 0.016516\n",
      "[511/00074] train_loss: 0.022722 kl_loss: 0.208273 normal_loss: 0.016474\n",
      "[513/00024] train_loss: 0.022747 kl_loss: 0.208093 normal_loss: 0.016505\n",
      "[514/00049] train_loss: 0.022776 kl_loss: 0.208802 normal_loss: 0.016512\n",
      "[515/00074] train_loss: 0.022746 kl_loss: 0.208249 normal_loss: 0.016499\n",
      "[517/00024] train_loss: 0.022772 kl_loss: 0.208067 normal_loss: 0.016530\n",
      "[518/00049] train_loss: 0.022737 kl_loss: 0.208503 normal_loss: 0.016482\n",
      "[519/00074] train_loss: 0.022738 kl_loss: 0.208087 normal_loss: 0.016496\n",
      "[521/00024] train_loss: 0.022760 kl_loss: 0.208318 normal_loss: 0.016511\n",
      "[522/00049] train_loss: 0.022716 kl_loss: 0.207961 normal_loss: 0.016478\n",
      "[523/00074] train_loss: 0.022711 kl_loss: 0.207868 normal_loss: 0.016475\n",
      "[525/00024] train_loss: 0.022689 kl_loss: 0.208140 normal_loss: 0.016444\n",
      "[526/00049] train_loss: 0.022796 kl_loss: 0.208333 normal_loss: 0.016546\n",
      "[527/00074] train_loss: 0.022584 kl_loss: 0.207168 normal_loss: 0.016369\n",
      "[529/00024] train_loss: 0.022774 kl_loss: 0.208106 normal_loss: 0.016530\n",
      "[530/00049] train_loss: 0.022723 kl_loss: 0.207877 normal_loss: 0.016487\n",
      "[531/00074] train_loss: 0.022579 kl_loss: 0.207171 normal_loss: 0.016364\n",
      "[533/00024] train_loss: 0.022626 kl_loss: 0.207695 normal_loss: 0.016395\n",
      "[534/00049] train_loss: 0.022691 kl_loss: 0.207591 normal_loss: 0.016464\n",
      "[535/00074] train_loss: 0.022654 kl_loss: 0.207345 normal_loss: 0.016433\n",
      "[537/00024] train_loss: 0.022689 kl_loss: 0.207674 normal_loss: 0.016459\n",
      "[538/00049] train_loss: 0.022538 kl_loss: 0.206831 normal_loss: 0.016333\n",
      "[539/00074] train_loss: 0.022739 kl_loss: 0.207643 normal_loss: 0.016509\n",
      "[541/00024] train_loss: 0.022606 kl_loss: 0.207794 normal_loss: 0.016372\n",
      "[542/00049] train_loss: 0.022584 kl_loss: 0.206753 normal_loss: 0.016382\n",
      "[543/00074] train_loss: 0.022618 kl_loss: 0.207112 normal_loss: 0.016405\n",
      "[545/00024] train_loss: 0.022642 kl_loss: 0.207414 normal_loss: 0.016420\n",
      "[546/00049] train_loss: 0.022539 kl_loss: 0.206185 normal_loss: 0.016353\n",
      "[547/00074] train_loss: 0.022662 kl_loss: 0.207572 normal_loss: 0.016435\n",
      "[549/00024] train_loss: 0.022543 kl_loss: 0.206222 normal_loss: 0.016356\n",
      "[549/00074] MMD 0.005278234835714102\n",
      "[549/00074] TMD 0.05892890691757202\n",
      "[550/00049] train_loss: 0.022586 kl_loss: 0.207289 normal_loss: 0.016367\n",
      "[551/00074] train_loss: 0.022633 kl_loss: 0.207181 normal_loss: 0.016418\n",
      "[553/00024] train_loss: 0.022584 kl_loss: 0.206867 normal_loss: 0.016378\n",
      "[554/00049] train_loss: 0.022654 kl_loss: 0.206981 normal_loss: 0.016444\n",
      "[555/00074] train_loss: 0.022558 kl_loss: 0.206352 normal_loss: 0.016367\n",
      "[557/00024] train_loss: 0.022570 kl_loss: 0.206474 normal_loss: 0.016375\n",
      "[558/00049] train_loss: 0.022582 kl_loss: 0.206672 normal_loss: 0.016382\n",
      "[559/00074] train_loss: 0.022602 kl_loss: 0.206595 normal_loss: 0.016404\n",
      "[561/00024] train_loss: 0.022595 kl_loss: 0.206681 normal_loss: 0.016394\n",
      "[562/00049] train_loss: 0.022665 kl_loss: 0.206672 normal_loss: 0.016465\n",
      "[563/00074] train_loss: 0.022501 kl_loss: 0.205961 normal_loss: 0.016322\n",
      "[565/00024] train_loss: 0.022533 kl_loss: 0.206145 normal_loss: 0.016349\n",
      "[566/00049] train_loss: 0.022537 kl_loss: 0.206442 normal_loss: 0.016344\n",
      "[567/00074] train_loss: 0.022537 kl_loss: 0.206302 normal_loss: 0.016348\n",
      "[569/00024] train_loss: 0.022479 kl_loss: 0.206188 normal_loss: 0.016294\n",
      "[570/00049] train_loss: 0.022581 kl_loss: 0.206224 normal_loss: 0.016394\n",
      "[571/00074] train_loss: 0.022507 kl_loss: 0.206008 normal_loss: 0.016327\n",
      "[573/00024] train_loss: 0.022521 kl_loss: 0.206170 normal_loss: 0.016336\n",
      "[574/00049] train_loss: 0.022464 kl_loss: 0.205632 normal_loss: 0.016295\n",
      "[575/00074] train_loss: 0.022532 kl_loss: 0.206191 normal_loss: 0.016347\n",
      "[577/00024] train_loss: 0.022415 kl_loss: 0.205356 normal_loss: 0.016255\n",
      "[578/00049] train_loss: 0.022531 kl_loss: 0.206232 normal_loss: 0.016344\n",
      "[579/00074] train_loss: 0.022499 kl_loss: 0.205944 normal_loss: 0.016320\n",
      "[581/00024] train_loss: 0.022447 kl_loss: 0.205736 normal_loss: 0.016275\n",
      "[582/00049] train_loss: 0.022483 kl_loss: 0.205964 normal_loss: 0.016304\n",
      "[583/00074] train_loss: 0.022441 kl_loss: 0.205387 normal_loss: 0.016280\n",
      "[585/00024] train_loss: 0.022499 kl_loss: 0.205628 normal_loss: 0.016331\n",
      "[586/00049] train_loss: 0.022423 kl_loss: 0.205432 normal_loss: 0.016260\n",
      "[587/00074] train_loss: 0.022453 kl_loss: 0.205577 normal_loss: 0.016286\n",
      "[589/00024] train_loss: 0.022439 kl_loss: 0.204929 normal_loss: 0.016291\n",
      "[590/00049] train_loss: 0.022554 kl_loss: 0.206632 normal_loss: 0.016355\n",
      "[591/00074] train_loss: 0.022369 kl_loss: 0.204644 normal_loss: 0.016229\n",
      "[593/00024] train_loss: 0.022354 kl_loss: 0.205346 normal_loss: 0.016194\n",
      "[594/00049] train_loss: 0.022469 kl_loss: 0.205178 normal_loss: 0.016314\n",
      "[595/00074] train_loss: 0.022364 kl_loss: 0.205248 normal_loss: 0.016207\n",
      "[597/00024] train_loss: 0.022405 kl_loss: 0.205538 normal_loss: 0.016239\n",
      "[598/00049] train_loss: 0.022395 kl_loss: 0.204641 normal_loss: 0.016255\n",
      "[599/00000] updated kl_weight: 0.03\n",
      "[599/00001] updated kl_weight: 0.03\n",
      "[599/00002] updated kl_weight: 0.03\n",
      "[599/00003] updated kl_weight: 0.03\n",
      "[599/00004] updated kl_weight: 0.03\n",
      "[599/00005] updated kl_weight: 0.03\n",
      "[599/00006] updated kl_weight: 0.03\n",
      "[599/00007] updated kl_weight: 0.03\n",
      "[599/00008] updated kl_weight: 0.03\n",
      "[599/00009] updated kl_weight: 0.03\n",
      "[599/00010] updated kl_weight: 0.03\n",
      "[599/00011] updated kl_weight: 0.03\n",
      "[599/00012] updated kl_weight: 0.03\n",
      "[599/00013] updated kl_weight: 0.03\n",
      "[599/00014] updated kl_weight: 0.03\n",
      "[599/00015] updated kl_weight: 0.03\n",
      "[599/00016] updated kl_weight: 0.03\n",
      "[599/00017] updated kl_weight: 0.03\n",
      "[599/00018] updated kl_weight: 0.03\n",
      "[599/00019] updated kl_weight: 0.03\n",
      "[599/00020] updated kl_weight: 0.03\n",
      "[599/00021] updated kl_weight: 0.03\n",
      "[599/00022] updated kl_weight: 0.03\n",
      "[599/00023] updated kl_weight: 0.03\n",
      "[599/00024] updated kl_weight: 0.03\n",
      "[599/00025] updated kl_weight: 0.03\n",
      "[599/00026] updated kl_weight: 0.03\n",
      "[599/00027] updated kl_weight: 0.03\n",
      "[599/00028] updated kl_weight: 0.03\n",
      "[599/00029] updated kl_weight: 0.03\n",
      "[599/00030] updated kl_weight: 0.03\n",
      "[599/00031] updated kl_weight: 0.03\n",
      "[599/00032] updated kl_weight: 0.03\n",
      "[599/00033] updated kl_weight: 0.03\n",
      "[599/00034] updated kl_weight: 0.03\n",
      "[599/00035] updated kl_weight: 0.03\n",
      "[599/00036] updated kl_weight: 0.03\n",
      "[599/00037] updated kl_weight: 0.03\n",
      "[599/00038] updated kl_weight: 0.03\n",
      "[599/00039] updated kl_weight: 0.03\n",
      "[599/00040] updated kl_weight: 0.03\n",
      "[599/00041] updated kl_weight: 0.03\n",
      "[599/00042] updated kl_weight: 0.03\n",
      "[599/00043] updated kl_weight: 0.03\n",
      "[599/00044] updated kl_weight: 0.03\n",
      "[599/00045] updated kl_weight: 0.03\n",
      "[599/00046] updated kl_weight: 0.03\n",
      "[599/00047] updated kl_weight: 0.03\n",
      "[599/00048] updated kl_weight: 0.03\n",
      "[599/00049] updated kl_weight: 0.03\n",
      "[599/00050] updated kl_weight: 0.03\n",
      "[599/00051] updated kl_weight: 0.03\n",
      "[599/00052] updated kl_weight: 0.03\n",
      "[599/00053] updated kl_weight: 0.03\n",
      "[599/00054] updated kl_weight: 0.03\n",
      "[599/00055] updated kl_weight: 0.03\n",
      "[599/00056] updated kl_weight: 0.03\n",
      "[599/00057] updated kl_weight: 0.03\n",
      "[599/00058] updated kl_weight: 0.03\n",
      "[599/00059] updated kl_weight: 0.03\n",
      "[599/00060] updated kl_weight: 0.03\n",
      "[599/00061] updated kl_weight: 0.03\n",
      "[599/00062] updated kl_weight: 0.03\n",
      "[599/00063] updated kl_weight: 0.03\n",
      "[599/00064] updated kl_weight: 0.03\n",
      "[599/00065] updated kl_weight: 0.03\n",
      "[599/00066] updated kl_weight: 0.03\n",
      "[599/00067] updated kl_weight: 0.03\n",
      "[599/00068] updated kl_weight: 0.03\n",
      "[599/00069] updated kl_weight: 0.03\n",
      "[599/00070] updated kl_weight: 0.03\n",
      "[599/00071] updated kl_weight: 0.03\n",
      "[599/00072] updated kl_weight: 0.03\n",
      "[599/00073] updated kl_weight: 0.03\n",
      "[599/00074] updated kl_weight: 0.03\n",
      "[599/00074] train_loss: 0.022380 kl_loss: 0.205128 normal_loss: 0.016226\n",
      "[599/00074] MMD 0.004921461921185255\n",
      "[599/00074] TMD 0.05919303745031357\n",
      "[601/00024] train_loss: 0.022314 kl_loss: 0.204713 normal_loss: 0.016173\n",
      "[602/00049] train_loss: 0.022311 kl_loss: 0.205386 normal_loss: 0.016149\n",
      "[603/00074] train_loss: 0.022363 kl_loss: 0.204854 normal_loss: 0.016217\n",
      "[605/00024] train_loss: 0.022278 kl_loss: 0.204744 normal_loss: 0.016135\n",
      "[606/00049] train_loss: 0.022347 kl_loss: 0.204964 normal_loss: 0.016198\n",
      "[607/00074] train_loss: 0.022292 kl_loss: 0.205004 normal_loss: 0.016142\n",
      "[609/00024] train_loss: 0.022383 kl_loss: 0.205440 normal_loss: 0.016219\n",
      "[610/00049] train_loss: 0.022312 kl_loss: 0.204581 normal_loss: 0.016174\n",
      "[611/00074] train_loss: 0.022222 kl_loss: 0.204445 normal_loss: 0.016089\n",
      "[613/00024] train_loss: 0.022276 kl_loss: 0.204417 normal_loss: 0.016143\n",
      "[614/00049] train_loss: 0.022393 kl_loss: 0.205491 normal_loss: 0.016228\n",
      "[615/00074] train_loss: 0.022266 kl_loss: 0.204313 normal_loss: 0.016136\n",
      "[617/00024] train_loss: 0.022246 kl_loss: 0.204516 normal_loss: 0.016111\n",
      "[618/00049] train_loss: 0.022350 kl_loss: 0.205068 normal_loss: 0.016198\n",
      "[619/00074] train_loss: 0.022280 kl_loss: 0.204408 normal_loss: 0.016148\n",
      "[621/00024] train_loss: 0.022272 kl_loss: 0.204488 normal_loss: 0.016137\n",
      "[622/00049] train_loss: 0.022230 kl_loss: 0.204338 normal_loss: 0.016100\n",
      "[623/00074] train_loss: 0.022318 kl_loss: 0.204933 normal_loss: 0.016170\n",
      "[625/00024] train_loss: 0.022207 kl_loss: 0.204479 normal_loss: 0.016072\n",
      "[626/00049] train_loss: 0.022262 kl_loss: 0.204560 normal_loss: 0.016125\n",
      "[627/00074] train_loss: 0.022265 kl_loss: 0.204478 normal_loss: 0.016131\n",
      "[629/00024] train_loss: 0.022213 kl_loss: 0.203762 normal_loss: 0.016100\n",
      "[630/00049] train_loss: 0.022336 kl_loss: 0.205459 normal_loss: 0.016172\n",
      "[631/00074] train_loss: 0.022213 kl_loss: 0.204049 normal_loss: 0.016092\n",
      "[633/00024] train_loss: 0.022266 kl_loss: 0.204416 normal_loss: 0.016133\n",
      "[634/00049] train_loss: 0.022228 kl_loss: 0.204251 normal_loss: 0.016100\n",
      "[635/00074] train_loss: 0.022205 kl_loss: 0.204374 normal_loss: 0.016074\n",
      "[637/00024] train_loss: 0.022194 kl_loss: 0.203950 normal_loss: 0.016076\n",
      "[638/00049] train_loss: 0.022244 kl_loss: 0.204767 normal_loss: 0.016101\n",
      "[639/00074] train_loss: 0.022228 kl_loss: 0.204066 normal_loss: 0.016106\n",
      "[641/00024] train_loss: 0.022181 kl_loss: 0.204110 normal_loss: 0.016057\n",
      "[642/00049] train_loss: 0.022212 kl_loss: 0.204162 normal_loss: 0.016087\n",
      "[643/00074] train_loss: 0.022199 kl_loss: 0.204268 normal_loss: 0.016071\n",
      "[645/00024] train_loss: 0.022222 kl_loss: 0.203984 normal_loss: 0.016103\n",
      "[646/00049] train_loss: 0.022185 kl_loss: 0.204066 normal_loss: 0.016063\n",
      "[647/00074] train_loss: 0.022256 kl_loss: 0.204240 normal_loss: 0.016128\n",
      "[649/00024] train_loss: 0.022205 kl_loss: 0.204296 normal_loss: 0.016077\n",
      "[649/00074] MMD 0.005192305892705917\n",
      "[649/00074] TMD 0.06799919903278351\n",
      "[650/00049] train_loss: 0.022180 kl_loss: 0.203593 normal_loss: 0.016072\n",
      "[651/00074] train_loss: 0.022237 kl_loss: 0.204157 normal_loss: 0.016113\n",
      "[653/00024] train_loss: 0.022243 kl_loss: 0.203871 normal_loss: 0.016127\n",
      "[654/00049] train_loss: 0.022104 kl_loss: 0.203224 normal_loss: 0.016007\n",
      "[655/00074] train_loss: 0.022348 kl_loss: 0.204728 normal_loss: 0.016206\n",
      "[657/00024] train_loss: 0.022193 kl_loss: 0.203762 normal_loss: 0.016080\n",
      "[658/00049] train_loss: 0.022295 kl_loss: 0.204075 normal_loss: 0.016173\n",
      "[659/00074] train_loss: 0.022138 kl_loss: 0.203763 normal_loss: 0.016025\n",
      "[661/00024] train_loss: 0.022196 kl_loss: 0.204283 normal_loss: 0.016068\n",
      "[662/00049] train_loss: 0.022143 kl_loss: 0.203469 normal_loss: 0.016039\n",
      "[663/00074] train_loss: 0.022200 kl_loss: 0.203609 normal_loss: 0.016091\n",
      "[665/00024] train_loss: 0.022189 kl_loss: 0.203729 normal_loss: 0.016077\n",
      "[666/00049] train_loss: 0.022091 kl_loss: 0.203541 normal_loss: 0.015984\n",
      "[667/00074] train_loss: 0.022223 kl_loss: 0.203861 normal_loss: 0.016107\n",
      "[669/00024] train_loss: 0.022076 kl_loss: 0.203469 normal_loss: 0.015972\n",
      "[670/00049] train_loss: 0.022268 kl_loss: 0.204141 normal_loss: 0.016144\n",
      "[671/00074] train_loss: 0.022131 kl_loss: 0.203283 normal_loss: 0.016032\n",
      "[673/00024] train_loss: 0.022160 kl_loss: 0.203601 normal_loss: 0.016052\n",
      "[674/00049] train_loss: 0.022089 kl_loss: 0.203109 normal_loss: 0.015996\n",
      "[675/00074] train_loss: 0.022189 kl_loss: 0.203944 normal_loss: 0.016071\n",
      "[677/00024] train_loss: 0.022122 kl_loss: 0.203325 normal_loss: 0.016023\n",
      "[678/00049] train_loss: 0.022180 kl_loss: 0.203514 normal_loss: 0.016074\n",
      "[679/00074] train_loss: 0.022118 kl_loss: 0.203563 normal_loss: 0.016011\n",
      "[681/00024] train_loss: 0.022178 kl_loss: 0.203405 normal_loss: 0.016076\n",
      "[682/00049] train_loss: 0.022078 kl_loss: 0.203112 normal_loss: 0.015984\n",
      "[683/00074] train_loss: 0.022219 kl_loss: 0.203660 normal_loss: 0.016109\n",
      "[685/00024] train_loss: 0.022112 kl_loss: 0.203653 normal_loss: 0.016002\n",
      "[686/00049] train_loss: 0.022047 kl_loss: 0.202901 normal_loss: 0.015960\n",
      "[687/00074] train_loss: 0.022118 kl_loss: 0.203396 normal_loss: 0.016016\n",
      "[689/00024] train_loss: 0.022083 kl_loss: 0.202816 normal_loss: 0.015999\n",
      "[690/00049] train_loss: 0.022148 kl_loss: 0.203847 normal_loss: 0.016032\n",
      "[691/00074] train_loss: 0.022152 kl_loss: 0.203056 normal_loss: 0.016060\n",
      "[693/00024] train_loss: 0.022081 kl_loss: 0.203301 normal_loss: 0.015981\n",
      "[694/00049] train_loss: 0.022200 kl_loss: 0.203393 normal_loss: 0.016099\n",
      "[695/00074] train_loss: 0.022082 kl_loss: 0.202784 normal_loss: 0.015998\n",
      "[697/00024] train_loss: 0.022099 kl_loss: 0.203148 normal_loss: 0.016004\n",
      "[698/00049] train_loss: 0.022122 kl_loss: 0.203207 normal_loss: 0.016026\n",
      "[699/00000] updated kl_weight: 0.03\n",
      "[699/00001] updated kl_weight: 0.03\n",
      "[699/00002] updated kl_weight: 0.03\n",
      "[699/00003] updated kl_weight: 0.03\n",
      "[699/00004] updated kl_weight: 0.03\n",
      "[699/00005] updated kl_weight: 0.03\n",
      "[699/00006] updated kl_weight: 0.03\n",
      "[699/00007] updated kl_weight: 0.03\n",
      "[699/00008] updated kl_weight: 0.03\n",
      "[699/00009] updated kl_weight: 0.03\n",
      "[699/00010] updated kl_weight: 0.03\n",
      "[699/00011] updated kl_weight: 0.03\n",
      "[699/00012] updated kl_weight: 0.03\n",
      "[699/00013] updated kl_weight: 0.03\n",
      "[699/00014] updated kl_weight: 0.03\n",
      "[699/00015] updated kl_weight: 0.03\n",
      "[699/00016] updated kl_weight: 0.03\n",
      "[699/00017] updated kl_weight: 0.03\n",
      "[699/00018] updated kl_weight: 0.03\n",
      "[699/00019] updated kl_weight: 0.03\n",
      "[699/00020] updated kl_weight: 0.03\n",
      "[699/00021] updated kl_weight: 0.03\n",
      "[699/00022] updated kl_weight: 0.03\n",
      "[699/00023] updated kl_weight: 0.03\n",
      "[699/00024] updated kl_weight: 0.03\n",
      "[699/00025] updated kl_weight: 0.03\n",
      "[699/00026] updated kl_weight: 0.03\n",
      "[699/00027] updated kl_weight: 0.03\n",
      "[699/00028] updated kl_weight: 0.03\n",
      "[699/00029] updated kl_weight: 0.03\n",
      "[699/00030] updated kl_weight: 0.03\n",
      "[699/00031] updated kl_weight: 0.03\n",
      "[699/00032] updated kl_weight: 0.03\n",
      "[699/00033] updated kl_weight: 0.03\n",
      "[699/00034] updated kl_weight: 0.03\n",
      "[699/00035] updated kl_weight: 0.03\n",
      "[699/00036] updated kl_weight: 0.03\n",
      "[699/00037] updated kl_weight: 0.03\n",
      "[699/00038] updated kl_weight: 0.03\n",
      "[699/00039] updated kl_weight: 0.03\n",
      "[699/00040] updated kl_weight: 0.03\n",
      "[699/00041] updated kl_weight: 0.03\n",
      "[699/00042] updated kl_weight: 0.03\n",
      "[699/00043] updated kl_weight: 0.03\n",
      "[699/00044] updated kl_weight: 0.03\n",
      "[699/00045] updated kl_weight: 0.03\n",
      "[699/00046] updated kl_weight: 0.03\n",
      "[699/00047] updated kl_weight: 0.03\n",
      "[699/00048] updated kl_weight: 0.03\n",
      "[699/00049] updated kl_weight: 0.03\n",
      "[699/00050] updated kl_weight: 0.03\n",
      "[699/00051] updated kl_weight: 0.03\n",
      "[699/00052] updated kl_weight: 0.03\n",
      "[699/00053] updated kl_weight: 0.03\n",
      "[699/00054] updated kl_weight: 0.03\n",
      "[699/00055] updated kl_weight: 0.03\n",
      "[699/00056] updated kl_weight: 0.03\n",
      "[699/00057] updated kl_weight: 0.03\n",
      "[699/00058] updated kl_weight: 0.03\n",
      "[699/00059] updated kl_weight: 0.03\n",
      "[699/00060] updated kl_weight: 0.03\n",
      "[699/00061] updated kl_weight: 0.03\n",
      "[699/00062] updated kl_weight: 0.03\n",
      "[699/00063] updated kl_weight: 0.03\n",
      "[699/00064] updated kl_weight: 0.03\n",
      "[699/00065] updated kl_weight: 0.03\n",
      "[699/00066] updated kl_weight: 0.03\n",
      "[699/00067] updated kl_weight: 0.03\n",
      "[699/00068] updated kl_weight: 0.03\n",
      "[699/00069] updated kl_weight: 0.03\n",
      "[699/00070] updated kl_weight: 0.03\n",
      "[699/00071] updated kl_weight: 0.03\n",
      "[699/00072] updated kl_weight: 0.03\n",
      "[699/00073] updated kl_weight: 0.03\n",
      "[699/00074] updated kl_weight: 0.03\n",
      "[699/00074] train_loss: 0.022057 kl_loss: 0.202884 normal_loss: 0.015971\n",
      "[699/00074] MMD 0.005001270677894354\n",
      "[699/00074] TMD 0.06325970590114594\n",
      "[701/00024] train_loss: 0.022127 kl_loss: 0.203467 normal_loss: 0.016023\n",
      "[702/00049] train_loss: 0.022055 kl_loss: 0.202846 normal_loss: 0.015969\n",
      "[703/00074] train_loss: 0.022049 kl_loss: 0.202736 normal_loss: 0.015967\n",
      "[705/00024] train_loss: 0.022067 kl_loss: 0.202852 normal_loss: 0.015982\n",
      "[706/00049] train_loss: 0.022095 kl_loss: 0.203414 normal_loss: 0.015993\n",
      "[707/00074] train_loss: 0.022004 kl_loss: 0.202667 normal_loss: 0.015924\n",
      "[709/00024] train_loss: 0.022072 kl_loss: 0.202780 normal_loss: 0.015988\n",
      "[710/00049] train_loss: 0.022031 kl_loss: 0.203042 normal_loss: 0.015940\n",
      "[711/00074] train_loss: 0.022080 kl_loss: 0.202988 normal_loss: 0.015990\n",
      "[713/00024] train_loss: 0.022138 kl_loss: 0.203468 normal_loss: 0.016034\n",
      "[714/00049] train_loss: 0.021956 kl_loss: 0.202012 normal_loss: 0.015895\n",
      "[715/00074] train_loss: 0.022131 kl_loss: 0.203216 normal_loss: 0.016035\n",
      "[717/00024] train_loss: 0.022123 kl_loss: 0.203344 normal_loss: 0.016023\n",
      "[718/00049] train_loss: 0.022004 kl_loss: 0.202620 normal_loss: 0.015925\n",
      "[719/00074] train_loss: 0.022038 kl_loss: 0.202620 normal_loss: 0.015959\n",
      "[721/00024] train_loss: 0.022101 kl_loss: 0.203147 normal_loss: 0.016007\n",
      "[722/00049] train_loss: 0.021973 kl_loss: 0.202135 normal_loss: 0.015909\n",
      "[723/00074] train_loss: 0.022141 kl_loss: 0.203182 normal_loss: 0.016046\n",
      "[725/00024] train_loss: 0.022009 kl_loss: 0.202902 normal_loss: 0.015922\n",
      "[726/00049] train_loss: 0.022068 kl_loss: 0.202685 normal_loss: 0.015988\n",
      "[727/00074] train_loss: 0.022074 kl_loss: 0.202760 normal_loss: 0.015991\n",
      "[729/00024] train_loss: 0.022001 kl_loss: 0.202411 normal_loss: 0.015929\n",
      "[730/00049] train_loss: 0.022086 kl_loss: 0.203169 normal_loss: 0.015991\n",
      "[731/00074] train_loss: 0.022086 kl_loss: 0.202648 normal_loss: 0.016006\n",
      "[733/00024] train_loss: 0.022061 kl_loss: 0.203002 normal_loss: 0.015971\n",
      "[734/00049] train_loss: 0.022074 kl_loss: 0.202743 normal_loss: 0.015992\n",
      "[735/00074] train_loss: 0.021939 kl_loss: 0.202375 normal_loss: 0.015868\n",
      "[737/00024] train_loss: 0.022015 kl_loss: 0.202471 normal_loss: 0.015941\n",
      "[738/00049] train_loss: 0.022035 kl_loss: 0.202680 normal_loss: 0.015955\n",
      "[739/00074] train_loss: 0.022021 kl_loss: 0.202854 normal_loss: 0.015936\n",
      "[741/00024] train_loss: 0.022108 kl_loss: 0.202836 normal_loss: 0.016023\n",
      "[742/00049] train_loss: 0.022020 kl_loss: 0.202810 normal_loss: 0.015935\n",
      "[743/00074] train_loss: 0.021968 kl_loss: 0.202241 normal_loss: 0.015901\n",
      "[745/00024] train_loss: 0.022050 kl_loss: 0.202787 normal_loss: 0.015967\n",
      "[746/00049] train_loss: 0.021949 kl_loss: 0.202075 normal_loss: 0.015887\n",
      "[747/00074] train_loss: 0.022064 kl_loss: 0.202908 normal_loss: 0.015977\n",
      "[749/00024] train_loss: 0.022053 kl_loss: 0.202603 normal_loss: 0.015975\n",
      "[749/00074] MMD 0.004948913585394621\n",
      "[749/00074] TMD 0.05819888412952423\n",
      "[750/00049] train_loss: 0.021989 kl_loss: 0.202695 normal_loss: 0.015908\n",
      "[751/00074] train_loss: 0.022007 kl_loss: 0.202355 normal_loss: 0.015937\n",
      "[753/00024] train_loss: 0.021970 kl_loss: 0.202091 normal_loss: 0.015907\n",
      "[754/00049] train_loss: 0.022007 kl_loss: 0.202887 normal_loss: 0.015921\n",
      "[755/00074] train_loss: 0.022061 kl_loss: 0.202551 normal_loss: 0.015984\n",
      "[757/00024] train_loss: 0.022006 kl_loss: 0.202480 normal_loss: 0.015932\n",
      "[758/00049] train_loss: 0.022066 kl_loss: 0.202428 normal_loss: 0.015993\n",
      "[759/00074] train_loss: 0.022000 kl_loss: 0.202502 normal_loss: 0.015925\n",
      "[761/00024] train_loss: 0.021999 kl_loss: 0.202739 normal_loss: 0.015916\n",
      "[762/00049] train_loss: 0.021986 kl_loss: 0.202241 normal_loss: 0.015919\n",
      "[763/00074] train_loss: 0.021991 kl_loss: 0.202313 normal_loss: 0.015921\n",
      "[765/00024] train_loss: 0.022051 kl_loss: 0.202509 normal_loss: 0.015976\n",
      "[766/00049] train_loss: 0.022025 kl_loss: 0.202517 normal_loss: 0.015950\n",
      "[767/00074] train_loss: 0.021934 kl_loss: 0.202149 normal_loss: 0.015870\n",
      "[769/00024] train_loss: 0.022048 kl_loss: 0.202349 normal_loss: 0.015977\n",
      "[770/00049] train_loss: 0.021901 kl_loss: 0.202047 normal_loss: 0.015840\n",
      "[771/00074] train_loss: 0.021988 kl_loss: 0.202668 normal_loss: 0.015908\n",
      "[773/00024] train_loss: 0.022013 kl_loss: 0.202478 normal_loss: 0.015939\n",
      "[774/00049] train_loss: 0.021952 kl_loss: 0.202321 normal_loss: 0.015882\n",
      "[775/00074] train_loss: 0.022018 kl_loss: 0.202146 normal_loss: 0.015953\n",
      "[777/00024] train_loss: 0.021945 kl_loss: 0.202060 normal_loss: 0.015883\n",
      "[778/00049] train_loss: 0.022059 kl_loss: 0.202393 normal_loss: 0.015987\n",
      "[779/00074] train_loss: 0.022021 kl_loss: 0.202381 normal_loss: 0.015949\n",
      "[781/00024] train_loss: 0.021903 kl_loss: 0.201908 normal_loss: 0.015846\n",
      "[782/00049] train_loss: 0.021987 kl_loss: 0.202345 normal_loss: 0.015916\n",
      "[783/00074] train_loss: 0.021981 kl_loss: 0.202472 normal_loss: 0.015907\n",
      "[785/00024] train_loss: 0.022022 kl_loss: 0.202538 normal_loss: 0.015946\n",
      "[786/00049] train_loss: 0.021880 kl_loss: 0.201999 normal_loss: 0.015820\n",
      "[787/00074] train_loss: 0.021948 kl_loss: 0.202071 normal_loss: 0.015886\n",
      "[789/00024] train_loss: 0.021946 kl_loss: 0.202111 normal_loss: 0.015883\n",
      "[790/00049] train_loss: 0.021921 kl_loss: 0.201821 normal_loss: 0.015866\n",
      "[791/00074] train_loss: 0.022034 kl_loss: 0.202556 normal_loss: 0.015958\n",
      "[793/00024] train_loss: 0.022012 kl_loss: 0.202303 normal_loss: 0.015943\n",
      "[794/00049] train_loss: 0.021940 kl_loss: 0.202059 normal_loss: 0.015878\n",
      "[795/00074] train_loss: 0.021914 kl_loss: 0.202014 normal_loss: 0.015853\n",
      "[797/00024] train_loss: 0.021930 kl_loss: 0.201999 normal_loss: 0.015870\n",
      "[798/00049] train_loss: 0.021970 kl_loss: 0.202173 normal_loss: 0.015904\n",
      "[799/00000] updated kl_weight: 0.03\n",
      "[799/00001] updated kl_weight: 0.03\n",
      "[799/00002] updated kl_weight: 0.03\n",
      "[799/00003] updated kl_weight: 0.03\n",
      "[799/00004] updated kl_weight: 0.03\n",
      "[799/00005] updated kl_weight: 0.03\n",
      "[799/00006] updated kl_weight: 0.03\n",
      "[799/00007] updated kl_weight: 0.03\n",
      "[799/00008] updated kl_weight: 0.03\n",
      "[799/00009] updated kl_weight: 0.03\n",
      "[799/00010] updated kl_weight: 0.03\n",
      "[799/00011] updated kl_weight: 0.03\n",
      "[799/00012] updated kl_weight: 0.03\n",
      "[799/00013] updated kl_weight: 0.03\n",
      "[799/00014] updated kl_weight: 0.03\n",
      "[799/00015] updated kl_weight: 0.03\n",
      "[799/00016] updated kl_weight: 0.03\n",
      "[799/00017] updated kl_weight: 0.03\n",
      "[799/00018] updated kl_weight: 0.03\n",
      "[799/00019] updated kl_weight: 0.03\n",
      "[799/00020] updated kl_weight: 0.03\n",
      "[799/00021] updated kl_weight: 0.03\n",
      "[799/00022] updated kl_weight: 0.03\n",
      "[799/00023] updated kl_weight: 0.03\n",
      "[799/00024] updated kl_weight: 0.03\n",
      "[799/00025] updated kl_weight: 0.03\n",
      "[799/00026] updated kl_weight: 0.03\n",
      "[799/00027] updated kl_weight: 0.03\n",
      "[799/00028] updated kl_weight: 0.03\n",
      "[799/00029] updated kl_weight: 0.03\n",
      "[799/00030] updated kl_weight: 0.03\n",
      "[799/00031] updated kl_weight: 0.03\n",
      "[799/00032] updated kl_weight: 0.03\n",
      "[799/00033] updated kl_weight: 0.03\n",
      "[799/00034] updated kl_weight: 0.03\n",
      "[799/00035] updated kl_weight: 0.03\n",
      "[799/00036] updated kl_weight: 0.03\n",
      "[799/00037] updated kl_weight: 0.03\n",
      "[799/00038] updated kl_weight: 0.03\n",
      "[799/00039] updated kl_weight: 0.03\n",
      "[799/00040] updated kl_weight: 0.03\n",
      "[799/00041] updated kl_weight: 0.03\n",
      "[799/00042] updated kl_weight: 0.03\n",
      "[799/00043] updated kl_weight: 0.03\n",
      "[799/00044] updated kl_weight: 0.03\n",
      "[799/00045] updated kl_weight: 0.03\n",
      "[799/00046] updated kl_weight: 0.03\n",
      "[799/00047] updated kl_weight: 0.03\n",
      "[799/00048] updated kl_weight: 0.03\n",
      "[799/00049] updated kl_weight: 0.03\n",
      "[799/00050] updated kl_weight: 0.03\n",
      "[799/00051] updated kl_weight: 0.03\n",
      "[799/00052] updated kl_weight: 0.03\n",
      "[799/00053] updated kl_weight: 0.03\n",
      "[799/00054] updated kl_weight: 0.03\n",
      "[799/00055] updated kl_weight: 0.03\n",
      "[799/00056] updated kl_weight: 0.03\n",
      "[799/00057] updated kl_weight: 0.03\n",
      "[799/00058] updated kl_weight: 0.03\n",
      "[799/00059] updated kl_weight: 0.03\n",
      "[799/00060] updated kl_weight: 0.03\n",
      "[799/00061] updated kl_weight: 0.03\n",
      "[799/00062] updated kl_weight: 0.03\n",
      "[799/00063] updated kl_weight: 0.03\n",
      "[799/00064] updated kl_weight: 0.03\n",
      "[799/00065] updated kl_weight: 0.03\n",
      "[799/00066] updated kl_weight: 0.03\n",
      "[799/00067] updated kl_weight: 0.03\n",
      "[799/00068] updated kl_weight: 0.03\n",
      "[799/00069] updated kl_weight: 0.03\n",
      "[799/00070] updated kl_weight: 0.03\n",
      "[799/00071] updated kl_weight: 0.03\n",
      "[799/00072] updated kl_weight: 0.03\n",
      "[799/00073] updated kl_weight: 0.03\n",
      "[799/00074] updated kl_weight: 0.03\n",
      "[799/00074] train_loss: 0.021928 kl_loss: 0.202086 normal_loss: 0.015866\n",
      "[799/00074] MMD 0.0052238330245018005\n",
      "[799/00074] TMD 0.06622792780399323\n",
      "[801/00024] train_loss: 0.021970 kl_loss: 0.202201 normal_loss: 0.015904\n",
      "[802/00049] train_loss: 0.021913 kl_loss: 0.201886 normal_loss: 0.015856\n",
      "[803/00074] train_loss: 0.021924 kl_loss: 0.202068 normal_loss: 0.015862\n",
      "[805/00024] train_loss: 0.021951 kl_loss: 0.201995 normal_loss: 0.015891\n",
      "[806/00049] train_loss: 0.021887 kl_loss: 0.201945 normal_loss: 0.015828\n",
      "[807/00074] train_loss: 0.021950 kl_loss: 0.202154 normal_loss: 0.015885\n",
      "[809/00024] train_loss: 0.021902 kl_loss: 0.201985 normal_loss: 0.015842\n",
      "[810/00049] train_loss: 0.022017 kl_loss: 0.202485 normal_loss: 0.015942\n",
      "[811/00074] train_loss: 0.021891 kl_loss: 0.201562 normal_loss: 0.015844\n",
      "[813/00024] train_loss: 0.021887 kl_loss: 0.201796 normal_loss: 0.015833\n",
      "[814/00049] train_loss: 0.022067 kl_loss: 0.202740 normal_loss: 0.015984\n",
      "[815/00074] train_loss: 0.021890 kl_loss: 0.201439 normal_loss: 0.015847\n",
      "[817/00024] train_loss: 0.021879 kl_loss: 0.202061 normal_loss: 0.015817\n",
      "[818/00049] train_loss: 0.021873 kl_loss: 0.201554 normal_loss: 0.015826\n",
      "[819/00074] train_loss: 0.021987 kl_loss: 0.202300 normal_loss: 0.015918\n",
      "[821/00024] train_loss: 0.021986 kl_loss: 0.201943 normal_loss: 0.015928\n",
      "[822/00049] train_loss: 0.021957 kl_loss: 0.202103 normal_loss: 0.015894\n",
      "[823/00074] train_loss: 0.021916 kl_loss: 0.201811 normal_loss: 0.015861\n",
      "[825/00024] train_loss: 0.021961 kl_loss: 0.202127 normal_loss: 0.015897\n",
      "[826/00049] train_loss: 0.021953 kl_loss: 0.202250 normal_loss: 0.015886\n",
      "[827/00074] train_loss: 0.021861 kl_loss: 0.201425 normal_loss: 0.015818\n",
      "[829/00024] train_loss: 0.021878 kl_loss: 0.201779 normal_loss: 0.015825\n",
      "[830/00049] train_loss: 0.022020 kl_loss: 0.202468 normal_loss: 0.015946\n",
      "[831/00074] train_loss: 0.021846 kl_loss: 0.201498 normal_loss: 0.015801\n",
      "[833/00024] train_loss: 0.021977 kl_loss: 0.202385 normal_loss: 0.015906\n",
      "[834/00049] train_loss: 0.021802 kl_loss: 0.201659 normal_loss: 0.015752\n",
      "[835/00074] train_loss: 0.021874 kl_loss: 0.201637 normal_loss: 0.015825\n",
      "[837/00024] train_loss: 0.021875 kl_loss: 0.201597 normal_loss: 0.015827\n",
      "[838/00049] train_loss: 0.021939 kl_loss: 0.202304 normal_loss: 0.015870\n",
      "[839/00074] train_loss: 0.021916 kl_loss: 0.201716 normal_loss: 0.015865\n",
      "[841/00024] train_loss: 0.021913 kl_loss: 0.201639 normal_loss: 0.015864\n",
      "[842/00049] train_loss: 0.021915 kl_loss: 0.201921 normal_loss: 0.015857\n",
      "[843/00074] train_loss: 0.021927 kl_loss: 0.201995 normal_loss: 0.015867\n",
      "[845/00024] train_loss: 0.021888 kl_loss: 0.201575 normal_loss: 0.015840\n",
      "[846/00049] train_loss: 0.021929 kl_loss: 0.202059 normal_loss: 0.015867\n",
      "[847/00074] train_loss: 0.021872 kl_loss: 0.201862 normal_loss: 0.015816\n",
      "[849/00024] train_loss: 0.021898 kl_loss: 0.202158 normal_loss: 0.015834\n",
      "[849/00074] MMD 0.0049630519933998585\n",
      "[849/00074] TMD 0.07152298837900162\n",
      "[850/00049] train_loss: 0.021815 kl_loss: 0.201062 normal_loss: 0.015783\n",
      "[851/00074] train_loss: 0.022000 kl_loss: 0.202211 normal_loss: 0.015933\n",
      "[853/00024] train_loss: 0.021930 kl_loss: 0.202043 normal_loss: 0.015869\n",
      "[854/00049] train_loss: 0.021954 kl_loss: 0.201693 normal_loss: 0.015903\n",
      "[855/00074] train_loss: 0.021883 kl_loss: 0.201637 normal_loss: 0.015834\n",
      "[857/00024] train_loss: 0.021923 kl_loss: 0.201800 normal_loss: 0.015869\n",
      "[858/00049] train_loss: 0.021937 kl_loss: 0.201836 normal_loss: 0.015882\n",
      "[859/00074] train_loss: 0.021867 kl_loss: 0.201683 normal_loss: 0.015816\n",
      "[861/00024] train_loss: 0.021853 kl_loss: 0.201496 normal_loss: 0.015809\n",
      "[862/00049] train_loss: 0.022010 kl_loss: 0.202669 normal_loss: 0.015930\n",
      "[863/00074] train_loss: 0.021797 kl_loss: 0.201096 normal_loss: 0.015764\n",
      "[865/00024] train_loss: 0.021889 kl_loss: 0.201775 normal_loss: 0.015836\n",
      "[866/00049] train_loss: 0.021965 kl_loss: 0.201991 normal_loss: 0.015905\n",
      "[867/00074] train_loss: 0.021822 kl_loss: 0.201433 normal_loss: 0.015779\n",
      "[869/00024] train_loss: 0.021860 kl_loss: 0.201323 normal_loss: 0.015821\n",
      "[870/00049] train_loss: 0.021915 kl_loss: 0.201836 normal_loss: 0.015860\n",
      "[871/00074] train_loss: 0.021927 kl_loss: 0.201980 normal_loss: 0.015867\n",
      "[873/00024] train_loss: 0.021836 kl_loss: 0.201324 normal_loss: 0.015796\n",
      "[874/00049] train_loss: 0.022019 kl_loss: 0.202694 normal_loss: 0.015938\n",
      "[875/00074] train_loss: 0.021856 kl_loss: 0.201063 normal_loss: 0.015824\n",
      "[877/00024] train_loss: 0.021907 kl_loss: 0.201991 normal_loss: 0.015847\n",
      "[878/00049] train_loss: 0.021871 kl_loss: 0.201334 normal_loss: 0.015831\n",
      "[879/00074] train_loss: 0.021895 kl_loss: 0.201696 normal_loss: 0.015844\n",
      "[881/00024] train_loss: 0.021875 kl_loss: 0.201576 normal_loss: 0.015828\n",
      "[882/00049] train_loss: 0.021969 kl_loss: 0.201948 normal_loss: 0.015910\n",
      "[883/00074] train_loss: 0.021863 kl_loss: 0.201439 normal_loss: 0.015820\n",
      "[885/00024] train_loss: 0.021900 kl_loss: 0.201873 normal_loss: 0.015843\n",
      "[886/00049] train_loss: 0.021917 kl_loss: 0.201452 normal_loss: 0.015874\n",
      "[887/00074] train_loss: 0.021844 kl_loss: 0.201578 normal_loss: 0.015796\n",
      "[889/00024] train_loss: 0.021813 kl_loss: 0.201035 normal_loss: 0.015782\n",
      "[890/00049] train_loss: 0.021958 kl_loss: 0.202160 normal_loss: 0.015893\n",
      "[891/00074] train_loss: 0.021853 kl_loss: 0.201650 normal_loss: 0.015803\n",
      "[893/00024] train_loss: 0.021932 kl_loss: 0.201776 normal_loss: 0.015878\n",
      "[894/00049] train_loss: 0.021766 kl_loss: 0.200839 normal_loss: 0.015741\n",
      "[895/00074] train_loss: 0.021994 kl_loss: 0.202170 normal_loss: 0.015929\n",
      "[897/00024] train_loss: 0.021856 kl_loss: 0.201241 normal_loss: 0.015819\n",
      "[898/00049] train_loss: 0.021918 kl_loss: 0.201887 normal_loss: 0.015862\n",
      "[899/00000] updated kl_weight: 0.03\n",
      "[899/00001] updated kl_weight: 0.03\n",
      "[899/00002] updated kl_weight: 0.03\n",
      "[899/00003] updated kl_weight: 0.03\n",
      "[899/00004] updated kl_weight: 0.03\n",
      "[899/00005] updated kl_weight: 0.03\n",
      "[899/00006] updated kl_weight: 0.03\n",
      "[899/00007] updated kl_weight: 0.03\n",
      "[899/00008] updated kl_weight: 0.03\n",
      "[899/00009] updated kl_weight: 0.03\n",
      "[899/00010] updated kl_weight: 0.03\n",
      "[899/00011] updated kl_weight: 0.03\n",
      "[899/00012] updated kl_weight: 0.03\n",
      "[899/00013] updated kl_weight: 0.03\n",
      "[899/00014] updated kl_weight: 0.03\n",
      "[899/00015] updated kl_weight: 0.03\n",
      "[899/00016] updated kl_weight: 0.03\n",
      "[899/00017] updated kl_weight: 0.03\n",
      "[899/00018] updated kl_weight: 0.03\n",
      "[899/00019] updated kl_weight: 0.03\n",
      "[899/00020] updated kl_weight: 0.03\n",
      "[899/00021] updated kl_weight: 0.03\n",
      "[899/00022] updated kl_weight: 0.03\n",
      "[899/00023] updated kl_weight: 0.03\n",
      "[899/00024] updated kl_weight: 0.03\n",
      "[899/00025] updated kl_weight: 0.03\n",
      "[899/00026] updated kl_weight: 0.03\n",
      "[899/00027] updated kl_weight: 0.03\n",
      "[899/00028] updated kl_weight: 0.03\n",
      "[899/00029] updated kl_weight: 0.03\n",
      "[899/00030] updated kl_weight: 0.03\n",
      "[899/00031] updated kl_weight: 0.03\n",
      "[899/00032] updated kl_weight: 0.03\n",
      "[899/00033] updated kl_weight: 0.03\n",
      "[899/00034] updated kl_weight: 0.03\n",
      "[899/00035] updated kl_weight: 0.03\n",
      "[899/00036] updated kl_weight: 0.03\n",
      "[899/00037] updated kl_weight: 0.03\n",
      "[899/00038] updated kl_weight: 0.03\n",
      "[899/00039] updated kl_weight: 0.03\n",
      "[899/00040] updated kl_weight: 0.03\n",
      "[899/00041] updated kl_weight: 0.03\n",
      "[899/00042] updated kl_weight: 0.03\n",
      "[899/00043] updated kl_weight: 0.03\n",
      "[899/00044] updated kl_weight: 0.03\n",
      "[899/00045] updated kl_weight: 0.03\n",
      "[899/00046] updated kl_weight: 0.03\n",
      "[899/00047] updated kl_weight: 0.03\n",
      "[899/00048] updated kl_weight: 0.03\n",
      "[899/00049] updated kl_weight: 0.03\n",
      "[899/00050] updated kl_weight: 0.03\n",
      "[899/00051] updated kl_weight: 0.03\n",
      "[899/00052] updated kl_weight: 0.03\n",
      "[899/00053] updated kl_weight: 0.03\n",
      "[899/00054] updated kl_weight: 0.03\n",
      "[899/00055] updated kl_weight: 0.03\n",
      "[899/00056] updated kl_weight: 0.03\n",
      "[899/00057] updated kl_weight: 0.03\n",
      "[899/00058] updated kl_weight: 0.03\n",
      "[899/00059] updated kl_weight: 0.03\n",
      "[899/00060] updated kl_weight: 0.03\n",
      "[899/00061] updated kl_weight: 0.03\n",
      "[899/00062] updated kl_weight: 0.03\n",
      "[899/00063] updated kl_weight: 0.03\n",
      "[899/00064] updated kl_weight: 0.03\n",
      "[899/00065] updated kl_weight: 0.03\n",
      "[899/00066] updated kl_weight: 0.03\n",
      "[899/00067] updated kl_weight: 0.03\n",
      "[899/00068] updated kl_weight: 0.03\n",
      "[899/00069] updated kl_weight: 0.03\n",
      "[899/00070] updated kl_weight: 0.03\n",
      "[899/00071] updated kl_weight: 0.03\n",
      "[899/00072] updated kl_weight: 0.03\n",
      "[899/00073] updated kl_weight: 0.03\n",
      "[899/00074] updated kl_weight: 0.03\n",
      "[899/00074] train_loss: 0.021926 kl_loss: 0.201600 normal_loss: 0.015878\n",
      "[899/00074] MMD 0.005077994894236326\n",
      "[899/00074] TMD 0.058784738183021545\n",
      "[901/00024] train_loss: 0.021838 kl_loss: 0.201432 normal_loss: 0.015795\n",
      "[902/00049] train_loss: 0.021824 kl_loss: 0.201557 normal_loss: 0.015777\n",
      "[903/00074] train_loss: 0.021897 kl_loss: 0.201690 normal_loss: 0.015846\n",
      "[905/00024] train_loss: 0.021829 kl_loss: 0.201441 normal_loss: 0.015786\n",
      "[906/00049] train_loss: 0.021872 kl_loss: 0.201493 normal_loss: 0.015827\n",
      "[907/00074] train_loss: 0.021924 kl_loss: 0.201717 normal_loss: 0.015873\n",
      "[909/00024] train_loss: 0.021845 kl_loss: 0.201446 normal_loss: 0.015802\n",
      "[910/00049] train_loss: 0.021972 kl_loss: 0.202259 normal_loss: 0.015904\n",
      "[911/00074] train_loss: 0.021798 kl_loss: 0.200916 normal_loss: 0.015771\n",
      "[913/00024] train_loss: 0.021888 kl_loss: 0.201561 normal_loss: 0.015841\n",
      "[914/00049] train_loss: 0.021899 kl_loss: 0.201723 normal_loss: 0.015848\n",
      "[915/00074] train_loss: 0.021820 kl_loss: 0.201308 normal_loss: 0.015781\n",
      "[917/00024] train_loss: 0.021876 kl_loss: 0.201381 normal_loss: 0.015834\n",
      "[918/00049] train_loss: 0.021890 kl_loss: 0.201803 normal_loss: 0.015836\n",
      "[919/00074] train_loss: 0.021899 kl_loss: 0.201378 normal_loss: 0.015858\n",
      "[921/00024] train_loss: 0.021884 kl_loss: 0.201454 normal_loss: 0.015841\n",
      "[922/00049] train_loss: 0.021881 kl_loss: 0.201483 normal_loss: 0.015837\n",
      "[923/00074] train_loss: 0.021843 kl_loss: 0.201598 normal_loss: 0.015795\n",
      "[925/00024] train_loss: 0.021866 kl_loss: 0.201726 normal_loss: 0.015814\n",
      "[926/00049] train_loss: 0.021896 kl_loss: 0.201455 normal_loss: 0.015852\n",
      "[927/00074] train_loss: 0.021817 kl_loss: 0.201324 normal_loss: 0.015777\n",
      "[929/00024] train_loss: 0.021904 kl_loss: 0.201708 normal_loss: 0.015853\n",
      "[930/00049] train_loss: 0.021829 kl_loss: 0.201659 normal_loss: 0.015779\n",
      "[931/00074] train_loss: 0.021793 kl_loss: 0.201108 normal_loss: 0.015760\n",
      "[933/00024] train_loss: 0.021869 kl_loss: 0.201418 normal_loss: 0.015826\n",
      "[934/00049] train_loss: 0.021900 kl_loss: 0.201450 normal_loss: 0.015856\n",
      "[935/00074] train_loss: 0.021886 kl_loss: 0.201576 normal_loss: 0.015839\n",
      "[937/00024] train_loss: 0.021967 kl_loss: 0.201604 normal_loss: 0.015919\n",
      "[938/00049] train_loss: 0.021762 kl_loss: 0.201173 normal_loss: 0.015727\n",
      "[939/00074] train_loss: 0.021919 kl_loss: 0.201639 normal_loss: 0.015870\n",
      "[941/00024] train_loss: 0.021897 kl_loss: 0.202152 normal_loss: 0.015832\n",
      "[942/00049] train_loss: 0.021730 kl_loss: 0.200636 normal_loss: 0.015711\n",
      "[943/00074] train_loss: 0.021901 kl_loss: 0.201597 normal_loss: 0.015853\n",
      "[945/00024] train_loss: 0.021846 kl_loss: 0.201370 normal_loss: 0.015805\n",
      "[946/00049] train_loss: 0.021841 kl_loss: 0.201624 normal_loss: 0.015792\n",
      "[947/00074] train_loss: 0.021832 kl_loss: 0.201363 normal_loss: 0.015791\n",
      "[949/00024] train_loss: 0.021842 kl_loss: 0.201443 normal_loss: 0.015798\n",
      "[949/00074] MMD 0.005082705058157444\n",
      "[949/00074] TMD 0.06526490300893784\n",
      "[950/00049] train_loss: 0.021879 kl_loss: 0.201466 normal_loss: 0.015836\n",
      "[951/00074] train_loss: 0.021870 kl_loss: 0.201417 normal_loss: 0.015828\n",
      "[953/00024] train_loss: 0.021770 kl_loss: 0.200925 normal_loss: 0.015743\n",
      "[954/00049] train_loss: 0.021942 kl_loss: 0.201919 normal_loss: 0.015884\n",
      "[955/00074] train_loss: 0.021909 kl_loss: 0.201452 normal_loss: 0.015865\n",
      "[957/00024] train_loss: 0.021840 kl_loss: 0.201206 normal_loss: 0.015804\n",
      "[958/00049] train_loss: 0.021943 kl_loss: 0.201479 normal_loss: 0.015899\n",
      "[959/00074] train_loss: 0.021869 kl_loss: 0.201582 normal_loss: 0.015821\n",
      "[961/00024] train_loss: 0.021762 kl_loss: 0.201274 normal_loss: 0.015723\n",
      "[962/00049] train_loss: 0.021996 kl_loss: 0.201971 normal_loss: 0.015937\n",
      "[963/00074] train_loss: 0.021798 kl_loss: 0.200994 normal_loss: 0.015769\n",
      "[965/00024] train_loss: 0.021895 kl_loss: 0.201924 normal_loss: 0.015838\n",
      "[966/00049] train_loss: 0.021806 kl_loss: 0.200930 normal_loss: 0.015778\n",
      "[967/00074] train_loss: 0.021864 kl_loss: 0.201355 normal_loss: 0.015823\n",
      "[969/00024] train_loss: 0.021907 kl_loss: 0.201683 normal_loss: 0.015856\n",
      "[970/00049] train_loss: 0.021799 kl_loss: 0.201086 normal_loss: 0.015767\n",
      "[971/00074] train_loss: 0.021851 kl_loss: 0.201412 normal_loss: 0.015809\n",
      "[973/00024] train_loss: 0.021854 kl_loss: 0.201270 normal_loss: 0.015816\n",
      "[974/00049] train_loss: 0.021847 kl_loss: 0.201327 normal_loss: 0.015807\n",
      "[975/00074] train_loss: 0.021862 kl_loss: 0.201554 normal_loss: 0.015816\n",
      "[977/00024] train_loss: 0.021817 kl_loss: 0.201061 normal_loss: 0.015785\n",
      "[978/00049] train_loss: 0.021881 kl_loss: 0.201692 normal_loss: 0.015830\n",
      "[979/00074] train_loss: 0.021861 kl_loss: 0.201369 normal_loss: 0.015820\n",
      "[981/00024] train_loss: 0.021816 kl_loss: 0.201142 normal_loss: 0.015782\n",
      "[982/00049] train_loss: 0.021905 kl_loss: 0.201893 normal_loss: 0.015848\n",
      "[983/00074] train_loss: 0.021840 kl_loss: 0.201058 normal_loss: 0.015808\n",
      "[985/00024] train_loss: 0.021914 kl_loss: 0.201728 normal_loss: 0.015862\n",
      "[986/00049] train_loss: 0.021847 kl_loss: 0.201192 normal_loss: 0.015811\n",
      "[987/00074] train_loss: 0.021816 kl_loss: 0.201143 normal_loss: 0.015781\n",
      "[989/00024] train_loss: 0.021841 kl_loss: 0.201233 normal_loss: 0.015804\n",
      "[990/00049] train_loss: 0.021988 kl_loss: 0.201757 normal_loss: 0.015935\n",
      "[991/00074] train_loss: 0.021793 kl_loss: 0.201045 normal_loss: 0.015762\n",
      "[993/00024] train_loss: 0.021830 kl_loss: 0.201149 normal_loss: 0.015796\n",
      "[994/00049] train_loss: 0.021897 kl_loss: 0.201895 normal_loss: 0.015840\n",
      "[995/00074] train_loss: 0.021830 kl_loss: 0.200962 normal_loss: 0.015802\n",
      "[997/00024] train_loss: 0.021845 kl_loss: 0.201386 normal_loss: 0.015804\n",
      "[998/00049] train_loss: 0.021814 kl_loss: 0.201077 normal_loss: 0.015781\n",
      "[999/00000] updated kl_weight: 0.03\n",
      "[999/00001] updated kl_weight: 0.03\n",
      "[999/00002] updated kl_weight: 0.03\n",
      "[999/00003] updated kl_weight: 0.03\n",
      "[999/00004] updated kl_weight: 0.03\n",
      "[999/00005] updated kl_weight: 0.03\n",
      "[999/00006] updated kl_weight: 0.03\n",
      "[999/00007] updated kl_weight: 0.03\n",
      "[999/00008] updated kl_weight: 0.03\n",
      "[999/00009] updated kl_weight: 0.03\n",
      "[999/00010] updated kl_weight: 0.03\n",
      "[999/00011] updated kl_weight: 0.03\n",
      "[999/00012] updated kl_weight: 0.03\n",
      "[999/00013] updated kl_weight: 0.03\n",
      "[999/00014] updated kl_weight: 0.03\n",
      "[999/00015] updated kl_weight: 0.03\n",
      "[999/00016] updated kl_weight: 0.03\n",
      "[999/00017] updated kl_weight: 0.03\n",
      "[999/00018] updated kl_weight: 0.03\n",
      "[999/00019] updated kl_weight: 0.03\n",
      "[999/00020] updated kl_weight: 0.03\n",
      "[999/00021] updated kl_weight: 0.03\n",
      "[999/00022] updated kl_weight: 0.03\n",
      "[999/00023] updated kl_weight: 0.03\n",
      "[999/00024] updated kl_weight: 0.03\n",
      "[999/00025] updated kl_weight: 0.03\n",
      "[999/00026] updated kl_weight: 0.03\n",
      "[999/00027] updated kl_weight: 0.03\n",
      "[999/00028] updated kl_weight: 0.03\n",
      "[999/00029] updated kl_weight: 0.03\n",
      "[999/00030] updated kl_weight: 0.03\n",
      "[999/00031] updated kl_weight: 0.03\n",
      "[999/00032] updated kl_weight: 0.03\n",
      "[999/00033] updated kl_weight: 0.03\n",
      "[999/00034] updated kl_weight: 0.03\n",
      "[999/00035] updated kl_weight: 0.03\n",
      "[999/00036] updated kl_weight: 0.03\n",
      "[999/00037] updated kl_weight: 0.03\n",
      "[999/00038] updated kl_weight: 0.03\n",
      "[999/00039] updated kl_weight: 0.03\n",
      "[999/00040] updated kl_weight: 0.03\n",
      "[999/00041] updated kl_weight: 0.03\n",
      "[999/00042] updated kl_weight: 0.03\n",
      "[999/00043] updated kl_weight: 0.03\n",
      "[999/00044] updated kl_weight: 0.03\n",
      "[999/00045] updated kl_weight: 0.03\n",
      "[999/00046] updated kl_weight: 0.03\n",
      "[999/00047] updated kl_weight: 0.03\n",
      "[999/00048] updated kl_weight: 0.03\n",
      "[999/00049] updated kl_weight: 0.03\n",
      "[999/00050] updated kl_weight: 0.03\n",
      "[999/00051] updated kl_weight: 0.03\n",
      "[999/00052] updated kl_weight: 0.03\n",
      "[999/00053] updated kl_weight: 0.03\n",
      "[999/00054] updated kl_weight: 0.03\n",
      "[999/00055] updated kl_weight: 0.03\n",
      "[999/00056] updated kl_weight: 0.03\n",
      "[999/00057] updated kl_weight: 0.03\n",
      "[999/00058] updated kl_weight: 0.03\n",
      "[999/00059] updated kl_weight: 0.03\n",
      "[999/00060] updated kl_weight: 0.03\n",
      "[999/00061] updated kl_weight: 0.03\n",
      "[999/00062] updated kl_weight: 0.03\n",
      "[999/00063] updated kl_weight: 0.03\n",
      "[999/00064] updated kl_weight: 0.03\n",
      "[999/00065] updated kl_weight: 0.03\n",
      "[999/00066] updated kl_weight: 0.03\n",
      "[999/00067] updated kl_weight: 0.03\n",
      "[999/00068] updated kl_weight: 0.03\n",
      "[999/00069] updated kl_weight: 0.03\n",
      "[999/00070] updated kl_weight: 0.03\n",
      "[999/00071] updated kl_weight: 0.03\n",
      "[999/00072] updated kl_weight: 0.03\n",
      "[999/00073] updated kl_weight: 0.03\n",
      "[999/00074] updated kl_weight: 0.03\n",
      "[999/00074] train_loss: 0.021876 kl_loss: 0.201513 normal_loss: 0.015830\n",
      "[999/00074] MMD 0.005058863200247288\n",
      "[999/00074] TMD 0.06404420733451843\n"
     ]
    }
   ],
   "source": [
    "# CHAIR VAD\n",
    "from scripts import train\n",
    "config = {\n",
    "    'experiment_name': 'chair_vad',\n",
    "    'device': 'cuda:0',\n",
    "    'is_overfit': False,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate_model': 0.01,\n",
    "    'learning_rate_code': 0.01,\n",
    "    'learning_rate_log_var':0.01,\n",
    "    'max_epochs': 1000,\n",
    "    'print_every_n': 100,\n",
    "    'latent_code_length' : 256,\n",
    "    'scheduler_step_size': 100,\n",
    "    'vad_free' : True,\n",
    "    'test': False,\n",
    "    'kl_weight': 0.03,\n",
    "    'kl_weight_increase_every_epochs': 100,\n",
    "    'kl_weight_increase_value': 0.0,\n",
    "    'mmd_every_epoch': 50,\n",
    "    'tmd_every_epoch': 50,\n",
    "    'iou_every_epoch': 10,\n",
    "    'resume_ckpt': None,\n",
    "    'filter_class': 'chair',\n",
    "    'decoder_var' : True\n",
    "}\n",
    "train.main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Data length 4800\n",
      "Training params: 3\n",
      "[001/00024] train_loss: 0.209842 kl_loss: 0.489154 normal_loss: 0.160927\n",
      "[002/00049] train_loss: 0.160607 kl_loss: 0.429894 normal_loss: 0.117618\n",
      "[003/00074] train_loss: 0.150132 kl_loss: 0.368432 normal_loss: 0.113288\n",
      "[005/00024] train_loss: 0.142441 kl_loss: 0.308028 normal_loss: 0.111638\n",
      "[006/00049] train_loss: 0.137221 kl_loss: 0.266177 normal_loss: 0.110604\n",
      "[007/00074] train_loss: 0.131735 kl_loss: 0.236801 normal_loss: 0.108055\n",
      "[009/00024] train_loss: 0.128022 kl_loss: 0.216909 normal_loss: 0.106331\n",
      "[010/00049] train_loss: 0.123229 kl_loss: 0.201270 normal_loss: 0.103102\n",
      "[011/00074] train_loss: 0.117859 kl_loss: 0.185326 normal_loss: 0.099327\n",
      "[013/00024] train_loss: 0.112892 kl_loss: 0.167775 normal_loss: 0.096114\n",
      "[014/00049] train_loss: 0.110428 kl_loss: 0.156501 normal_loss: 0.094778\n",
      "[015/00074] train_loss: 0.106607 kl_loss: 0.147298 normal_loss: 0.091878\n",
      "[017/00024] train_loss: 0.102991 kl_loss: 0.138078 normal_loss: 0.089183\n",
      "[018/00049] train_loss: 0.099948 kl_loss: 0.131104 normal_loss: 0.086838\n",
      "[019/00074] train_loss: 0.097561 kl_loss: 0.125007 normal_loss: 0.085060\n",
      "[021/00024] train_loss: 0.095285 kl_loss: 0.118249 normal_loss: 0.083460\n",
      "[022/00049] train_loss: 0.095594 kl_loss: 0.113696 normal_loss: 0.084224\n",
      "[023/00074] train_loss: 0.093140 kl_loss: 0.108675 normal_loss: 0.082272\n",
      "[025/00024] train_loss: 0.093274 kl_loss: 0.104756 normal_loss: 0.082799\n",
      "[026/00049] train_loss: 0.092315 kl_loss: 0.100875 normal_loss: 0.082228\n",
      "[027/00074] train_loss: 0.090158 kl_loss: 0.098900 normal_loss: 0.080268\n",
      "[029/00024] train_loss: 0.088017 kl_loss: 0.096057 normal_loss: 0.078412\n",
      "[030/00049] train_loss: 0.088090 kl_loss: 0.095180 normal_loss: 0.078572\n",
      "[031/00074] train_loss: 0.086872 kl_loss: 0.094174 normal_loss: 0.077454\n",
      "[033/00024] train_loss: 0.085701 kl_loss: 0.094365 normal_loss: 0.076265\n",
      "[034/00049] train_loss: 0.084668 kl_loss: 0.094523 normal_loss: 0.075215\n",
      "[035/00074] train_loss: 0.084211 kl_loss: 0.094696 normal_loss: 0.074741\n",
      "[037/00024] train_loss: 0.082947 kl_loss: 0.095860 normal_loss: 0.073361\n",
      "[038/00049] train_loss: 0.082720 kl_loss: 0.096677 normal_loss: 0.073052\n",
      "[039/00074] train_loss: 0.081118 kl_loss: 0.097296 normal_loss: 0.071389\n",
      "[041/00024] train_loss: 0.080891 kl_loss: 0.098552 normal_loss: 0.071036\n",
      "[042/00049] train_loss: 0.079999 kl_loss: 0.098065 normal_loss: 0.070192\n",
      "[043/00074] train_loss: 0.079764 kl_loss: 0.099941 normal_loss: 0.069770\n",
      "[045/00024] train_loss: 0.079739 kl_loss: 0.100805 normal_loss: 0.069659\n",
      "[046/00049] train_loss: 0.079694 kl_loss: 0.101916 normal_loss: 0.069503\n",
      "[047/00074] train_loss: 0.077587 kl_loss: 0.102546 normal_loss: 0.067333\n",
      "[049/00024] train_loss: 0.076703 kl_loss: 0.103283 normal_loss: 0.066374\n",
      "[049/00074] MMD 0.0049779354594647884\n",
      "[049/00074] TMD 0.06792832165956497\n",
      "[050/00049] train_loss: 0.076058 kl_loss: 0.103778 normal_loss: 0.065680\n",
      "[051/00074] train_loss: 0.076517 kl_loss: 0.105153 normal_loss: 0.066001\n",
      "[053/00024] train_loss: 0.075475 kl_loss: 0.105885 normal_loss: 0.064887\n",
      "[054/00049] train_loss: 0.075991 kl_loss: 0.106872 normal_loss: 0.065304\n",
      "[055/00074] train_loss: 0.074607 kl_loss: 0.107112 normal_loss: 0.063896\n",
      "[057/00024] train_loss: 0.076290 kl_loss: 0.108045 normal_loss: 0.065485\n",
      "[058/00049] train_loss: 0.073867 kl_loss: 0.109727 normal_loss: 0.062894\n",
      "[059/00074] train_loss: 0.073933 kl_loss: 0.109835 normal_loss: 0.062949\n",
      "[061/00024] train_loss: 0.074395 kl_loss: 0.111064 normal_loss: 0.063289\n",
      "[062/00049] train_loss: 0.073369 kl_loss: 0.112156 normal_loss: 0.062153\n",
      "[063/00074] train_loss: 0.072860 kl_loss: 0.111786 normal_loss: 0.061681\n",
      "[065/00024] train_loss: 0.071785 kl_loss: 0.112008 normal_loss: 0.060585\n",
      "[066/00049] train_loss: 0.072136 kl_loss: 0.114380 normal_loss: 0.060698\n",
      "[067/00074] train_loss: 0.071575 kl_loss: 0.113795 normal_loss: 0.060195\n",
      "[069/00024] train_loss: 0.072199 kl_loss: 0.115071 normal_loss: 0.060692\n",
      "[070/00049] train_loss: 0.071320 kl_loss: 0.115263 normal_loss: 0.059794\n",
      "[071/00074] train_loss: 0.071557 kl_loss: 0.116318 normal_loss: 0.059925\n",
      "[073/00024] train_loss: 0.070604 kl_loss: 0.116947 normal_loss: 0.058909\n",
      "[074/00049] train_loss: 0.070184 kl_loss: 0.117948 normal_loss: 0.058389\n",
      "[075/00074] train_loss: 0.071549 kl_loss: 0.118275 normal_loss: 0.059721\n",
      "[077/00024] train_loss: 0.070471 kl_loss: 0.119687 normal_loss: 0.058502\n",
      "[078/00049] train_loss: 0.069787 kl_loss: 0.119233 normal_loss: 0.057863\n",
      "[079/00074] train_loss: 0.069980 kl_loss: 0.120352 normal_loss: 0.057945\n",
      "[081/00024] train_loss: 0.069194 kl_loss: 0.120934 normal_loss: 0.057101\n",
      "[082/00049] train_loss: 0.069608 kl_loss: 0.121608 normal_loss: 0.057447\n",
      "[083/00074] train_loss: 0.068698 kl_loss: 0.122825 normal_loss: 0.056416\n",
      "[085/00024] train_loss: 0.068450 kl_loss: 0.121999 normal_loss: 0.056250\n",
      "[086/00049] train_loss: 0.068858 kl_loss: 0.124881 normal_loss: 0.056370\n",
      "[087/00074] train_loss: 0.068120 kl_loss: 0.124188 normal_loss: 0.055702\n",
      "[089/00024] train_loss: 0.067459 kl_loss: 0.124888 normal_loss: 0.054970\n",
      "[090/00049] train_loss: 0.067236 kl_loss: 0.126313 normal_loss: 0.054605\n",
      "[091/00074] train_loss: 0.067620 kl_loss: 0.125588 normal_loss: 0.055061\n",
      "[093/00024] train_loss: 0.067234 kl_loss: 0.126848 normal_loss: 0.054549\n",
      "[094/00049] train_loss: 0.066986 kl_loss: 0.127773 normal_loss: 0.054209\n",
      "[095/00074] train_loss: 0.066173 kl_loss: 0.128009 normal_loss: 0.053372\n",
      "[097/00024] train_loss: 0.065484 kl_loss: 0.128420 normal_loss: 0.052642\n",
      "[098/00049] train_loss: 0.067072 kl_loss: 0.129823 normal_loss: 0.054090\n",
      "[099/00000] updated kl_weight: 0.1\n",
      "[099/00001] updated kl_weight: 0.1\n",
      "[099/00002] updated kl_weight: 0.1\n",
      "[099/00003] updated kl_weight: 0.1\n",
      "[099/00004] updated kl_weight: 0.1\n",
      "[099/00005] updated kl_weight: 0.1\n",
      "[099/00006] updated kl_weight: 0.1\n",
      "[099/00007] updated kl_weight: 0.1\n",
      "[099/00008] updated kl_weight: 0.1\n",
      "[099/00009] updated kl_weight: 0.1\n",
      "[099/00010] updated kl_weight: 0.1\n",
      "[099/00011] updated kl_weight: 0.1\n",
      "[099/00012] updated kl_weight: 0.1\n",
      "[099/00013] updated kl_weight: 0.1\n",
      "[099/00014] updated kl_weight: 0.1\n",
      "[099/00015] updated kl_weight: 0.1\n",
      "[099/00016] updated kl_weight: 0.1\n",
      "[099/00017] updated kl_weight: 0.1\n",
      "[099/00018] updated kl_weight: 0.1\n",
      "[099/00019] updated kl_weight: 0.1\n",
      "[099/00020] updated kl_weight: 0.1\n",
      "[099/00021] updated kl_weight: 0.1\n",
      "[099/00022] updated kl_weight: 0.1\n",
      "[099/00023] updated kl_weight: 0.1\n",
      "[099/00024] updated kl_weight: 0.1\n",
      "[099/00025] updated kl_weight: 0.1\n",
      "[099/00026] updated kl_weight: 0.1\n",
      "[099/00027] updated kl_weight: 0.1\n",
      "[099/00028] updated kl_weight: 0.1\n",
      "[099/00029] updated kl_weight: 0.1\n",
      "[099/00030] updated kl_weight: 0.1\n",
      "[099/00031] updated kl_weight: 0.1\n",
      "[099/00032] updated kl_weight: 0.1\n",
      "[099/00033] updated kl_weight: 0.1\n",
      "[099/00034] updated kl_weight: 0.1\n",
      "[099/00035] updated kl_weight: 0.1\n",
      "[099/00036] updated kl_weight: 0.1\n",
      "[099/00037] updated kl_weight: 0.1\n",
      "[099/00038] updated kl_weight: 0.1\n",
      "[099/00039] updated kl_weight: 0.1\n",
      "[099/00040] updated kl_weight: 0.1\n",
      "[099/00041] updated kl_weight: 0.1\n",
      "[099/00042] updated kl_weight: 0.1\n",
      "[099/00043] updated kl_weight: 0.1\n",
      "[099/00044] updated kl_weight: 0.1\n",
      "[099/00045] updated kl_weight: 0.1\n",
      "[099/00046] updated kl_weight: 0.1\n",
      "[099/00047] updated kl_weight: 0.1\n",
      "[099/00048] updated kl_weight: 0.1\n",
      "[099/00049] updated kl_weight: 0.1\n",
      "[099/00050] updated kl_weight: 0.1\n",
      "[099/00051] updated kl_weight: 0.1\n",
      "[099/00052] updated kl_weight: 0.1\n",
      "[099/00053] updated kl_weight: 0.1\n",
      "[099/00054] updated kl_weight: 0.1\n",
      "[099/00055] updated kl_weight: 0.1\n",
      "[099/00056] updated kl_weight: 0.1\n",
      "[099/00057] updated kl_weight: 0.1\n",
      "[099/00058] updated kl_weight: 0.1\n",
      "[099/00059] updated kl_weight: 0.1\n",
      "[099/00060] updated kl_weight: 0.1\n",
      "[099/00061] updated kl_weight: 0.1\n",
      "[099/00062] updated kl_weight: 0.1\n",
      "[099/00063] updated kl_weight: 0.1\n",
      "[099/00064] updated kl_weight: 0.1\n",
      "[099/00065] updated kl_weight: 0.1\n",
      "[099/00066] updated kl_weight: 0.1\n",
      "[099/00067] updated kl_weight: 0.1\n",
      "[099/00068] updated kl_weight: 0.1\n",
      "[099/00069] updated kl_weight: 0.1\n",
      "[099/00070] updated kl_weight: 0.1\n",
      "[099/00071] updated kl_weight: 0.1\n",
      "[099/00072] updated kl_weight: 0.1\n",
      "[099/00073] updated kl_weight: 0.1\n",
      "[099/00074] updated kl_weight: 0.1\n",
      "[099/00074] train_loss: 0.067202 kl_loss: 0.129625 normal_loss: 0.054240\n",
      "[099/00074] MMD 0.0050935582257807255\n",
      "[099/00074] TMD 0.054668452590703964\n",
      "[101/00024] train_loss: 0.064375 kl_loss: 0.129509 normal_loss: 0.051424\n",
      "[102/00049] train_loss: 0.063788 kl_loss: 0.128254 normal_loss: 0.050963\n",
      "[103/00074] train_loss: 0.062609 kl_loss: 0.125957 normal_loss: 0.050013\n",
      "[105/00024] train_loss: 0.061587 kl_loss: 0.124659 normal_loss: 0.049121\n",
      "[106/00049] train_loss: 0.060710 kl_loss: 0.122443 normal_loss: 0.048465\n",
      "[107/00074] train_loss: 0.061902 kl_loss: 0.121935 normal_loss: 0.049708\n",
      "[109/00024] train_loss: 0.060703 kl_loss: 0.120567 normal_loss: 0.048647\n",
      "[110/00049] train_loss: 0.059809 kl_loss: 0.119981 normal_loss: 0.047811\n",
      "[111/00074] train_loss: 0.059727 kl_loss: 0.119153 normal_loss: 0.047812\n",
      "[113/00024] train_loss: 0.059297 kl_loss: 0.118587 normal_loss: 0.047439\n",
      "[114/00049] train_loss: 0.058812 kl_loss: 0.118368 normal_loss: 0.046976\n",
      "[115/00074] train_loss: 0.059293 kl_loss: 0.117699 normal_loss: 0.047523\n",
      "[117/00024] train_loss: 0.058547 kl_loss: 0.117836 normal_loss: 0.046764\n",
      "[118/00049] train_loss: 0.058212 kl_loss: 0.117283 normal_loss: 0.046483\n",
      "[119/00074] train_loss: 0.057877 kl_loss: 0.116891 normal_loss: 0.046188\n",
      "[121/00024] train_loss: 0.058048 kl_loss: 0.117286 normal_loss: 0.046319\n",
      "[122/00049] train_loss: 0.058216 kl_loss: 0.117442 normal_loss: 0.046472\n",
      "[123/00074] train_loss: 0.058075 kl_loss: 0.116480 normal_loss: 0.046427\n",
      "[125/00024] train_loss: 0.057781 kl_loss: 0.117817 normal_loss: 0.045999\n",
      "[126/00049] train_loss: 0.057427 kl_loss: 0.116397 normal_loss: 0.045788\n",
      "[127/00074] train_loss: 0.057561 kl_loss: 0.117011 normal_loss: 0.045860\n",
      "[129/00024] train_loss: 0.057304 kl_loss: 0.117447 normal_loss: 0.045559\n",
      "[130/00049] train_loss: 0.057170 kl_loss: 0.117604 normal_loss: 0.045409\n",
      "[131/00074] train_loss: 0.057793 kl_loss: 0.117832 normal_loss: 0.046010\n",
      "[133/00024] train_loss: 0.058401 kl_loss: 0.117823 normal_loss: 0.046619\n",
      "[134/00049] train_loss: 0.057154 kl_loss: 0.118823 normal_loss: 0.045271\n",
      "[135/00074] train_loss: 0.057108 kl_loss: 0.118495 normal_loss: 0.045259\n",
      "[137/00024] train_loss: 0.056769 kl_loss: 0.119275 normal_loss: 0.044842\n",
      "[138/00049] train_loss: 0.056233 kl_loss: 0.118587 normal_loss: 0.044375\n",
      "[139/00074] train_loss: 0.055901 kl_loss: 0.119496 normal_loss: 0.043952\n",
      "[141/00024] train_loss: 0.055547 kl_loss: 0.119284 normal_loss: 0.043618\n",
      "[142/00049] train_loss: 0.056220 kl_loss: 0.120509 normal_loss: 0.044169\n",
      "[143/00074] train_loss: 0.055317 kl_loss: 0.119282 normal_loss: 0.043389\n",
      "[145/00024] train_loss: 0.055563 kl_loss: 0.119865 normal_loss: 0.043577\n",
      "[146/00049] train_loss: 0.055920 kl_loss: 0.121698 normal_loss: 0.043750\n",
      "[147/00074] train_loss: 0.054879 kl_loss: 0.119770 normal_loss: 0.042902\n",
      "[149/00024] train_loss: 0.054854 kl_loss: 0.121074 normal_loss: 0.042747\n",
      "[149/00074] MMD 0.005028381012380123\n",
      "[149/00074] TMD 0.050647493451833725\n",
      "[150/00049] train_loss: 0.054668 kl_loss: 0.120302 normal_loss: 0.042638\n",
      "[151/00074] train_loss: 0.055263 kl_loss: 0.121647 normal_loss: 0.043098\n",
      "[153/00024] train_loss: 0.054439 kl_loss: 0.120873 normal_loss: 0.042352\n",
      "[154/00049] train_loss: 0.054625 kl_loss: 0.122318 normal_loss: 0.042393\n",
      "[155/00074] train_loss: 0.054565 kl_loss: 0.122083 normal_loss: 0.042357\n",
      "[157/00024] train_loss: 0.054247 kl_loss: 0.122831 normal_loss: 0.041964\n",
      "[158/00049] train_loss: 0.054072 kl_loss: 0.121600 normal_loss: 0.041912\n",
      "[159/00074] train_loss: 0.055241 kl_loss: 0.122905 normal_loss: 0.042951\n",
      "[161/00024] train_loss: 0.054040 kl_loss: 0.123124 normal_loss: 0.041728\n",
      "[162/00049] train_loss: 0.053268 kl_loss: 0.122928 normal_loss: 0.040975\n",
      "[163/00074] train_loss: 0.053573 kl_loss: 0.123466 normal_loss: 0.041226\n",
      "[165/00024] train_loss: 0.053382 kl_loss: 0.123439 normal_loss: 0.041038\n",
      "[166/00049] train_loss: 0.053453 kl_loss: 0.124678 normal_loss: 0.040986\n",
      "[167/00074] train_loss: 0.052915 kl_loss: 0.123433 normal_loss: 0.040571\n",
      "[169/00024] train_loss: 0.053032 kl_loss: 0.124308 normal_loss: 0.040601\n",
      "[170/00049] train_loss: 0.052742 kl_loss: 0.124047 normal_loss: 0.040337\n",
      "[171/00074] train_loss: 0.052996 kl_loss: 0.125137 normal_loss: 0.040483\n",
      "[173/00024] train_loss: 0.052702 kl_loss: 0.124938 normal_loss: 0.040208\n",
      "[174/00049] train_loss: 0.052439 kl_loss: 0.125569 normal_loss: 0.039882\n",
      "[175/00074] train_loss: 0.052224 kl_loss: 0.124628 normal_loss: 0.039762\n",
      "[177/00024] train_loss: 0.052384 kl_loss: 0.125324 normal_loss: 0.039852\n",
      "[178/00049] train_loss: 0.052371 kl_loss: 0.125254 normal_loss: 0.039846\n",
      "[179/00074] train_loss: 0.052072 kl_loss: 0.125665 normal_loss: 0.039506\n",
      "[181/00024] train_loss: 0.051630 kl_loss: 0.125142 normal_loss: 0.039116\n",
      "[182/00049] train_loss: 0.052015 kl_loss: 0.126227 normal_loss: 0.039392\n",
      "[183/00074] train_loss: 0.051811 kl_loss: 0.125567 normal_loss: 0.039254\n",
      "[185/00024] train_loss: 0.051363 kl_loss: 0.125467 normal_loss: 0.038816\n",
      "[186/00049] train_loss: 0.051130 kl_loss: 0.126382 normal_loss: 0.038492\n",
      "[187/00074] train_loss: 0.051829 kl_loss: 0.126510 normal_loss: 0.039178\n",
      "[189/00024] train_loss: 0.050997 kl_loss: 0.125791 normal_loss: 0.038418\n",
      "[190/00049] train_loss: 0.051138 kl_loss: 0.127142 normal_loss: 0.038424\n",
      "[191/00074] train_loss: 0.051237 kl_loss: 0.127068 normal_loss: 0.038530\n",
      "[193/00024] train_loss: 0.050902 kl_loss: 0.127019 normal_loss: 0.038200\n",
      "[194/00049] train_loss: 0.050993 kl_loss: 0.127190 normal_loss: 0.038274\n",
      "[195/00074] train_loss: 0.050426 kl_loss: 0.127364 normal_loss: 0.037689\n",
      "[197/00024] train_loss: 0.050778 kl_loss: 0.127435 normal_loss: 0.038035\n",
      "[198/00049] train_loss: 0.050639 kl_loss: 0.127779 normal_loss: 0.037861\n",
      "[199/00000] updated kl_weight: 0.1\n",
      "[199/00001] updated kl_weight: 0.1\n",
      "[199/00002] updated kl_weight: 0.1\n",
      "[199/00003] updated kl_weight: 0.1\n",
      "[199/00004] updated kl_weight: 0.1\n",
      "[199/00005] updated kl_weight: 0.1\n",
      "[199/00006] updated kl_weight: 0.1\n",
      "[199/00007] updated kl_weight: 0.1\n",
      "[199/00008] updated kl_weight: 0.1\n",
      "[199/00009] updated kl_weight: 0.1\n",
      "[199/00010] updated kl_weight: 0.1\n",
      "[199/00011] updated kl_weight: 0.1\n",
      "[199/00012] updated kl_weight: 0.1\n",
      "[199/00013] updated kl_weight: 0.1\n",
      "[199/00014] updated kl_weight: 0.1\n",
      "[199/00015] updated kl_weight: 0.1\n",
      "[199/00016] updated kl_weight: 0.1\n",
      "[199/00017] updated kl_weight: 0.1\n",
      "[199/00018] updated kl_weight: 0.1\n",
      "[199/00019] updated kl_weight: 0.1\n",
      "[199/00020] updated kl_weight: 0.1\n",
      "[199/00021] updated kl_weight: 0.1\n",
      "[199/00022] updated kl_weight: 0.1\n",
      "[199/00023] updated kl_weight: 0.1\n",
      "[199/00024] updated kl_weight: 0.1\n",
      "[199/00025] updated kl_weight: 0.1\n",
      "[199/00026] updated kl_weight: 0.1\n",
      "[199/00027] updated kl_weight: 0.1\n",
      "[199/00028] updated kl_weight: 0.1\n",
      "[199/00029] updated kl_weight: 0.1\n",
      "[199/00030] updated kl_weight: 0.1\n",
      "[199/00031] updated kl_weight: 0.1\n",
      "[199/00032] updated kl_weight: 0.1\n",
      "[199/00033] updated kl_weight: 0.1\n",
      "[199/00034] updated kl_weight: 0.1\n",
      "[199/00035] updated kl_weight: 0.1\n",
      "[199/00036] updated kl_weight: 0.1\n",
      "[199/00037] updated kl_weight: 0.1\n",
      "[199/00038] updated kl_weight: 0.1\n",
      "[199/00039] updated kl_weight: 0.1\n",
      "[199/00040] updated kl_weight: 0.1\n",
      "[199/00041] updated kl_weight: 0.1\n",
      "[199/00042] updated kl_weight: 0.1\n",
      "[199/00043] updated kl_weight: 0.1\n",
      "[199/00044] updated kl_weight: 0.1\n",
      "[199/00045] updated kl_weight: 0.1\n",
      "[199/00046] updated kl_weight: 0.1\n",
      "[199/00047] updated kl_weight: 0.1\n",
      "[199/00048] updated kl_weight: 0.1\n",
      "[199/00049] updated kl_weight: 0.1\n",
      "[199/00050] updated kl_weight: 0.1\n",
      "[199/00051] updated kl_weight: 0.1\n",
      "[199/00052] updated kl_weight: 0.1\n",
      "[199/00053] updated kl_weight: 0.1\n",
      "[199/00054] updated kl_weight: 0.1\n",
      "[199/00055] updated kl_weight: 0.1\n",
      "[199/00056] updated kl_weight: 0.1\n",
      "[199/00057] updated kl_weight: 0.1\n",
      "[199/00058] updated kl_weight: 0.1\n",
      "[199/00059] updated kl_weight: 0.1\n",
      "[199/00060] updated kl_weight: 0.1\n",
      "[199/00061] updated kl_weight: 0.1\n",
      "[199/00062] updated kl_weight: 0.1\n",
      "[199/00063] updated kl_weight: 0.1\n",
      "[199/00064] updated kl_weight: 0.1\n",
      "[199/00065] updated kl_weight: 0.1\n",
      "[199/00066] updated kl_weight: 0.1\n",
      "[199/00067] updated kl_weight: 0.1\n",
      "[199/00068] updated kl_weight: 0.1\n",
      "[199/00069] updated kl_weight: 0.1\n",
      "[199/00070] updated kl_weight: 0.1\n",
      "[199/00071] updated kl_weight: 0.1\n",
      "[199/00072] updated kl_weight: 0.1\n",
      "[199/00073] updated kl_weight: 0.1\n",
      "[199/00074] updated kl_weight: 0.1\n",
      "[199/00074] train_loss: 0.050483 kl_loss: 0.127431 normal_loss: 0.037740\n",
      "[199/00074] MMD 0.0049752043560147285\n",
      "[199/00074] TMD 0.05464789643883705\n",
      "[201/00024] train_loss: 0.049314 kl_loss: 0.127268 normal_loss: 0.036587\n",
      "[202/00049] train_loss: 0.048518 kl_loss: 0.126868 normal_loss: 0.035831\n",
      "[203/00074] train_loss: 0.048711 kl_loss: 0.127037 normal_loss: 0.036007\n",
      "[205/00024] train_loss: 0.048173 kl_loss: 0.126090 normal_loss: 0.035564\n",
      "[206/00049] train_loss: 0.048173 kl_loss: 0.125565 normal_loss: 0.035616\n",
      "[207/00074] train_loss: 0.048100 kl_loss: 0.125027 normal_loss: 0.035597\n",
      "[209/00024] train_loss: 0.047721 kl_loss: 0.124649 normal_loss: 0.035256\n",
      "[210/00049] train_loss: 0.047590 kl_loss: 0.125049 normal_loss: 0.035085\n",
      "[211/00074] train_loss: 0.047409 kl_loss: 0.123485 normal_loss: 0.035061\n",
      "[213/00024] train_loss: 0.047254 kl_loss: 0.123306 normal_loss: 0.034924\n",
      "[214/00049] train_loss: 0.047337 kl_loss: 0.124271 normal_loss: 0.034910\n",
      "[215/00074] train_loss: 0.046938 kl_loss: 0.122500 normal_loss: 0.034688\n",
      "[217/00024] train_loss: 0.046795 kl_loss: 0.122499 normal_loss: 0.034545\n",
      "[218/00049] train_loss: 0.046892 kl_loss: 0.122966 normal_loss: 0.034596\n",
      "[219/00074] train_loss: 0.046822 kl_loss: 0.122440 normal_loss: 0.034578\n",
      "[221/00024] train_loss: 0.046439 kl_loss: 0.122037 normal_loss: 0.034236\n",
      "[222/00049] train_loss: 0.046464 kl_loss: 0.121450 normal_loss: 0.034319\n",
      "[223/00074] train_loss: 0.046840 kl_loss: 0.122172 normal_loss: 0.034623\n",
      "[225/00024] train_loss: 0.046236 kl_loss: 0.121414 normal_loss: 0.034094\n",
      "[226/00049] train_loss: 0.046330 kl_loss: 0.121668 normal_loss: 0.034163\n",
      "[227/00074] train_loss: 0.046338 kl_loss: 0.121096 normal_loss: 0.034228\n",
      "[229/00024] train_loss: 0.046297 kl_loss: 0.121459 normal_loss: 0.034151\n",
      "[230/00049] train_loss: 0.045976 kl_loss: 0.120535 normal_loss: 0.033923\n",
      "[231/00074] train_loss: 0.045950 kl_loss: 0.120930 normal_loss: 0.033857\n",
      "[233/00024] train_loss: 0.045963 kl_loss: 0.120587 normal_loss: 0.033904\n",
      "[234/00049] train_loss: 0.045928 kl_loss: 0.120950 normal_loss: 0.033833\n",
      "[235/00074] train_loss: 0.046007 kl_loss: 0.120511 normal_loss: 0.033956\n",
      "[237/00024] train_loss: 0.045903 kl_loss: 0.120466 normal_loss: 0.033856\n",
      "[238/00049] train_loss: 0.045777 kl_loss: 0.120476 normal_loss: 0.033729\n",
      "[239/00074] train_loss: 0.045622 kl_loss: 0.120304 normal_loss: 0.033592\n",
      "[241/00024] train_loss: 0.045677 kl_loss: 0.120562 normal_loss: 0.033621\n",
      "[242/00049] train_loss: 0.045536 kl_loss: 0.120005 normal_loss: 0.033535\n",
      "[243/00074] train_loss: 0.045417 kl_loss: 0.120229 normal_loss: 0.033394\n",
      "[245/00024] train_loss: 0.045397 kl_loss: 0.120268 normal_loss: 0.033370\n",
      "[246/00049] train_loss: 0.045480 kl_loss: 0.120301 normal_loss: 0.033450\n",
      "[247/00074] train_loss: 0.045164 kl_loss: 0.119791 normal_loss: 0.033185\n",
      "[249/00024] train_loss: 0.045142 kl_loss: 0.120240 normal_loss: 0.033118\n",
      "[249/00074] MMD 0.004903558641672134\n",
      "[249/00074] TMD 0.05951046943664551\n",
      "[250/00049] train_loss: 0.044949 kl_loss: 0.119701 normal_loss: 0.032979\n",
      "[251/00074] train_loss: 0.045216 kl_loss: 0.120027 normal_loss: 0.033214\n",
      "[253/00024] train_loss: 0.045369 kl_loss: 0.120097 normal_loss: 0.033359\n",
      "[254/00049] train_loss: 0.044999 kl_loss: 0.120162 normal_loss: 0.032982\n",
      "[255/00074] train_loss: 0.045235 kl_loss: 0.119741 normal_loss: 0.033261\n",
      "[257/00024] train_loss: 0.044921 kl_loss: 0.120166 normal_loss: 0.032904\n",
      "[258/00049] train_loss: 0.045221 kl_loss: 0.119938 normal_loss: 0.033228\n",
      "[259/00074] train_loss: 0.044937 kl_loss: 0.119499 normal_loss: 0.032987\n",
      "[261/00024] train_loss: 0.044699 kl_loss: 0.119606 normal_loss: 0.032739\n",
      "[262/00049] train_loss: 0.044608 kl_loss: 0.120417 normal_loss: 0.032566\n",
      "[263/00074] train_loss: 0.044657 kl_loss: 0.119508 normal_loss: 0.032706\n",
      "[265/00024] train_loss: 0.044218 kl_loss: 0.120044 normal_loss: 0.032214\n",
      "[266/00049] train_loss: 0.044176 kl_loss: 0.119744 normal_loss: 0.032202\n",
      "[267/00074] train_loss: 0.044354 kl_loss: 0.119849 normal_loss: 0.032369\n",
      "[269/00024] train_loss: 0.044331 kl_loss: 0.119814 normal_loss: 0.032350\n",
      "[270/00049] train_loss: 0.044152 kl_loss: 0.119805 normal_loss: 0.032172\n",
      "[271/00074] train_loss: 0.044081 kl_loss: 0.119855 normal_loss: 0.032095\n",
      "[273/00024] train_loss: 0.043975 kl_loss: 0.119942 normal_loss: 0.031981\n",
      "[274/00049] train_loss: 0.044051 kl_loss: 0.119524 normal_loss: 0.032098\n",
      "[275/00074] train_loss: 0.043683 kl_loss: 0.119611 normal_loss: 0.031722\n",
      "[277/00024] train_loss: 0.043904 kl_loss: 0.119390 normal_loss: 0.031965\n",
      "[278/00049] train_loss: 0.043972 kl_loss: 0.120245 normal_loss: 0.031947\n",
      "[279/00074] train_loss: 0.043641 kl_loss: 0.119451 normal_loss: 0.031695\n",
      "[281/00024] train_loss: 0.043851 kl_loss: 0.119431 normal_loss: 0.031908\n",
      "[282/00049] train_loss: 0.044154 kl_loss: 0.120461 normal_loss: 0.032108\n",
      "[283/00074] train_loss: 0.043796 kl_loss: 0.119384 normal_loss: 0.031857\n",
      "[285/00024] train_loss: 0.043440 kl_loss: 0.120224 normal_loss: 0.031418\n",
      "[286/00049] train_loss: 0.043326 kl_loss: 0.118953 normal_loss: 0.031430\n",
      "[287/00074] train_loss: 0.043453 kl_loss: 0.120058 normal_loss: 0.031448\n",
      "[289/00024] train_loss: 0.043316 kl_loss: 0.119448 normal_loss: 0.031372\n",
      "[290/00049] train_loss: 0.043368 kl_loss: 0.120169 normal_loss: 0.031351\n",
      "[291/00074] train_loss: 0.043327 kl_loss: 0.119369 normal_loss: 0.031390\n",
      "[293/00024] train_loss: 0.043131 kl_loss: 0.120129 normal_loss: 0.031118\n",
      "[294/00049] train_loss: 0.042987 kl_loss: 0.119520 normal_loss: 0.031035\n",
      "[295/00074] train_loss: 0.042792 kl_loss: 0.119271 normal_loss: 0.030865\n",
      "[297/00024] train_loss: 0.043117 kl_loss: 0.120069 normal_loss: 0.031111\n",
      "[298/00049] train_loss: 0.042891 kl_loss: 0.119286 normal_loss: 0.030963\n",
      "[299/00000] updated kl_weight: 0.1\n",
      "[299/00001] updated kl_weight: 0.1\n",
      "[299/00002] updated kl_weight: 0.1\n",
      "[299/00003] updated kl_weight: 0.1\n",
      "[299/00004] updated kl_weight: 0.1\n",
      "[299/00005] updated kl_weight: 0.1\n",
      "[299/00006] updated kl_weight: 0.1\n",
      "[299/00007] updated kl_weight: 0.1\n",
      "[299/00008] updated kl_weight: 0.1\n",
      "[299/00009] updated kl_weight: 0.1\n",
      "[299/00010] updated kl_weight: 0.1\n",
      "[299/00011] updated kl_weight: 0.1\n",
      "[299/00012] updated kl_weight: 0.1\n",
      "[299/00013] updated kl_weight: 0.1\n",
      "[299/00014] updated kl_weight: 0.1\n",
      "[299/00015] updated kl_weight: 0.1\n",
      "[299/00016] updated kl_weight: 0.1\n",
      "[299/00017] updated kl_weight: 0.1\n",
      "[299/00018] updated kl_weight: 0.1\n",
      "[299/00019] updated kl_weight: 0.1\n",
      "[299/00020] updated kl_weight: 0.1\n",
      "[299/00021] updated kl_weight: 0.1\n",
      "[299/00022] updated kl_weight: 0.1\n",
      "[299/00023] updated kl_weight: 0.1\n",
      "[299/00024] updated kl_weight: 0.1\n",
      "[299/00025] updated kl_weight: 0.1\n",
      "[299/00026] updated kl_weight: 0.1\n",
      "[299/00027] updated kl_weight: 0.1\n",
      "[299/00028] updated kl_weight: 0.1\n",
      "[299/00029] updated kl_weight: 0.1\n",
      "[299/00030] updated kl_weight: 0.1\n",
      "[299/00031] updated kl_weight: 0.1\n",
      "[299/00032] updated kl_weight: 0.1\n",
      "[299/00033] updated kl_weight: 0.1\n",
      "[299/00034] updated kl_weight: 0.1\n",
      "[299/00035] updated kl_weight: 0.1\n",
      "[299/00036] updated kl_weight: 0.1\n",
      "[299/00037] updated kl_weight: 0.1\n",
      "[299/00038] updated kl_weight: 0.1\n",
      "[299/00039] updated kl_weight: 0.1\n",
      "[299/00040] updated kl_weight: 0.1\n",
      "[299/00041] updated kl_weight: 0.1\n",
      "[299/00042] updated kl_weight: 0.1\n",
      "[299/00043] updated kl_weight: 0.1\n",
      "[299/00044] updated kl_weight: 0.1\n",
      "[299/00045] updated kl_weight: 0.1\n",
      "[299/00046] updated kl_weight: 0.1\n",
      "[299/00047] updated kl_weight: 0.1\n",
      "[299/00048] updated kl_weight: 0.1\n",
      "[299/00049] updated kl_weight: 0.1\n",
      "[299/00050] updated kl_weight: 0.1\n",
      "[299/00051] updated kl_weight: 0.1\n",
      "[299/00052] updated kl_weight: 0.1\n",
      "[299/00053] updated kl_weight: 0.1\n",
      "[299/00054] updated kl_weight: 0.1\n",
      "[299/00055] updated kl_weight: 0.1\n",
      "[299/00056] updated kl_weight: 0.1\n",
      "[299/00057] updated kl_weight: 0.1\n",
      "[299/00058] updated kl_weight: 0.1\n",
      "[299/00059] updated kl_weight: 0.1\n",
      "[299/00060] updated kl_weight: 0.1\n",
      "[299/00061] updated kl_weight: 0.1\n",
      "[299/00062] updated kl_weight: 0.1\n",
      "[299/00063] updated kl_weight: 0.1\n",
      "[299/00064] updated kl_weight: 0.1\n",
      "[299/00065] updated kl_weight: 0.1\n",
      "[299/00066] updated kl_weight: 0.1\n",
      "[299/00067] updated kl_weight: 0.1\n",
      "[299/00068] updated kl_weight: 0.1\n",
      "[299/00069] updated kl_weight: 0.1\n",
      "[299/00070] updated kl_weight: 0.1\n",
      "[299/00071] updated kl_weight: 0.1\n",
      "[299/00072] updated kl_weight: 0.1\n",
      "[299/00073] updated kl_weight: 0.1\n",
      "[299/00074] updated kl_weight: 0.1\n",
      "[299/00074] train_loss: 0.042795 kl_loss: 0.119233 normal_loss: 0.030871\n",
      "[299/00074] MMD 0.005131459329277277\n",
      "[299/00074] TMD 0.05371399223804474\n",
      "[301/00024] train_loss: 0.042539 kl_loss: 0.119702 normal_loss: 0.030569\n",
      "[302/00049] train_loss: 0.042210 kl_loss: 0.118983 normal_loss: 0.030311\n",
      "[303/00074] train_loss: 0.042242 kl_loss: 0.119247 normal_loss: 0.030317\n",
      "[305/00024] train_loss: 0.041936 kl_loss: 0.118748 normal_loss: 0.030061\n",
      "[306/00049] train_loss: 0.041779 kl_loss: 0.118933 normal_loss: 0.029886\n",
      "[307/00074] train_loss: 0.041887 kl_loss: 0.118913 normal_loss: 0.029995\n",
      "[309/00024] train_loss: 0.041610 kl_loss: 0.118207 normal_loss: 0.029790\n",
      "[310/00049] train_loss: 0.042221 kl_loss: 0.118877 normal_loss: 0.030333\n",
      "[311/00074] train_loss: 0.041659 kl_loss: 0.118161 normal_loss: 0.029842\n",
      "[313/00024] train_loss: 0.041741 kl_loss: 0.118511 normal_loss: 0.029890\n",
      "[314/00049] train_loss: 0.041424 kl_loss: 0.117244 normal_loss: 0.029700\n",
      "[315/00074] train_loss: 0.041676 kl_loss: 0.118287 normal_loss: 0.029848\n",
      "[317/00024] train_loss: 0.041239 kl_loss: 0.117540 normal_loss: 0.029485\n",
      "[318/00049] train_loss: 0.041393 kl_loss: 0.117749 normal_loss: 0.029618\n",
      "[319/00074] train_loss: 0.041223 kl_loss: 0.117579 normal_loss: 0.029466\n",
      "[321/00024] train_loss: 0.041547 kl_loss: 0.117281 normal_loss: 0.029819\n",
      "[322/00049] train_loss: 0.041275 kl_loss: 0.117799 normal_loss: 0.029495\n",
      "[323/00074] train_loss: 0.041118 kl_loss: 0.116658 normal_loss: 0.029452\n",
      "[325/00024] train_loss: 0.041217 kl_loss: 0.117195 normal_loss: 0.029497\n",
      "[326/00049] train_loss: 0.041123 kl_loss: 0.116448 normal_loss: 0.029478\n",
      "[327/00074] train_loss: 0.041302 kl_loss: 0.117163 normal_loss: 0.029586\n",
      "[329/00024] train_loss: 0.041155 kl_loss: 0.116966 normal_loss: 0.029458\n",
      "[330/00049] train_loss: 0.040930 kl_loss: 0.116464 normal_loss: 0.029283\n",
      "[331/00074] train_loss: 0.041012 kl_loss: 0.116599 normal_loss: 0.029352\n",
      "[333/00024] train_loss: 0.041117 kl_loss: 0.116265 normal_loss: 0.029490\n",
      "[334/00049] train_loss: 0.040852 kl_loss: 0.116735 normal_loss: 0.029178\n",
      "[335/00074] train_loss: 0.040993 kl_loss: 0.116289 normal_loss: 0.029364\n",
      "[337/00024] train_loss: 0.041180 kl_loss: 0.116533 normal_loss: 0.029527\n",
      "[338/00049] train_loss: 0.040897 kl_loss: 0.116175 normal_loss: 0.029279\n",
      "[339/00074] train_loss: 0.040592 kl_loss: 0.115913 normal_loss: 0.029001\n",
      "[341/00024] train_loss: 0.040808 kl_loss: 0.116190 normal_loss: 0.029189\n",
      "[342/00049] train_loss: 0.040614 kl_loss: 0.116166 normal_loss: 0.028997\n",
      "[343/00074] train_loss: 0.040688 kl_loss: 0.115597 normal_loss: 0.029128\n",
      "[345/00024] train_loss: 0.040853 kl_loss: 0.115816 normal_loss: 0.029271\n",
      "[346/00049] train_loss: 0.040869 kl_loss: 0.116124 normal_loss: 0.029257\n",
      "[347/00074] train_loss: 0.040437 kl_loss: 0.115484 normal_loss: 0.028888\n",
      "[349/00024] train_loss: 0.040510 kl_loss: 0.115726 normal_loss: 0.028937\n",
      "[349/00074] MMD 0.00485511077567935\n",
      "[349/00074] TMD 0.05593280866742134\n",
      "[350/00049] train_loss: 0.040550 kl_loss: 0.115367 normal_loss: 0.029013\n",
      "[351/00074] train_loss: 0.040428 kl_loss: 0.115810 normal_loss: 0.028847\n",
      "[353/00024] train_loss: 0.040601 kl_loss: 0.115275 normal_loss: 0.029073\n",
      "[354/00049] train_loss: 0.040483 kl_loss: 0.115663 normal_loss: 0.028917\n",
      "[355/00074] train_loss: 0.040601 kl_loss: 0.115299 normal_loss: 0.029071\n",
      "[357/00024] train_loss: 0.040248 kl_loss: 0.115286 normal_loss: 0.028719\n",
      "[358/00049] train_loss: 0.040404 kl_loss: 0.115545 normal_loss: 0.028849\n",
      "[359/00074] train_loss: 0.040252 kl_loss: 0.115049 normal_loss: 0.028747\n",
      "[361/00024] train_loss: 0.040373 kl_loss: 0.115457 normal_loss: 0.028828\n",
      "[362/00049] train_loss: 0.040107 kl_loss: 0.114582 normal_loss: 0.028649\n",
      "[363/00074] train_loss: 0.040299 kl_loss: 0.115418 normal_loss: 0.028757\n",
      "[365/00024] train_loss: 0.040168 kl_loss: 0.115006 normal_loss: 0.028667\n",
      "[366/00049] train_loss: 0.040205 kl_loss: 0.115520 normal_loss: 0.028653\n",
      "[367/00074] train_loss: 0.040240 kl_loss: 0.114662 normal_loss: 0.028774\n",
      "[369/00024] train_loss: 0.040161 kl_loss: 0.115423 normal_loss: 0.028619\n",
      "[370/00049] train_loss: 0.039967 kl_loss: 0.114728 normal_loss: 0.028494\n",
      "[371/00074] train_loss: 0.040036 kl_loss: 0.114659 normal_loss: 0.028570\n",
      "[373/00024] train_loss: 0.039892 kl_loss: 0.114880 normal_loss: 0.028404\n",
      "[374/00049] train_loss: 0.040049 kl_loss: 0.115141 normal_loss: 0.028535\n",
      "[375/00074] train_loss: 0.040010 kl_loss: 0.114521 normal_loss: 0.028558\n",
      "[377/00024] train_loss: 0.039840 kl_loss: 0.114631 normal_loss: 0.028377\n",
      "[378/00049] train_loss: 0.039838 kl_loss: 0.114957 normal_loss: 0.028342\n",
      "[379/00074] train_loss: 0.039988 kl_loss: 0.114624 normal_loss: 0.028525\n",
      "[381/00024] train_loss: 0.039861 kl_loss: 0.114852 normal_loss: 0.028375\n",
      "[382/00049] train_loss: 0.039599 kl_loss: 0.114371 normal_loss: 0.028162\n",
      "[383/00074] train_loss: 0.039859 kl_loss: 0.114686 normal_loss: 0.028390\n",
      "[385/00024] train_loss: 0.039719 kl_loss: 0.114658 normal_loss: 0.028253\n",
      "[386/00049] train_loss: 0.039636 kl_loss: 0.114581 normal_loss: 0.028178\n",
      "[387/00074] train_loss: 0.039721 kl_loss: 0.114292 normal_loss: 0.028292\n",
      "[389/00024] train_loss: 0.039868 kl_loss: 0.115019 normal_loss: 0.028366\n",
      "[390/00049] train_loss: 0.039602 kl_loss: 0.114105 normal_loss: 0.028191\n",
      "[391/00074] train_loss: 0.039581 kl_loss: 0.114064 normal_loss: 0.028174\n",
      "[393/00024] train_loss: 0.039491 kl_loss: 0.114074 normal_loss: 0.028083\n",
      "[394/00049] train_loss: 0.039708 kl_loss: 0.114725 normal_loss: 0.028236\n",
      "[395/00074] train_loss: 0.039494 kl_loss: 0.114106 normal_loss: 0.028084\n",
      "[397/00024] train_loss: 0.039443 kl_loss: 0.113720 normal_loss: 0.028071\n",
      "[398/00049] train_loss: 0.039418 kl_loss: 0.114605 normal_loss: 0.027958\n",
      "[399/00000] updated kl_weight: 0.1\n",
      "[399/00001] updated kl_weight: 0.1\n",
      "[399/00002] updated kl_weight: 0.1\n",
      "[399/00003] updated kl_weight: 0.1\n",
      "[399/00004] updated kl_weight: 0.1\n",
      "[399/00005] updated kl_weight: 0.1\n",
      "[399/00006] updated kl_weight: 0.1\n",
      "[399/00007] updated kl_weight: 0.1\n",
      "[399/00008] updated kl_weight: 0.1\n",
      "[399/00009] updated kl_weight: 0.1\n",
      "[399/00010] updated kl_weight: 0.1\n",
      "[399/00011] updated kl_weight: 0.1\n",
      "[399/00012] updated kl_weight: 0.1\n",
      "[399/00013] updated kl_weight: 0.1\n",
      "[399/00014] updated kl_weight: 0.1\n",
      "[399/00015] updated kl_weight: 0.1\n",
      "[399/00016] updated kl_weight: 0.1\n",
      "[399/00017] updated kl_weight: 0.1\n",
      "[399/00018] updated kl_weight: 0.1\n",
      "[399/00019] updated kl_weight: 0.1\n",
      "[399/00020] updated kl_weight: 0.1\n",
      "[399/00021] updated kl_weight: 0.1\n",
      "[399/00022] updated kl_weight: 0.1\n",
      "[399/00023] updated kl_weight: 0.1\n",
      "[399/00024] updated kl_weight: 0.1\n",
      "[399/00025] updated kl_weight: 0.1\n",
      "[399/00026] updated kl_weight: 0.1\n",
      "[399/00027] updated kl_weight: 0.1\n",
      "[399/00028] updated kl_weight: 0.1\n",
      "[399/00029] updated kl_weight: 0.1\n",
      "[399/00030] updated kl_weight: 0.1\n",
      "[399/00031] updated kl_weight: 0.1\n",
      "[399/00032] updated kl_weight: 0.1\n",
      "[399/00033] updated kl_weight: 0.1\n",
      "[399/00034] updated kl_weight: 0.1\n",
      "[399/00035] updated kl_weight: 0.1\n",
      "[399/00036] updated kl_weight: 0.1\n",
      "[399/00037] updated kl_weight: 0.1\n",
      "[399/00038] updated kl_weight: 0.1\n",
      "[399/00039] updated kl_weight: 0.1\n",
      "[399/00040] updated kl_weight: 0.1\n",
      "[399/00041] updated kl_weight: 0.1\n",
      "[399/00042] updated kl_weight: 0.1\n",
      "[399/00043] updated kl_weight: 0.1\n",
      "[399/00044] updated kl_weight: 0.1\n",
      "[399/00045] updated kl_weight: 0.1\n",
      "[399/00046] updated kl_weight: 0.1\n",
      "[399/00047] updated kl_weight: 0.1\n",
      "[399/00048] updated kl_weight: 0.1\n",
      "[399/00049] updated kl_weight: 0.1\n",
      "[399/00050] updated kl_weight: 0.1\n",
      "[399/00051] updated kl_weight: 0.1\n",
      "[399/00052] updated kl_weight: 0.1\n",
      "[399/00053] updated kl_weight: 0.1\n",
      "[399/00054] updated kl_weight: 0.1\n",
      "[399/00055] updated kl_weight: 0.1\n",
      "[399/00056] updated kl_weight: 0.1\n",
      "[399/00057] updated kl_weight: 0.1\n",
      "[399/00058] updated kl_weight: 0.1\n",
      "[399/00059] updated kl_weight: 0.1\n",
      "[399/00060] updated kl_weight: 0.1\n",
      "[399/00061] updated kl_weight: 0.1\n",
      "[399/00062] updated kl_weight: 0.1\n",
      "[399/00063] updated kl_weight: 0.1\n",
      "[399/00064] updated kl_weight: 0.1\n",
      "[399/00065] updated kl_weight: 0.1\n",
      "[399/00066] updated kl_weight: 0.1\n",
      "[399/00067] updated kl_weight: 0.1\n",
      "[399/00068] updated kl_weight: 0.1\n",
      "[399/00069] updated kl_weight: 0.1\n",
      "[399/00070] updated kl_weight: 0.1\n",
      "[399/00071] updated kl_weight: 0.1\n",
      "[399/00072] updated kl_weight: 0.1\n",
      "[399/00073] updated kl_weight: 0.1\n",
      "[399/00074] updated kl_weight: 0.1\n",
      "[399/00074] train_loss: 0.039390 kl_loss: 0.114107 normal_loss: 0.027980\n",
      "[399/00074] MMD 0.005122062284499407\n",
      "[399/00074] TMD 0.049341313540935516\n",
      "[401/00024] train_loss: 0.039222 kl_loss: 0.113906 normal_loss: 0.027832\n",
      "[402/00049] train_loss: 0.039029 kl_loss: 0.114305 normal_loss: 0.027599\n",
      "[403/00074] train_loss: 0.038948 kl_loss: 0.113780 normal_loss: 0.027570\n",
      "[405/00024] train_loss: 0.039078 kl_loss: 0.113816 normal_loss: 0.027696\n",
      "[406/00049] train_loss: 0.039013 kl_loss: 0.114203 normal_loss: 0.027592\n",
      "[407/00074] train_loss: 0.038936 kl_loss: 0.113477 normal_loss: 0.027588\n",
      "[409/00024] train_loss: 0.039034 kl_loss: 0.113700 normal_loss: 0.027664\n",
      "[410/00049] train_loss: 0.038935 kl_loss: 0.113943 normal_loss: 0.027541\n",
      "[411/00074] train_loss: 0.039070 kl_loss: 0.113350 normal_loss: 0.027735\n",
      "[413/00024] train_loss: 0.038835 kl_loss: 0.113868 normal_loss: 0.027448\n",
      "[414/00049] train_loss: 0.038764 kl_loss: 0.113337 normal_loss: 0.027431\n",
      "[415/00074] train_loss: 0.038908 kl_loss: 0.113365 normal_loss: 0.027572\n",
      "[417/00024] train_loss: 0.038725 kl_loss: 0.113241 normal_loss: 0.027401\n",
      "[418/00049] train_loss: 0.038928 kl_loss: 0.113618 normal_loss: 0.027566\n",
      "[419/00074] train_loss: 0.038904 kl_loss: 0.113279 normal_loss: 0.027576\n",
      "[421/00024] train_loss: 0.038762 kl_loss: 0.113261 normal_loss: 0.027436\n",
      "[422/00049] train_loss: 0.038711 kl_loss: 0.113531 normal_loss: 0.027358\n",
      "[423/00074] train_loss: 0.038551 kl_loss: 0.112962 normal_loss: 0.027255\n",
      "[425/00024] train_loss: 0.038560 kl_loss: 0.113078 normal_loss: 0.027252\n",
      "[426/00049] train_loss: 0.038580 kl_loss: 0.113375 normal_loss: 0.027242\n",
      "[427/00074] train_loss: 0.038572 kl_loss: 0.112856 normal_loss: 0.027286\n",
      "[429/00024] train_loss: 0.038639 kl_loss: 0.113078 normal_loss: 0.027331\n",
      "[430/00049] train_loss: 0.038375 kl_loss: 0.112559 normal_loss: 0.027119\n",
      "[431/00074] train_loss: 0.038594 kl_loss: 0.113223 normal_loss: 0.027272\n",
      "[433/00024] train_loss: 0.038478 kl_loss: 0.112796 normal_loss: 0.027199\n",
      "[434/00049] train_loss: 0.038351 kl_loss: 0.112561 normal_loss: 0.027095\n",
      "[435/00074] train_loss: 0.038567 kl_loss: 0.113095 normal_loss: 0.027257\n",
      "[437/00024] train_loss: 0.038517 kl_loss: 0.112799 normal_loss: 0.027237\n",
      "[438/00049] train_loss: 0.038268 kl_loss: 0.112372 normal_loss: 0.027031\n",
      "[439/00074] train_loss: 0.038694 kl_loss: 0.112853 normal_loss: 0.027409\n",
      "[441/00024] train_loss: 0.038283 kl_loss: 0.112480 normal_loss: 0.027035\n",
      "[442/00049] train_loss: 0.038559 kl_loss: 0.112861 normal_loss: 0.027273\n",
      "[443/00074] train_loss: 0.038502 kl_loss: 0.112298 normal_loss: 0.027272\n",
      "[445/00024] train_loss: 0.038304 kl_loss: 0.112519 normal_loss: 0.027052\n",
      "[446/00049] train_loss: 0.038532 kl_loss: 0.112603 normal_loss: 0.027271\n",
      "[447/00074] train_loss: 0.038302 kl_loss: 0.112182 normal_loss: 0.027084\n",
      "[449/00024] train_loss: 0.038199 kl_loss: 0.112210 normal_loss: 0.026977\n",
      "[449/00074] MMD 0.005069850943982601\n",
      "[449/00074] TMD 0.05222398042678833\n",
      "[450/00049] train_loss: 0.038418 kl_loss: 0.112601 normal_loss: 0.027158\n",
      "[451/00074] train_loss: 0.038312 kl_loss: 0.112165 normal_loss: 0.027096\n",
      "[453/00024] train_loss: 0.038307 kl_loss: 0.112272 normal_loss: 0.027080\n",
      "[454/00049] train_loss: 0.038267 kl_loss: 0.112042 normal_loss: 0.027063\n",
      "[455/00074] train_loss: 0.038041 kl_loss: 0.112330 normal_loss: 0.026808\n",
      "[457/00024] train_loss: 0.038372 kl_loss: 0.112115 normal_loss: 0.027160\n",
      "[458/00049] train_loss: 0.038230 kl_loss: 0.112075 normal_loss: 0.027022\n",
      "[459/00074] train_loss: 0.038296 kl_loss: 0.112092 normal_loss: 0.027087\n",
      "[461/00024] train_loss: 0.038038 kl_loss: 0.111622 normal_loss: 0.026876\n",
      "[462/00049] train_loss: 0.038354 kl_loss: 0.112347 normal_loss: 0.027120\n",
      "[463/00074] train_loss: 0.038272 kl_loss: 0.112055 normal_loss: 0.027067\n",
      "[465/00024] train_loss: 0.038019 kl_loss: 0.112001 normal_loss: 0.026819\n",
      "[466/00049] train_loss: 0.038281 kl_loss: 0.111688 normal_loss: 0.027112\n",
      "[467/00074] train_loss: 0.038120 kl_loss: 0.112086 normal_loss: 0.026912\n",
      "[469/00024] train_loss: 0.038147 kl_loss: 0.111801 normal_loss: 0.026967\n",
      "[470/00049] train_loss: 0.038080 kl_loss: 0.111872 normal_loss: 0.026893\n",
      "[471/00074] train_loss: 0.037979 kl_loss: 0.111817 normal_loss: 0.026797\n",
      "[473/00024] train_loss: 0.037940 kl_loss: 0.111377 normal_loss: 0.026802\n",
      "[474/00049] train_loss: 0.038047 kl_loss: 0.112300 normal_loss: 0.026817\n",
      "[475/00074] train_loss: 0.038067 kl_loss: 0.111575 normal_loss: 0.026909\n",
      "[477/00024] train_loss: 0.038177 kl_loss: 0.111857 normal_loss: 0.026991\n",
      "[478/00049] train_loss: 0.038009 kl_loss: 0.111345 normal_loss: 0.026875\n",
      "[479/00074] train_loss: 0.037906 kl_loss: 0.111795 normal_loss: 0.026726\n",
      "[481/00024] train_loss: 0.038102 kl_loss: 0.111815 normal_loss: 0.026920\n",
      "[482/00049] train_loss: 0.037855 kl_loss: 0.111565 normal_loss: 0.026699\n",
      "[483/00074] train_loss: 0.038039 kl_loss: 0.111403 normal_loss: 0.026898\n",
      "[485/00024] train_loss: 0.038029 kl_loss: 0.111612 normal_loss: 0.026867\n",
      "[486/00049] train_loss: 0.037893 kl_loss: 0.111441 normal_loss: 0.026749\n",
      "[487/00074] train_loss: 0.037988 kl_loss: 0.111533 normal_loss: 0.026835\n",
      "[489/00024] train_loss: 0.037880 kl_loss: 0.111102 normal_loss: 0.026770\n",
      "[490/00049] train_loss: 0.037903 kl_loss: 0.111972 normal_loss: 0.026706\n",
      "[491/00074] train_loss: 0.037827 kl_loss: 0.111238 normal_loss: 0.026704\n",
      "[493/00024] train_loss: 0.037795 kl_loss: 0.111256 normal_loss: 0.026670\n",
      "[494/00049] train_loss: 0.037732 kl_loss: 0.111235 normal_loss: 0.026609\n",
      "[495/00074] train_loss: 0.037936 kl_loss: 0.111588 normal_loss: 0.026778\n",
      "[497/00024] train_loss: 0.037746 kl_loss: 0.111328 normal_loss: 0.026613\n",
      "[498/00049] train_loss: 0.037806 kl_loss: 0.111532 normal_loss: 0.026653\n",
      "[499/00000] updated kl_weight: 0.1\n",
      "[499/00001] updated kl_weight: 0.1\n",
      "[499/00002] updated kl_weight: 0.1\n",
      "[499/00003] updated kl_weight: 0.1\n",
      "[499/00004] updated kl_weight: 0.1\n",
      "[499/00005] updated kl_weight: 0.1\n",
      "[499/00006] updated kl_weight: 0.1\n",
      "[499/00007] updated kl_weight: 0.1\n",
      "[499/00008] updated kl_weight: 0.1\n",
      "[499/00009] updated kl_weight: 0.1\n",
      "[499/00010] updated kl_weight: 0.1\n",
      "[499/00011] updated kl_weight: 0.1\n",
      "[499/00012] updated kl_weight: 0.1\n",
      "[499/00013] updated kl_weight: 0.1\n",
      "[499/00014] updated kl_weight: 0.1\n",
      "[499/00015] updated kl_weight: 0.1\n",
      "[499/00016] updated kl_weight: 0.1\n",
      "[499/00017] updated kl_weight: 0.1\n",
      "[499/00018] updated kl_weight: 0.1\n",
      "[499/00019] updated kl_weight: 0.1\n",
      "[499/00020] updated kl_weight: 0.1\n",
      "[499/00021] updated kl_weight: 0.1\n",
      "[499/00022] updated kl_weight: 0.1\n",
      "[499/00023] updated kl_weight: 0.1\n",
      "[499/00024] updated kl_weight: 0.1\n",
      "[499/00025] updated kl_weight: 0.1\n",
      "[499/00026] updated kl_weight: 0.1\n",
      "[499/00027] updated kl_weight: 0.1\n",
      "[499/00028] updated kl_weight: 0.1\n",
      "[499/00029] updated kl_weight: 0.1\n",
      "[499/00030] updated kl_weight: 0.1\n",
      "[499/00031] updated kl_weight: 0.1\n",
      "[499/00032] updated kl_weight: 0.1\n",
      "[499/00033] updated kl_weight: 0.1\n",
      "[499/00034] updated kl_weight: 0.1\n",
      "[499/00035] updated kl_weight: 0.1\n",
      "[499/00036] updated kl_weight: 0.1\n",
      "[499/00037] updated kl_weight: 0.1\n",
      "[499/00038] updated kl_weight: 0.1\n",
      "[499/00039] updated kl_weight: 0.1\n",
      "[499/00040] updated kl_weight: 0.1\n",
      "[499/00041] updated kl_weight: 0.1\n",
      "[499/00042] updated kl_weight: 0.1\n",
      "[499/00043] updated kl_weight: 0.1\n",
      "[499/00044] updated kl_weight: 0.1\n",
      "[499/00045] updated kl_weight: 0.1\n",
      "[499/00046] updated kl_weight: 0.1\n",
      "[499/00047] updated kl_weight: 0.1\n",
      "[499/00048] updated kl_weight: 0.1\n",
      "[499/00049] updated kl_weight: 0.1\n",
      "[499/00050] updated kl_weight: 0.1\n",
      "[499/00051] updated kl_weight: 0.1\n",
      "[499/00052] updated kl_weight: 0.1\n",
      "[499/00053] updated kl_weight: 0.1\n",
      "[499/00054] updated kl_weight: 0.1\n",
      "[499/00055] updated kl_weight: 0.1\n",
      "[499/00056] updated kl_weight: 0.1\n",
      "[499/00057] updated kl_weight: 0.1\n",
      "[499/00058] updated kl_weight: 0.1\n",
      "[499/00059] updated kl_weight: 0.1\n",
      "[499/00060] updated kl_weight: 0.1\n",
      "[499/00061] updated kl_weight: 0.1\n",
      "[499/00062] updated kl_weight: 0.1\n",
      "[499/00063] updated kl_weight: 0.1\n",
      "[499/00064] updated kl_weight: 0.1\n",
      "[499/00065] updated kl_weight: 0.1\n",
      "[499/00066] updated kl_weight: 0.1\n",
      "[499/00067] updated kl_weight: 0.1\n",
      "[499/00068] updated kl_weight: 0.1\n",
      "[499/00069] updated kl_weight: 0.1\n",
      "[499/00070] updated kl_weight: 0.1\n",
      "[499/00071] updated kl_weight: 0.1\n",
      "[499/00072] updated kl_weight: 0.1\n",
      "[499/00073] updated kl_weight: 0.1\n",
      "[499/00074] updated kl_weight: 0.1\n",
      "[499/00074] train_loss: 0.037709 kl_loss: 0.110969 normal_loss: 0.026612\n",
      "[499/00074] MMD 0.005079459398984909\n",
      "[499/00074] TMD 0.06533458083868027\n",
      "[501/00024] train_loss: 0.037555 kl_loss: 0.111094 normal_loss: 0.026446\n",
      "[502/00049] train_loss: 0.037820 kl_loss: 0.111552 normal_loss: 0.026664\n",
      "[503/00074] train_loss: 0.037531 kl_loss: 0.110989 normal_loss: 0.026432\n",
      "[505/00024] train_loss: 0.037618 kl_loss: 0.110810 normal_loss: 0.026537\n",
      "[506/00049] train_loss: 0.037570 kl_loss: 0.111275 normal_loss: 0.026443\n",
      "[507/00074] train_loss: 0.037689 kl_loss: 0.111366 normal_loss: 0.026553\n",
      "[509/00024] train_loss: 0.037493 kl_loss: 0.111265 normal_loss: 0.026366\n",
      "[510/00049] train_loss: 0.037280 kl_loss: 0.110257 normal_loss: 0.026254\n",
      "[511/00074] train_loss: 0.037694 kl_loss: 0.111754 normal_loss: 0.026519\n",
      "[513/00024] train_loss: 0.037630 kl_loss: 0.111147 normal_loss: 0.026515\n",
      "[514/00049] train_loss: 0.037397 kl_loss: 0.110629 normal_loss: 0.026334\n",
      "[515/00074] train_loss: 0.037648 kl_loss: 0.111316 normal_loss: 0.026516\n",
      "[517/00024] train_loss: 0.037500 kl_loss: 0.111022 normal_loss: 0.026398\n",
      "[518/00049] train_loss: 0.037482 kl_loss: 0.111219 normal_loss: 0.026360\n",
      "[519/00074] train_loss: 0.037370 kl_loss: 0.110686 normal_loss: 0.026301\n",
      "[521/00024] train_loss: 0.037582 kl_loss: 0.111241 normal_loss: 0.026458\n",
      "[522/00049] train_loss: 0.037244 kl_loss: 0.110078 normal_loss: 0.026236\n",
      "[523/00074] train_loss: 0.037570 kl_loss: 0.111447 normal_loss: 0.026425\n",
      "[525/00024] train_loss: 0.037341 kl_loss: 0.110629 normal_loss: 0.026278\n",
      "[526/00049] train_loss: 0.037611 kl_loss: 0.111242 normal_loss: 0.026487\n",
      "[527/00074] train_loss: 0.037425 kl_loss: 0.110717 normal_loss: 0.026353\n",
      "[529/00024] train_loss: 0.037421 kl_loss: 0.110731 normal_loss: 0.026348\n",
      "[530/00049] train_loss: 0.037462 kl_loss: 0.111100 normal_loss: 0.026352\n",
      "[531/00074] train_loss: 0.037307 kl_loss: 0.110606 normal_loss: 0.026247\n",
      "[533/00024] train_loss: 0.037393 kl_loss: 0.110744 normal_loss: 0.026319\n",
      "[534/00049] train_loss: 0.037334 kl_loss: 0.110457 normal_loss: 0.026288\n",
      "[535/00074] train_loss: 0.037413 kl_loss: 0.111039 normal_loss: 0.026309\n",
      "[537/00024] train_loss: 0.037340 kl_loss: 0.110596 normal_loss: 0.026280\n",
      "[538/00049] train_loss: 0.037305 kl_loss: 0.110520 normal_loss: 0.026253\n",
      "[539/00074] train_loss: 0.037329 kl_loss: 0.110971 normal_loss: 0.026232\n",
      "[541/00024] train_loss: 0.037478 kl_loss: 0.110677 normal_loss: 0.026410\n",
      "[542/00049] train_loss: 0.037328 kl_loss: 0.110764 normal_loss: 0.026252\n",
      "[543/00074] train_loss: 0.037208 kl_loss: 0.110467 normal_loss: 0.026162\n",
      "[545/00024] train_loss: 0.037230 kl_loss: 0.110846 normal_loss: 0.026145\n",
      "[546/00049] train_loss: 0.037144 kl_loss: 0.110026 normal_loss: 0.026141\n",
      "[547/00074] train_loss: 0.037294 kl_loss: 0.110861 normal_loss: 0.026208\n",
      "[549/00024] train_loss: 0.037256 kl_loss: 0.110618 normal_loss: 0.026194\n",
      "[549/00074] MMD 0.004944016691297293\n",
      "[549/00074] TMD 0.05190045386552811\n",
      "[550/00049] train_loss: 0.037212 kl_loss: 0.110283 normal_loss: 0.026183\n",
      "[551/00074] train_loss: 0.037206 kl_loss: 0.110658 normal_loss: 0.026140\n",
      "[553/00024] train_loss: 0.037101 kl_loss: 0.110714 normal_loss: 0.026030\n",
      "[554/00049] train_loss: 0.037206 kl_loss: 0.110547 normal_loss: 0.026151\n",
      "[555/00074] train_loss: 0.037063 kl_loss: 0.110084 normal_loss: 0.026054\n",
      "[557/00024] train_loss: 0.037215 kl_loss: 0.110382 normal_loss: 0.026177\n",
      "[558/00049] train_loss: 0.037313 kl_loss: 0.110731 normal_loss: 0.026240\n",
      "[559/00074] train_loss: 0.037113 kl_loss: 0.110052 normal_loss: 0.026108\n",
      "[561/00024] train_loss: 0.037171 kl_loss: 0.110347 normal_loss: 0.026136\n",
      "[562/00049] train_loss: 0.037235 kl_loss: 0.110210 normal_loss: 0.026214\n",
      "[563/00074] train_loss: 0.036974 kl_loss: 0.110440 normal_loss: 0.025930\n",
      "[565/00024] train_loss: 0.037203 kl_loss: 0.110002 normal_loss: 0.026203\n",
      "[566/00049] train_loss: 0.037180 kl_loss: 0.110484 normal_loss: 0.026132\n",
      "[567/00074] train_loss: 0.037162 kl_loss: 0.110341 normal_loss: 0.026128\n",
      "[569/00024] train_loss: 0.037226 kl_loss: 0.110423 normal_loss: 0.026184\n",
      "[570/00049] train_loss: 0.037191 kl_loss: 0.110059 normal_loss: 0.026185\n",
      "[571/00074] train_loss: 0.037052 kl_loss: 0.110208 normal_loss: 0.026032\n",
      "[573/00024] train_loss: 0.037199 kl_loss: 0.110021 normal_loss: 0.026197\n",
      "[574/00049] train_loss: 0.037040 kl_loss: 0.110010 normal_loss: 0.026039\n",
      "[575/00074] train_loss: 0.037124 kl_loss: 0.110544 normal_loss: 0.026070\n",
      "[577/00024] train_loss: 0.037052 kl_loss: 0.110265 normal_loss: 0.026025\n",
      "[578/00049] train_loss: 0.037021 kl_loss: 0.110274 normal_loss: 0.025994\n",
      "[579/00074] train_loss: 0.037131 kl_loss: 0.109868 normal_loss: 0.026144\n",
      "[581/00024] train_loss: 0.036933 kl_loss: 0.109651 normal_loss: 0.025968\n",
      "[582/00049] train_loss: 0.037188 kl_loss: 0.110678 normal_loss: 0.026120\n",
      "[583/00074] train_loss: 0.036978 kl_loss: 0.109930 normal_loss: 0.025985\n",
      "[585/00024] train_loss: 0.036875 kl_loss: 0.109766 normal_loss: 0.025898\n",
      "[586/00049] train_loss: 0.037012 kl_loss: 0.110338 normal_loss: 0.025979\n",
      "[587/00074] train_loss: 0.036994 kl_loss: 0.110037 normal_loss: 0.025990\n",
      "[589/00024] train_loss: 0.037201 kl_loss: 0.110382 normal_loss: 0.026163\n",
      "[590/00049] train_loss: 0.036846 kl_loss: 0.109883 normal_loss: 0.025857\n",
      "[591/00074] train_loss: 0.036885 kl_loss: 0.109743 normal_loss: 0.025911\n",
      "[593/00024] train_loss: 0.037064 kl_loss: 0.110169 normal_loss: 0.026047\n",
      "[594/00049] train_loss: 0.036960 kl_loss: 0.109969 normal_loss: 0.025963\n",
      "[595/00074] train_loss: 0.037026 kl_loss: 0.109716 normal_loss: 0.026054\n",
      "[597/00024] train_loss: 0.036815 kl_loss: 0.109344 normal_loss: 0.025881\n",
      "[598/00049] train_loss: 0.037096 kl_loss: 0.110756 normal_loss: 0.026020\n",
      "[599/00000] updated kl_weight: 0.1\n",
      "[599/00001] updated kl_weight: 0.1\n",
      "[599/00002] updated kl_weight: 0.1\n",
      "[599/00003] updated kl_weight: 0.1\n",
      "[599/00004] updated kl_weight: 0.1\n",
      "[599/00005] updated kl_weight: 0.1\n",
      "[599/00006] updated kl_weight: 0.1\n",
      "[599/00007] updated kl_weight: 0.1\n",
      "[599/00008] updated kl_weight: 0.1\n",
      "[599/00009] updated kl_weight: 0.1\n",
      "[599/00010] updated kl_weight: 0.1\n",
      "[599/00011] updated kl_weight: 0.1\n",
      "[599/00012] updated kl_weight: 0.1\n",
      "[599/00013] updated kl_weight: 0.1\n",
      "[599/00014] updated kl_weight: 0.1\n",
      "[599/00015] updated kl_weight: 0.1\n",
      "[599/00016] updated kl_weight: 0.1\n",
      "[599/00017] updated kl_weight: 0.1\n",
      "[599/00018] updated kl_weight: 0.1\n",
      "[599/00019] updated kl_weight: 0.1\n",
      "[599/00020] updated kl_weight: 0.1\n",
      "[599/00021] updated kl_weight: 0.1\n",
      "[599/00022] updated kl_weight: 0.1\n",
      "[599/00023] updated kl_weight: 0.1\n",
      "[599/00024] updated kl_weight: 0.1\n",
      "[599/00025] updated kl_weight: 0.1\n",
      "[599/00026] updated kl_weight: 0.1\n",
      "[599/00027] updated kl_weight: 0.1\n",
      "[599/00028] updated kl_weight: 0.1\n",
      "[599/00029] updated kl_weight: 0.1\n",
      "[599/00030] updated kl_weight: 0.1\n",
      "[599/00031] updated kl_weight: 0.1\n",
      "[599/00032] updated kl_weight: 0.1\n",
      "[599/00033] updated kl_weight: 0.1\n",
      "[599/00034] updated kl_weight: 0.1\n",
      "[599/00035] updated kl_weight: 0.1\n",
      "[599/00036] updated kl_weight: 0.1\n",
      "[599/00037] updated kl_weight: 0.1\n",
      "[599/00038] updated kl_weight: 0.1\n",
      "[599/00039] updated kl_weight: 0.1\n",
      "[599/00040] updated kl_weight: 0.1\n",
      "[599/00041] updated kl_weight: 0.1\n",
      "[599/00042] updated kl_weight: 0.1\n",
      "[599/00043] updated kl_weight: 0.1\n",
      "[599/00044] updated kl_weight: 0.1\n",
      "[599/00045] updated kl_weight: 0.1\n",
      "[599/00046] updated kl_weight: 0.1\n",
      "[599/00047] updated kl_weight: 0.1\n",
      "[599/00048] updated kl_weight: 0.1\n",
      "[599/00049] updated kl_weight: 0.1\n",
      "[599/00050] updated kl_weight: 0.1\n",
      "[599/00051] updated kl_weight: 0.1\n",
      "[599/00052] updated kl_weight: 0.1\n",
      "[599/00053] updated kl_weight: 0.1\n",
      "[599/00054] updated kl_weight: 0.1\n",
      "[599/00055] updated kl_weight: 0.1\n",
      "[599/00056] updated kl_weight: 0.1\n",
      "[599/00057] updated kl_weight: 0.1\n",
      "[599/00058] updated kl_weight: 0.1\n",
      "[599/00059] updated kl_weight: 0.1\n",
      "[599/00060] updated kl_weight: 0.1\n",
      "[599/00061] updated kl_weight: 0.1\n",
      "[599/00062] updated kl_weight: 0.1\n",
      "[599/00063] updated kl_weight: 0.1\n",
      "[599/00064] updated kl_weight: 0.1\n",
      "[599/00065] updated kl_weight: 0.1\n",
      "[599/00066] updated kl_weight: 0.1\n",
      "[599/00067] updated kl_weight: 0.1\n",
      "[599/00068] updated kl_weight: 0.1\n",
      "[599/00069] updated kl_weight: 0.1\n",
      "[599/00070] updated kl_weight: 0.1\n",
      "[599/00071] updated kl_weight: 0.1\n",
      "[599/00072] updated kl_weight: 0.1\n",
      "[599/00073] updated kl_weight: 0.1\n",
      "[599/00074] updated kl_weight: 0.1\n",
      "[599/00074] train_loss: 0.036779 kl_loss: 0.109633 normal_loss: 0.025816\n",
      "[599/00074] MMD 0.005210452247411013\n",
      "[599/00074] TMD 0.060605186969041824\n",
      "[601/00024] train_loss: 0.036988 kl_loss: 0.109806 normal_loss: 0.026007\n",
      "[602/00049] train_loss: 0.036820 kl_loss: 0.110202 normal_loss: 0.025800\n",
      "[603/00074] train_loss: 0.036865 kl_loss: 0.109607 normal_loss: 0.025904\n",
      "[605/00024] train_loss: 0.037019 kl_loss: 0.110400 normal_loss: 0.025979\n",
      "[606/00049] train_loss: 0.036594 kl_loss: 0.109399 normal_loss: 0.025654\n",
      "[607/00074] train_loss: 0.036715 kl_loss: 0.109720 normal_loss: 0.025743\n",
      "[609/00024] train_loss: 0.036664 kl_loss: 0.109496 normal_loss: 0.025714\n",
      "[610/00049] train_loss: 0.036933 kl_loss: 0.110061 normal_loss: 0.025927\n",
      "[611/00074] train_loss: 0.036774 kl_loss: 0.109847 normal_loss: 0.025789\n",
      "[613/00024] train_loss: 0.036797 kl_loss: 0.109757 normal_loss: 0.025822\n",
      "[614/00049] train_loss: 0.036578 kl_loss: 0.109762 normal_loss: 0.025602\n",
      "[615/00074] train_loss: 0.036877 kl_loss: 0.109784 normal_loss: 0.025898\n",
      "[617/00024] train_loss: 0.036662 kl_loss: 0.109530 normal_loss: 0.025709\n",
      "[618/00049] train_loss: 0.036814 kl_loss: 0.109947 normal_loss: 0.025819\n",
      "[619/00074] train_loss: 0.036908 kl_loss: 0.109722 normal_loss: 0.025935\n",
      "[621/00024] train_loss: 0.036765 kl_loss: 0.109817 normal_loss: 0.025783\n",
      "[622/00049] train_loss: 0.036806 kl_loss: 0.109789 normal_loss: 0.025828\n",
      "[623/00074] train_loss: 0.036691 kl_loss: 0.109504 normal_loss: 0.025741\n",
      "[625/00024] train_loss: 0.036633 kl_loss: 0.109626 normal_loss: 0.025670\n",
      "[626/00049] train_loss: 0.036649 kl_loss: 0.109741 normal_loss: 0.025675\n",
      "[627/00074] train_loss: 0.036809 kl_loss: 0.109631 normal_loss: 0.025846\n",
      "[629/00024] train_loss: 0.036623 kl_loss: 0.109173 normal_loss: 0.025705\n",
      "[630/00049] train_loss: 0.036767 kl_loss: 0.110301 normal_loss: 0.025737\n",
      "[631/00074] train_loss: 0.036746 kl_loss: 0.109424 normal_loss: 0.025804\n",
      "[633/00024] train_loss: 0.036632 kl_loss: 0.109428 normal_loss: 0.025689\n",
      "[634/00049] train_loss: 0.036685 kl_loss: 0.109488 normal_loss: 0.025737\n",
      "[635/00074] train_loss: 0.036707 kl_loss: 0.109895 normal_loss: 0.025718\n",
      "[637/00024] train_loss: 0.036720 kl_loss: 0.109618 normal_loss: 0.025759\n",
      "[638/00049] train_loss: 0.036600 kl_loss: 0.109217 normal_loss: 0.025678\n",
      "[639/00074] train_loss: 0.036874 kl_loss: 0.109883 normal_loss: 0.025886\n",
      "[641/00024] train_loss: 0.036630 kl_loss: 0.109520 normal_loss: 0.025678\n",
      "[642/00049] train_loss: 0.036642 kl_loss: 0.109585 normal_loss: 0.025684\n",
      "[643/00074] train_loss: 0.036715 kl_loss: 0.109523 normal_loss: 0.025763\n",
      "[645/00024] train_loss: 0.036655 kl_loss: 0.109690 normal_loss: 0.025686\n",
      "[646/00049] train_loss: 0.036741 kl_loss: 0.109557 normal_loss: 0.025785\n",
      "[647/00074] train_loss: 0.036713 kl_loss: 0.109293 normal_loss: 0.025784\n",
      "[649/00024] train_loss: 0.036923 kl_loss: 0.109796 normal_loss: 0.025944\n",
      "[649/00074] MMD 0.005262576974928379\n",
      "[649/00074] TMD 0.05663289874792099\n",
      "[650/00049] train_loss: 0.036564 kl_loss: 0.109108 normal_loss: 0.025653\n",
      "[651/00074] train_loss: 0.036604 kl_loss: 0.109563 normal_loss: 0.025648\n",
      "[653/00024] train_loss: 0.036716 kl_loss: 0.109728 normal_loss: 0.025743\n",
      "[654/00049] train_loss: 0.036613 kl_loss: 0.109200 normal_loss: 0.025693\n",
      "[655/00074] train_loss: 0.036865 kl_loss: 0.109452 normal_loss: 0.025920\n",
      "[657/00024] train_loss: 0.036582 kl_loss: 0.109340 normal_loss: 0.025648\n",
      "[658/00049] train_loss: 0.036782 kl_loss: 0.109936 normal_loss: 0.025788\n",
      "[659/00074] train_loss: 0.036637 kl_loss: 0.109028 normal_loss: 0.025734\n",
      "[661/00024] train_loss: 0.036658 kl_loss: 0.109805 normal_loss: 0.025678\n",
      "[662/00049] train_loss: 0.036552 kl_loss: 0.108757 normal_loss: 0.025676\n",
      "[663/00074] train_loss: 0.036653 kl_loss: 0.109658 normal_loss: 0.025687\n",
      "[665/00024] train_loss: 0.036582 kl_loss: 0.109383 normal_loss: 0.025643\n",
      "[666/00049] train_loss: 0.036672 kl_loss: 0.109543 normal_loss: 0.025718\n",
      "[667/00074] train_loss: 0.036485 kl_loss: 0.109195 normal_loss: 0.025565\n",
      "[669/00024] train_loss: 0.036513 kl_loss: 0.109262 normal_loss: 0.025587\n",
      "[670/00049] train_loss: 0.036669 kl_loss: 0.109634 normal_loss: 0.025706\n",
      "[671/00074] train_loss: 0.036631 kl_loss: 0.109129 normal_loss: 0.025718\n",
      "[673/00024] train_loss: 0.036611 kl_loss: 0.109538 normal_loss: 0.025658\n",
      "[674/00049] train_loss: 0.036586 kl_loss: 0.109314 normal_loss: 0.025655\n",
      "[675/00074] train_loss: 0.036490 kl_loss: 0.109105 normal_loss: 0.025580\n",
      "[677/00024] train_loss: 0.036577 kl_loss: 0.109284 normal_loss: 0.025649\n",
      "[678/00049] train_loss: 0.036665 kl_loss: 0.109510 normal_loss: 0.025714\n",
      "[679/00074] train_loss: 0.036551 kl_loss: 0.109072 normal_loss: 0.025644\n",
      "[681/00024] train_loss: 0.036543 kl_loss: 0.109269 normal_loss: 0.025616\n",
      "[682/00049] train_loss: 0.036499 kl_loss: 0.108947 normal_loss: 0.025604\n",
      "[683/00074] train_loss: 0.036844 kl_loss: 0.109571 normal_loss: 0.025887\n",
      "[685/00024] train_loss: 0.036497 kl_loss: 0.109147 normal_loss: 0.025582\n",
      "[686/00049] train_loss: 0.036587 kl_loss: 0.109351 normal_loss: 0.025652\n",
      "[687/00074] train_loss: 0.036461 kl_loss: 0.109228 normal_loss: 0.025538\n",
      "[689/00024] train_loss: 0.036620 kl_loss: 0.109372 normal_loss: 0.025682\n",
      "[690/00049] train_loss: 0.036563 kl_loss: 0.108740 normal_loss: 0.025689\n",
      "[691/00074] train_loss: 0.036560 kl_loss: 0.109531 normal_loss: 0.025607\n",
      "[693/00024] train_loss: 0.036592 kl_loss: 0.109141 normal_loss: 0.025677\n",
      "[694/00049] train_loss: 0.036545 kl_loss: 0.109298 normal_loss: 0.025615\n",
      "[695/00074] train_loss: 0.036464 kl_loss: 0.109133 normal_loss: 0.025551\n",
      "[697/00024] train_loss: 0.036599 kl_loss: 0.109311 normal_loss: 0.025668\n",
      "[698/00049] train_loss: 0.036452 kl_loss: 0.109103 normal_loss: 0.025541\n",
      "[699/00000] updated kl_weight: 0.1\n",
      "[699/00001] updated kl_weight: 0.1\n",
      "[699/00002] updated kl_weight: 0.1\n",
      "[699/00003] updated kl_weight: 0.1\n",
      "[699/00004] updated kl_weight: 0.1\n",
      "[699/00005] updated kl_weight: 0.1\n",
      "[699/00006] updated kl_weight: 0.1\n",
      "[699/00007] updated kl_weight: 0.1\n",
      "[699/00008] updated kl_weight: 0.1\n",
      "[699/00009] updated kl_weight: 0.1\n",
      "[699/00010] updated kl_weight: 0.1\n",
      "[699/00011] updated kl_weight: 0.1\n",
      "[699/00012] updated kl_weight: 0.1\n",
      "[699/00013] updated kl_weight: 0.1\n",
      "[699/00014] updated kl_weight: 0.1\n",
      "[699/00015] updated kl_weight: 0.1\n",
      "[699/00016] updated kl_weight: 0.1\n",
      "[699/00017] updated kl_weight: 0.1\n",
      "[699/00018] updated kl_weight: 0.1\n",
      "[699/00019] updated kl_weight: 0.1\n",
      "[699/00020] updated kl_weight: 0.1\n",
      "[699/00021] updated kl_weight: 0.1\n",
      "[699/00022] updated kl_weight: 0.1\n",
      "[699/00023] updated kl_weight: 0.1\n",
      "[699/00024] updated kl_weight: 0.1\n",
      "[699/00025] updated kl_weight: 0.1\n",
      "[699/00026] updated kl_weight: 0.1\n",
      "[699/00027] updated kl_weight: 0.1\n",
      "[699/00028] updated kl_weight: 0.1\n",
      "[699/00029] updated kl_weight: 0.1\n",
      "[699/00030] updated kl_weight: 0.1\n",
      "[699/00031] updated kl_weight: 0.1\n",
      "[699/00032] updated kl_weight: 0.1\n",
      "[699/00033] updated kl_weight: 0.1\n",
      "[699/00034] updated kl_weight: 0.1\n",
      "[699/00035] updated kl_weight: 0.1\n",
      "[699/00036] updated kl_weight: 0.1\n",
      "[699/00037] updated kl_weight: 0.1\n",
      "[699/00038] updated kl_weight: 0.1\n",
      "[699/00039] updated kl_weight: 0.1\n",
      "[699/00040] updated kl_weight: 0.1\n",
      "[699/00041] updated kl_weight: 0.1\n",
      "[699/00042] updated kl_weight: 0.1\n",
      "[699/00043] updated kl_weight: 0.1\n",
      "[699/00044] updated kl_weight: 0.1\n",
      "[699/00045] updated kl_weight: 0.1\n",
      "[699/00046] updated kl_weight: 0.1\n",
      "[699/00047] updated kl_weight: 0.1\n",
      "[699/00048] updated kl_weight: 0.1\n",
      "[699/00049] updated kl_weight: 0.1\n",
      "[699/00050] updated kl_weight: 0.1\n",
      "[699/00051] updated kl_weight: 0.1\n",
      "[699/00052] updated kl_weight: 0.1\n",
      "[699/00053] updated kl_weight: 0.1\n",
      "[699/00054] updated kl_weight: 0.1\n",
      "[699/00055] updated kl_weight: 0.1\n",
      "[699/00056] updated kl_weight: 0.1\n",
      "[699/00057] updated kl_weight: 0.1\n",
      "[699/00058] updated kl_weight: 0.1\n",
      "[699/00059] updated kl_weight: 0.1\n",
      "[699/00060] updated kl_weight: 0.1\n",
      "[699/00061] updated kl_weight: 0.1\n",
      "[699/00062] updated kl_weight: 0.1\n",
      "[699/00063] updated kl_weight: 0.1\n",
      "[699/00064] updated kl_weight: 0.1\n",
      "[699/00065] updated kl_weight: 0.1\n",
      "[699/00066] updated kl_weight: 0.1\n",
      "[699/00067] updated kl_weight: 0.1\n",
      "[699/00068] updated kl_weight: 0.1\n",
      "[699/00069] updated kl_weight: 0.1\n",
      "[699/00070] updated kl_weight: 0.1\n",
      "[699/00071] updated kl_weight: 0.1\n",
      "[699/00072] updated kl_weight: 0.1\n",
      "[699/00073] updated kl_weight: 0.1\n",
      "[699/00074] updated kl_weight: 0.1\n",
      "[699/00074] train_loss: 0.036518 kl_loss: 0.109079 normal_loss: 0.025610\n",
      "[699/00074] MMD 0.005632794927805662\n",
      "[699/00074] TMD 0.06272869557142258\n",
      "[701/00024] train_loss: 0.036477 kl_loss: 0.109114 normal_loss: 0.025565\n",
      "[702/00049] train_loss: 0.036487 kl_loss: 0.109279 normal_loss: 0.025559\n",
      "[703/00074] train_loss: 0.036490 kl_loss: 0.109027 normal_loss: 0.025587\n",
      "[705/00024] train_loss: 0.036498 kl_loss: 0.109386 normal_loss: 0.025559\n",
      "[706/00049] train_loss: 0.036333 kl_loss: 0.108902 normal_loss: 0.025443\n",
      "[707/00074] train_loss: 0.036438 kl_loss: 0.109089 normal_loss: 0.025529\n",
      "[709/00024] train_loss: 0.036482 kl_loss: 0.109035 normal_loss: 0.025578\n",
      "[710/00049] train_loss: 0.036353 kl_loss: 0.109313 normal_loss: 0.025422\n",
      "[711/00074] train_loss: 0.036455 kl_loss: 0.108980 normal_loss: 0.025557\n",
      "[713/00024] train_loss: 0.036585 kl_loss: 0.109539 normal_loss: 0.025631\n",
      "[714/00049] train_loss: 0.036322 kl_loss: 0.108658 normal_loss: 0.025456\n",
      "[715/00074] train_loss: 0.036487 kl_loss: 0.109091 normal_loss: 0.025578\n",
      "[717/00024] train_loss: 0.036414 kl_loss: 0.108958 normal_loss: 0.025519\n",
      "[718/00049] train_loss: 0.036482 kl_loss: 0.109244 normal_loss: 0.025558\n",
      "[719/00074] train_loss: 0.036472 kl_loss: 0.109046 normal_loss: 0.025567\n",
      "[721/00024] train_loss: 0.036428 kl_loss: 0.109231 normal_loss: 0.025505\n",
      "[722/00049] train_loss: 0.036370 kl_loss: 0.108856 normal_loss: 0.025485\n",
      "[723/00074] train_loss: 0.036559 kl_loss: 0.109120 normal_loss: 0.025647\n",
      "[725/00024] train_loss: 0.036516 kl_loss: 0.108931 normal_loss: 0.025623\n",
      "[726/00049] train_loss: 0.036397 kl_loss: 0.108829 normal_loss: 0.025514\n",
      "[727/00074] train_loss: 0.036639 kl_loss: 0.109405 normal_loss: 0.025699\n",
      "[729/00024] train_loss: 0.036532 kl_loss: 0.108969 normal_loss: 0.025635\n",
      "[730/00049] train_loss: 0.036432 kl_loss: 0.109040 normal_loss: 0.025528\n",
      "[731/00074] train_loss: 0.036462 kl_loss: 0.109117 normal_loss: 0.025550\n",
      "[733/00024] train_loss: 0.036503 kl_loss: 0.109339 normal_loss: 0.025569\n",
      "[734/00049] train_loss: 0.036456 kl_loss: 0.108766 normal_loss: 0.025580\n",
      "[735/00074] train_loss: 0.036320 kl_loss: 0.108978 normal_loss: 0.025423\n",
      "[737/00024] train_loss: 0.036322 kl_loss: 0.108974 normal_loss: 0.025425\n",
      "[738/00049] train_loss: 0.036278 kl_loss: 0.108784 normal_loss: 0.025399\n",
      "[739/00074] train_loss: 0.036542 kl_loss: 0.109279 normal_loss: 0.025614\n",
      "[741/00024] train_loss: 0.036294 kl_loss: 0.108993 normal_loss: 0.025394\n",
      "[742/00049] train_loss: 0.036525 kl_loss: 0.109181 normal_loss: 0.025607\n",
      "[743/00074] train_loss: 0.036328 kl_loss: 0.108815 normal_loss: 0.025446\n",
      "[745/00024] train_loss: 0.036281 kl_loss: 0.108913 normal_loss: 0.025390\n",
      "[746/00049] train_loss: 0.036440 kl_loss: 0.108977 normal_loss: 0.025542\n",
      "[747/00074] train_loss: 0.036435 kl_loss: 0.109052 normal_loss: 0.025530\n",
      "[749/00024] train_loss: 0.036438 kl_loss: 0.109673 normal_loss: 0.025471\n",
      "[749/00074] MMD 0.005120540503412485\n",
      "[749/00074] TMD 0.06605833023786545\n",
      "[750/00049] train_loss: 0.036235 kl_loss: 0.108303 normal_loss: 0.025405\n",
      "[751/00074] train_loss: 0.036421 kl_loss: 0.108923 normal_loss: 0.025529\n",
      "[753/00024] train_loss: 0.036556 kl_loss: 0.109185 normal_loss: 0.025637\n",
      "[754/00049] train_loss: 0.036239 kl_loss: 0.108482 normal_loss: 0.025391\n",
      "[755/00074] train_loss: 0.036576 kl_loss: 0.109194 normal_loss: 0.025657\n",
      "[757/00024] train_loss: 0.036321 kl_loss: 0.109036 normal_loss: 0.025417\n",
      "[758/00049] train_loss: 0.036551 kl_loss: 0.109147 normal_loss: 0.025636\n",
      "[759/00074] train_loss: 0.036388 kl_loss: 0.108639 normal_loss: 0.025525\n",
      "[761/00024] train_loss: 0.036364 kl_loss: 0.109112 normal_loss: 0.025453\n",
      "[762/00049] train_loss: 0.036093 kl_loss: 0.108418 normal_loss: 0.025251\n",
      "[763/00074] train_loss: 0.036485 kl_loss: 0.109248 normal_loss: 0.025560\n",
      "[765/00024] train_loss: 0.036426 kl_loss: 0.108713 normal_loss: 0.025555\n",
      "[766/00049] train_loss: 0.036342 kl_loss: 0.108709 normal_loss: 0.025471\n",
      "[767/00074] train_loss: 0.036460 kl_loss: 0.109313 normal_loss: 0.025529\n",
      "[769/00024] train_loss: 0.036476 kl_loss: 0.109332 normal_loss: 0.025543\n",
      "[770/00049] train_loss: 0.036204 kl_loss: 0.108789 normal_loss: 0.025325\n",
      "[771/00074] train_loss: 0.036423 kl_loss: 0.108576 normal_loss: 0.025565\n",
      "[773/00024] train_loss: 0.036407 kl_loss: 0.109121 normal_loss: 0.025495\n",
      "[774/00049] train_loss: 0.036330 kl_loss: 0.108853 normal_loss: 0.025445\n",
      "[775/00074] train_loss: 0.036177 kl_loss: 0.108682 normal_loss: 0.025308\n",
      "[777/00024] train_loss: 0.036379 kl_loss: 0.108907 normal_loss: 0.025488\n",
      "[778/00049] train_loss: 0.036390 kl_loss: 0.108887 normal_loss: 0.025501\n",
      "[779/00074] train_loss: 0.036361 kl_loss: 0.108819 normal_loss: 0.025479\n",
      "[781/00024] train_loss: 0.036298 kl_loss: 0.108731 normal_loss: 0.025425\n",
      "[782/00049] train_loss: 0.036427 kl_loss: 0.108998 normal_loss: 0.025527\n",
      "[783/00074] train_loss: 0.036355 kl_loss: 0.108845 normal_loss: 0.025470\n",
      "[785/00024] train_loss: 0.036212 kl_loss: 0.108615 normal_loss: 0.025351\n",
      "[786/00049] train_loss: 0.036375 kl_loss: 0.108991 normal_loss: 0.025476\n",
      "[787/00074] train_loss: 0.036320 kl_loss: 0.108926 normal_loss: 0.025427\n",
      "[789/00024] train_loss: 0.036374 kl_loss: 0.108686 normal_loss: 0.025505\n",
      "[790/00049] train_loss: 0.036312 kl_loss: 0.108681 normal_loss: 0.025444\n",
      "[791/00074] train_loss: 0.036360 kl_loss: 0.109121 normal_loss: 0.025448\n",
      "[793/00024] train_loss: 0.036421 kl_loss: 0.108809 normal_loss: 0.025541\n",
      "[794/00049] train_loss: 0.036156 kl_loss: 0.108822 normal_loss: 0.025274\n",
      "[795/00074] train_loss: 0.036421 kl_loss: 0.108821 normal_loss: 0.025539\n",
      "[797/00024] train_loss: 0.036227 kl_loss: 0.108757 normal_loss: 0.025352\n",
      "[798/00049] train_loss: 0.036225 kl_loss: 0.109107 normal_loss: 0.025315\n",
      "[799/00000] updated kl_weight: 0.1\n",
      "[799/00001] updated kl_weight: 0.1\n",
      "[799/00002] updated kl_weight: 0.1\n",
      "[799/00003] updated kl_weight: 0.1\n",
      "[799/00004] updated kl_weight: 0.1\n",
      "[799/00005] updated kl_weight: 0.1\n",
      "[799/00006] updated kl_weight: 0.1\n",
      "[799/00007] updated kl_weight: 0.1\n",
      "[799/00008] updated kl_weight: 0.1\n",
      "[799/00009] updated kl_weight: 0.1\n",
      "[799/00010] updated kl_weight: 0.1\n",
      "[799/00011] updated kl_weight: 0.1\n",
      "[799/00012] updated kl_weight: 0.1\n",
      "[799/00013] updated kl_weight: 0.1\n",
      "[799/00014] updated kl_weight: 0.1\n",
      "[799/00015] updated kl_weight: 0.1\n",
      "[799/00016] updated kl_weight: 0.1\n",
      "[799/00017] updated kl_weight: 0.1\n",
      "[799/00018] updated kl_weight: 0.1\n",
      "[799/00019] updated kl_weight: 0.1\n",
      "[799/00020] updated kl_weight: 0.1\n",
      "[799/00021] updated kl_weight: 0.1\n",
      "[799/00022] updated kl_weight: 0.1\n",
      "[799/00023] updated kl_weight: 0.1\n",
      "[799/00024] updated kl_weight: 0.1\n",
      "[799/00025] updated kl_weight: 0.1\n",
      "[799/00026] updated kl_weight: 0.1\n",
      "[799/00027] updated kl_weight: 0.1\n",
      "[799/00028] updated kl_weight: 0.1\n",
      "[799/00029] updated kl_weight: 0.1\n",
      "[799/00030] updated kl_weight: 0.1\n",
      "[799/00031] updated kl_weight: 0.1\n",
      "[799/00032] updated kl_weight: 0.1\n",
      "[799/00033] updated kl_weight: 0.1\n",
      "[799/00034] updated kl_weight: 0.1\n",
      "[799/00035] updated kl_weight: 0.1\n",
      "[799/00036] updated kl_weight: 0.1\n",
      "[799/00037] updated kl_weight: 0.1\n",
      "[799/00038] updated kl_weight: 0.1\n",
      "[799/00039] updated kl_weight: 0.1\n",
      "[799/00040] updated kl_weight: 0.1\n",
      "[799/00041] updated kl_weight: 0.1\n",
      "[799/00042] updated kl_weight: 0.1\n",
      "[799/00043] updated kl_weight: 0.1\n",
      "[799/00044] updated kl_weight: 0.1\n",
      "[799/00045] updated kl_weight: 0.1\n",
      "[799/00046] updated kl_weight: 0.1\n",
      "[799/00047] updated kl_weight: 0.1\n",
      "[799/00048] updated kl_weight: 0.1\n",
      "[799/00049] updated kl_weight: 0.1\n",
      "[799/00050] updated kl_weight: 0.1\n",
      "[799/00051] updated kl_weight: 0.1\n",
      "[799/00052] updated kl_weight: 0.1\n",
      "[799/00053] updated kl_weight: 0.1\n",
      "[799/00054] updated kl_weight: 0.1\n",
      "[799/00055] updated kl_weight: 0.1\n",
      "[799/00056] updated kl_weight: 0.1\n",
      "[799/00057] updated kl_weight: 0.1\n",
      "[799/00058] updated kl_weight: 0.1\n",
      "[799/00059] updated kl_weight: 0.1\n",
      "[799/00060] updated kl_weight: 0.1\n",
      "[799/00061] updated kl_weight: 0.1\n",
      "[799/00062] updated kl_weight: 0.1\n",
      "[799/00063] updated kl_weight: 0.1\n",
      "[799/00064] updated kl_weight: 0.1\n",
      "[799/00065] updated kl_weight: 0.1\n",
      "[799/00066] updated kl_weight: 0.1\n",
      "[799/00067] updated kl_weight: 0.1\n",
      "[799/00068] updated kl_weight: 0.1\n",
      "[799/00069] updated kl_weight: 0.1\n",
      "[799/00070] updated kl_weight: 0.1\n",
      "[799/00071] updated kl_weight: 0.1\n",
      "[799/00072] updated kl_weight: 0.1\n",
      "[799/00073] updated kl_weight: 0.1\n",
      "[799/00074] updated kl_weight: 0.1\n",
      "[799/00074] train_loss: 0.036348 kl_loss: 0.108545 normal_loss: 0.025493\n",
      "[799/00074] MMD 0.005185774061828852\n",
      "[799/00074] TMD 0.05766476318240166\n",
      "[801/00024] train_loss: 0.036292 kl_loss: 0.108470 normal_loss: 0.025445\n",
      "[802/00049] train_loss: 0.036269 kl_loss: 0.109324 normal_loss: 0.025336\n",
      "[803/00074] train_loss: 0.036345 kl_loss: 0.108580 normal_loss: 0.025487\n",
      "[805/00024] train_loss: 0.036239 kl_loss: 0.108876 normal_loss: 0.025351\n",
      "[806/00049] train_loss: 0.036154 kl_loss: 0.108732 normal_loss: 0.025280\n",
      "[807/00074] train_loss: 0.036431 kl_loss: 0.108746 normal_loss: 0.025557\n",
      "[809/00024] train_loss: 0.036416 kl_loss: 0.109060 normal_loss: 0.025510\n",
      "[810/00049] train_loss: 0.036120 kl_loss: 0.108539 normal_loss: 0.025266\n",
      "[811/00074] train_loss: 0.036288 kl_loss: 0.108737 normal_loss: 0.025414\n",
      "[813/00024] train_loss: 0.036263 kl_loss: 0.108804 normal_loss: 0.025383\n",
      "[814/00049] train_loss: 0.036351 kl_loss: 0.108970 normal_loss: 0.025454\n",
      "[815/00074] train_loss: 0.036279 kl_loss: 0.108540 normal_loss: 0.025425\n",
      "[817/00024] train_loss: 0.036301 kl_loss: 0.108837 normal_loss: 0.025418\n",
      "[818/00049] train_loss: 0.036199 kl_loss: 0.108971 normal_loss: 0.025302\n",
      "[819/00074] train_loss: 0.036276 kl_loss: 0.108485 normal_loss: 0.025427\n",
      "[821/00024] train_loss: 0.036293 kl_loss: 0.108719 normal_loss: 0.025421\n",
      "[822/00049] train_loss: 0.036232 kl_loss: 0.108777 normal_loss: 0.025355\n",
      "[823/00074] train_loss: 0.036170 kl_loss: 0.108775 normal_loss: 0.025293\n",
      "[825/00024] train_loss: 0.036273 kl_loss: 0.108426 normal_loss: 0.025430\n",
      "[826/00049] train_loss: 0.036316 kl_loss: 0.108824 normal_loss: 0.025433\n",
      "[827/00074] train_loss: 0.036359 kl_loss: 0.108997 normal_loss: 0.025459\n",
      "[829/00024] train_loss: 0.036254 kl_loss: 0.108848 normal_loss: 0.025369\n",
      "[830/00049] train_loss: 0.036415 kl_loss: 0.108724 normal_loss: 0.025543\n",
      "[831/00074] train_loss: 0.036217 kl_loss: 0.108657 normal_loss: 0.025352\n",
      "[833/00024] train_loss: 0.036298 kl_loss: 0.108873 normal_loss: 0.025410\n",
      "[834/00049] train_loss: 0.036274 kl_loss: 0.108403 normal_loss: 0.025434\n",
      "[835/00074] train_loss: 0.036311 kl_loss: 0.108929 normal_loss: 0.025418\n",
      "[837/00024] train_loss: 0.036472 kl_loss: 0.108856 normal_loss: 0.025586\n",
      "[838/00049] train_loss: 0.036295 kl_loss: 0.108635 normal_loss: 0.025432\n",
      "[839/00074] train_loss: 0.036232 kl_loss: 0.108693 normal_loss: 0.025363\n",
      "[841/00024] train_loss: 0.036180 kl_loss: 0.108422 normal_loss: 0.025338\n",
      "[842/00049] train_loss: 0.036392 kl_loss: 0.108954 normal_loss: 0.025496\n",
      "[843/00074] train_loss: 0.036284 kl_loss: 0.108788 normal_loss: 0.025405\n",
      "[845/00024] train_loss: 0.036356 kl_loss: 0.109026 normal_loss: 0.025453\n",
      "[846/00049] train_loss: 0.036260 kl_loss: 0.108100 normal_loss: 0.025450\n",
      "[847/00074] train_loss: 0.036423 kl_loss: 0.109016 normal_loss: 0.025522\n",
      "[849/00024] train_loss: 0.036375 kl_loss: 0.109017 normal_loss: 0.025473\n",
      "[849/00074] MMD 0.004886834416538477\n",
      "[849/00074] TMD 0.06170355901122093\n",
      "[850/00049] train_loss: 0.036013 kl_loss: 0.107926 normal_loss: 0.025220\n",
      "[851/00074] train_loss: 0.036439 kl_loss: 0.109183 normal_loss: 0.025521\n",
      "[853/00024] train_loss: 0.036191 kl_loss: 0.108898 normal_loss: 0.025301\n",
      "[854/00049] train_loss: 0.036416 kl_loss: 0.108519 normal_loss: 0.025564\n",
      "[855/00074] train_loss: 0.036246 kl_loss: 0.108689 normal_loss: 0.025377\n",
      "[857/00024] train_loss: 0.036225 kl_loss: 0.108695 normal_loss: 0.025355\n",
      "[858/00049] train_loss: 0.036405 kl_loss: 0.108683 normal_loss: 0.025537\n",
      "[859/00074] train_loss: 0.036324 kl_loss: 0.108712 normal_loss: 0.025453\n",
      "[861/00024] train_loss: 0.036335 kl_loss: 0.108864 normal_loss: 0.025448\n",
      "[862/00049] train_loss: 0.036332 kl_loss: 0.108689 normal_loss: 0.025463\n",
      "[863/00074] train_loss: 0.036220 kl_loss: 0.108522 normal_loss: 0.025368\n",
      "[865/00024] train_loss: 0.036310 kl_loss: 0.108821 normal_loss: 0.025428\n",
      "[866/00049] train_loss: 0.036258 kl_loss: 0.108874 normal_loss: 0.025370\n",
      "[867/00074] train_loss: 0.036259 kl_loss: 0.108361 normal_loss: 0.025423\n",
      "[869/00024] train_loss: 0.036317 kl_loss: 0.108945 normal_loss: 0.025422\n",
      "[870/00049] train_loss: 0.036108 kl_loss: 0.108376 normal_loss: 0.025270\n",
      "[871/00074] train_loss: 0.036367 kl_loss: 0.108717 normal_loss: 0.025495\n",
      "[873/00024] train_loss: 0.036251 kl_loss: 0.108790 normal_loss: 0.025371\n",
      "[874/00049] train_loss: 0.036160 kl_loss: 0.108307 normal_loss: 0.025329\n",
      "[875/00074] train_loss: 0.036249 kl_loss: 0.108923 normal_loss: 0.025356\n",
      "[877/00024] train_loss: 0.036135 kl_loss: 0.108699 normal_loss: 0.025265\n",
      "[878/00049] train_loss: 0.036226 kl_loss: 0.108551 normal_loss: 0.025371\n",
      "[879/00074] train_loss: 0.036194 kl_loss: 0.108749 normal_loss: 0.025319\n",
      "[881/00024] train_loss: 0.036224 kl_loss: 0.108989 normal_loss: 0.025325\n",
      "[882/00049] train_loss: 0.036317 kl_loss: 0.108765 normal_loss: 0.025440\n",
      "[883/00074] train_loss: 0.036084 kl_loss: 0.108223 normal_loss: 0.025262\n",
      "[885/00024] train_loss: 0.036064 kl_loss: 0.108506 normal_loss: 0.025213\n",
      "[886/00049] train_loss: 0.036364 kl_loss: 0.109150 normal_loss: 0.025449\n",
      "[887/00074] train_loss: 0.036195 kl_loss: 0.108298 normal_loss: 0.025365\n",
      "[889/00024] train_loss: 0.036294 kl_loss: 0.109020 normal_loss: 0.025392\n",
      "[890/00049] train_loss: 0.036152 kl_loss: 0.108368 normal_loss: 0.025315\n",
      "[891/00074] train_loss: 0.036073 kl_loss: 0.108545 normal_loss: 0.025218\n",
      "[893/00024] train_loss: 0.036314 kl_loss: 0.108796 normal_loss: 0.025434\n",
      "[894/00049] train_loss: 0.036094 kl_loss: 0.108107 normal_loss: 0.025284\n",
      "[895/00074] train_loss: 0.036105 kl_loss: 0.109005 normal_loss: 0.025205\n",
      "[897/00024] train_loss: 0.036143 kl_loss: 0.108261 normal_loss: 0.025317\n",
      "[898/00049] train_loss: 0.036412 kl_loss: 0.109167 normal_loss: 0.025496\n",
      "[899/00000] updated kl_weight: 0.1\n",
      "[899/00001] updated kl_weight: 0.1\n",
      "[899/00002] updated kl_weight: 0.1\n",
      "[899/00003] updated kl_weight: 0.1\n",
      "[899/00004] updated kl_weight: 0.1\n",
      "[899/00005] updated kl_weight: 0.1\n",
      "[899/00006] updated kl_weight: 0.1\n",
      "[899/00007] updated kl_weight: 0.1\n",
      "[899/00008] updated kl_weight: 0.1\n",
      "[899/00009] updated kl_weight: 0.1\n",
      "[899/00010] updated kl_weight: 0.1\n",
      "[899/00011] updated kl_weight: 0.1\n",
      "[899/00012] updated kl_weight: 0.1\n",
      "[899/00013] updated kl_weight: 0.1\n",
      "[899/00014] updated kl_weight: 0.1\n",
      "[899/00015] updated kl_weight: 0.1\n",
      "[899/00016] updated kl_weight: 0.1\n",
      "[899/00017] updated kl_weight: 0.1\n",
      "[899/00018] updated kl_weight: 0.1\n",
      "[899/00019] updated kl_weight: 0.1\n",
      "[899/00020] updated kl_weight: 0.1\n",
      "[899/00021] updated kl_weight: 0.1\n",
      "[899/00022] updated kl_weight: 0.1\n",
      "[899/00023] updated kl_weight: 0.1\n",
      "[899/00024] updated kl_weight: 0.1\n",
      "[899/00025] updated kl_weight: 0.1\n",
      "[899/00026] updated kl_weight: 0.1\n",
      "[899/00027] updated kl_weight: 0.1\n",
      "[899/00028] updated kl_weight: 0.1\n",
      "[899/00029] updated kl_weight: 0.1\n",
      "[899/00030] updated kl_weight: 0.1\n",
      "[899/00031] updated kl_weight: 0.1\n",
      "[899/00032] updated kl_weight: 0.1\n",
      "[899/00033] updated kl_weight: 0.1\n",
      "[899/00034] updated kl_weight: 0.1\n",
      "[899/00035] updated kl_weight: 0.1\n",
      "[899/00036] updated kl_weight: 0.1\n",
      "[899/00037] updated kl_weight: 0.1\n",
      "[899/00038] updated kl_weight: 0.1\n",
      "[899/00039] updated kl_weight: 0.1\n",
      "[899/00040] updated kl_weight: 0.1\n",
      "[899/00041] updated kl_weight: 0.1\n",
      "[899/00042] updated kl_weight: 0.1\n",
      "[899/00043] updated kl_weight: 0.1\n",
      "[899/00044] updated kl_weight: 0.1\n",
      "[899/00045] updated kl_weight: 0.1\n",
      "[899/00046] updated kl_weight: 0.1\n",
      "[899/00047] updated kl_weight: 0.1\n",
      "[899/00048] updated kl_weight: 0.1\n",
      "[899/00049] updated kl_weight: 0.1\n",
      "[899/00050] updated kl_weight: 0.1\n",
      "[899/00051] updated kl_weight: 0.1\n",
      "[899/00052] updated kl_weight: 0.1\n",
      "[899/00053] updated kl_weight: 0.1\n",
      "[899/00054] updated kl_weight: 0.1\n",
      "[899/00055] updated kl_weight: 0.1\n",
      "[899/00056] updated kl_weight: 0.1\n",
      "[899/00057] updated kl_weight: 0.1\n",
      "[899/00058] updated kl_weight: 0.1\n",
      "[899/00059] updated kl_weight: 0.1\n",
      "[899/00060] updated kl_weight: 0.1\n",
      "[899/00061] updated kl_weight: 0.1\n",
      "[899/00062] updated kl_weight: 0.1\n",
      "[899/00063] updated kl_weight: 0.1\n",
      "[899/00064] updated kl_weight: 0.1\n",
      "[899/00065] updated kl_weight: 0.1\n",
      "[899/00066] updated kl_weight: 0.1\n",
      "[899/00067] updated kl_weight: 0.1\n",
      "[899/00068] updated kl_weight: 0.1\n",
      "[899/00069] updated kl_weight: 0.1\n",
      "[899/00070] updated kl_weight: 0.1\n",
      "[899/00071] updated kl_weight: 0.1\n",
      "[899/00072] updated kl_weight: 0.1\n",
      "[899/00073] updated kl_weight: 0.1\n",
      "[899/00074] updated kl_weight: 0.1\n",
      "[899/00074] train_loss: 0.036192 kl_loss: 0.108456 normal_loss: 0.025347\n",
      "[899/00074] MMD 0.005229662172496319\n",
      "[899/00074] TMD 0.057851482182741165\n",
      "[901/00024] train_loss: 0.036239 kl_loss: 0.108814 normal_loss: 0.025358\n",
      "[902/00049] train_loss: 0.036205 kl_loss: 0.108499 normal_loss: 0.025355\n",
      "[903/00074] train_loss: 0.036099 kl_loss: 0.108552 normal_loss: 0.025243\n",
      "[905/00024] train_loss: 0.036261 kl_loss: 0.108959 normal_loss: 0.025365\n",
      "[906/00049] train_loss: 0.036038 kl_loss: 0.108244 normal_loss: 0.025213\n",
      "[907/00074] train_loss: 0.036164 kl_loss: 0.108652 normal_loss: 0.025299\n",
      "[909/00024] train_loss: 0.036157 kl_loss: 0.108566 normal_loss: 0.025300\n",
      "[910/00049] train_loss: 0.036185 kl_loss: 0.108757 normal_loss: 0.025309\n",
      "[911/00074] train_loss: 0.036068 kl_loss: 0.108522 normal_loss: 0.025215\n",
      "[913/00024] train_loss: 0.036135 kl_loss: 0.108490 normal_loss: 0.025286\n",
      "[914/00049] train_loss: 0.036197 kl_loss: 0.108503 normal_loss: 0.025347\n",
      "[915/00074] train_loss: 0.036238 kl_loss: 0.108840 normal_loss: 0.025354\n",
      "[917/00024] train_loss: 0.036136 kl_loss: 0.108731 normal_loss: 0.025263\n",
      "[918/00049] train_loss: 0.036208 kl_loss: 0.108870 normal_loss: 0.025321\n",
      "[919/00074] train_loss: 0.036188 kl_loss: 0.108221 normal_loss: 0.025366\n",
      "[921/00024] train_loss: 0.035966 kl_loss: 0.108259 normal_loss: 0.025140\n",
      "[922/00049] train_loss: 0.036244 kl_loss: 0.108866 normal_loss: 0.025357\n",
      "[923/00074] train_loss: 0.036127 kl_loss: 0.108685 normal_loss: 0.025258\n",
      "[925/00024] train_loss: 0.036338 kl_loss: 0.108917 normal_loss: 0.025446\n",
      "[926/00049] train_loss: 0.036156 kl_loss: 0.108570 normal_loss: 0.025299\n",
      "[927/00074] train_loss: 0.036138 kl_loss: 0.108312 normal_loss: 0.025307\n",
      "[929/00024] train_loss: 0.036211 kl_loss: 0.108623 normal_loss: 0.025348\n",
      "[930/00049] train_loss: 0.036194 kl_loss: 0.108601 normal_loss: 0.025334\n",
      "[931/00074] train_loss: 0.036262 kl_loss: 0.108564 normal_loss: 0.025406\n",
      "[933/00024] train_loss: 0.036106 kl_loss: 0.108465 normal_loss: 0.025260\n",
      "[934/00049] train_loss: 0.036239 kl_loss: 0.108384 normal_loss: 0.025401\n",
      "[935/00074] train_loss: 0.036297 kl_loss: 0.108929 normal_loss: 0.025404\n",
      "[937/00024] train_loss: 0.036137 kl_loss: 0.108900 normal_loss: 0.025247\n",
      "[938/00049] train_loss: 0.036121 kl_loss: 0.108386 normal_loss: 0.025283\n",
      "[939/00074] train_loss: 0.036097 kl_loss: 0.108482 normal_loss: 0.025249\n",
      "[941/00024] train_loss: 0.036205 kl_loss: 0.108723 normal_loss: 0.025333\n",
      "[942/00049] train_loss: 0.036008 kl_loss: 0.108224 normal_loss: 0.025186\n",
      "[943/00074] train_loss: 0.036289 kl_loss: 0.108807 normal_loss: 0.025408\n",
      "[945/00024] train_loss: 0.036047 kl_loss: 0.108572 normal_loss: 0.025190\n",
      "[946/00049] train_loss: 0.036159 kl_loss: 0.108631 normal_loss: 0.025296\n",
      "[947/00074] train_loss: 0.036213 kl_loss: 0.108540 normal_loss: 0.025359\n",
      "[949/00024] train_loss: 0.036102 kl_loss: 0.108491 normal_loss: 0.025253\n",
      "[949/00074] MMD 0.005339762195944786\n",
      "[949/00074] TMD 0.05311828479170799\n",
      "[950/00049] train_loss: 0.036156 kl_loss: 0.108844 normal_loss: 0.025271\n",
      "[951/00074] train_loss: 0.036028 kl_loss: 0.108397 normal_loss: 0.025188\n",
      "[953/00024] train_loss: 0.036211 kl_loss: 0.108852 normal_loss: 0.025326\n",
      "[954/00049] train_loss: 0.036132 kl_loss: 0.108299 normal_loss: 0.025302\n",
      "[955/00074] train_loss: 0.036162 kl_loss: 0.108568 normal_loss: 0.025305\n",
      "[957/00024] train_loss: 0.036334 kl_loss: 0.108991 normal_loss: 0.025435\n",
      "[958/00049] train_loss: 0.036129 kl_loss: 0.108283 normal_loss: 0.025301\n",
      "[959/00074] train_loss: 0.036176 kl_loss: 0.108435 normal_loss: 0.025333\n",
      "[961/00024] train_loss: 0.036182 kl_loss: 0.108440 normal_loss: 0.025338\n",
      "[962/00049] train_loss: 0.036245 kl_loss: 0.108910 normal_loss: 0.025354\n",
      "[963/00074] train_loss: 0.035980 kl_loss: 0.108350 normal_loss: 0.025145\n",
      "[965/00024] train_loss: 0.036137 kl_loss: 0.108699 normal_loss: 0.025267\n",
      "[966/00049] train_loss: 0.036101 kl_loss: 0.108405 normal_loss: 0.025260\n",
      "[967/00074] train_loss: 0.036255 kl_loss: 0.108585 normal_loss: 0.025397\n",
      "[969/00024] train_loss: 0.036133 kl_loss: 0.108872 normal_loss: 0.025246\n",
      "[970/00049] train_loss: 0.036145 kl_loss: 0.108237 normal_loss: 0.025321\n",
      "[971/00074] train_loss: 0.036233 kl_loss: 0.108568 normal_loss: 0.025376\n",
      "[973/00024] train_loss: 0.036120 kl_loss: 0.108523 normal_loss: 0.025268\n",
      "[974/00049] train_loss: 0.036165 kl_loss: 0.108676 normal_loss: 0.025298\n",
      "[975/00074] train_loss: 0.036176 kl_loss: 0.108469 normal_loss: 0.025329\n",
      "[977/00024] train_loss: 0.035874 kl_loss: 0.108039 normal_loss: 0.025070\n",
      "[978/00049] train_loss: 0.036354 kl_loss: 0.109502 normal_loss: 0.025404\n",
      "[979/00074] train_loss: 0.036102 kl_loss: 0.108117 normal_loss: 0.025290\n",
      "[981/00024] train_loss: 0.036245 kl_loss: 0.108550 normal_loss: 0.025390\n",
      "[982/00049] train_loss: 0.036048 kl_loss: 0.108107 normal_loss: 0.025238\n",
      "[983/00074] train_loss: 0.036346 kl_loss: 0.108988 normal_loss: 0.025447\n",
      "[985/00024] train_loss: 0.036185 kl_loss: 0.108339 normal_loss: 0.025351\n",
      "[986/00049] train_loss: 0.036235 kl_loss: 0.109167 normal_loss: 0.025319\n",
      "[987/00074] train_loss: 0.035966 kl_loss: 0.108131 normal_loss: 0.025153\n",
      "[989/00024] train_loss: 0.036306 kl_loss: 0.108723 normal_loss: 0.025433\n",
      "[990/00049] train_loss: 0.036267 kl_loss: 0.108403 normal_loss: 0.025426\n",
      "[991/00074] train_loss: 0.036060 kl_loss: 0.108501 normal_loss: 0.025210\n",
      "[993/00024] train_loss: 0.036185 kl_loss: 0.108526 normal_loss: 0.025332\n",
      "[994/00049] train_loss: 0.036255 kl_loss: 0.108752 normal_loss: 0.025380\n",
      "[995/00074] train_loss: 0.036105 kl_loss: 0.108341 normal_loss: 0.025271\n",
      "[997/00024] train_loss: 0.036158 kl_loss: 0.108818 normal_loss: 0.025276\n",
      "[998/00049] train_loss: 0.036092 kl_loss: 0.108134 normal_loss: 0.025279\n",
      "[999/00000] updated kl_weight: 0.1\n",
      "[999/00001] updated kl_weight: 0.1\n",
      "[999/00002] updated kl_weight: 0.1\n",
      "[999/00003] updated kl_weight: 0.1\n",
      "[999/00004] updated kl_weight: 0.1\n",
      "[999/00005] updated kl_weight: 0.1\n",
      "[999/00006] updated kl_weight: 0.1\n",
      "[999/00007] updated kl_weight: 0.1\n",
      "[999/00008] updated kl_weight: 0.1\n",
      "[999/00009] updated kl_weight: 0.1\n",
      "[999/00010] updated kl_weight: 0.1\n",
      "[999/00011] updated kl_weight: 0.1\n",
      "[999/00012] updated kl_weight: 0.1\n",
      "[999/00013] updated kl_weight: 0.1\n",
      "[999/00014] updated kl_weight: 0.1\n",
      "[999/00015] updated kl_weight: 0.1\n",
      "[999/00016] updated kl_weight: 0.1\n",
      "[999/00017] updated kl_weight: 0.1\n",
      "[999/00018] updated kl_weight: 0.1\n",
      "[999/00019] updated kl_weight: 0.1\n",
      "[999/00020] updated kl_weight: 0.1\n",
      "[999/00021] updated kl_weight: 0.1\n",
      "[999/00022] updated kl_weight: 0.1\n",
      "[999/00023] updated kl_weight: 0.1\n",
      "[999/00024] updated kl_weight: 0.1\n",
      "[999/00025] updated kl_weight: 0.1\n",
      "[999/00026] updated kl_weight: 0.1\n",
      "[999/00027] updated kl_weight: 0.1\n",
      "[999/00028] updated kl_weight: 0.1\n",
      "[999/00029] updated kl_weight: 0.1\n",
      "[999/00030] updated kl_weight: 0.1\n",
      "[999/00031] updated kl_weight: 0.1\n",
      "[999/00032] updated kl_weight: 0.1\n",
      "[999/00033] updated kl_weight: 0.1\n",
      "[999/00034] updated kl_weight: 0.1\n",
      "[999/00035] updated kl_weight: 0.1\n",
      "[999/00036] updated kl_weight: 0.1\n",
      "[999/00037] updated kl_weight: 0.1\n",
      "[999/00038] updated kl_weight: 0.1\n",
      "[999/00039] updated kl_weight: 0.1\n",
      "[999/00040] updated kl_weight: 0.1\n",
      "[999/00041] updated kl_weight: 0.1\n",
      "[999/00042] updated kl_weight: 0.1\n",
      "[999/00043] updated kl_weight: 0.1\n",
      "[999/00044] updated kl_weight: 0.1\n",
      "[999/00045] updated kl_weight: 0.1\n",
      "[999/00046] updated kl_weight: 0.1\n",
      "[999/00047] updated kl_weight: 0.1\n",
      "[999/00048] updated kl_weight: 0.1\n",
      "[999/00049] updated kl_weight: 0.1\n",
      "[999/00050] updated kl_weight: 0.1\n",
      "[999/00051] updated kl_weight: 0.1\n",
      "[999/00052] updated kl_weight: 0.1\n",
      "[999/00053] updated kl_weight: 0.1\n",
      "[999/00054] updated kl_weight: 0.1\n",
      "[999/00055] updated kl_weight: 0.1\n",
      "[999/00056] updated kl_weight: 0.1\n",
      "[999/00057] updated kl_weight: 0.1\n",
      "[999/00058] updated kl_weight: 0.1\n",
      "[999/00059] updated kl_weight: 0.1\n",
      "[999/00060] updated kl_weight: 0.1\n",
      "[999/00061] updated kl_weight: 0.1\n",
      "[999/00062] updated kl_weight: 0.1\n",
      "[999/00063] updated kl_weight: 0.1\n",
      "[999/00064] updated kl_weight: 0.1\n",
      "[999/00065] updated kl_weight: 0.1\n",
      "[999/00066] updated kl_weight: 0.1\n",
      "[999/00067] updated kl_weight: 0.1\n",
      "[999/00068] updated kl_weight: 0.1\n",
      "[999/00069] updated kl_weight: 0.1\n",
      "[999/00070] updated kl_weight: 0.1\n",
      "[999/00071] updated kl_weight: 0.1\n",
      "[999/00072] updated kl_weight: 0.1\n",
      "[999/00073] updated kl_weight: 0.1\n",
      "[999/00074] updated kl_weight: 0.1\n",
      "[999/00074] train_loss: 0.036211 kl_loss: 0.108657 normal_loss: 0.025345\n",
      "[999/00074] MMD 0.005273937247693539\n",
      "[999/00074] TMD 0.0568268820643425\n"
     ]
    }
   ],
   "source": [
    "# CHAIR VAD\n",
    "from scripts import train\n",
    "config = {\n",
    "    'experiment_name': 'chair_vad_0.05kl',\n",
    "    'device': 'cuda:0',\n",
    "    'is_overfit': False,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate_model': 0.01,\n",
    "    'learning_rate_code': 0.01,\n",
    "    'learning_rate_log_var':0.01,\n",
    "    'max_epochs': 1000,\n",
    "    'print_every_n': 100,\n",
    "    'latent_code_length' : 256,\n",
    "    'scheduler_step_size': 100,\n",
    "    'vad_free' : True,\n",
    "    'test': False,\n",
    "    'kl_weight': 0.05,\n",
    "    'kl_weight_increase_every_epochs': 100,\n",
    "    'kl_weight_increase_value': 0.0,\n",
    "    'mmd_every_epoch': 50,\n",
    "    'tmd_every_epoch': 50,\n",
    "    'iou_every_epoch': 10,\n",
    "    'resume_ckpt': None,\n",
    "    'filter_class': 'chair',\n",
    "    'decoder_var' : True\n",
    "}\n",
    "train.main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "#                   #\n",
    "#    VISUALIZING    #\n",
    "#                   #\n",
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.visualize import visualize_dataset_sample, visualize_ad, visualize_vad, visualize_vad_norm, visualize_vad_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75feeec3886641628476b007ee7d44eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "experiment = \"airplane_vad\"\n",
    "experiment2 = \"sofa_ad\"\n",
    "# experiment2 = \"sofa_ad\"\n",
    "filter_class = \"airplane\"\n",
    "index = 4123\n",
    "index1 = random.choice(range(len(ShapeNet('train', filter_class = \"airplane\"))))\n",
    "index2 = random.choice(range(len(ShapeNet('train', filter_class = filter_class))))\n",
    "a1 = 0.5\n",
    "a2 = 1 - a1\n",
    "#-------\n",
    "# visualize_ad(\"airplane_ad\", index1)\n",
    "#-------\n",
    "visualize_vad_norm(\"chair_vad_0.1kl\")\n",
    "# visualize_vad_norm(experiment)\n",
    "# visualize_ad(experiment, index1)\n",
    "# visualize_vad_norm(experiment2)\n",
    "# visualize_ad(experiment, index)\n",
    "#-------\n",
    "# visualize_vad_norm(experiment)\n",
    "# visualize_vad_norm(experiment2)\n",
    "# visualize_dataset_sample(filter_class, index)\n",
    "#-------\n",
    "# visualize_interpolation_ad(experiment, index1, index2, a1, a2)\n",
    "# visualize_ad(experiment, index1)\n",
    "# visualize_ad(experiment, index2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "#                  #\n",
    "#    EVALUATION    #\n",
    "#                  #\n",
    "####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.evaluate import generate_samples, convert_df_to_point_cloud, chamfer_distance, MMD, convert_set_to_point_cloud, visualize_point_cloud, _mmd, TMD, IOU\n",
    "from util.visualization import visualize_mesh\n",
    "from skimage.measure import marching_cubes\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TMD\n",
    "tmd, samples = TMD('chair_vad_0.1kl', n_samples=10, device=torch.device('cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0606, device='cuda:0')"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bfd74b83871415e8f108ffc3bfb12de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 8\n",
    "input_mesh = marching_cubes(samples[index].cpu().detach().numpy(), level=1)\n",
    "visualize_mesh(input_mesh[0], input_mesh[1], flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MMD\n",
    "mmd, mmds = MMD('chair_vad_0.1kl', 'val', 'chair', n_samples=10, device=torch.device('cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0053, device='cuda:0')"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate n new samples\n",
    "n = 10\n",
    "samples = generate_samples('table_vad', n)\n",
    "samples = samples.squeeze(1)\n",
    "# convert_set_to_point_cloud(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd33410c3d30460da76090db6fd40007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 8\n",
    "input_mesh = marching_cubes(samples[index].detach().numpy(), level=1)\n",
    "visualize_mesh(input_mesh[0], input_mesh[1], flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = []\n",
    "val_dataset = ShapeNet('val', filter_class='airplane')\n",
    "for data_dict in val_dataset:\n",
    "    target_df = torch.from_numpy(data_dict['target_df']).float()\n",
    "    val.append(target_df)\n",
    "val = torch.stack(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1278, -0.0485,  0.0794],\n",
      "        [ 0.5927,  0.0102, -0.0656],\n",
      "        [-0.2694, -0.2313, -0.0475],\n",
      "        ...,\n",
      "        [ 0.2366, -0.2002, -0.0627],\n",
      "        [-0.2262, -0.0294,  0.4132],\n",
      "        [-0.3590, -0.0955, -0.7992]])\n",
      "tensor([[ 0.1878, -0.1604, -0.5195],\n",
      "        [ 0.7181, -0.0691, -0.2029],\n",
      "        [ 0.0807, -0.2327, -0.4569],\n",
      "        ...,\n",
      "        [-0.0027,  0.0769,  0.7589],\n",
      "        [-0.0543, -0.1888,  0.0906],\n",
      "        [-0.0586, -0.1129, -0.2101]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f1d30f523f4de49715baa2f63fd912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=768, layout=Layout(height='auto', width='100%'), width=1024)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd03b16127742b5b1c060e38ab758c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=768, layout=Layout(height='auto', width='100%'), width=1024)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 0\n",
    "# visualize\n",
    "input_mesh = marching_cubes(val[index].detach().numpy(), level=1)\n",
    "input_mesh2 = marching_cubes(samples[index].detach().numpy(), level=1)\n",
    "# visualize_mesh(input_mesh[0], input_mesh[1], flip_axes=True)\n",
    "point_cloud = convert_df_to_point_cloud(val[index])\n",
    "point_cloud2 = convert_df_to_point_cloud(samples[index])\n",
    "print(point_cloud)\n",
    "print(point_cloud2)\n",
    "visualize_point_cloud(point_cloud.numpy())\n",
    "visualize_point_cloud(point_cloud2.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_point_clouds = convert_set_to_point_cloud(val[0:10], count=10000)\n",
    "samples_point_clouds2 = convert_set_to_point_cloud(val[0:1], count=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_point_clouds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 0.00033399579115211964\n"
     ]
    }
   ],
   "source": [
    "mmd_value = _mmd(samples_point_clouds, samples_point_clouds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Munzer\\Documents\\uni\\ADL4CV\\adl4cv-vad\\index.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Munzer/Documents/uni/ADL4CV/adl4cv-vad/index.ipynb#ch0000032?line=0'>1</a>\u001b[0m _mmd(samples, samples)\n",
      "File \u001b[1;32mc:\\Users\\Munzer\\Documents\\uni\\ADL4CV\\adl4cv-vad\\scripts\\evaluate.py:148\u001b[0m, in \u001b[0;36m_mmd\u001b[1;34m(set1, set2)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer/Documents/uni/ADL4CV/adl4cv-vad/scripts/evaluate.py?line=145'>146</a>\u001b[0m sample_distances \u001b[39m=\u001b[39m []\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer/Documents/uni/ADL4CV/adl4cv-vad/scripts/evaluate.py?line=146'>147</a>\u001b[0m \u001b[39mfor\u001b[39;00m sample2 \u001b[39min\u001b[39;00m set2:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Munzer/Documents/uni/ADL4CV/adl4cv-vad/scripts/evaluate.py?line=147'>148</a>\u001b[0m     cf_distance \u001b[39m=\u001b[39m chamfer_distance(sample, sample2)\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer/Documents/uni/ADL4CV/adl4cv-vad/scripts/evaluate.py?line=148'>149</a>\u001b[0m     sample_distances\u001b[39m.\u001b[39mappend(cf_distance)\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer/Documents/uni/ADL4CV/adl4cv-vad/scripts/evaluate.py?line=149'>150</a>\u001b[0m mmd \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(sample_distances) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(sample_distances)\n",
      "File \u001b[1;32mc:\\Users\\Munzer\\Documents\\uni\\ADL4CV\\adl4cv-vad\\scripts\\evaluate.py:130\u001b[0m, in \u001b[0;36mchamfer_distance\u001b[1;34m(point_cloud1, point_cloud2)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer/Documents/uni/ADL4CV/adl4cv-vad/scripts/evaluate.py?line=122'>123</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer/Documents/uni/ADL4CV/adl4cv-vad/scripts/evaluate.py?line=123'>124</a>\u001b[0m \u001b[39minput: \u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer/Documents/uni/ADL4CV/adl4cv-vad/scripts/evaluate.py?line=124'>125</a>\u001b[0m \u001b[39m    point_cloud1: tensor (counts, 3)\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer/Documents/uni/ADL4CV/adl4cv-vad/scripts/evaluate.py?line=125'>126</a>\u001b[0m \u001b[39m    point_cloud2: tensor (counts, 3)\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer/Documents/uni/ADL4CV/adl4cv-vad/scripts/evaluate.py?line=126'>127</a>\u001b[0m \u001b[39moutput: float\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer/Documents/uni/ADL4CV/adl4cv-vad/scripts/evaluate.py?line=127'>128</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer/Documents/uni/ADL4CV/adl4cv-vad/scripts/evaluate.py?line=128'>129</a>\u001b[0m dist \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Munzer/Documents/uni/ADL4CV/adl4cv-vad/scripts/evaluate.py?line=129'>130</a>\u001b[0m av_dist1 \u001b[39m=\u001b[39m _point_clouds_min_distance(point_cloud1, point_cloud2)\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer/Documents/uni/ADL4CV/adl4cv-vad/scripts/evaluate.py?line=130'>131</a>\u001b[0m av_dist2 \u001b[39m=\u001b[39m _point_clouds_min_distance(point_cloud2, point_cloud1)\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer/Documents/uni/ADL4CV/adl4cv-vad/scripts/evaluate.py?line=131'>132</a>\u001b[0m dist \u001b[39m=\u001b[39m dist \u001b[39m+\u001b[39m av_dist1 \u001b[39m+\u001b[39m av_dist2\n",
      "File \u001b[1;32mc:\\Users\\Munzer\\Documents\\uni\\ADL4CV\\adl4cv-vad\\scripts\\evaluate.py:106\u001b[0m, in \u001b[0;36m_point_clouds_min_distance\u001b[1;34m(point_cloud1, point_cloud2)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Munzer/Documents/uni/ADL4CV/adl4cv-vad/scripts/evaluate.py?line=97'>98</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_point_clouds_min_distance\u001b[39m(point_cloud1, point_cloud2):\n\u001b[0;32m     <a href='file:///c%3A/Users/Munzer/Documents/uni/ADL4CV/adl4cv-vad/scripts/evaluate.py?line=98'>99</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer/Documents/uni/ADL4CV/adl4cv-vad/scripts/evaluate.py?line=99'>100</a>\u001b[0m \u001b[39m    arguments: \u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer/Documents/uni/ADL4CV/adl4cv-vad/scripts/evaluate.py?line=100'>101</a>\u001b[0m \u001b[39m        point_cloud1: tensor (num_point, num_feature)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer/Documents/uni/ADL4CV/adl4cv-vad/scripts/evaluate.py?line=103'>104</a>\u001b[0m \u001b[39m        distances: each entry is the distance from a sample to array1 \u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer/Documents/uni/ADL4CV/adl4cv-vad/scripts/evaluate.py?line=104'>105</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Munzer/Documents/uni/ADL4CV/adl4cv-vad/scripts/evaluate.py?line=105'>106</a>\u001b[0m     num_point, num_features \u001b[39m=\u001b[39m point_cloud1\u001b[39m.\u001b[39mshape\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer/Documents/uni/ADL4CV/adl4cv-vad/scripts/evaluate.py?line=106'>107</a>\u001b[0m     expanded_array1 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtile(point_cloud1, (num_point, \u001b[39m1\u001b[39m)) \u001b[39m# num_points * num_points, num_feature\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer/Documents/uni/ADL4CV/adl4cv-vad/scripts/evaluate.py?line=107'>108</a>\u001b[0m     expanded_array2 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mreshape(\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer/Documents/uni/ADL4CV/adl4cv-vad/scripts/evaluate.py?line=108'>109</a>\u001b[0m         torch\u001b[39m.\u001b[39mtile(\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer/Documents/uni/ADL4CV/adl4cv-vad/scripts/evaluate.py?line=109'>110</a>\u001b[0m             torch\u001b[39m.\u001b[39munsqueeze(point_cloud2, \u001b[39m1\u001b[39m), \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer/Documents/uni/ADL4CV/adl4cv-vad/scripts/evaluate.py?line=112'>113</a>\u001b[0m         (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, num_features)\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer/Documents/uni/ADL4CV/adl4cv-vad/scripts/evaluate.py?line=113'>114</a>\u001b[0m     ) \u001b[39m# num_points * num_points, num_feature\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "_mmd(samples, samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1142, 0.0598, 0.0302,  ..., 0.0104, 0.0498, 0.0848])\n",
      "tensor([0.0288, 0.0441, 0.0509,  ..., 0.0924, 0.1467, 0.1362])\n"
     ]
    }
   ],
   "source": [
    "cf = chamfer_distance(point_cloud, point_cloud2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1314) tensor(0.0657)\n"
     ]
    }
   ],
   "source": [
    "print(cf, cf / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 3])\n"
     ]
    }
   ],
   "source": [
    "print(point_cloud.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0521)\n"
     ]
    }
   ],
   "source": [
    "min = 10000\n",
    "for i in range(2048):\n",
    "    dist = torch.linalg.norm(point_cloud[5]-point_cloud2[i], axis=0)\n",
    "    if dist < min:\n",
    "        min = dist\n",
    "print(min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6862)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.norm(point_cloud[0]-point_cloud2[0], axis=0) # num_points * num_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 0.18461653590202332\n",
      "2: 0.18126583099365234\n",
      "3: 0.18387258052825928\n",
      "4: 0.18040665984153748\n",
      "5: 0.1862756311893463\n",
      "6: 0.20319686830043793\n",
      "7: 0.16356226801872253\n",
      "8: 0.1683862805366516\n",
      "9: 0.16741611063480377\n",
      "10: 0.17503449320793152\n"
     ]
    }
   ],
   "source": [
    "# MMD\n",
    "mmd, mmds = MMD('airplane_vad', 'val', 'airplane', n_samples=10, device=torch.device('cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1371, device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmd"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8edcb304c74d7de69396267fdd221ef1d3cdc7db9124f1020d58ca6af5038c14"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('adl4cv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

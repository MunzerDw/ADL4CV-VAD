{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | Name         | Type             | Params  \n",
      "-----------------------------------------------------\n",
      "0  | bottleneck   | Sequential       | 197376  \n",
      "1  | bottleneck.0 | Linear           | 65792   \n",
      "2  | bottleneck.1 | ReLU             | 0       \n",
      "3  | bottleneck.2 | Linear           | 131584  \n",
      "4  | bottleneck.3 | ReLU             | 0       \n",
      "5  | decoder1     | Sequential       | 8389376 \n",
      "6  | decoder1.0   | ConvTranspose3d  | 8388864 \n",
      "7  | decoder1.1   | BatchNorm3d      | 512     \n",
      "8  | decoder1.2   | ReLU             | 0       \n",
      "9  | decoder2     | Sequential       | 2097536 \n",
      "10 | decoder2.0   | ConvTranspose3d  | 2097280 \n",
      "11 | decoder2.1   | BatchNorm3d      | 256     \n",
      "12 | decoder2.2   | ReLU             | 0       \n",
      "13 | decoder3     | Sequential       | 524480  \n",
      "14 | decoder3.0   | ConvTranspose3d  | 524352  \n",
      "15 | decoder3.1   | BatchNorm3d      | 128     \n",
      "16 | decoder3.2   | ReLU             | 0       \n",
      "17 | decoder4     | Sequential       | 4097    \n",
      "18 | decoder4.0   | ConvTranspose3d  | 4097    \n",
      "19 | TOTAL        | ThreeDEPNDecoder | 11212865\n"
     ]
    }
   ],
   "source": [
    "from model.threedepn import ThreeDEPNDecoder\n",
    "from util.model import summarize_model\n",
    "\n",
    "threedepn = ThreeDEPNDecoder()\n",
    "print(summarize_model(threedepn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train set: 3173\n",
      "Length of overfit set: 64\n"
     ]
    }
   ],
   "source": [
    "from data.shapenet import ShapeNet\n",
    "\n",
    "# Create a dataset with train split\n",
    "train_dataset = ShapeNet('train', filter_class = 'sofa')\n",
    "overfit_dataset = ShapeNet('overfit')\n",
    "\n",
    "# Get length, which is a call to __len__ function\n",
    "print(f'Length of train set: {len(train_dataset)}')  # expected output: 153540\n",
    "# Get length, which is a call to __len__ function\n",
    "print(f'Length of overfit set: {len(overfit_dataset)}')  # expected output: 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target DF: (32, 32, 32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a4c43c491f48d09b0558b091bc1748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from util.visualization import visualize_mesh\n",
    "from skimage.measure import marching_cubes\n",
    "\n",
    "sample = train_dataset[0]\n",
    "print(f'Target DF: {sample[\"target_df\"].shape}')  # expected output: (32, 32, 32)\n",
    "\n",
    "input_mesh = marching_cubes(sample['target_df'], level=1)\n",
    "visualize_mesh(input_mesh[0], input_mesh[1], flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "#                #\n",
    "#    TRAINING    #\n",
    "#                #\n",
    "##################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Loading saved model, latent codes, and latent variances...\n",
      "Training params: 3\n",
      "[001/00004] train_loss: 0.010115 kl_loss: 0.007572 normal_loss: 0.002543\n",
      "[001/00004] train_loss: 0.010374 kl_loss: 0.007749 normal_loss: 0.002626\n",
      "[002/00004] train_loss: 0.008716 kl_loss: 0.007542 normal_loss: 0.001174\n",
      "[002/00004] train_loss: 0.008393 kl_loss: 0.007422 normal_loss: 0.000971\n",
      "[003/00004] train_loss: 0.008175 kl_loss: 0.007302 normal_loss: 0.000872\n",
      "[003/00004] train_loss: 0.008076 kl_loss: 0.007325 normal_loss: 0.000750\n",
      "[004/00004] train_loss: 0.007750 kl_loss: 0.007125 normal_loss: 0.000625\n",
      "[004/00004] train_loss: 0.007689 kl_loss: 0.007174 normal_loss: 0.000515\n"
     ]
    }
   ],
   "source": [
    "# OVERFIT\n",
    "from training import train\n",
    "config = {\n",
    "    'experiment_name': 'overfit',\n",
    "    'device': 'cuda:0',  # change this to cpu if you do not have a GPU\n",
    "    'is_overfit': True,\n",
    "    'batch_size': 32,\n",
    "    'learning_rate_model': 0.01,\n",
    "    'learning_rate_code': 0.01,\n",
    "    'learning_rate_log_var':0.01,\n",
    "    'max_epochs': 4,\n",
    "    'print_every_n': 1,\n",
    "    'validate_every_n': 250,\n",
    "    'latent_code_length' : 256,\n",
    "    'vad_free' : True,\n",
    "    'test': False,\n",
    "    'kl_weight': 1,\n",
    "    'resume_ckpt': None\n",
    "\n",
    "}\n",
    "train.main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Training params: 2\n",
      "[001/00035] train_loss: 0.107308 kl_loss: 0.000000 normal_loss: 0.107308\n",
      "[003/00007] train_loss: 0.045517 kl_loss: 0.000000 normal_loss: 0.045517\n",
      "[004/00043] train_loss: 0.036284 kl_loss: 0.000000 normal_loss: 0.036284\n",
      "[006/00015] train_loss: 0.034843 kl_loss: 0.000000 normal_loss: 0.034843\n",
      "[007/00051] train_loss: 0.030958 kl_loss: 0.000000 normal_loss: 0.030958\n",
      "[009/00023] train_loss: 0.029536 kl_loss: 0.000000 normal_loss: 0.029536\n",
      "[010/00059] train_loss: 0.031433 kl_loss: 0.000000 normal_loss: 0.031433\n",
      "[012/00031] train_loss: 0.030174 kl_loss: 0.000000 normal_loss: 0.030174\n",
      "[014/00003] train_loss: 0.029374 kl_loss: 0.000000 normal_loss: 0.029374\n",
      "[015/00039] train_loss: 0.028661 kl_loss: 0.000000 normal_loss: 0.028661\n",
      "[017/00011] train_loss: 0.027764 kl_loss: 0.000000 normal_loss: 0.027764\n",
      "[018/00047] train_loss: 0.026550 kl_loss: 0.000000 normal_loss: 0.026550\n",
      "[020/00019] train_loss: 0.025417 kl_loss: 0.000000 normal_loss: 0.025417\n",
      "[021/00055] train_loss: 0.020581 kl_loss: 0.000000 normal_loss: 0.020581\n",
      "[023/00027] train_loss: 0.020864 kl_loss: 0.000000 normal_loss: 0.020864\n",
      "[024/00063] train_loss: 0.020507 kl_loss: 0.000000 normal_loss: 0.020507\n",
      "[026/00035] train_loss: 0.019881 kl_loss: 0.000000 normal_loss: 0.019881\n",
      "[028/00007] train_loss: 0.020202 kl_loss: 0.000000 normal_loss: 0.020202\n",
      "[029/00043] train_loss: 0.020114 kl_loss: 0.000000 normal_loss: 0.020114\n",
      "[031/00015] train_loss: 0.019694 kl_loss: 0.000000 normal_loss: 0.019694\n",
      "[032/00051] train_loss: 0.019919 kl_loss: 0.000000 normal_loss: 0.019919\n",
      "[034/00023] train_loss: 0.019752 kl_loss: 0.000000 normal_loss: 0.019752\n",
      "[035/00059] train_loss: 0.019399 kl_loss: 0.000000 normal_loss: 0.019399\n",
      "[037/00031] train_loss: 0.019251 kl_loss: 0.000000 normal_loss: 0.019251\n",
      "[039/00003] train_loss: 0.018806 kl_loss: 0.000000 normal_loss: 0.018806\n",
      "[040/00039] train_loss: 0.018089 kl_loss: 0.000000 normal_loss: 0.018089\n",
      "[042/00011] train_loss: 0.016048 kl_loss: 0.000000 normal_loss: 0.016048\n",
      "[043/00047] train_loss: 0.015897 kl_loss: 0.000000 normal_loss: 0.015897\n",
      "[045/00019] train_loss: 0.016128 kl_loss: 0.000000 normal_loss: 0.016128\n",
      "[046/00055] train_loss: 0.015799 kl_loss: 0.000000 normal_loss: 0.015799\n",
      "[048/00027] train_loss: 0.015944 kl_loss: 0.000000 normal_loss: 0.015944\n",
      "[049/00063] train_loss: 0.016014 kl_loss: 0.000000 normal_loss: 0.016014\n",
      "[051/00035] train_loss: 0.015566 kl_loss: 0.000000 normal_loss: 0.015566\n",
      "[053/00007] train_loss: 0.015497 kl_loss: 0.000000 normal_loss: 0.015497\n",
      "[054/00043] train_loss: 0.015785 kl_loss: 0.000000 normal_loss: 0.015785\n",
      "[056/00015] train_loss: 0.015714 kl_loss: 0.000000 normal_loss: 0.015714\n",
      "[057/00051] train_loss: 0.015630 kl_loss: 0.000000 normal_loss: 0.015630\n",
      "[059/00023] train_loss: 0.015047 kl_loss: 0.000000 normal_loss: 0.015047\n",
      "[060/00059] train_loss: 0.014603 kl_loss: 0.000000 normal_loss: 0.014603\n",
      "[062/00031] train_loss: 0.014013 kl_loss: 0.000000 normal_loss: 0.014013\n",
      "[064/00003] train_loss: 0.013866 kl_loss: 0.000000 normal_loss: 0.013866\n",
      "[065/00039] train_loss: 0.013783 kl_loss: 0.000000 normal_loss: 0.013783\n",
      "[067/00011] train_loss: 0.013585 kl_loss: 0.000000 normal_loss: 0.013585\n",
      "[068/00047] train_loss: 0.013819 kl_loss: 0.000000 normal_loss: 0.013819\n",
      "[070/00019] train_loss: 0.013629 kl_loss: 0.000000 normal_loss: 0.013629\n",
      "[071/00055] train_loss: 0.013676 kl_loss: 0.000000 normal_loss: 0.013676\n",
      "[073/00027] train_loss: 0.013468 kl_loss: 0.000000 normal_loss: 0.013468\n",
      "[074/00063] train_loss: 0.013653 kl_loss: 0.000000 normal_loss: 0.013653\n",
      "[076/00035] train_loss: 0.013496 kl_loss: 0.000000 normal_loss: 0.013496\n",
      "[078/00007] train_loss: 0.013367 kl_loss: 0.000000 normal_loss: 0.013367\n",
      "[079/00043] train_loss: 0.013232 kl_loss: 0.000000 normal_loss: 0.013232\n",
      "[081/00015] train_loss: 0.013007 kl_loss: 0.000000 normal_loss: 0.013007\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Munzer Dwedari\\miniconda3\\envs\\adl4cv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3397, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Munzer Dwedari\\AppData\\Local\\Temp\\ipykernel_16500\\673902499.py\", line 20, in <cell line: 20>\n",
      "    train.main(config)\n",
      "  File \"c:\\Users\\Munzer Dwedari\\Documents\\uni\\ADL4CV\\adl4cv-vad\\training\\train.py\", line 167, in main\n",
      "  File \"c:\\Users\\Munzer Dwedari\\Documents\\uni\\ADL4CV\\adl4cv-vad\\training\\train.py\", line 55, in train\n",
      "    for epoch in range(config['max_epochs']):\n",
      "  File \"c:\\Users\\Munzer Dwedari\\miniconda3\\envs\\adl4cv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 368, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"c:\\Users\\Munzer Dwedari\\miniconda3\\envs\\adl4cv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 314, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"c:\\Users\\Munzer Dwedari\\miniconda3\\envs\\adl4cv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 927, in __init__\n",
      "    w.start()\n",
      "  File \"c:\\Users\\Munzer Dwedari\\miniconda3\\envs\\adl4cv\\lib\\multiprocessing\\process.py\", line 121, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"c:\\Users\\Munzer Dwedari\\miniconda3\\envs\\adl4cv\\lib\\multiprocessing\\context.py\", line 224, in _Popen\n",
      "    return _default_context.get_context().Process._Popen(process_obj)\n",
      "  File \"c:\\Users\\Munzer Dwedari\\miniconda3\\envs\\adl4cv\\lib\\multiprocessing\\context.py\", line 327, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"c:\\Users\\Munzer Dwedari\\miniconda3\\envs\\adl4cv\\lib\\multiprocessing\\popen_spawn_win32.py\", line 93, in __init__\n",
      "    reduction.dump(process_obj, to_child)\n",
      "  File \"c:\\Users\\Munzer Dwedari\\miniconda3\\envs\\adl4cv\\lib\\multiprocessing\\reduction.py\", line 60, in dump\n",
      "    ForkingPickler(file, protocol).dump(obj)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Munzer Dwedari\\miniconda3\\envs\\adl4cv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1992, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"c:\\Users\\Munzer Dwedari\\miniconda3\\envs\\adl4cv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"c:\\Users\\Munzer Dwedari\\miniconda3\\envs\\adl4cv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"c:\\Users\\Munzer Dwedari\\miniconda3\\envs\\adl4cv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"c:\\Users\\Munzer Dwedari\\miniconda3\\envs\\adl4cv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"c:\\Users\\Munzer Dwedari\\miniconda3\\envs\\adl4cv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"c:\\Users\\Munzer Dwedari\\miniconda3\\envs\\adl4cv\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\Munzer Dwedari\\miniconda3\\envs\\adl4cv\\lib\\site-packages\\stack_data\\core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"c:\\Users\\Munzer Dwedari\\miniconda3\\envs\\adl4cv\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\Munzer Dwedari\\miniconda3\\envs\\adl4cv\\lib\\site-packages\\stack_data\\core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"c:\\Users\\Munzer Dwedari\\miniconda3\\envs\\adl4cv\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\Munzer Dwedari\\miniconda3\\envs\\adl4cv\\lib\\site-packages\\stack_data\\core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"c:\\Users\\Munzer Dwedari\\miniconda3\\envs\\adl4cv\\lib\\site-packages\\executing\\executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "# AIRPLANE\n",
    "from training import train\n",
    "config = {\n",
    "    'experiment_name': 'airplane_ad',\n",
    "    'device': 'cuda:0',  # change this to cpu if you do not have a GPU\n",
    "    'is_overfit': False,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate_model': 0.01,\n",
    "    'learning_rate_code': 0.01,\n",
    "    'learning_rate_log_var':0.01,\n",
    "    'max_epochs': 500,\n",
    "    'print_every_n': 100,\n",
    "    'latent_code_length' : 256,\n",
    "    'scheduler_step_size': 20,\n",
    "    'vad_free' : True,\n",
    "    'test': False,\n",
    "    'kl_weight': 0.01,\n",
    "    'resume_ckpt': None,\n",
    "    'filter_class': 'airplane',\n",
    "    'decoder_var' : False\n",
    "}\n",
    "train.main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Data length 6000\n",
      "Training params: 2\n",
      "[001/00005] train_loss: 0.170789 kl_loss: 0.000000 normal_loss: 0.170789\n",
      "[002/00011] train_loss: 0.119310 kl_loss: 0.000000 normal_loss: 0.119310\n",
      "[003/00017] train_loss: 0.112543 kl_loss: 0.000000 normal_loss: 0.112543\n",
      "[004/00023] train_loss: 0.106655 kl_loss: 0.000000 normal_loss: 0.106655\n",
      "[005/00029] train_loss: 0.104214 kl_loss: 0.000000 normal_loss: 0.104214\n",
      "[006/00035] train_loss: 0.098748 kl_loss: 0.000000 normal_loss: 0.098748\n",
      "[007/00041] train_loss: 0.095269 kl_loss: 0.000000 normal_loss: 0.095269\n",
      "[008/00047] train_loss: 0.090359 kl_loss: 0.000000 normal_loss: 0.090359\n",
      "[009/00053] train_loss: 0.089151 kl_loss: 0.000000 normal_loss: 0.089151\n",
      "[010/00059] train_loss: 0.084609 kl_loss: 0.000000 normal_loss: 0.084609\n",
      "[011/00065] train_loss: 0.083053 kl_loss: 0.000000 normal_loss: 0.083053\n",
      "[012/00071] train_loss: 0.081139 kl_loss: 0.000000 normal_loss: 0.081139\n",
      "[013/00077] train_loss: 0.077102 kl_loss: 0.000000 normal_loss: 0.077102\n",
      "[014/00083] train_loss: 0.074768 kl_loss: 0.000000 normal_loss: 0.074768\n",
      "[015/00089] train_loss: 0.073191 kl_loss: 0.000000 normal_loss: 0.073191\n",
      "[017/00001] train_loss: 0.069703 kl_loss: 0.000000 normal_loss: 0.069703\n",
      "[018/00007] train_loss: 0.067230 kl_loss: 0.000000 normal_loss: 0.067230\n",
      "[019/00013] train_loss: 0.064515 kl_loss: 0.000000 normal_loss: 0.064515\n",
      "[020/00019] train_loss: 0.061605 kl_loss: 0.000000 normal_loss: 0.061605\n",
      "[021/00025] train_loss: 0.059996 kl_loss: 0.000000 normal_loss: 0.059996\n",
      "[022/00031] train_loss: 0.058021 kl_loss: 0.000000 normal_loss: 0.058021\n",
      "[023/00037] train_loss: 0.056354 kl_loss: 0.000000 normal_loss: 0.056354\n",
      "[024/00043] train_loss: 0.054989 kl_loss: 0.000000 normal_loss: 0.054989\n",
      "[025/00049] train_loss: 0.054142 kl_loss: 0.000000 normal_loss: 0.054142\n",
      "[026/00055] train_loss: 0.051831 kl_loss: 0.000000 normal_loss: 0.051831\n",
      "[027/00061] train_loss: 0.049995 kl_loss: 0.000000 normal_loss: 0.049995\n",
      "[028/00067] train_loss: 0.049668 kl_loss: 0.000000 normal_loss: 0.049668\n",
      "[029/00073] train_loss: 0.047884 kl_loss: 0.000000 normal_loss: 0.047884\n",
      "[030/00079] train_loss: 0.047094 kl_loss: 0.000000 normal_loss: 0.047094\n",
      "[031/00085] train_loss: 0.044595 kl_loss: 0.000000 normal_loss: 0.044595\n",
      "[032/00091] train_loss: 0.045461 kl_loss: 0.000000 normal_loss: 0.045461\n",
      "[034/00003] train_loss: 0.043912 kl_loss: 0.000000 normal_loss: 0.043912\n",
      "[035/00009] train_loss: 0.042033 kl_loss: 0.000000 normal_loss: 0.042033\n",
      "[036/00015] train_loss: 0.040447 kl_loss: 0.000000 normal_loss: 0.040447\n",
      "[037/00021] train_loss: 0.040736 kl_loss: 0.000000 normal_loss: 0.040736\n",
      "[038/00027] train_loss: 0.038222 kl_loss: 0.000000 normal_loss: 0.038222\n",
      "[039/00033] train_loss: 0.038747 kl_loss: 0.000000 normal_loss: 0.038747\n",
      "[040/00039] train_loss: 0.037341 kl_loss: 0.000000 normal_loss: 0.037341\n",
      "[041/00045] train_loss: 0.036072 kl_loss: 0.000000 normal_loss: 0.036072\n",
      "[042/00051] train_loss: 0.035633 kl_loss: 0.000000 normal_loss: 0.035633\n",
      "[043/00057] train_loss: 0.036622 kl_loss: 0.000000 normal_loss: 0.036622\n",
      "[044/00063] train_loss: 0.035593 kl_loss: 0.000000 normal_loss: 0.035593\n",
      "[045/00069] train_loss: 0.034966 kl_loss: 0.000000 normal_loss: 0.034966\n",
      "[046/00075] train_loss: 0.033288 kl_loss: 0.000000 normal_loss: 0.033288\n",
      "[047/00081] train_loss: 0.033041 kl_loss: 0.000000 normal_loss: 0.033041\n",
      "[048/00087] train_loss: 0.032261 kl_loss: 0.000000 normal_loss: 0.032261\n",
      "[049/00093] train_loss: 0.032458 kl_loss: 0.000000 normal_loss: 0.032458\n",
      "[051/00005] train_loss: 0.031604 kl_loss: 0.000000 normal_loss: 0.031604\n",
      "[052/00011] train_loss: 0.030685 kl_loss: 0.000000 normal_loss: 0.030685\n",
      "[053/00017] train_loss: 0.029773 kl_loss: 0.000000 normal_loss: 0.029773\n",
      "[054/00023] train_loss: 0.029984 kl_loss: 0.000000 normal_loss: 0.029984\n",
      "[055/00029] train_loss: 0.029556 kl_loss: 0.000000 normal_loss: 0.029556\n",
      "[056/00035] train_loss: 0.029127 kl_loss: 0.000000 normal_loss: 0.029127\n",
      "[057/00041] train_loss: 0.028202 kl_loss: 0.000000 normal_loss: 0.028202\n",
      "[058/00047] train_loss: 0.028775 kl_loss: 0.000000 normal_loss: 0.028775\n",
      "[059/00053] train_loss: 0.027824 kl_loss: 0.000000 normal_loss: 0.027824\n",
      "[060/00059] train_loss: 0.026386 kl_loss: 0.000000 normal_loss: 0.026386\n",
      "[061/00065] train_loss: 0.027572 kl_loss: 0.000000 normal_loss: 0.027572\n",
      "[062/00071] train_loss: 0.027168 kl_loss: 0.000000 normal_loss: 0.027168\n",
      "[063/00077] train_loss: 0.026140 kl_loss: 0.000000 normal_loss: 0.026140\n",
      "[064/00083] train_loss: 0.026373 kl_loss: 0.000000 normal_loss: 0.026373\n",
      "[065/00089] train_loss: 0.025501 kl_loss: 0.000000 normal_loss: 0.025501\n",
      "[067/00001] train_loss: 0.026152 kl_loss: 0.000000 normal_loss: 0.026152\n",
      "[068/00007] train_loss: 0.025439 kl_loss: 0.000000 normal_loss: 0.025439\n",
      "[069/00013] train_loss: 0.025331 kl_loss: 0.000000 normal_loss: 0.025331\n",
      "[070/00019] train_loss: 0.024891 kl_loss: 0.000000 normal_loss: 0.024891\n",
      "[071/00025] train_loss: 0.023769 kl_loss: 0.000000 normal_loss: 0.023769\n",
      "[072/00031] train_loss: 0.023991 kl_loss: 0.000000 normal_loss: 0.023991\n",
      "[073/00037] train_loss: 0.023924 kl_loss: 0.000000 normal_loss: 0.023924\n",
      "[074/00043] train_loss: 0.024434 kl_loss: 0.000000 normal_loss: 0.024434\n",
      "[075/00049] train_loss: 0.023806 kl_loss: 0.000000 normal_loss: 0.023806\n",
      "[076/00055] train_loss: 0.022933 kl_loss: 0.000000 normal_loss: 0.022933\n",
      "[077/00061] train_loss: 0.023120 kl_loss: 0.000000 normal_loss: 0.023120\n",
      "[078/00067] train_loss: 0.023447 kl_loss: 0.000000 normal_loss: 0.023447\n",
      "[079/00073] train_loss: 0.023398 kl_loss: 0.000000 normal_loss: 0.023398\n",
      "[080/00079] train_loss: 0.023096 kl_loss: 0.000000 normal_loss: 0.023096\n",
      "[081/00085] train_loss: 0.022661 kl_loss: 0.000000 normal_loss: 0.022661\n",
      "[082/00091] train_loss: 0.022616 kl_loss: 0.000000 normal_loss: 0.022616\n",
      "[084/00003] train_loss: 0.022916 kl_loss: 0.000000 normal_loss: 0.022916\n",
      "[085/00009] train_loss: 0.022678 kl_loss: 0.000000 normal_loss: 0.022678\n",
      "[086/00015] train_loss: 0.022548 kl_loss: 0.000000 normal_loss: 0.022548\n",
      "[087/00021] train_loss: 0.022197 kl_loss: 0.000000 normal_loss: 0.022197\n",
      "[088/00027] train_loss: 0.022057 kl_loss: 0.000000 normal_loss: 0.022057\n",
      "[089/00033] train_loss: 0.021671 kl_loss: 0.000000 normal_loss: 0.021671\n",
      "[090/00039] train_loss: 0.021144 kl_loss: 0.000000 normal_loss: 0.021144\n",
      "[091/00045] train_loss: 0.021607 kl_loss: 0.000000 normal_loss: 0.021607\n",
      "[092/00051] train_loss: 0.021018 kl_loss: 0.000000 normal_loss: 0.021018\n",
      "[093/00057] train_loss: 0.021011 kl_loss: 0.000000 normal_loss: 0.021011\n",
      "[094/00063] train_loss: 0.020048 kl_loss: 0.000000 normal_loss: 0.020048\n",
      "[095/00069] train_loss: 0.020947 kl_loss: 0.000000 normal_loss: 0.020947\n",
      "[096/00075] train_loss: 0.021325 kl_loss: 0.000000 normal_loss: 0.021325\n",
      "[097/00081] train_loss: 0.020538 kl_loss: 0.000000 normal_loss: 0.020538\n",
      "[098/00087] train_loss: 0.021223 kl_loss: 0.000000 normal_loss: 0.021223\n",
      "[099/00093] train_loss: 0.020470 kl_loss: 0.000000 normal_loss: 0.020470\n",
      "[101/00005] train_loss: 0.017555 kl_loss: 0.000000 normal_loss: 0.017555\n",
      "[102/00011] train_loss: 0.015651 kl_loss: 0.000000 normal_loss: 0.015651\n",
      "[103/00017] train_loss: 0.015574 kl_loss: 0.000000 normal_loss: 0.015574\n",
      "[104/00023] train_loss: 0.015257 kl_loss: 0.000000 normal_loss: 0.015257\n",
      "[105/00029] train_loss: 0.015437 kl_loss: 0.000000 normal_loss: 0.015437\n",
      "[106/00035] train_loss: 0.015329 kl_loss: 0.000000 normal_loss: 0.015329\n",
      "[107/00041] train_loss: 0.015530 kl_loss: 0.000000 normal_loss: 0.015530\n",
      "[108/00047] train_loss: 0.015547 kl_loss: 0.000000 normal_loss: 0.015547\n",
      "[109/00053] train_loss: 0.015737 kl_loss: 0.000000 normal_loss: 0.015737\n",
      "[110/00059] train_loss: 0.015648 kl_loss: 0.000000 normal_loss: 0.015648\n",
      "[111/00065] train_loss: 0.015295 kl_loss: 0.000000 normal_loss: 0.015295\n",
      "[112/00071] train_loss: 0.015117 kl_loss: 0.000000 normal_loss: 0.015117\n",
      "[113/00077] train_loss: 0.015775 kl_loss: 0.000000 normal_loss: 0.015775\n",
      "[114/00083] train_loss: 0.016034 kl_loss: 0.000000 normal_loss: 0.016034\n",
      "[115/00089] train_loss: 0.015433 kl_loss: 0.000000 normal_loss: 0.015433\n",
      "[117/00001] train_loss: 0.015185 kl_loss: 0.000000 normal_loss: 0.015185\n",
      "[118/00007] train_loss: 0.015829 kl_loss: 0.000000 normal_loss: 0.015829\n",
      "[119/00013] train_loss: 0.015666 kl_loss: 0.000000 normal_loss: 0.015666\n",
      "[120/00019] train_loss: 0.015286 kl_loss: 0.000000 normal_loss: 0.015286\n",
      "[121/00025] train_loss: 0.015482 kl_loss: 0.000000 normal_loss: 0.015482\n",
      "[122/00031] train_loss: 0.015904 kl_loss: 0.000000 normal_loss: 0.015904\n",
      "[123/00037] train_loss: 0.015639 kl_loss: 0.000000 normal_loss: 0.015639\n",
      "[124/00043] train_loss: 0.015177 kl_loss: 0.000000 normal_loss: 0.015177\n",
      "[125/00049] train_loss: 0.014996 kl_loss: 0.000000 normal_loss: 0.014996\n",
      "[126/00055] train_loss: 0.014901 kl_loss: 0.000000 normal_loss: 0.014901\n",
      "[127/00061] train_loss: 0.015679 kl_loss: 0.000000 normal_loss: 0.015679\n",
      "[128/00067] train_loss: 0.015258 kl_loss: 0.000000 normal_loss: 0.015258\n",
      "[129/00073] train_loss: 0.015340 kl_loss: 0.000000 normal_loss: 0.015340\n",
      "[130/00079] train_loss: 0.015420 kl_loss: 0.000000 normal_loss: 0.015420\n",
      "[131/00085] train_loss: 0.015211 kl_loss: 0.000000 normal_loss: 0.015211\n",
      "[132/00091] train_loss: 0.014825 kl_loss: 0.000000 normal_loss: 0.014825\n",
      "[134/00003] train_loss: 0.014890 kl_loss: 0.000000 normal_loss: 0.014890\n",
      "[135/00009] train_loss: 0.015089 kl_loss: 0.000000 normal_loss: 0.015089\n",
      "[136/00015] train_loss: 0.015091 kl_loss: 0.000000 normal_loss: 0.015091\n",
      "[137/00021] train_loss: 0.015065 kl_loss: 0.000000 normal_loss: 0.015065\n",
      "[138/00027] train_loss: 0.014805 kl_loss: 0.000000 normal_loss: 0.014805\n",
      "[139/00033] train_loss: 0.014967 kl_loss: 0.000000 normal_loss: 0.014967\n",
      "[140/00039] train_loss: 0.014646 kl_loss: 0.000000 normal_loss: 0.014646\n",
      "[141/00045] train_loss: 0.014927 kl_loss: 0.000000 normal_loss: 0.014927\n",
      "[142/00051] train_loss: 0.014857 kl_loss: 0.000000 normal_loss: 0.014857\n",
      "[143/00057] train_loss: 0.014817 kl_loss: 0.000000 normal_loss: 0.014817\n",
      "[144/00063] train_loss: 0.014645 kl_loss: 0.000000 normal_loss: 0.014645\n",
      "[145/00069] train_loss: 0.014525 kl_loss: 0.000000 normal_loss: 0.014525\n",
      "[146/00075] train_loss: 0.014808 kl_loss: 0.000000 normal_loss: 0.014808\n",
      "[147/00081] train_loss: 0.014537 kl_loss: 0.000000 normal_loss: 0.014537\n",
      "[148/00087] train_loss: 0.014322 kl_loss: 0.000000 normal_loss: 0.014322\n",
      "[149/00093] train_loss: 0.014082 kl_loss: 0.000000 normal_loss: 0.014082\n",
      "[151/00005] train_loss: 0.014684 kl_loss: 0.000000 normal_loss: 0.014684\n",
      "[152/00011] train_loss: 0.014507 kl_loss: 0.000000 normal_loss: 0.014507\n",
      "[153/00017] train_loss: 0.015022 kl_loss: 0.000000 normal_loss: 0.015022\n",
      "[154/00023] train_loss: 0.014567 kl_loss: 0.000000 normal_loss: 0.014567\n",
      "[155/00029] train_loss: 0.014520 kl_loss: 0.000000 normal_loss: 0.014520\n",
      "[156/00035] train_loss: 0.014692 kl_loss: 0.000000 normal_loss: 0.014692\n",
      "[157/00041] train_loss: 0.014294 kl_loss: 0.000000 normal_loss: 0.014294\n",
      "[158/00047] train_loss: 0.014516 kl_loss: 0.000000 normal_loss: 0.014516\n",
      "[159/00053] train_loss: 0.013960 kl_loss: 0.000000 normal_loss: 0.013960\n",
      "[160/00059] train_loss: 0.013956 kl_loss: 0.000000 normal_loss: 0.013956\n",
      "[161/00065] train_loss: 0.014307 kl_loss: 0.000000 normal_loss: 0.014307\n",
      "[162/00071] train_loss: 0.014611 kl_loss: 0.000000 normal_loss: 0.014611\n",
      "[163/00077] train_loss: 0.014380 kl_loss: 0.000000 normal_loss: 0.014380\n",
      "[164/00083] train_loss: 0.014190 kl_loss: 0.000000 normal_loss: 0.014190\n",
      "[165/00089] train_loss: 0.014364 kl_loss: 0.000000 normal_loss: 0.014364\n",
      "[167/00001] train_loss: 0.014217 kl_loss: 0.000000 normal_loss: 0.014217\n",
      "[168/00007] train_loss: 0.013905 kl_loss: 0.000000 normal_loss: 0.013905\n",
      "[169/00013] train_loss: 0.013691 kl_loss: 0.000000 normal_loss: 0.013691\n",
      "[170/00019] train_loss: 0.013563 kl_loss: 0.000000 normal_loss: 0.013563\n",
      "[171/00025] train_loss: 0.014289 kl_loss: 0.000000 normal_loss: 0.014289\n",
      "[172/00031] train_loss: 0.014284 kl_loss: 0.000000 normal_loss: 0.014284\n",
      "[173/00037] train_loss: 0.014072 kl_loss: 0.000000 normal_loss: 0.014072\n",
      "[174/00043] train_loss: 0.014386 kl_loss: 0.000000 normal_loss: 0.014386\n",
      "[175/00049] train_loss: 0.014073 kl_loss: 0.000000 normal_loss: 0.014073\n",
      "[176/00055] train_loss: 0.013806 kl_loss: 0.000000 normal_loss: 0.013806\n",
      "[177/00061] train_loss: 0.013736 kl_loss: 0.000000 normal_loss: 0.013736\n",
      "[178/00067] train_loss: 0.014115 kl_loss: 0.000000 normal_loss: 0.014115\n",
      "[179/00073] train_loss: 0.013644 kl_loss: 0.000000 normal_loss: 0.013644\n",
      "[180/00079] train_loss: 0.013642 kl_loss: 0.000000 normal_loss: 0.013642\n",
      "[181/00085] train_loss: 0.013909 kl_loss: 0.000000 normal_loss: 0.013909\n",
      "[182/00091] train_loss: 0.013913 kl_loss: 0.000000 normal_loss: 0.013913\n",
      "[184/00003] train_loss: 0.014096 kl_loss: 0.000000 normal_loss: 0.014096\n",
      "[185/00009] train_loss: 0.013900 kl_loss: 0.000000 normal_loss: 0.013900\n",
      "[186/00015] train_loss: 0.013933 kl_loss: 0.000000 normal_loss: 0.013933\n",
      "[187/00021] train_loss: 0.013852 kl_loss: 0.000000 normal_loss: 0.013852\n",
      "[188/00027] train_loss: 0.013193 kl_loss: 0.000000 normal_loss: 0.013193\n",
      "[189/00033] train_loss: 0.013133 kl_loss: 0.000000 normal_loss: 0.013133\n",
      "[190/00039] train_loss: 0.013644 kl_loss: 0.000000 normal_loss: 0.013644\n",
      "[191/00045] train_loss: 0.013735 kl_loss: 0.000000 normal_loss: 0.013735\n",
      "[192/00051] train_loss: 0.014015 kl_loss: 0.000000 normal_loss: 0.014015\n",
      "[193/00057] train_loss: 0.013924 kl_loss: 0.000000 normal_loss: 0.013924\n",
      "[194/00063] train_loss: 0.013562 kl_loss: 0.000000 normal_loss: 0.013562\n",
      "[195/00069] train_loss: 0.013730 kl_loss: 0.000000 normal_loss: 0.013730\n",
      "[196/00075] train_loss: 0.013645 kl_loss: 0.000000 normal_loss: 0.013645\n",
      "[197/00081] train_loss: 0.013245 kl_loss: 0.000000 normal_loss: 0.013245\n",
      "[198/00087] train_loss: 0.013792 kl_loss: 0.000000 normal_loss: 0.013792\n",
      "[199/00093] train_loss: 0.013519 kl_loss: 0.000000 normal_loss: 0.013519\n",
      "[201/00005] train_loss: 0.012326 kl_loss: 0.000000 normal_loss: 0.012326\n",
      "[202/00011] train_loss: 0.011625 kl_loss: 0.000000 normal_loss: 0.011625\n",
      "[203/00017] train_loss: 0.011559 kl_loss: 0.000000 normal_loss: 0.011559\n",
      "[204/00023] train_loss: 0.011415 kl_loss: 0.000000 normal_loss: 0.011415\n",
      "[205/00029] train_loss: 0.011501 kl_loss: 0.000000 normal_loss: 0.011501\n",
      "[206/00035] train_loss: 0.011453 kl_loss: 0.000000 normal_loss: 0.011453\n",
      "[207/00041] train_loss: 0.011392 kl_loss: 0.000000 normal_loss: 0.011392\n",
      "[208/00047] train_loss: 0.011547 kl_loss: 0.000000 normal_loss: 0.011547\n",
      "[209/00053] train_loss: 0.011568 kl_loss: 0.000000 normal_loss: 0.011568\n",
      "[210/00059] train_loss: 0.011670 kl_loss: 0.000000 normal_loss: 0.011670\n",
      "[211/00065] train_loss: 0.011558 kl_loss: 0.000000 normal_loss: 0.011558\n",
      "[212/00071] train_loss: 0.011680 kl_loss: 0.000000 normal_loss: 0.011680\n",
      "[213/00077] train_loss: 0.011607 kl_loss: 0.000000 normal_loss: 0.011607\n",
      "[214/00083] train_loss: 0.011376 kl_loss: 0.000000 normal_loss: 0.011376\n",
      "[215/00089] train_loss: 0.011502 kl_loss: 0.000000 normal_loss: 0.011502\n",
      "[217/00001] train_loss: 0.011622 kl_loss: 0.000000 normal_loss: 0.011622\n",
      "[218/00007] train_loss: 0.011672 kl_loss: 0.000000 normal_loss: 0.011672\n",
      "[219/00013] train_loss: 0.011692 kl_loss: 0.000000 normal_loss: 0.011692\n",
      "[220/00019] train_loss: 0.011661 kl_loss: 0.000000 normal_loss: 0.011661\n",
      "[221/00025] train_loss: 0.011621 kl_loss: 0.000000 normal_loss: 0.011621\n",
      "[222/00031] train_loss: 0.011576 kl_loss: 0.000000 normal_loss: 0.011576\n",
      "[223/00037] train_loss: 0.011488 kl_loss: 0.000000 normal_loss: 0.011488\n",
      "[224/00043] train_loss: 0.011545 kl_loss: 0.000000 normal_loss: 0.011545\n",
      "[225/00049] train_loss: 0.011521 kl_loss: 0.000000 normal_loss: 0.011521\n",
      "[226/00055] train_loss: 0.011663 kl_loss: 0.000000 normal_loss: 0.011663\n",
      "[227/00061] train_loss: 0.011432 kl_loss: 0.000000 normal_loss: 0.011432\n",
      "[228/00067] train_loss: 0.011706 kl_loss: 0.000000 normal_loss: 0.011706\n",
      "[229/00073] train_loss: 0.011519 kl_loss: 0.000000 normal_loss: 0.011519\n",
      "[230/00079] train_loss: 0.011489 kl_loss: 0.000000 normal_loss: 0.011489\n",
      "[231/00085] train_loss: 0.011500 kl_loss: 0.000000 normal_loss: 0.011500\n",
      "[232/00091] train_loss: 0.011477 kl_loss: 0.000000 normal_loss: 0.011477\n",
      "[234/00003] train_loss: 0.011595 kl_loss: 0.000000 normal_loss: 0.011595\n",
      "[235/00009] train_loss: 0.011436 kl_loss: 0.000000 normal_loss: 0.011436\n",
      "[236/00015] train_loss: 0.011719 kl_loss: 0.000000 normal_loss: 0.011719\n",
      "[237/00021] train_loss: 0.011364 kl_loss: 0.000000 normal_loss: 0.011364\n",
      "[238/00027] train_loss: 0.011530 kl_loss: 0.000000 normal_loss: 0.011530\n",
      "[239/00033] train_loss: 0.011472 kl_loss: 0.000000 normal_loss: 0.011472\n",
      "[240/00039] train_loss: 0.011302 kl_loss: 0.000000 normal_loss: 0.011302\n",
      "[241/00045] train_loss: 0.011359 kl_loss: 0.000000 normal_loss: 0.011359\n",
      "[242/00051] train_loss: 0.011315 kl_loss: 0.000000 normal_loss: 0.011315\n",
      "[243/00057] train_loss: 0.011296 kl_loss: 0.000000 normal_loss: 0.011296\n",
      "[244/00063] train_loss: 0.011389 kl_loss: 0.000000 normal_loss: 0.011389\n",
      "[245/00069] train_loss: 0.011350 kl_loss: 0.000000 normal_loss: 0.011350\n",
      "[246/00075] train_loss: 0.011162 kl_loss: 0.000000 normal_loss: 0.011162\n",
      "[247/00081] train_loss: 0.011681 kl_loss: 0.000000 normal_loss: 0.011681\n",
      "[248/00087] train_loss: 0.011401 kl_loss: 0.000000 normal_loss: 0.011401\n",
      "[249/00093] train_loss: 0.011451 kl_loss: 0.000000 normal_loss: 0.011451\n",
      "[251/00005] train_loss: 0.011298 kl_loss: 0.000000 normal_loss: 0.011298\n",
      "[252/00011] train_loss: 0.011140 kl_loss: 0.000000 normal_loss: 0.011140\n",
      "[253/00017] train_loss: 0.011190 kl_loss: 0.000000 normal_loss: 0.011190\n",
      "[254/00023] train_loss: 0.011457 kl_loss: 0.000000 normal_loss: 0.011457\n",
      "[255/00029] train_loss: 0.011560 kl_loss: 0.000000 normal_loss: 0.011560\n",
      "[256/00035] train_loss: 0.011217 kl_loss: 0.000000 normal_loss: 0.011217\n",
      "[257/00041] train_loss: 0.011065 kl_loss: 0.000000 normal_loss: 0.011065\n",
      "[258/00047] train_loss: 0.011403 kl_loss: 0.000000 normal_loss: 0.011403\n",
      "[259/00053] train_loss: 0.011368 kl_loss: 0.000000 normal_loss: 0.011368\n",
      "[260/00059] train_loss: 0.011352 kl_loss: 0.000000 normal_loss: 0.011352\n",
      "[261/00065] train_loss: 0.011223 kl_loss: 0.000000 normal_loss: 0.011223\n",
      "[262/00071] train_loss: 0.011281 kl_loss: 0.000000 normal_loss: 0.011281\n",
      "[263/00077] train_loss: 0.011121 kl_loss: 0.000000 normal_loss: 0.011121\n",
      "[264/00083] train_loss: 0.011101 kl_loss: 0.000000 normal_loss: 0.011101\n",
      "[265/00089] train_loss: 0.011221 kl_loss: 0.000000 normal_loss: 0.011221\n",
      "[267/00001] train_loss: 0.011442 kl_loss: 0.000000 normal_loss: 0.011442\n",
      "[268/00007] train_loss: 0.011258 kl_loss: 0.000000 normal_loss: 0.011258\n",
      "[269/00013] train_loss: 0.011185 kl_loss: 0.000000 normal_loss: 0.011185\n",
      "[270/00019] train_loss: 0.011169 kl_loss: 0.000000 normal_loss: 0.011169\n",
      "[271/00025] train_loss: 0.011144 kl_loss: 0.000000 normal_loss: 0.011144\n",
      "[272/00031] train_loss: 0.011069 kl_loss: 0.000000 normal_loss: 0.011069\n",
      "[273/00037] train_loss: 0.011306 kl_loss: 0.000000 normal_loss: 0.011306\n",
      "[274/00043] train_loss: 0.011143 kl_loss: 0.000000 normal_loss: 0.011143\n",
      "[275/00049] train_loss: 0.011317 kl_loss: 0.000000 normal_loss: 0.011317\n",
      "[276/00055] train_loss: 0.011050 kl_loss: 0.000000 normal_loss: 0.011050\n",
      "[277/00061] train_loss: 0.011095 kl_loss: 0.000000 normal_loss: 0.011095\n",
      "[278/00067] train_loss: 0.011292 kl_loss: 0.000000 normal_loss: 0.011292\n",
      "[279/00073] train_loss: 0.011090 kl_loss: 0.000000 normal_loss: 0.011090\n",
      "[280/00079] train_loss: 0.011195 kl_loss: 0.000000 normal_loss: 0.011195\n",
      "[281/00085] train_loss: 0.011025 kl_loss: 0.000000 normal_loss: 0.011025\n",
      "[282/00091] train_loss: 0.011012 kl_loss: 0.000000 normal_loss: 0.011012\n",
      "[284/00003] train_loss: 0.010984 kl_loss: 0.000000 normal_loss: 0.010984\n",
      "[285/00009] train_loss: 0.011148 kl_loss: 0.000000 normal_loss: 0.011148\n",
      "[286/00015] train_loss: 0.011265 kl_loss: 0.000000 normal_loss: 0.011265\n",
      "[287/00021] train_loss: 0.011245 kl_loss: 0.000000 normal_loss: 0.011245\n",
      "[288/00027] train_loss: 0.010894 kl_loss: 0.000000 normal_loss: 0.010894\n",
      "[289/00033] train_loss: 0.010918 kl_loss: 0.000000 normal_loss: 0.010918\n",
      "[290/00039] train_loss: 0.011049 kl_loss: 0.000000 normal_loss: 0.011049\n",
      "[291/00045] train_loss: 0.011065 kl_loss: 0.000000 normal_loss: 0.011065\n",
      "[292/00051] train_loss: 0.011161 kl_loss: 0.000000 normal_loss: 0.011161\n",
      "[293/00057] train_loss: 0.011162 kl_loss: 0.000000 normal_loss: 0.011162\n",
      "[294/00063] train_loss: 0.011098 kl_loss: 0.000000 normal_loss: 0.011098\n",
      "[295/00069] train_loss: 0.010842 kl_loss: 0.000000 normal_loss: 0.010842\n",
      "[296/00075] train_loss: 0.011159 kl_loss: 0.000000 normal_loss: 0.011159\n",
      "[297/00081] train_loss: 0.010983 kl_loss: 0.000000 normal_loss: 0.010983\n",
      "[298/00087] train_loss: 0.011065 kl_loss: 0.000000 normal_loss: 0.011065\n",
      "[299/00093] train_loss: 0.011041 kl_loss: 0.000000 normal_loss: 0.011041\n",
      "[301/00005] train_loss: 0.010517 kl_loss: 0.000000 normal_loss: 0.010517\n",
      "[302/00011] train_loss: 0.010246 kl_loss: 0.000000 normal_loss: 0.010246\n",
      "[303/00017] train_loss: 0.010262 kl_loss: 0.000000 normal_loss: 0.010262\n",
      "[304/00023] train_loss: 0.010249 kl_loss: 0.000000 normal_loss: 0.010249\n",
      "[305/00029] train_loss: 0.010271 kl_loss: 0.000000 normal_loss: 0.010271\n",
      "[306/00035] train_loss: 0.010117 kl_loss: 0.000000 normal_loss: 0.010117\n",
      "[307/00041] train_loss: 0.010226 kl_loss: 0.000000 normal_loss: 0.010226\n",
      "[308/00047] train_loss: 0.010246 kl_loss: 0.000000 normal_loss: 0.010246\n",
      "[309/00053] train_loss: 0.010148 kl_loss: 0.000000 normal_loss: 0.010148\n",
      "[310/00059] train_loss: 0.010184 kl_loss: 0.000000 normal_loss: 0.010184\n",
      "[311/00065] train_loss: 0.010260 kl_loss: 0.000000 normal_loss: 0.010260\n",
      "[312/00071] train_loss: 0.010252 kl_loss: 0.000000 normal_loss: 0.010252\n",
      "[313/00077] train_loss: 0.010283 kl_loss: 0.000000 normal_loss: 0.010283\n",
      "[314/00083] train_loss: 0.010220 kl_loss: 0.000000 normal_loss: 0.010220\n",
      "[315/00089] train_loss: 0.010255 kl_loss: 0.000000 normal_loss: 0.010255\n",
      "[317/00001] train_loss: 0.010203 kl_loss: 0.000000 normal_loss: 0.010203\n",
      "[318/00007] train_loss: 0.010226 kl_loss: 0.000000 normal_loss: 0.010226\n",
      "[319/00013] train_loss: 0.010222 kl_loss: 0.000000 normal_loss: 0.010222\n",
      "[320/00019] train_loss: 0.010265 kl_loss: 0.000000 normal_loss: 0.010265\n",
      "[321/00025] train_loss: 0.010266 kl_loss: 0.000000 normal_loss: 0.010266\n",
      "[322/00031] train_loss: 0.010246 kl_loss: 0.000000 normal_loss: 0.010246\n",
      "[323/00037] train_loss: 0.010218 kl_loss: 0.000000 normal_loss: 0.010218\n",
      "[324/00043] train_loss: 0.010209 kl_loss: 0.000000 normal_loss: 0.010209\n",
      "[325/00049] train_loss: 0.010175 kl_loss: 0.000000 normal_loss: 0.010175\n",
      "[326/00055] train_loss: 0.010127 kl_loss: 0.000000 normal_loss: 0.010127\n",
      "[327/00061] train_loss: 0.010312 kl_loss: 0.000000 normal_loss: 0.010312\n",
      "[328/00067] train_loss: 0.010165 kl_loss: 0.000000 normal_loss: 0.010165\n",
      "[329/00073] train_loss: 0.010248 kl_loss: 0.000000 normal_loss: 0.010248\n",
      "[330/00079] train_loss: 0.010207 kl_loss: 0.000000 normal_loss: 0.010207\n",
      "[331/00085] train_loss: 0.010198 kl_loss: 0.000000 normal_loss: 0.010198\n",
      "[332/00091] train_loss: 0.010193 kl_loss: 0.000000 normal_loss: 0.010193\n",
      "[334/00003] train_loss: 0.010178 kl_loss: 0.000000 normal_loss: 0.010178\n",
      "[335/00009] train_loss: 0.010130 kl_loss: 0.000000 normal_loss: 0.010130\n",
      "[336/00015] train_loss: 0.010189 kl_loss: 0.000000 normal_loss: 0.010189\n",
      "[337/00021] train_loss: 0.010203 kl_loss: 0.000000 normal_loss: 0.010203\n",
      "[338/00027] train_loss: 0.010221 kl_loss: 0.000000 normal_loss: 0.010221\n",
      "[339/00033] train_loss: 0.010256 kl_loss: 0.000000 normal_loss: 0.010256\n",
      "[340/00039] train_loss: 0.010155 kl_loss: 0.000000 normal_loss: 0.010155\n",
      "[341/00045] train_loss: 0.010119 kl_loss: 0.000000 normal_loss: 0.010119\n",
      "[342/00051] train_loss: 0.010171 kl_loss: 0.000000 normal_loss: 0.010171\n",
      "[343/00057] train_loss: 0.010198 kl_loss: 0.000000 normal_loss: 0.010198\n",
      "[344/00063] train_loss: 0.010181 kl_loss: 0.000000 normal_loss: 0.010181\n",
      "[345/00069] train_loss: 0.010173 kl_loss: 0.000000 normal_loss: 0.010173\n",
      "[346/00075] train_loss: 0.010180 kl_loss: 0.000000 normal_loss: 0.010180\n",
      "[347/00081] train_loss: 0.010072 kl_loss: 0.000000 normal_loss: 0.010072\n",
      "[348/00087] train_loss: 0.010118 kl_loss: 0.000000 normal_loss: 0.010118\n",
      "[349/00093] train_loss: 0.010134 kl_loss: 0.000000 normal_loss: 0.010134\n",
      "[351/00005] train_loss: 0.010090 kl_loss: 0.000000 normal_loss: 0.010090\n",
      "[352/00011] train_loss: 0.010110 kl_loss: 0.000000 normal_loss: 0.010110\n",
      "[353/00017] train_loss: 0.010092 kl_loss: 0.000000 normal_loss: 0.010092\n",
      "[354/00023] train_loss: 0.010162 kl_loss: 0.000000 normal_loss: 0.010162\n",
      "[355/00029] train_loss: 0.010098 kl_loss: 0.000000 normal_loss: 0.010098\n",
      "[356/00035] train_loss: 0.010046 kl_loss: 0.000000 normal_loss: 0.010046\n",
      "[357/00041] train_loss: 0.010071 kl_loss: 0.000000 normal_loss: 0.010071\n",
      "[358/00047] train_loss: 0.010113 kl_loss: 0.000000 normal_loss: 0.010113\n",
      "[359/00053] train_loss: 0.010060 kl_loss: 0.000000 normal_loss: 0.010060\n",
      "[360/00059] train_loss: 0.010085 kl_loss: 0.000000 normal_loss: 0.010085\n",
      "[361/00065] train_loss: 0.010169 kl_loss: 0.000000 normal_loss: 0.010169\n",
      "[362/00071] train_loss: 0.010050 kl_loss: 0.000000 normal_loss: 0.010050\n",
      "[363/00077] train_loss: 0.010029 kl_loss: 0.000000 normal_loss: 0.010029\n",
      "[364/00083] train_loss: 0.010070 kl_loss: 0.000000 normal_loss: 0.010070\n",
      "[365/00089] train_loss: 0.010169 kl_loss: 0.000000 normal_loss: 0.010169\n",
      "[367/00001] train_loss: 0.010005 kl_loss: 0.000000 normal_loss: 0.010005\n",
      "[368/00007] train_loss: 0.010060 kl_loss: 0.000000 normal_loss: 0.010060\n",
      "[369/00013] train_loss: 0.009988 kl_loss: 0.000000 normal_loss: 0.009988\n",
      "[370/00019] train_loss: 0.010120 kl_loss: 0.000000 normal_loss: 0.010120\n",
      "[371/00025] train_loss: 0.010066 kl_loss: 0.000000 normal_loss: 0.010066\n",
      "[372/00031] train_loss: 0.009933 kl_loss: 0.000000 normal_loss: 0.009933\n",
      "[373/00037] train_loss: 0.010093 kl_loss: 0.000000 normal_loss: 0.010093\n",
      "[374/00043] train_loss: 0.009972 kl_loss: 0.000000 normal_loss: 0.009972\n",
      "[375/00049] train_loss: 0.010037 kl_loss: 0.000000 normal_loss: 0.010037\n",
      "[376/00055] train_loss: 0.009991 kl_loss: 0.000000 normal_loss: 0.009991\n",
      "[377/00061] train_loss: 0.010022 kl_loss: 0.000000 normal_loss: 0.010022\n",
      "[378/00067] train_loss: 0.010008 kl_loss: 0.000000 normal_loss: 0.010008\n",
      "[379/00073] train_loss: 0.009970 kl_loss: 0.000000 normal_loss: 0.009970\n",
      "[380/00079] train_loss: 0.010011 kl_loss: 0.000000 normal_loss: 0.010011\n",
      "[381/00085] train_loss: 0.009967 kl_loss: 0.000000 normal_loss: 0.009967\n",
      "[382/00091] train_loss: 0.009960 kl_loss: 0.000000 normal_loss: 0.009960\n",
      "[384/00003] train_loss: 0.010048 kl_loss: 0.000000 normal_loss: 0.010048\n",
      "[385/00009] train_loss: 0.009959 kl_loss: 0.000000 normal_loss: 0.009959\n",
      "[386/00015] train_loss: 0.010017 kl_loss: 0.000000 normal_loss: 0.010017\n",
      "[387/00021] train_loss: 0.010008 kl_loss: 0.000000 normal_loss: 0.010008\n",
      "[388/00027] train_loss: 0.009994 kl_loss: 0.000000 normal_loss: 0.009994\n",
      "[389/00033] train_loss: 0.010066 kl_loss: 0.000000 normal_loss: 0.010066\n",
      "[390/00039] train_loss: 0.010017 kl_loss: 0.000000 normal_loss: 0.010017\n",
      "[391/00045] train_loss: 0.009861 kl_loss: 0.000000 normal_loss: 0.009861\n",
      "[392/00051] train_loss: 0.010109 kl_loss: 0.000000 normal_loss: 0.010109\n",
      "[393/00057] train_loss: 0.009989 kl_loss: 0.000000 normal_loss: 0.009989\n",
      "[394/00063] train_loss: 0.009996 kl_loss: 0.000000 normal_loss: 0.009996\n",
      "[395/00069] train_loss: 0.009870 kl_loss: 0.000000 normal_loss: 0.009870\n",
      "[396/00075] train_loss: 0.009969 kl_loss: 0.000000 normal_loss: 0.009969\n",
      "[397/00081] train_loss: 0.009880 kl_loss: 0.000000 normal_loss: 0.009880\n",
      "[398/00087] train_loss: 0.009947 kl_loss: 0.000000 normal_loss: 0.009947\n",
      "[399/00093] train_loss: 0.009983 kl_loss: 0.000000 normal_loss: 0.009983\n",
      "[401/00005] train_loss: 0.009788 kl_loss: 0.000000 normal_loss: 0.009788\n",
      "[402/00011] train_loss: 0.009675 kl_loss: 0.000000 normal_loss: 0.009675\n",
      "[403/00017] train_loss: 0.009665 kl_loss: 0.000000 normal_loss: 0.009665\n",
      "[404/00023] train_loss: 0.009673 kl_loss: 0.000000 normal_loss: 0.009673\n",
      "[405/00029] train_loss: 0.009681 kl_loss: 0.000000 normal_loss: 0.009681\n",
      "[406/00035] train_loss: 0.009675 kl_loss: 0.000000 normal_loss: 0.009675\n",
      "[407/00041] train_loss: 0.009686 kl_loss: 0.000000 normal_loss: 0.009686\n",
      "[408/00047] train_loss: 0.009626 kl_loss: 0.000000 normal_loss: 0.009626\n",
      "[409/00053] train_loss: 0.009652 kl_loss: 0.000000 normal_loss: 0.009652\n",
      "[410/00059] train_loss: 0.009662 kl_loss: 0.000000 normal_loss: 0.009662\n",
      "[411/00065] train_loss: 0.009678 kl_loss: 0.000000 normal_loss: 0.009678\n",
      "[412/00071] train_loss: 0.009712 kl_loss: 0.000000 normal_loss: 0.009712\n",
      "[413/00077] train_loss: 0.009683 kl_loss: 0.000000 normal_loss: 0.009683\n",
      "[414/00083] train_loss: 0.009658 kl_loss: 0.000000 normal_loss: 0.009658\n",
      "[415/00089] train_loss: 0.009679 kl_loss: 0.000000 normal_loss: 0.009679\n",
      "[417/00001] train_loss: 0.009674 kl_loss: 0.000000 normal_loss: 0.009674\n",
      "[418/00007] train_loss: 0.009655 kl_loss: 0.000000 normal_loss: 0.009655\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Munzer Dwedari\\Documents\\uni\\ADL4CV\\adl4cv-vad\\index.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Munzer%20Dwedari/Documents/uni/ADL4CV/adl4cv-vad/index.ipynb#ch0000016?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtraining\u001b[39;00m \u001b[39mimport\u001b[39;00m train\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Munzer%20Dwedari/Documents/uni/ADL4CV/adl4cv-vad/index.ipynb#ch0000016?line=2'>3</a>\u001b[0m config \u001b[39m=\u001b[39m {\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Munzer%20Dwedari/Documents/uni/ADL4CV/adl4cv-vad/index.ipynb#ch0000016?line=3'>4</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mexperiment_name\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mchair_ad\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Munzer%20Dwedari/Documents/uni/ADL4CV/adl4cv-vad/index.ipynb#ch0000016?line=4'>5</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m'\u001b[39m,  \u001b[39m# change this to cpu if you do not have a GPU\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Munzer%20Dwedari/Documents/uni/ADL4CV/adl4cv-vad/index.ipynb#ch0000016?line=19'>20</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mdecoder_var\u001b[39m\u001b[39m'\u001b[39m : \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Munzer%20Dwedari/Documents/uni/ADL4CV/adl4cv-vad/index.ipynb#ch0000016?line=20'>21</a>\u001b[0m }\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Munzer%20Dwedari/Documents/uni/ADL4CV/adl4cv-vad/index.ipynb#ch0000016?line=21'>22</a>\u001b[0m train\u001b[39m.\u001b[39;49mmain(config)\n",
      "File \u001b[1;32mc:\\Users\\Munzer Dwedari\\Documents\\uni\\ADL4CV\\adl4cv-vad\\training\\train.py:186\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer%20Dwedari/Documents/uni/ADL4CV/adl4cv-vad/training/train.py?line=182'>183</a>\u001b[0m     json\u001b[39m.\u001b[39mdump(config, f)\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer%20Dwedari/Documents/uni/ADL4CV/adl4cv-vad/training/train.py?line=184'>185</a>\u001b[0m \u001b[39m# Start training\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Munzer%20Dwedari/Documents/uni/ADL4CV/adl4cv-vad/training/train.py?line=185'>186</a>\u001b[0m train(model, train_dataloader, latent_vectors, latent_log_var, device, config)\n",
      "File \u001b[1;32mc:\\Users\\Munzer Dwedari\\Documents\\uni\\ADL4CV\\adl4cv-vad\\training\\train.py:98\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_dataloader, latent_vectors, latent_log_var, device, config)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Munzer%20Dwedari/Documents/uni/ADL4CV/adl4cv-vad/training/train.py?line=95'>96</a>\u001b[0m     loss \u001b[39m=\u001b[39m reconstruction_loss\n\u001b[0;32m     <a href='file:///c%3A/Users/Munzer%20Dwedari/Documents/uni/ADL4CV/adl4cv-vad/training/train.py?line=96'>97</a>\u001b[0m \u001b[39m# Compute gradients\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/Users/Munzer%20Dwedari/Documents/uni/ADL4CV/adl4cv-vad/training/train.py?line=97'>98</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer%20Dwedari/Documents/uni/ADL4CV/adl4cv-vad/training/train.py?line=99'>100</a>\u001b[0m \u001b[39m# Update network parameters\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer%20Dwedari/Documents/uni/ADL4CV/adl4cv-vad/training/train.py?line=100'>101</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\Munzer Dwedari\\miniconda3\\envs\\adl4cv\\lib\\site-packages\\torch\\_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer%20Dwedari/miniconda3/envs/adl4cv/lib/site-packages/torch/_tensor.py?line=353'>354</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer%20Dwedari/miniconda3/envs/adl4cv/lib/site-packages/torch/_tensor.py?line=354'>355</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer%20Dwedari/miniconda3/envs/adl4cv/lib/site-packages/torch/_tensor.py?line=355'>356</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer%20Dwedari/miniconda3/envs/adl4cv/lib/site-packages/torch/_tensor.py?line=356'>357</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer%20Dwedari/miniconda3/envs/adl4cv/lib/site-packages/torch/_tensor.py?line=360'>361</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer%20Dwedari/miniconda3/envs/adl4cv/lib/site-packages/torch/_tensor.py?line=361'>362</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Munzer%20Dwedari/miniconda3/envs/adl4cv/lib/site-packages/torch/_tensor.py?line=362'>363</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\Munzer Dwedari\\miniconda3\\envs\\adl4cv\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer%20Dwedari/miniconda3/envs/adl4cv/lib/site-packages/torch/autograd/__init__.py?line=167'>168</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer%20Dwedari/miniconda3/envs/adl4cv/lib/site-packages/torch/autograd/__init__.py?line=169'>170</a>\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer%20Dwedari/miniconda3/envs/adl4cv/lib/site-packages/torch/autograd/__init__.py?line=170'>171</a>\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer%20Dwedari/miniconda3/envs/adl4cv/lib/site-packages/torch/autograd/__init__.py?line=171'>172</a>\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Munzer%20Dwedari/miniconda3/envs/adl4cv/lib/site-packages/torch/autograd/__init__.py?line=172'>173</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer%20Dwedari/miniconda3/envs/adl4cv/lib/site-packages/torch/autograd/__init__.py?line=173'>174</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer%20Dwedari/miniconda3/envs/adl4cv/lib/site-packages/torch/autograd/__init__.py?line=174'>175</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# CHAIR\n",
    "from training import train\n",
    "config = {\n",
    "    'experiment_name': 'chair_ad',\n",
    "    'device': 'cuda:0',  # change this to cpu if you do not have a GPU\n",
    "    'is_overfit': False,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate_model': 0.01,\n",
    "    'learning_rate_code': 0.01,\n",
    "    'learning_rate_log_var':0.01,\n",
    "    'max_epochs': 500,\n",
    "    'print_every_n': 100,\n",
    "    'latent_code_length' : 256,\n",
    "    'scheduler_step_size': 100,\n",
    "    'vad_free' : True,\n",
    "    'test': False,\n",
    "    'kl_weight': 0.01,\n",
    "    'resume_ckpt': None,\n",
    "    'filter_class': 'chair',\n",
    "    'decoder_var' : False\n",
    "}\n",
    "train.main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOFA & CHAIR VAD\n",
    "from training import train\n",
    "config = {\n",
    "    'experiment_name': 'sofa_chair_vad',\n",
    "    'device': 'cuda:0',  # change this to cpu if you do not have a GPU\n",
    "    'is_overfit': False,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate_model': 0.01,\n",
    "    'learning_rate_code': 0.01,\n",
    "    'learning_rate_log_var':0.01,\n",
    "    'max_epochs': 500,\n",
    "    'print_every_n': 100,\n",
    "    'latent_code_length' : 256,\n",
    "    'scheduler_step_size': 100,\n",
    "    'vad_free' : True,\n",
    "    'test': False,\n",
    "    'kl_weight': 0.03,\n",
    "    'resume_ckpt': None,\n",
    "    'filter_class': 'sofa_chair',\n",
    "    'decoder_var' : True\n",
    "}\n",
    "train.main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Data length 3173\n",
      "Training params: 3\n",
      "[001/00049] train_loss: 0.158797 kl_loss: 0.485190 normal_loss: 0.144241\n",
      "[003/00049] train_loss: 0.103193 kl_loss: 0.413880 normal_loss: 0.090777\n",
      "[005/00049] train_loss: 0.092658 kl_loss: 0.348836 normal_loss: 0.082193\n",
      "[007/00049] train_loss: 0.089486 kl_loss: 0.300002 normal_loss: 0.080486\n",
      "[009/00049] train_loss: 0.084510 kl_loss: 0.266648 normal_loss: 0.076511\n",
      "[011/00049] train_loss: 0.080834 kl_loss: 0.244796 normal_loss: 0.073490\n",
      "[013/00049] train_loss: 0.075477 kl_loss: 0.232309 normal_loss: 0.068508\n",
      "[015/00049] train_loss: 0.072623 kl_loss: 0.224983 normal_loss: 0.065873\n",
      "[017/00049] train_loss: 0.070084 kl_loss: 0.216381 normal_loss: 0.063592\n",
      "[019/00049] train_loss: 0.068342 kl_loss: 0.208961 normal_loss: 0.062073\n",
      "[021/00049] train_loss: 0.065641 kl_loss: 0.202974 normal_loss: 0.059552\n",
      "[023/00049] train_loss: 0.062942 kl_loss: 0.197744 normal_loss: 0.057010\n",
      "[025/00049] train_loss: 0.061899 kl_loss: 0.192079 normal_loss: 0.056137\n",
      "[027/00049] train_loss: 0.059484 kl_loss: 0.187513 normal_loss: 0.053859\n",
      "[029/00049] train_loss: 0.058626 kl_loss: 0.183452 normal_loss: 0.053122\n",
      "[031/00049] train_loss: 0.058840 kl_loss: 0.180400 normal_loss: 0.053428\n",
      "[033/00049] train_loss: 0.057099 kl_loss: 0.178188 normal_loss: 0.051754\n",
      "[035/00049] train_loss: 0.055559 kl_loss: 0.176012 normal_loss: 0.050278\n",
      "[037/00049] train_loss: 0.053583 kl_loss: 0.174599 normal_loss: 0.048345\n",
      "[039/00049] train_loss: 0.054169 kl_loss: 0.173451 normal_loss: 0.048966\n",
      "[041/00049] train_loss: 0.052052 kl_loss: 0.172690 normal_loss: 0.046871\n",
      "[043/00049] train_loss: 0.052532 kl_loss: 0.171810 normal_loss: 0.047378\n",
      "[045/00049] train_loss: 0.050681 kl_loss: 0.170677 normal_loss: 0.045561\n",
      "[047/00049] train_loss: 0.049992 kl_loss: 0.170478 normal_loss: 0.044878\n",
      "[049/00049] train_loss: 0.049948 kl_loss: 0.170287 normal_loss: 0.044839\n",
      "[051/00049] train_loss: 0.048990 kl_loss: 0.170063 normal_loss: 0.043888\n",
      "[053/00049] train_loss: 0.048732 kl_loss: 0.169346 normal_loss: 0.043652\n",
      "[055/00049] train_loss: 0.048494 kl_loss: 0.169516 normal_loss: 0.043409\n",
      "[057/00049] train_loss: 0.047484 kl_loss: 0.169542 normal_loss: 0.042398\n",
      "[059/00049] train_loss: 0.045750 kl_loss: 0.169900 normal_loss: 0.040653\n",
      "[061/00049] train_loss: 0.046257 kl_loss: 0.170086 normal_loss: 0.041154\n",
      "[063/00049] train_loss: 0.045244 kl_loss: 0.170302 normal_loss: 0.040135\n",
      "[065/00049] train_loss: 0.045412 kl_loss: 0.170895 normal_loss: 0.040286\n",
      "[067/00049] train_loss: 0.044639 kl_loss: 0.171221 normal_loss: 0.039503\n",
      "[069/00049] train_loss: 0.044389 kl_loss: 0.171689 normal_loss: 0.039239\n",
      "[071/00049] train_loss: 0.044083 kl_loss: 0.171934 normal_loss: 0.038925\n",
      "[073/00049] train_loss: 0.043876 kl_loss: 0.173409 normal_loss: 0.038674\n",
      "[075/00049] train_loss: 0.042309 kl_loss: 0.174524 normal_loss: 0.037073\n",
      "[077/00049] train_loss: 0.042777 kl_loss: 0.175583 normal_loss: 0.037509\n",
      "[079/00049] train_loss: 0.042217 kl_loss: 0.176266 normal_loss: 0.036929\n",
      "[081/00049] train_loss: 0.041699 kl_loss: 0.177738 normal_loss: 0.036367\n",
      "[083/00049] train_loss: 0.041630 kl_loss: 0.179094 normal_loss: 0.036257\n",
      "[085/00049] train_loss: 0.040626 kl_loss: 0.180166 normal_loss: 0.035221\n",
      "[087/00049] train_loss: 0.040599 kl_loss: 0.181578 normal_loss: 0.035151\n",
      "[089/00049] train_loss: 0.040178 kl_loss: 0.182782 normal_loss: 0.034694\n",
      "[091/00049] train_loss: 0.039949 kl_loss: 0.184032 normal_loss: 0.034428\n",
      "[093/00049] train_loss: 0.039943 kl_loss: 0.184855 normal_loss: 0.034397\n",
      "[095/00049] train_loss: 0.039653 kl_loss: 0.185723 normal_loss: 0.034081\n",
      "[097/00049] train_loss: 0.039297 kl_loss: 0.186599 normal_loss: 0.033699\n",
      "[099/00049] train_loss: 0.039506 kl_loss: 0.188096 normal_loss: 0.033864\n",
      "[101/00049] train_loss: 0.035651 kl_loss: 0.188075 normal_loss: 0.030009\n",
      "[103/00049] train_loss: 0.035288 kl_loss: 0.186099 normal_loss: 0.029705\n",
      "[105/00049] train_loss: 0.034492 kl_loss: 0.184361 normal_loss: 0.028961\n",
      "[107/00049] train_loss: 0.034181 kl_loss: 0.182726 normal_loss: 0.028699\n",
      "[109/00049] train_loss: 0.034218 kl_loss: 0.181609 normal_loss: 0.028770\n",
      "[111/00049] train_loss: 0.033851 kl_loss: 0.180504 normal_loss: 0.028436\n",
      "[113/00049] train_loss: 0.033729 kl_loss: 0.179692 normal_loss: 0.028339\n",
      "[115/00049] train_loss: 0.033467 kl_loss: 0.178709 normal_loss: 0.028106\n",
      "[117/00049] train_loss: 0.033524 kl_loss: 0.177987 normal_loss: 0.028185\n",
      "[119/00049] train_loss: 0.033528 kl_loss: 0.177737 normal_loss: 0.028196\n",
      "[121/00049] train_loss: 0.033043 kl_loss: 0.177363 normal_loss: 0.027722\n",
      "[123/00049] train_loss: 0.032972 kl_loss: 0.177073 normal_loss: 0.027660\n",
      "[125/00049] train_loss: 0.032669 kl_loss: 0.176627 normal_loss: 0.027370\n",
      "[127/00049] train_loss: 0.032384 kl_loss: 0.176546 normal_loss: 0.027088\n",
      "[129/00049] train_loss: 0.032324 kl_loss: 0.176525 normal_loss: 0.027028\n",
      "[131/00049] train_loss: 0.032250 kl_loss: 0.176592 normal_loss: 0.026952\n",
      "[133/00049] train_loss: 0.032227 kl_loss: 0.176547 normal_loss: 0.026931\n",
      "[135/00049] train_loss: 0.031908 kl_loss: 0.176931 normal_loss: 0.026600\n",
      "[137/00049] train_loss: 0.032233 kl_loss: 0.177011 normal_loss: 0.026923\n",
      "[139/00049] train_loss: 0.032038 kl_loss: 0.177213 normal_loss: 0.026722\n",
      "[141/00049] train_loss: 0.031605 kl_loss: 0.177699 normal_loss: 0.026274\n",
      "[143/00049] train_loss: 0.031743 kl_loss: 0.177965 normal_loss: 0.026404\n",
      "[145/00049] train_loss: 0.031229 kl_loss: 0.178326 normal_loss: 0.025879\n",
      "[147/00049] train_loss: 0.031140 kl_loss: 0.178554 normal_loss: 0.025784\n",
      "[149/00049] train_loss: 0.030914 kl_loss: 0.179021 normal_loss: 0.025544\n",
      "[151/00049] train_loss: 0.030670 kl_loss: 0.179293 normal_loss: 0.025291\n",
      "[153/00049] train_loss: 0.030855 kl_loss: 0.179572 normal_loss: 0.025468\n",
      "[155/00049] train_loss: 0.030587 kl_loss: 0.179908 normal_loss: 0.025189\n",
      "[157/00049] train_loss: 0.029987 kl_loss: 0.180173 normal_loss: 0.024582\n",
      "[159/00049] train_loss: 0.030099 kl_loss: 0.180335 normal_loss: 0.024689\n",
      "[161/00049] train_loss: 0.030461 kl_loss: 0.180657 normal_loss: 0.025041\n",
      "[163/00049] train_loss: 0.030057 kl_loss: 0.181056 normal_loss: 0.024626\n",
      "[165/00049] train_loss: 0.029992 kl_loss: 0.181596 normal_loss: 0.024544\n",
      "[167/00049] train_loss: 0.029740 kl_loss: 0.181741 normal_loss: 0.024287\n",
      "[169/00049] train_loss: 0.029392 kl_loss: 0.181966 normal_loss: 0.023933\n",
      "[171/00049] train_loss: 0.029154 kl_loss: 0.182248 normal_loss: 0.023687\n",
      "[173/00049] train_loss: 0.029491 kl_loss: 0.182706 normal_loss: 0.024010\n",
      "[175/00049] train_loss: 0.029005 kl_loss: 0.182898 normal_loss: 0.023518\n",
      "[177/00049] train_loss: 0.028615 kl_loss: 0.183165 normal_loss: 0.023120\n",
      "[179/00049] train_loss: 0.028678 kl_loss: 0.183436 normal_loss: 0.023175\n",
      "[181/00049] train_loss: 0.028636 kl_loss: 0.183565 normal_loss: 0.023129\n",
      "[183/00049] train_loss: 0.028922 kl_loss: 0.183896 normal_loss: 0.023405\n",
      "[185/00049] train_loss: 0.028800 kl_loss: 0.184217 normal_loss: 0.023274\n",
      "[187/00049] train_loss: 0.028287 kl_loss: 0.184347 normal_loss: 0.022757\n",
      "[189/00049] train_loss: 0.028455 kl_loss: 0.184610 normal_loss: 0.022917\n",
      "[191/00049] train_loss: 0.028019 kl_loss: 0.184813 normal_loss: 0.022474\n",
      "[193/00049] train_loss: 0.027900 kl_loss: 0.184912 normal_loss: 0.022352\n",
      "[195/00049] train_loss: 0.027723 kl_loss: 0.185343 normal_loss: 0.022162\n",
      "[197/00049] train_loss: 0.027717 kl_loss: 0.185384 normal_loss: 0.022156\n",
      "[199/00049] train_loss: 0.027726 kl_loss: 0.185875 normal_loss: 0.022149\n",
      "[201/00049] train_loss: 0.026158 kl_loss: 0.185587 normal_loss: 0.020591\n",
      "[203/00049] train_loss: 0.025869 kl_loss: 0.185479 normal_loss: 0.020305\n",
      "[205/00049] train_loss: 0.025548 kl_loss: 0.184956 normal_loss: 0.019999\n",
      "[207/00049] train_loss: 0.025465 kl_loss: 0.184499 normal_loss: 0.019930\n",
      "[209/00049] train_loss: 0.025254 kl_loss: 0.184125 normal_loss: 0.019730\n",
      "[211/00049] train_loss: 0.025229 kl_loss: 0.183703 normal_loss: 0.019718\n",
      "[213/00049] train_loss: 0.025097 kl_loss: 0.183236 normal_loss: 0.019600\n",
      "[215/00049] train_loss: 0.024943 kl_loss: 0.182732 normal_loss: 0.019461\n",
      "[217/00049] train_loss: 0.025139 kl_loss: 0.182408 normal_loss: 0.019667\n",
      "[219/00049] train_loss: 0.025077 kl_loss: 0.182216 normal_loss: 0.019610\n",
      "[221/00049] train_loss: 0.025002 kl_loss: 0.181818 normal_loss: 0.019547\n",
      "[223/00049] train_loss: 0.024814 kl_loss: 0.181485 normal_loss: 0.019370\n",
      "[225/00049] train_loss: 0.024834 kl_loss: 0.181221 normal_loss: 0.019397\n",
      "[227/00049] train_loss: 0.024689 kl_loss: 0.180899 normal_loss: 0.019262\n",
      "[229/00049] train_loss: 0.024377 kl_loss: 0.180745 normal_loss: 0.018954\n",
      "[231/00049] train_loss: 0.024501 kl_loss: 0.180540 normal_loss: 0.019085\n",
      "[233/00049] train_loss: 0.024324 kl_loss: 0.180141 normal_loss: 0.018920\n",
      "[235/00049] train_loss: 0.024363 kl_loss: 0.179955 normal_loss: 0.018964\n",
      "[237/00049] train_loss: 0.024252 kl_loss: 0.179787 normal_loss: 0.018858\n",
      "[239/00049] train_loss: 0.024158 kl_loss: 0.179605 normal_loss: 0.018770\n",
      "[241/00049] train_loss: 0.024240 kl_loss: 0.179561 normal_loss: 0.018853\n",
      "[243/00049] train_loss: 0.024350 kl_loss: 0.179312 normal_loss: 0.018971\n",
      "[245/00049] train_loss: 0.024075 kl_loss: 0.179325 normal_loss: 0.018695\n",
      "[247/00049] train_loss: 0.024145 kl_loss: 0.179106 normal_loss: 0.018772\n",
      "[249/00049] train_loss: 0.023969 kl_loss: 0.178880 normal_loss: 0.018602\n",
      "[251/00049] train_loss: 0.024001 kl_loss: 0.178768 normal_loss: 0.018638\n",
      "[253/00049] train_loss: 0.023967 kl_loss: 0.178838 normal_loss: 0.018602\n",
      "[255/00049] train_loss: 0.023779 kl_loss: 0.178616 normal_loss: 0.018421\n",
      "[257/00049] train_loss: 0.023683 kl_loss: 0.178582 normal_loss: 0.018326\n",
      "[259/00049] train_loss: 0.023678 kl_loss: 0.178373 normal_loss: 0.018327\n",
      "[261/00049] train_loss: 0.023760 kl_loss: 0.178394 normal_loss: 0.018408\n",
      "[263/00049] train_loss: 0.023516 kl_loss: 0.178227 normal_loss: 0.018169\n",
      "[265/00049] train_loss: 0.023459 kl_loss: 0.178157 normal_loss: 0.018114\n",
      "[267/00049] train_loss: 0.023535 kl_loss: 0.178088 normal_loss: 0.018192\n",
      "[269/00049] train_loss: 0.023216 kl_loss: 0.178185 normal_loss: 0.017870\n",
      "[271/00049] train_loss: 0.023478 kl_loss: 0.178087 normal_loss: 0.018135\n",
      "[273/00049] train_loss: 0.023274 kl_loss: 0.178033 normal_loss: 0.017933\n",
      "[275/00049] train_loss: 0.023182 kl_loss: 0.177997 normal_loss: 0.017842\n",
      "[277/00049] train_loss: 0.023134 kl_loss: 0.177804 normal_loss: 0.017800\n",
      "[279/00049] train_loss: 0.023227 kl_loss: 0.177872 normal_loss: 0.017891\n",
      "[281/00049] train_loss: 0.023134 kl_loss: 0.177822 normal_loss: 0.017799\n",
      "[283/00049] train_loss: 0.022995 kl_loss: 0.177784 normal_loss: 0.017662\n",
      "[285/00049] train_loss: 0.022884 kl_loss: 0.177783 normal_loss: 0.017551\n",
      "[287/00049] train_loss: 0.023202 kl_loss: 0.177633 normal_loss: 0.017873\n",
      "[289/00049] train_loss: 0.023050 kl_loss: 0.177741 normal_loss: 0.017718\n",
      "[291/00049] train_loss: 0.022876 kl_loss: 0.177732 normal_loss: 0.017544\n",
      "[293/00049] train_loss: 0.022834 kl_loss: 0.177653 normal_loss: 0.017504\n",
      "[295/00049] train_loss: 0.022793 kl_loss: 0.177580 normal_loss: 0.017466\n",
      "[297/00049] train_loss: 0.022545 kl_loss: 0.177588 normal_loss: 0.017217\n",
      "[299/00049] train_loss: 0.022638 kl_loss: 0.177423 normal_loss: 0.017316\n",
      "[301/00049] train_loss: 0.022014 kl_loss: 0.177131 normal_loss: 0.016700\n",
      "[303/00049] train_loss: 0.021783 kl_loss: 0.177116 normal_loss: 0.016470\n",
      "[305/00049] train_loss: 0.021748 kl_loss: 0.176914 normal_loss: 0.016441\n",
      "[307/00049] train_loss: 0.021618 kl_loss: 0.176799 normal_loss: 0.016314\n",
      "[309/00049] train_loss: 0.021609 kl_loss: 0.176716 normal_loss: 0.016308\n",
      "[311/00049] train_loss: 0.021615 kl_loss: 0.176545 normal_loss: 0.016319\n",
      "[313/00049] train_loss: 0.021493 kl_loss: 0.176303 normal_loss: 0.016204\n",
      "[315/00049] train_loss: 0.021467 kl_loss: 0.176164 normal_loss: 0.016182\n",
      "[317/00049] train_loss: 0.021416 kl_loss: 0.175951 normal_loss: 0.016137\n",
      "[319/00049] train_loss: 0.021430 kl_loss: 0.175806 normal_loss: 0.016156\n",
      "[321/00049] train_loss: 0.021467 kl_loss: 0.175710 normal_loss: 0.016195\n",
      "[323/00049] train_loss: 0.021447 kl_loss: 0.175533 normal_loss: 0.016181\n",
      "[325/00049] train_loss: 0.021262 kl_loss: 0.175355 normal_loss: 0.016001\n",
      "[327/00049] train_loss: 0.021281 kl_loss: 0.175218 normal_loss: 0.016025\n",
      "[329/00049] train_loss: 0.021234 kl_loss: 0.174976 normal_loss: 0.015985\n",
      "[331/00049] train_loss: 0.021301 kl_loss: 0.174921 normal_loss: 0.016053\n",
      "[333/00049] train_loss: 0.021245 kl_loss: 0.174771 normal_loss: 0.016002\n",
      "[335/00049] train_loss: 0.021169 kl_loss: 0.174648 normal_loss: 0.015930\n",
      "[337/00049] train_loss: 0.021251 kl_loss: 0.174502 normal_loss: 0.016016\n",
      "[339/00049] train_loss: 0.021105 kl_loss: 0.174483 normal_loss: 0.015871\n",
      "[341/00049] train_loss: 0.021088 kl_loss: 0.174287 normal_loss: 0.015859\n",
      "[343/00049] train_loss: 0.021080 kl_loss: 0.174137 normal_loss: 0.015856\n",
      "[345/00049] train_loss: 0.021112 kl_loss: 0.174035 normal_loss: 0.015891\n",
      "[347/00049] train_loss: 0.021022 kl_loss: 0.173902 normal_loss: 0.015805\n",
      "[349/00049] train_loss: 0.021061 kl_loss: 0.173786 normal_loss: 0.015847\n",
      "[351/00049] train_loss: 0.020983 kl_loss: 0.173591 normal_loss: 0.015775\n",
      "[353/00049] train_loss: 0.020949 kl_loss: 0.173379 normal_loss: 0.015748\n",
      "[355/00049] train_loss: 0.020869 kl_loss: 0.173346 normal_loss: 0.015668\n",
      "[357/00049] train_loss: 0.020854 kl_loss: 0.173260 normal_loss: 0.015656\n",
      "[359/00049] train_loss: 0.020884 kl_loss: 0.173135 normal_loss: 0.015690\n",
      "[361/00049] train_loss: 0.020913 kl_loss: 0.173051 normal_loss: 0.015722\n",
      "[363/00049] train_loss: 0.020771 kl_loss: 0.172923 normal_loss: 0.015583\n",
      "[365/00049] train_loss: 0.020787 kl_loss: 0.172795 normal_loss: 0.015603\n",
      "[367/00049] train_loss: 0.020746 kl_loss: 0.172787 normal_loss: 0.015562\n",
      "[369/00049] train_loss: 0.020866 kl_loss: 0.172658 normal_loss: 0.015686\n",
      "[371/00049] train_loss: 0.020671 kl_loss: 0.172478 normal_loss: 0.015497\n",
      "[373/00049] train_loss: 0.020683 kl_loss: 0.172489 normal_loss: 0.015508\n",
      "[375/00049] train_loss: 0.020624 kl_loss: 0.172283 normal_loss: 0.015455\n",
      "[377/00049] train_loss: 0.020498 kl_loss: 0.172187 normal_loss: 0.015333\n",
      "[379/00049] train_loss: 0.020644 kl_loss: 0.172089 normal_loss: 0.015481\n",
      "[381/00049] train_loss: 0.020661 kl_loss: 0.171948 normal_loss: 0.015503\n",
      "[383/00049] train_loss: 0.020562 kl_loss: 0.171919 normal_loss: 0.015404\n",
      "[385/00049] train_loss: 0.020541 kl_loss: 0.171867 normal_loss: 0.015385\n",
      "[387/00049] train_loss: 0.020526 kl_loss: 0.171841 normal_loss: 0.015371\n",
      "[389/00049] train_loss: 0.020425 kl_loss: 0.171752 normal_loss: 0.015273\n",
      "[391/00049] train_loss: 0.020395 kl_loss: 0.171685 normal_loss: 0.015244\n",
      "[393/00049] train_loss: 0.020512 kl_loss: 0.171605 normal_loss: 0.015364\n",
      "[395/00049] train_loss: 0.020410 kl_loss: 0.171481 normal_loss: 0.015266\n",
      "[397/00049] train_loss: 0.020266 kl_loss: 0.171439 normal_loss: 0.015123\n",
      "[399/00049] train_loss: 0.020305 kl_loss: 0.171254 normal_loss: 0.015167\n",
      "[401/00049] train_loss: 0.020047 kl_loss: 0.171241 normal_loss: 0.014910\n",
      "[403/00049] train_loss: 0.020031 kl_loss: 0.171195 normal_loss: 0.014896\n",
      "[405/00049] train_loss: 0.019981 kl_loss: 0.171212 normal_loss: 0.014844\n",
      "[407/00049] train_loss: 0.019939 kl_loss: 0.171080 normal_loss: 0.014807\n",
      "[409/00049] train_loss: 0.019964 kl_loss: 0.170919 normal_loss: 0.014837\n",
      "[411/00049] train_loss: 0.019873 kl_loss: 0.170838 normal_loss: 0.014748\n",
      "[413/00049] train_loss: 0.019919 kl_loss: 0.170830 normal_loss: 0.014794\n",
      "[415/00049] train_loss: 0.019831 kl_loss: 0.170729 normal_loss: 0.014709\n",
      "[417/00049] train_loss: 0.019866 kl_loss: 0.170656 normal_loss: 0.014746\n",
      "[419/00049] train_loss: 0.019943 kl_loss: 0.170548 normal_loss: 0.014826\n",
      "[421/00049] train_loss: 0.019831 kl_loss: 0.170525 normal_loss: 0.014715\n",
      "[423/00049] train_loss: 0.019792 kl_loss: 0.170445 normal_loss: 0.014679\n",
      "[425/00049] train_loss: 0.019797 kl_loss: 0.170346 normal_loss: 0.014687\n",
      "[427/00049] train_loss: 0.019769 kl_loss: 0.170243 normal_loss: 0.014662\n",
      "[429/00049] train_loss: 0.019775 kl_loss: 0.170280 normal_loss: 0.014666\n",
      "[431/00049] train_loss: 0.019739 kl_loss: 0.170085 normal_loss: 0.014636\n",
      "[433/00049] train_loss: 0.019728 kl_loss: 0.170046 normal_loss: 0.014627\n",
      "[435/00049] train_loss: 0.019741 kl_loss: 0.170012 normal_loss: 0.014641\n",
      "[437/00049] train_loss: 0.019713 kl_loss: 0.169901 normal_loss: 0.014616\n",
      "[439/00049] train_loss: 0.019623 kl_loss: 0.169828 normal_loss: 0.014528\n",
      "[441/00049] train_loss: 0.019677 kl_loss: 0.169907 normal_loss: 0.014580\n",
      "[443/00049] train_loss: 0.019659 kl_loss: 0.169708 normal_loss: 0.014568\n",
      "[445/00049] train_loss: 0.019646 kl_loss: 0.169616 normal_loss: 0.014558\n",
      "[447/00049] train_loss: 0.019608 kl_loss: 0.169558 normal_loss: 0.014522\n",
      "[449/00049] train_loss: 0.019661 kl_loss: 0.169399 normal_loss: 0.014579\n",
      "[451/00049] train_loss: 0.019577 kl_loss: 0.169463 normal_loss: 0.014493\n",
      "[453/00049] train_loss: 0.019569 kl_loss: 0.169361 normal_loss: 0.014489\n",
      "[455/00049] train_loss: 0.019589 kl_loss: 0.169272 normal_loss: 0.014511\n",
      "[457/00049] train_loss: 0.019573 kl_loss: 0.169153 normal_loss: 0.014498\n",
      "[459/00049] train_loss: 0.019558 kl_loss: 0.169156 normal_loss: 0.014483\n",
      "[461/00049] train_loss: 0.019515 kl_loss: 0.169094 normal_loss: 0.014442\n",
      "[463/00049] train_loss: 0.019538 kl_loss: 0.168979 normal_loss: 0.014469\n",
      "[465/00049] train_loss: 0.019515 kl_loss: 0.168962 normal_loss: 0.014446\n",
      "[467/00049] train_loss: 0.019466 kl_loss: 0.168890 normal_loss: 0.014399\n",
      "[469/00049] train_loss: 0.019453 kl_loss: 0.168773 normal_loss: 0.014390\n",
      "[471/00049] train_loss: 0.019428 kl_loss: 0.168749 normal_loss: 0.014365\n",
      "[473/00049] train_loss: 0.019454 kl_loss: 0.168576 normal_loss: 0.014397\n",
      "[475/00049] train_loss: 0.019458 kl_loss: 0.168565 normal_loss: 0.014401\n",
      "[477/00049] train_loss: 0.019497 kl_loss: 0.168535 normal_loss: 0.014441\n",
      "[479/00049] train_loss: 0.019410 kl_loss: 0.168581 normal_loss: 0.014353\n",
      "[481/00049] train_loss: 0.019414 kl_loss: 0.168393 normal_loss: 0.014362\n",
      "[483/00049] train_loss: 0.019320 kl_loss: 0.168440 normal_loss: 0.014267\n",
      "[485/00049] train_loss: 0.019430 kl_loss: 0.168287 normal_loss: 0.014381\n",
      "[487/00049] train_loss: 0.019338 kl_loss: 0.168266 normal_loss: 0.014290\n",
      "[489/00049] train_loss: 0.019372 kl_loss: 0.168235 normal_loss: 0.014325\n",
      "[491/00049] train_loss: 0.019382 kl_loss: 0.168193 normal_loss: 0.014336\n",
      "[493/00049] train_loss: 0.019283 kl_loss: 0.168007 normal_loss: 0.014243\n",
      "[495/00049] train_loss: 0.019289 kl_loss: 0.167999 normal_loss: 0.014249\n",
      "[497/00049] train_loss: 0.019290 kl_loss: 0.167932 normal_loss: 0.014252\n",
      "[499/00049] train_loss: 0.019259 kl_loss: 0.167835 normal_loss: 0.014224\n"
     ]
    }
   ],
   "source": [
    "# SOFA VAD\n",
    "from training import train\n",
    "config = {\n",
    "    'experiment_name': 'sofa_vad_0_03kl',\n",
    "    'device': 'cuda:0',  # change this to cpu if you do not have a GPU\n",
    "    'is_overfit': False,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate_model': 0.01,\n",
    "    'learning_rate_code': 0.01,\n",
    "    'learning_rate_log_var':0.01,\n",
    "    'max_epochs': 500,\n",
    "    'print_every_n': 100,\n",
    "    'latent_code_length' : 256,\n",
    "    'scheduler_step_size': 100,\n",
    "    'vad_free' : True,\n",
    "    'test': False,\n",
    "    'kl_weight': 0.03,\n",
    "    'resume_ckpt': None,\n",
    "    'filter_class': 'sofa',\n",
    "    'decoder_var' : True\n",
    "}\n",
    "train.main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Data length 3173\n",
      "Training params: 2\n",
      "[001/00049] train_loss: 0.147046 kl_loss: 0.000000 normal_loss: 0.147046\n",
      "[003/00049] train_loss: 0.086997 kl_loss: 0.000000 normal_loss: 0.086997\n",
      "[005/00049] train_loss: 0.078271 kl_loss: 0.000000 normal_loss: 0.078271\n",
      "[007/00049] train_loss: 0.072125 kl_loss: 0.000000 normal_loss: 0.072125\n",
      "[009/00049] train_loss: 0.063552 kl_loss: 0.000000 normal_loss: 0.063552\n",
      "[011/00049] train_loss: 0.060275 kl_loss: 0.000000 normal_loss: 0.060275\n",
      "[013/00049] train_loss: 0.056823 kl_loss: 0.000000 normal_loss: 0.056823\n",
      "[015/00049] train_loss: 0.056097 kl_loss: 0.000000 normal_loss: 0.056097\n",
      "[017/00049] train_loss: 0.051553 kl_loss: 0.000000 normal_loss: 0.051553\n",
      "[019/00049] train_loss: 0.050349 kl_loss: 0.000000 normal_loss: 0.050349\n",
      "[021/00049] train_loss: 0.047069 kl_loss: 0.000000 normal_loss: 0.047069\n",
      "[023/00049] train_loss: 0.044120 kl_loss: 0.000000 normal_loss: 0.044120\n",
      "[025/00049] train_loss: 0.043236 kl_loss: 0.000000 normal_loss: 0.043236\n",
      "[027/00049] train_loss: 0.041510 kl_loss: 0.000000 normal_loss: 0.041510\n",
      "[029/00049] train_loss: 0.040672 kl_loss: 0.000000 normal_loss: 0.040672\n",
      "[031/00049] train_loss: 0.039042 kl_loss: 0.000000 normal_loss: 0.039042\n",
      "[033/00049] train_loss: 0.037533 kl_loss: 0.000000 normal_loss: 0.037533\n",
      "[035/00049] train_loss: 0.035808 kl_loss: 0.000000 normal_loss: 0.035808\n",
      "[037/00049] train_loss: 0.034947 kl_loss: 0.000000 normal_loss: 0.034947\n",
      "[039/00049] train_loss: 0.033185 kl_loss: 0.000000 normal_loss: 0.033185\n",
      "[041/00049] train_loss: 0.032495 kl_loss: 0.000000 normal_loss: 0.032495\n",
      "[043/00049] train_loss: 0.031494 kl_loss: 0.000000 normal_loss: 0.031494\n",
      "[045/00049] train_loss: 0.030708 kl_loss: 0.000000 normal_loss: 0.030708\n",
      "[047/00049] train_loss: 0.030595 kl_loss: 0.000000 normal_loss: 0.030595\n",
      "[049/00049] train_loss: 0.029956 kl_loss: 0.000000 normal_loss: 0.029956\n",
      "[051/00049] train_loss: 0.028813 kl_loss: 0.000000 normal_loss: 0.028813\n",
      "[053/00049] train_loss: 0.027714 kl_loss: 0.000000 normal_loss: 0.027714\n",
      "[055/00049] train_loss: 0.027332 kl_loss: 0.000000 normal_loss: 0.027332\n",
      "[057/00049] train_loss: 0.027308 kl_loss: 0.000000 normal_loss: 0.027308\n",
      "[059/00049] train_loss: 0.026427 kl_loss: 0.000000 normal_loss: 0.026427\n",
      "[061/00049] train_loss: 0.026049 kl_loss: 0.000000 normal_loss: 0.026049\n",
      "[063/00049] train_loss: 0.024755 kl_loss: 0.000000 normal_loss: 0.024755\n",
      "[065/00049] train_loss: 0.024271 kl_loss: 0.000000 normal_loss: 0.024271\n",
      "[067/00049] train_loss: 0.024266 kl_loss: 0.000000 normal_loss: 0.024266\n",
      "[069/00049] train_loss: 0.024478 kl_loss: 0.000000 normal_loss: 0.024478\n",
      "[071/00049] train_loss: 0.024100 kl_loss: 0.000000 normal_loss: 0.024100\n",
      "[073/00049] train_loss: 0.022835 kl_loss: 0.000000 normal_loss: 0.022835\n",
      "[075/00049] train_loss: 0.022686 kl_loss: 0.000000 normal_loss: 0.022686\n",
      "[077/00049] train_loss: 0.023004 kl_loss: 0.000000 normal_loss: 0.023004\n",
      "[079/00049] train_loss: 0.022281 kl_loss: 0.000000 normal_loss: 0.022281\n",
      "[081/00049] train_loss: 0.021605 kl_loss: 0.000000 normal_loss: 0.021605\n",
      "[083/00049] train_loss: 0.020298 kl_loss: 0.000000 normal_loss: 0.020298\n",
      "[085/00049] train_loss: 0.020655 kl_loss: 0.000000 normal_loss: 0.020655\n",
      "[087/00049] train_loss: 0.021509 kl_loss: 0.000000 normal_loss: 0.021509\n",
      "[089/00049] train_loss: 0.022649 kl_loss: 0.000000 normal_loss: 0.022649\n",
      "[091/00049] train_loss: 0.020297 kl_loss: 0.000000 normal_loss: 0.020297\n",
      "[093/00049] train_loss: 0.021210 kl_loss: 0.000000 normal_loss: 0.021210\n",
      "[095/00049] train_loss: 0.019058 kl_loss: 0.000000 normal_loss: 0.019058\n",
      "[097/00049] train_loss: 0.019488 kl_loss: 0.000000 normal_loss: 0.019488\n",
      "[099/00049] train_loss: 0.018620 kl_loss: 0.000000 normal_loss: 0.018620\n",
      "[101/00049] train_loss: 0.016498 kl_loss: 0.000000 normal_loss: 0.016498\n",
      "[103/00049] train_loss: 0.014815 kl_loss: 0.000000 normal_loss: 0.014815\n",
      "[105/00049] train_loss: 0.014853 kl_loss: 0.000000 normal_loss: 0.014853\n",
      "[107/00049] train_loss: 0.015392 kl_loss: 0.000000 normal_loss: 0.015392\n",
      "[109/00049] train_loss: 0.016997 kl_loss: 0.000000 normal_loss: 0.016997\n",
      "[111/00049] train_loss: 0.014858 kl_loss: 0.000000 normal_loss: 0.014858\n",
      "[113/00049] train_loss: 0.014544 kl_loss: 0.000000 normal_loss: 0.014544\n",
      "[115/00049] train_loss: 0.014657 kl_loss: 0.000000 normal_loss: 0.014657\n",
      "[117/00049] train_loss: 0.014345 kl_loss: 0.000000 normal_loss: 0.014345\n",
      "[119/00049] train_loss: 0.013949 kl_loss: 0.000000 normal_loss: 0.013949\n",
      "[121/00049] train_loss: 0.014472 kl_loss: 0.000000 normal_loss: 0.014472\n",
      "[123/00049] train_loss: 0.015266 kl_loss: 0.000000 normal_loss: 0.015266\n",
      "[125/00049] train_loss: 0.014614 kl_loss: 0.000000 normal_loss: 0.014614\n",
      "[127/00049] train_loss: 0.013951 kl_loss: 0.000000 normal_loss: 0.013951\n",
      "[129/00049] train_loss: 0.014564 kl_loss: 0.000000 normal_loss: 0.014564\n",
      "[131/00049] train_loss: 0.013915 kl_loss: 0.000000 normal_loss: 0.013915\n",
      "[133/00049] train_loss: 0.013754 kl_loss: 0.000000 normal_loss: 0.013754\n",
      "[135/00049] train_loss: 0.013780 kl_loss: 0.000000 normal_loss: 0.013780\n",
      "[137/00049] train_loss: 0.013444 kl_loss: 0.000000 normal_loss: 0.013444\n",
      "[139/00049] train_loss: 0.013381 kl_loss: 0.000000 normal_loss: 0.013381\n",
      "[141/00049] train_loss: 0.013236 kl_loss: 0.000000 normal_loss: 0.013236\n",
      "[143/00049] train_loss: 0.013419 kl_loss: 0.000000 normal_loss: 0.013419\n",
      "[145/00049] train_loss: 0.013631 kl_loss: 0.000000 normal_loss: 0.013631\n",
      "[147/00049] train_loss: 0.013256 kl_loss: 0.000000 normal_loss: 0.013256\n",
      "[149/00049] train_loss: 0.013501 kl_loss: 0.000000 normal_loss: 0.013501\n",
      "[151/00049] train_loss: 0.013316 kl_loss: 0.000000 normal_loss: 0.013316\n",
      "[153/00049] train_loss: 0.012754 kl_loss: 0.000000 normal_loss: 0.012754\n",
      "[155/00049] train_loss: 0.012450 kl_loss: 0.000000 normal_loss: 0.012450\n",
      "[157/00049] train_loss: 0.013149 kl_loss: 0.000000 normal_loss: 0.013149\n",
      "[159/00049] train_loss: 0.012789 kl_loss: 0.000000 normal_loss: 0.012789\n",
      "[161/00049] train_loss: 0.013052 kl_loss: 0.000000 normal_loss: 0.013052\n",
      "[163/00049] train_loss: 0.012452 kl_loss: 0.000000 normal_loss: 0.012452\n",
      "[165/00049] train_loss: 0.012844 kl_loss: 0.000000 normal_loss: 0.012844\n",
      "[167/00049] train_loss: 0.012598 kl_loss: 0.000000 normal_loss: 0.012598\n",
      "[169/00049] train_loss: 0.012433 kl_loss: 0.000000 normal_loss: 0.012433\n",
      "[171/00049] train_loss: 0.012264 kl_loss: 0.000000 normal_loss: 0.012264\n",
      "[173/00049] train_loss: 0.012649 kl_loss: 0.000000 normal_loss: 0.012649\n",
      "[175/00049] train_loss: 0.012375 kl_loss: 0.000000 normal_loss: 0.012375\n",
      "[177/00049] train_loss: 0.012224 kl_loss: 0.000000 normal_loss: 0.012224\n",
      "[179/00049] train_loss: 0.012347 kl_loss: 0.000000 normal_loss: 0.012347\n",
      "[181/00049] train_loss: 0.012235 kl_loss: 0.000000 normal_loss: 0.012235\n",
      "[183/00049] train_loss: 0.012057 kl_loss: 0.000000 normal_loss: 0.012057\n",
      "[185/00049] train_loss: 0.012528 kl_loss: 0.000000 normal_loss: 0.012528\n",
      "[187/00049] train_loss: 0.012125 kl_loss: 0.000000 normal_loss: 0.012125\n",
      "[189/00049] train_loss: 0.012086 kl_loss: 0.000000 normal_loss: 0.012086\n",
      "[191/00049] train_loss: 0.012190 kl_loss: 0.000000 normal_loss: 0.012190\n",
      "[193/00049] train_loss: 0.012084 kl_loss: 0.000000 normal_loss: 0.012084\n",
      "[195/00049] train_loss: 0.011601 kl_loss: 0.000000 normal_loss: 0.011601\n",
      "[197/00049] train_loss: 0.011606 kl_loss: 0.000000 normal_loss: 0.011606\n",
      "[199/00049] train_loss: 0.011835 kl_loss: 0.000000 normal_loss: 0.011835\n",
      "[201/00049] train_loss: 0.010245 kl_loss: 0.000000 normal_loss: 0.010245\n",
      "[203/00049] train_loss: 0.009693 kl_loss: 0.000000 normal_loss: 0.009693\n",
      "[205/00049] train_loss: 0.009638 kl_loss: 0.000000 normal_loss: 0.009638\n",
      "[207/00049] train_loss: 0.009711 kl_loss: 0.000000 normal_loss: 0.009711\n",
      "[209/00049] train_loss: 0.009666 kl_loss: 0.000000 normal_loss: 0.009666\n",
      "[211/00049] train_loss: 0.009929 kl_loss: 0.000000 normal_loss: 0.009929\n",
      "[213/00049] train_loss: 0.009723 kl_loss: 0.000000 normal_loss: 0.009723\n",
      "[215/00049] train_loss: 0.009604 kl_loss: 0.000000 normal_loss: 0.009604\n",
      "[217/00049] train_loss: 0.009741 kl_loss: 0.000000 normal_loss: 0.009741\n",
      "[219/00049] train_loss: 0.009573 kl_loss: 0.000000 normal_loss: 0.009573\n",
      "[221/00049] train_loss: 0.009610 kl_loss: 0.000000 normal_loss: 0.009610\n",
      "[223/00049] train_loss: 0.009645 kl_loss: 0.000000 normal_loss: 0.009645\n",
      "[225/00049] train_loss: 0.010178 kl_loss: 0.000000 normal_loss: 0.010178\n",
      "[227/00049] train_loss: 0.009635 kl_loss: 0.000000 normal_loss: 0.009635\n",
      "[229/00049] train_loss: 0.009561 kl_loss: 0.000000 normal_loss: 0.009561\n",
      "[231/00049] train_loss: 0.009556 kl_loss: 0.000000 normal_loss: 0.009556\n",
      "[233/00049] train_loss: 0.009592 kl_loss: 0.000000 normal_loss: 0.009592\n",
      "[235/00049] train_loss: 0.009393 kl_loss: 0.000000 normal_loss: 0.009393\n",
      "[237/00049] train_loss: 0.009423 kl_loss: 0.000000 normal_loss: 0.009423\n",
      "[239/00049] train_loss: 0.009530 kl_loss: 0.000000 normal_loss: 0.009530\n",
      "[241/00049] train_loss: 0.009409 kl_loss: 0.000000 normal_loss: 0.009409\n",
      "[243/00049] train_loss: 0.009378 kl_loss: 0.000000 normal_loss: 0.009378\n",
      "[245/00049] train_loss: 0.009269 kl_loss: 0.000000 normal_loss: 0.009269\n",
      "[247/00049] train_loss: 0.009874 kl_loss: 0.000000 normal_loss: 0.009874\n",
      "[249/00049] train_loss: 0.009428 kl_loss: 0.000000 normal_loss: 0.009428\n",
      "[251/00049] train_loss: 0.009331 kl_loss: 0.000000 normal_loss: 0.009331\n",
      "[253/00049] train_loss: 0.009261 kl_loss: 0.000000 normal_loss: 0.009261\n",
      "[255/00049] train_loss: 0.009186 kl_loss: 0.000000 normal_loss: 0.009186\n",
      "[257/00049] train_loss: 0.009217 kl_loss: 0.000000 normal_loss: 0.009217\n",
      "[259/00049] train_loss: 0.009274 kl_loss: 0.000000 normal_loss: 0.009274\n",
      "[261/00049] train_loss: 0.009253 kl_loss: 0.000000 normal_loss: 0.009253\n",
      "[263/00049] train_loss: 0.009154 kl_loss: 0.000000 normal_loss: 0.009154\n",
      "[265/00049] train_loss: 0.009312 kl_loss: 0.000000 normal_loss: 0.009312\n",
      "[267/00049] train_loss: 0.009182 kl_loss: 0.000000 normal_loss: 0.009182\n",
      "[269/00049] train_loss: 0.009103 kl_loss: 0.000000 normal_loss: 0.009103\n",
      "[271/00049] train_loss: 0.009021 kl_loss: 0.000000 normal_loss: 0.009021\n",
      "[273/00049] train_loss: 0.009119 kl_loss: 0.000000 normal_loss: 0.009119\n",
      "[275/00049] train_loss: 0.009051 kl_loss: 0.000000 normal_loss: 0.009051\n",
      "[277/00049] train_loss: 0.009004 kl_loss: 0.000000 normal_loss: 0.009004\n",
      "[279/00049] train_loss: 0.009004 kl_loss: 0.000000 normal_loss: 0.009004\n",
      "[281/00049] train_loss: 0.009110 kl_loss: 0.000000 normal_loss: 0.009110\n",
      "[283/00049] train_loss: 0.008988 kl_loss: 0.000000 normal_loss: 0.008988\n",
      "[285/00049] train_loss: 0.009043 kl_loss: 0.000000 normal_loss: 0.009043\n",
      "[287/00049] train_loss: 0.009085 kl_loss: 0.000000 normal_loss: 0.009085\n",
      "[289/00049] train_loss: 0.009061 kl_loss: 0.000000 normal_loss: 0.009061\n",
      "[291/00049] train_loss: 0.009048 kl_loss: 0.000000 normal_loss: 0.009048\n",
      "[293/00049] train_loss: 0.009074 kl_loss: 0.000000 normal_loss: 0.009074\n",
      "[295/00049] train_loss: 0.008822 kl_loss: 0.000000 normal_loss: 0.008822\n",
      "[297/00049] train_loss: 0.008993 kl_loss: 0.000000 normal_loss: 0.008993\n",
      "[299/00049] train_loss: 0.009084 kl_loss: 0.000000 normal_loss: 0.009084\n",
      "[301/00049] train_loss: 0.008269 kl_loss: 0.000000 normal_loss: 0.008269\n",
      "[303/00049] train_loss: 0.008235 kl_loss: 0.000000 normal_loss: 0.008235\n",
      "[305/00049] train_loss: 0.007957 kl_loss: 0.000000 normal_loss: 0.007957\n",
      "[307/00049] train_loss: 0.007999 kl_loss: 0.000000 normal_loss: 0.007999\n",
      "[309/00049] train_loss: 0.008008 kl_loss: 0.000000 normal_loss: 0.008008\n",
      "[311/00049] train_loss: 0.007940 kl_loss: 0.000000 normal_loss: 0.007940\n",
      "[313/00049] train_loss: 0.007987 kl_loss: 0.000000 normal_loss: 0.007987\n",
      "[315/00049] train_loss: 0.007912 kl_loss: 0.000000 normal_loss: 0.007912\n",
      "[317/00049] train_loss: 0.007917 kl_loss: 0.000000 normal_loss: 0.007917\n",
      "[319/00049] train_loss: 0.008026 kl_loss: 0.000000 normal_loss: 0.008026\n",
      "[321/00049] train_loss: 0.007986 kl_loss: 0.000000 normal_loss: 0.007986\n",
      "[323/00049] train_loss: 0.008022 kl_loss: 0.000000 normal_loss: 0.008022\n",
      "[325/00049] train_loss: 0.007902 kl_loss: 0.000000 normal_loss: 0.007902\n",
      "[327/00049] train_loss: 0.007901 kl_loss: 0.000000 normal_loss: 0.007901\n",
      "[329/00049] train_loss: 0.007892 kl_loss: 0.000000 normal_loss: 0.007892\n",
      "[331/00049] train_loss: 0.007906 kl_loss: 0.000000 normal_loss: 0.007906\n",
      "[333/00049] train_loss: 0.007951 kl_loss: 0.000000 normal_loss: 0.007951\n",
      "[335/00049] train_loss: 0.007999 kl_loss: 0.000000 normal_loss: 0.007999\n",
      "[337/00049] train_loss: 0.007971 kl_loss: 0.000000 normal_loss: 0.007971\n",
      "[339/00049] train_loss: 0.007929 kl_loss: 0.000000 normal_loss: 0.007929\n",
      "[341/00049] train_loss: 0.007864 kl_loss: 0.000000 normal_loss: 0.007864\n",
      "[343/00049] train_loss: 0.007930 kl_loss: 0.000000 normal_loss: 0.007930\n",
      "[345/00049] train_loss: 0.007838 kl_loss: 0.000000 normal_loss: 0.007838\n",
      "[347/00049] train_loss: 0.007828 kl_loss: 0.000000 normal_loss: 0.007828\n",
      "[349/00049] train_loss: 0.007752 kl_loss: 0.000000 normal_loss: 0.007752\n",
      "[351/00049] train_loss: 0.007833 kl_loss: 0.000000 normal_loss: 0.007833\n",
      "[353/00049] train_loss: 0.007786 kl_loss: 0.000000 normal_loss: 0.007786\n",
      "[355/00049] train_loss: 0.007723 kl_loss: 0.000000 normal_loss: 0.007723\n",
      "[357/00049] train_loss: 0.007965 kl_loss: 0.000000 normal_loss: 0.007965\n",
      "[359/00049] train_loss: 0.007852 kl_loss: 0.000000 normal_loss: 0.007852\n",
      "[361/00049] train_loss: 0.007754 kl_loss: 0.000000 normal_loss: 0.007754\n",
      "[363/00049] train_loss: 0.007941 kl_loss: 0.000000 normal_loss: 0.007941\n",
      "[365/00049] train_loss: 0.007849 kl_loss: 0.000000 normal_loss: 0.007849\n",
      "[367/00049] train_loss: 0.007733 kl_loss: 0.000000 normal_loss: 0.007733\n",
      "[369/00049] train_loss: 0.007711 kl_loss: 0.000000 normal_loss: 0.007711\n",
      "[371/00049] train_loss: 0.007828 kl_loss: 0.000000 normal_loss: 0.007828\n",
      "[373/00049] train_loss: 0.007737 kl_loss: 0.000000 normal_loss: 0.007737\n",
      "[375/00049] train_loss: 0.007653 kl_loss: 0.000000 normal_loss: 0.007653\n",
      "[377/00049] train_loss: 0.007701 kl_loss: 0.000000 normal_loss: 0.007701\n",
      "[379/00049] train_loss: 0.007686 kl_loss: 0.000000 normal_loss: 0.007686\n",
      "[381/00049] train_loss: 0.007610 kl_loss: 0.000000 normal_loss: 0.007610\n",
      "[383/00049] train_loss: 0.007665 kl_loss: 0.000000 normal_loss: 0.007665\n",
      "[385/00049] train_loss: 0.007645 kl_loss: 0.000000 normal_loss: 0.007645\n",
      "[387/00049] train_loss: 0.007624 kl_loss: 0.000000 normal_loss: 0.007624\n",
      "[389/00049] train_loss: 0.007573 kl_loss: 0.000000 normal_loss: 0.007573\n",
      "[391/00049] train_loss: 0.007549 kl_loss: 0.000000 normal_loss: 0.007549\n",
      "[393/00049] train_loss: 0.007596 kl_loss: 0.000000 normal_loss: 0.007596\n",
      "[395/00049] train_loss: 0.007568 kl_loss: 0.000000 normal_loss: 0.007568\n",
      "[397/00049] train_loss: 0.007679 kl_loss: 0.000000 normal_loss: 0.007679\n",
      "[399/00049] train_loss: 0.007571 kl_loss: 0.000000 normal_loss: 0.007571\n",
      "[401/00049] train_loss: 0.007387 kl_loss: 0.000000 normal_loss: 0.007387\n",
      "[403/00049] train_loss: 0.007264 kl_loss: 0.000000 normal_loss: 0.007264\n",
      "[405/00049] train_loss: 0.007265 kl_loss: 0.000000 normal_loss: 0.007265\n",
      "[407/00049] train_loss: 0.007248 kl_loss: 0.000000 normal_loss: 0.007248\n",
      "[409/00049] train_loss: 0.007270 kl_loss: 0.000000 normal_loss: 0.007270\n",
      "[411/00049] train_loss: 0.007240 kl_loss: 0.000000 normal_loss: 0.007240\n",
      "[413/00049] train_loss: 0.007286 kl_loss: 0.000000 normal_loss: 0.007286\n",
      "[415/00049] train_loss: 0.007280 kl_loss: 0.000000 normal_loss: 0.007280\n",
      "[417/00049] train_loss: 0.007265 kl_loss: 0.000000 normal_loss: 0.007265\n",
      "[419/00049] train_loss: 0.007276 kl_loss: 0.000000 normal_loss: 0.007276\n",
      "[421/00049] train_loss: 0.007284 kl_loss: 0.000000 normal_loss: 0.007284\n",
      "[423/00049] train_loss: 0.007252 kl_loss: 0.000000 normal_loss: 0.007252\n",
      "[425/00049] train_loss: 0.007216 kl_loss: 0.000000 normal_loss: 0.007216\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Munzer Dwedari\\Documents\\uni\\ADL4CV\\adl4cv-vad\\index.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Munzer%20Dwedari/Documents/uni/ADL4CV/adl4cv-vad/index.ipynb#ch0000006?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtraining\u001b[39;00m \u001b[39mimport\u001b[39;00m train\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Munzer%20Dwedari/Documents/uni/ADL4CV/adl4cv-vad/index.ipynb#ch0000006?line=2'>3</a>\u001b[0m config \u001b[39m=\u001b[39m {\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Munzer%20Dwedari/Documents/uni/ADL4CV/adl4cv-vad/index.ipynb#ch0000006?line=3'>4</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mexperiment_name\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39msofa_ad\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Munzer%20Dwedari/Documents/uni/ADL4CV/adl4cv-vad/index.ipynb#ch0000006?line=4'>5</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m'\u001b[39m,  \u001b[39m# change this to cpu if you do not have a GPU\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Munzer%20Dwedari/Documents/uni/ADL4CV/adl4cv-vad/index.ipynb#ch0000006?line=19'>20</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mdecoder_var\u001b[39m\u001b[39m'\u001b[39m : \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Munzer%20Dwedari/Documents/uni/ADL4CV/adl4cv-vad/index.ipynb#ch0000006?line=20'>21</a>\u001b[0m }\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Munzer%20Dwedari/Documents/uni/ADL4CV/adl4cv-vad/index.ipynb#ch0000006?line=21'>22</a>\u001b[0m train\u001b[39m.\u001b[39;49mmain(config)\n",
      "File \u001b[1;32mc:\\Users\\Munzer Dwedari\\Documents\\uni\\ADL4CV\\adl4cv-vad\\training\\train.py:186\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer%20Dwedari/Documents/uni/ADL4CV/adl4cv-vad/training/train.py?line=182'>183</a>\u001b[0m     json\u001b[39m.\u001b[39mdump(config, f)\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer%20Dwedari/Documents/uni/ADL4CV/adl4cv-vad/training/train.py?line=184'>185</a>\u001b[0m \u001b[39m# Start training\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Munzer%20Dwedari/Documents/uni/ADL4CV/adl4cv-vad/training/train.py?line=185'>186</a>\u001b[0m train(model, train_dataloader, latent_vectors, latent_log_var, device, config)\n",
      "File \u001b[1;32mc:\\Users\\Munzer Dwedari\\Documents\\uni\\ADL4CV\\adl4cv-vad\\training\\train.py:98\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_dataloader, latent_vectors, latent_log_var, device, config)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Munzer%20Dwedari/Documents/uni/ADL4CV/adl4cv-vad/training/train.py?line=95'>96</a>\u001b[0m     loss \u001b[39m=\u001b[39m reconstruction_loss\n\u001b[0;32m     <a href='file:///c%3A/Users/Munzer%20Dwedari/Documents/uni/ADL4CV/adl4cv-vad/training/train.py?line=96'>97</a>\u001b[0m \u001b[39m# Compute gradients\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/Users/Munzer%20Dwedari/Documents/uni/ADL4CV/adl4cv-vad/training/train.py?line=97'>98</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer%20Dwedari/Documents/uni/ADL4CV/adl4cv-vad/training/train.py?line=99'>100</a>\u001b[0m \u001b[39m# Update network parameters\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer%20Dwedari/Documents/uni/ADL4CV/adl4cv-vad/training/train.py?line=100'>101</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\Munzer Dwedari\\miniconda3\\envs\\adl4cv\\lib\\site-packages\\torch\\_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer%20Dwedari/miniconda3/envs/adl4cv/lib/site-packages/torch/_tensor.py?line=353'>354</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer%20Dwedari/miniconda3/envs/adl4cv/lib/site-packages/torch/_tensor.py?line=354'>355</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer%20Dwedari/miniconda3/envs/adl4cv/lib/site-packages/torch/_tensor.py?line=355'>356</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer%20Dwedari/miniconda3/envs/adl4cv/lib/site-packages/torch/_tensor.py?line=356'>357</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer%20Dwedari/miniconda3/envs/adl4cv/lib/site-packages/torch/_tensor.py?line=360'>361</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer%20Dwedari/miniconda3/envs/adl4cv/lib/site-packages/torch/_tensor.py?line=361'>362</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Munzer%20Dwedari/miniconda3/envs/adl4cv/lib/site-packages/torch/_tensor.py?line=362'>363</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\Munzer Dwedari\\miniconda3\\envs\\adl4cv\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer%20Dwedari/miniconda3/envs/adl4cv/lib/site-packages/torch/autograd/__init__.py?line=167'>168</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer%20Dwedari/miniconda3/envs/adl4cv/lib/site-packages/torch/autograd/__init__.py?line=169'>170</a>\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer%20Dwedari/miniconda3/envs/adl4cv/lib/site-packages/torch/autograd/__init__.py?line=170'>171</a>\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer%20Dwedari/miniconda3/envs/adl4cv/lib/site-packages/torch/autograd/__init__.py?line=171'>172</a>\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Munzer%20Dwedari/miniconda3/envs/adl4cv/lib/site-packages/torch/autograd/__init__.py?line=172'>173</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer%20Dwedari/miniconda3/envs/adl4cv/lib/site-packages/torch/autograd/__init__.py?line=173'>174</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    <a href='file:///c%3A/Users/Munzer%20Dwedari/miniconda3/envs/adl4cv/lib/site-packages/torch/autograd/__init__.py?line=174'>175</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# SOFA AD\n",
    "from training import train\n",
    "config = {\n",
    "    'experiment_name': 'sofa_ad',\n",
    "    'device': 'cuda:0',  # change this to cpu if you do not have a GPU\n",
    "    'is_overfit': False,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate_model': 0.01,\n",
    "    'learning_rate_code': 0.01,\n",
    "    'learning_rate_log_var':0.01,\n",
    "    'max_epochs': 500,\n",
    "    'print_every_n': 100,\n",
    "    'latent_code_length' : 256,\n",
    "    'scheduler_step_size': 100,\n",
    "    'vad_free' : True,\n",
    "    'test': False,\n",
    "    'kl_weight': 0.01,\n",
    "    'resume_ckpt': None,\n",
    "    'filter_class': 'sofa',\n",
    "    'decoder_var' : False\n",
    "}\n",
    "train.main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "#                   #\n",
    "#    VISUALIZING    #\n",
    "#                   #\n",
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.threedepn import ThreeDEPNDecoder\n",
    "from util.visualization import visualize_mesh\n",
    "from skimage.measure import marching_cubes\n",
    "import torch.distributions as dist\n",
    "import torch\n",
    "\n",
    "def visualize_dataset_sample(filter_class, index):\n",
    "    dataset = ShapeNet('train', filter_class = filter_class)\n",
    "    sample = dataset[index]\n",
    "    input_mesh = marching_cubes(sample['target_df'], level=1)\n",
    "    visualize_mesh(input_mesh[0], input_mesh[1], flip_axes=True)\n",
    "\n",
    "def visualize_ad(experiment, index):\n",
    "    # Load model\n",
    "    model = ThreeDEPNDecoder()\n",
    "    model.load_state_dict(torch.load(f\"runs/{experiment}/model_best.ckpt\", map_location='cpu'))\n",
    "    # Load latent codes\n",
    "    latent_vectors = torch.load(f\"runs/{experiment}/latent_best.pt\", map_location = 'cpu')\n",
    "    # Sample\n",
    "    x = latent_vectors[index].unsqueeze(0)\n",
    "    # Forward pass\n",
    "    output_meshes_int = model(x)\n",
    "    # Visualize\n",
    "    output_mesh_int = marching_cubes(output_meshes_int[0].detach().numpy(), level=1)\n",
    "    visualize_mesh(output_mesh_int[0], output_mesh_int[1], flip_axes=True)\n",
    "\n",
    "def visualize_vad(experiment, index):\n",
    "    # Load model\n",
    "    model = ThreeDEPNDecoder()\n",
    "    model.load_state_dict(torch.load(f\"runs/{experiment}/model_best.ckpt\", map_location='cpu'))\n",
    "    # Load latent codes\n",
    "    latent_vectors = torch.load(f\"runs/{experiment}/latent_best.pt\", map_location = 'cpu')\n",
    "    log_vars = torch.load(f\"runs/{experiment}/latent_best.pt\", map_location = 'cpu')\n",
    "    # Sample\n",
    "    x = latent_vectors[index]\n",
    "    Dist = dist.Normal(x, torch.exp(log_vars[index]))\n",
    "    x_vad = Dist.rsample().unsqueeze(0)\n",
    "    # Forward pass\n",
    "    output_meshes_int = model(x_vad)\n",
    "    # Visualize\n",
    "    output_mesh_int = marching_cubes(output_meshes_int[0].detach().numpy(), level=1)\n",
    "    visualize_mesh(output_mesh_int[0], output_mesh_int[1], flip_axes=True)\n",
    "\n",
    "def visualize_vad_norm(experiment):\n",
    "    # Load model\n",
    "    model = ThreeDEPNDecoder()\n",
    "    model.load_state_dict(torch.load(f\"runs/{experiment}/model_best.ckpt\", map_location='cpu'))\n",
    "    # Sample\n",
    "    # Dist = dist.Normal(torch.zeros(256), torch.ones(256))\n",
    "    x_vad = torch.randn(256).unsqueeze(0)\n",
    "    # Forward pass\n",
    "    output_meshes_int = model(x_vad)\n",
    "    # Visualize\n",
    "    output_mesh_int = marching_cubes(output_meshes_int[0].detach().numpy(), level=1)\n",
    "    visualize_mesh(output_mesh_int[0], output_mesh_int[1], flip_axes=True)\n",
    "\n",
    "def visualize_interpolation_ad(experiment, index1, index2, a1=0.5, a2=0.5):\n",
    "    # Load model\n",
    "    model = ThreeDEPNDecoder()\n",
    "    model.load_state_dict(torch.load(f\"runs/{experiment}/model_best.ckpt\", map_location='cpu'))\n",
    "    # Load latent codes\n",
    "    latent_vectors = torch.load(f\"runs/{experiment}/latent_best.pt\", map_location = 'cpu')\n",
    "    # Sample\n",
    "    x1 = latent_vectors[index1]\n",
    "    x2 = latent_vectors[index2]\n",
    "    x = (a1*x1 + a2*x2).unsqueeze(0)\n",
    "    # Forward pass\n",
    "    output_meshes_int = model(x)\n",
    "    # Visualize\n",
    "    output_mesh_int = marching_cubes(output_meshes_int[0].detach().numpy(), level=1)\n",
    "    visualize_mesh(output_mesh_int[0], output_mesh_int[1], flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61bb6b1aa4a14f818deca0329423f070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a9d7eed17774346882716e18206d5ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 0\n",
    "index1 = 15\n",
    "index2 = 2334\n",
    "a1 = 0.5\n",
    "a2 = 1 - a1\n",
    "# experiment = \"sofa_ad\"\n",
    "# filter_class = \"sofa\"\n",
    "experiment = \"sofa_vad_0_03kl\"\n",
    "experiment2 = \"sofa_ad\"\n",
    "filter_class = \"sofa\"\n",
    "visualize_vad_norm(experiment)\n",
    "visualize_vad_norm(experiment2)\n",
    "#-------\n",
    "# visualize_vad(experiment, index)\n",
    "# visualize_ad(experiment, index)\n",
    "# visualize_dataset_sample(filter_class, index)\n",
    "#-------\n",
    "# visualize_interpolation_ad(\"chair_ad\", index1, index2, a1, a2)\n",
    "# visualize_ad(experiment, index1)\n",
    "# visualize_ad(experiment, index2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00862b34921449e983f816a3f5dffb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc318834a3ea4d7e8763838ee854af57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e6e37737e142a18ba21a339a0c4f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from model.threedepn import ThreeDEPNDecoder\n",
    "from util.visualization import visualize_mesh\n",
    "from skimage.measure import marching_cubes\n",
    "import torch.distributions as dist\n",
    "import torch\n",
    "\n",
    "# load model\n",
    "name_temp = 'sofa_ad'\n",
    "model = ThreeDEPNDecoder()\n",
    "model.load_state_dict(torch.load(f\"runs/{name_temp}/model_best.ckpt\", map_location='cpu'))\n",
    "latent_vectors = torch.load(f\"runs/{name_temp}/latent_best.pt\", map_location = 'cpu')\n",
    "log_vars = torch.load(f\"runs/{name_temp}/log_var_best.pt\", map_location = 'cpu')\n",
    "Dist = dist.Normal(latent_vectors[1002], torch.exp(log_vars[1002]))\n",
    "Dist2 = dist.Normal(latent_vectors[1000], torch.exp(log_vars[1000]))\n",
    "#x_vad_n = torch.randn(256, device='cpu')\n",
    "x_vad = Dist.rsample()#.unsqueeze(0)\n",
    "x_vad2 = Dist2.rsample()#.unsqueeze(0)\n",
    "\n",
    "a1 = 0.5\n",
    "a2 = 0.5\n",
    "f1 = 5\n",
    "f2 = 105\n",
    "output_meshes_int = model((x_vad*a1 + x_vad2*a2).unsqueeze(0))\n",
    "output_mesh_int = marching_cubes(output_meshes_int[0].detach().numpy(), level=1)\n",
    "visualize_mesh(output_mesh_int[0], output_mesh_int[1], flip_axes=True)\n",
    "\n",
    "output_meshes = model(x_vad.unsqueeze(0))\n",
    "output_mesh = marching_cubes(output_meshes[0].detach().numpy(), level=1)\n",
    "visualize_mesh(output_mesh[0], output_mesh[1], flip_axes=True)\n",
    "\n",
    "output_meshes = model(x_vad2.unsqueeze(0))\n",
    "output_mesh = marching_cubes(output_meshes[0].detach().numpy(), level=1)\n",
    "visualize_mesh(output_mesh[0], output_mesh[1], flip_axes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target DF: (32, 32, 32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca351708eaa4addbfc5b3ae6957994c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7d6af7f7ae4b758d8db8fa80246362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c37264fb2946c5989b9589d5329c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c0b1f2ca8f437286882ddd1b59d2b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from model.threedepn import ThreeDEPNDecoder\n",
    "from util.visualization import visualize_mesh\n",
    "from skimage.measure import marching_cubes\n",
    "import torch.distributions as dist\n",
    "import torch\n",
    "from util.visualization import visualize_mesh\n",
    "from skimage.measure import marching_cubes\n",
    "\n",
    "sample = train_dataset[5]\n",
    "print(f'Target DF: {sample[\"target_df\"].shape}')  # expected output: (32, 32, 32)\n",
    "\n",
    "input_mesh = marching_cubes(sample['target_df'], level=1)\n",
    "visualize_mesh(input_mesh[0], input_mesh[1], flip_axes=True)\n",
    "# load model\n",
    "name_temp = 'generalization_airplane_no_vad'\n",
    "model = ThreeDEPNDecoder()\n",
    "model.load_state_dict(torch.load(f\"runs/{name_temp}/model_best.ckpt\", map_location='cpu'))\n",
    "\n",
    "# load latent codes and latent variances\n",
    "latent_vectors = torch.load(f\"runs/{name_temp}/latent_best.pt\", map_location = 'cpu')\n",
    "log_vars = torch.load(f\"runs/{name_temp}/log_var_best.pt\", map_location = 'cpu')\n",
    "\n",
    "x_vad_n = x_vad_n.unsqueeze(0)\n",
    "output_meshes = model(latent_vectors[5].unsqueeze(0))\n",
    "\n",
    "# Visualize\n",
    "output_mesh = marching_cubes(output_meshes[0].detach().numpy(), level=1)\n",
    "visualize_mesh(output_mesh[0], output_mesh[1], flip_axes=True)\n",
    "\n",
    "output_meshes = model(latent_vectors[105].unsqueeze(0))\n",
    "\n",
    "# Visualize\n",
    "output_mesh = marching_cubes(output_meshes[0].detach().numpy(), level=1)\n",
    "visualize_mesh(output_mesh[0], output_mesh[1], flip_axes=True)\n",
    "a1 = 0.5\n",
    "a2 = 0.5\n",
    "f1 = 5\n",
    "f2 = 105\n",
    "output_meshes_int = model((latent_vectors[f1]*a1 + latent_vectors[f2]*a2).unsqueeze(0))\n",
    "output_mesh_int = marching_cubes(output_meshes_int[0].detach().numpy(), level=1)\n",
    "visualize_mesh(output_mesh_int[0], output_mesh_int[1], flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "62a9db08bae3858a47e0749c92dd3faa3fcc5b478149a89cc50b2ccab095deb2"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('adl4cv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

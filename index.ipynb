{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | Name         | Type             | Params  \n",
      "-----------------------------------------------------\n",
      "0  | bottleneck   | Sequential       | 197376  \n",
      "1  | bottleneck.0 | Linear           | 65792   \n",
      "2  | bottleneck.1 | ReLU             | 0       \n",
      "3  | bottleneck.2 | Linear           | 131584  \n",
      "4  | bottleneck.3 | ReLU             | 0       \n",
      "5  | decoder1     | Sequential       | 8389376 \n",
      "6  | decoder1.0   | ConvTranspose3d  | 8388864 \n",
      "7  | decoder1.1   | BatchNorm3d      | 512     \n",
      "8  | decoder1.2   | ReLU             | 0       \n",
      "9  | decoder2     | Sequential       | 2097536 \n",
      "10 | decoder2.0   | ConvTranspose3d  | 2097280 \n",
      "11 | decoder2.1   | BatchNorm3d      | 256     \n",
      "12 | decoder2.2   | ReLU             | 0       \n",
      "13 | decoder3     | Sequential       | 524480  \n",
      "14 | decoder3.0   | ConvTranspose3d  | 524352  \n",
      "15 | decoder3.1   | BatchNorm3d      | 128     \n",
      "16 | decoder3.2   | ReLU             | 0       \n",
      "17 | decoder4     | Sequential       | 4097    \n",
      "18 | decoder4.0   | ConvTranspose3d  | 4097    \n",
      "19 | TOTAL        | ThreeDEPNDecoder | 11212865\n"
     ]
    }
   ],
   "source": [
    "from model.threedepn import ThreeDEPNDecoder\n",
    "from util.model import summarize_model\n",
    "\n",
    "threedepn = ThreeDEPNDecoder()\n",
    "print(summarize_model(threedepn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train set: 1854\n",
      "Length of val set: 232\n",
      "Length of test set: 232\n"
     ]
    }
   ],
   "source": [
    "from data.shapenet import ShapeNet\n",
    "\n",
    "# Create a dataset with train split\n",
    "train_dataset = ShapeNet('train', filter_class='lamp')\n",
    "val_dataset = ShapeNet('val', filter_class='lamp')\n",
    "test_dataset = ShapeNet('test', filter_class='lamp')\n",
    "\n",
    "print(f'Length of train set: {len(train_dataset)}')  # expected output: 153540\n",
    "print(f'Length of val set: {len(val_dataset)}')  # expected output: 153540\n",
    "print(f'Length of test set: {len(test_dataset)}')  # expected output: 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target DF: (32, 32, 32)\n",
      "Target DF: <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be8986754fb4504b13533f665f03a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from util.visualization import visualize_mesh\n",
    "from skimage.measure import marching_cubes\n",
    "\n",
    "sample = test_dataset[231]\n",
    "print(f'Target DF: {sample[\"target_df\"].shape}')  # expected output: (32, 32, 32)\n",
    "print(f'Target DF: {type(sample[\"target_df\"])}')  # expected output: <class 'numpy.ndarray'>\n",
    "\n",
    "input_mesh = marching_cubes(sample['target_df'], level=1)\n",
    "visualize_mesh(input_mesh[0], input_mesh[1], flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "#                #\n",
    "#    TRAINING    #\n",
    "#                #\n",
    "##################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Data length 3236\n",
      "Training params: 2\n",
      "[001/00048] train_loss: 0.106201 kl_loss: 0.000000 normal_loss: 0.106201\n",
      "[003/00046] train_loss: 0.042423 kl_loss: 0.000000 normal_loss: 0.042423\n",
      "[005/00044] train_loss: 0.035614 kl_loss: 0.000000 normal_loss: 0.035614\n",
      "[007/00042] train_loss: 0.031330 kl_loss: 0.000000 normal_loss: 0.031330\n",
      "[009/00040] train_loss: 0.029408 kl_loss: 0.000000 normal_loss: 0.029408\n",
      "[011/00038] train_loss: 0.028273 kl_loss: 0.000000 normal_loss: 0.028273\n",
      "[013/00036] train_loss: 0.025522 kl_loss: 0.000000 normal_loss: 0.025522\n",
      "[015/00034] train_loss: 0.024653 kl_loss: 0.000000 normal_loss: 0.024653\n",
      "[017/00032] train_loss: 0.025657 kl_loss: 0.000000 normal_loss: 0.025657\n",
      "[019/00030] train_loss: 0.022715 kl_loss: 0.000000 normal_loss: 0.022715\n",
      "[021/00028] train_loss: 0.021348 kl_loss: 0.000000 normal_loss: 0.021348\n",
      "[023/00026] train_loss: 0.020369 kl_loss: 0.000000 normal_loss: 0.020369\n",
      "[025/00024] train_loss: 0.024364 kl_loss: 0.000000 normal_loss: 0.024364\n",
      "[027/00022] train_loss: 0.022951 kl_loss: 0.000000 normal_loss: 0.022951\n",
      "[029/00020] train_loss: 0.021597 kl_loss: 0.000000 normal_loss: 0.021597\n",
      "[031/00018] train_loss: 0.020342 kl_loss: 0.000000 normal_loss: 0.020342\n",
      "[033/00016] train_loss: 0.019189 kl_loss: 0.000000 normal_loss: 0.019189\n",
      "[035/00014] train_loss: 0.018313 kl_loss: 0.000000 normal_loss: 0.018313\n",
      "[037/00012] train_loss: 0.017717 kl_loss: 0.000000 normal_loss: 0.017717\n",
      "[039/00010] train_loss: 0.017121 kl_loss: 0.000000 normal_loss: 0.017121\n",
      "[041/00008] train_loss: 0.016550 kl_loss: 0.000000 normal_loss: 0.016550\n",
      "[043/00006] train_loss: 0.016037 kl_loss: 0.000000 normal_loss: 0.016037\n",
      "[045/00004] train_loss: 0.014177 kl_loss: 0.000000 normal_loss: 0.014177\n",
      "[047/00002] train_loss: 0.015520 kl_loss: 0.000000 normal_loss: 0.015520\n",
      "[049/00000] train_loss: 0.015192 kl_loss: 0.000000 normal_loss: 0.015192\n",
      "[049/00050] IOU 0.8063006274567914\n",
      "[050/00049] train_loss: 0.014601 kl_loss: 0.000000 normal_loss: 0.014601\n",
      "[052/00047] train_loss: 0.014220 kl_loss: 0.000000 normal_loss: 0.014220\n",
      "[054/00045] train_loss: 0.013703 kl_loss: 0.000000 normal_loss: 0.013703\n",
      "[056/00043] train_loss: 0.013695 kl_loss: 0.000000 normal_loss: 0.013695\n",
      "[058/00041] train_loss: 0.012883 kl_loss: 0.000000 normal_loss: 0.012883\n",
      "[060/00039] train_loss: 0.012819 kl_loss: 0.000000 normal_loss: 0.012819\n",
      "[062/00037] train_loss: 0.012836 kl_loss: 0.000000 normal_loss: 0.012836\n",
      "[064/00035] train_loss: 0.012791 kl_loss: 0.000000 normal_loss: 0.012791\n",
      "[066/00033] train_loss: 0.012476 kl_loss: 0.000000 normal_loss: 0.012476\n",
      "[068/00031] train_loss: 0.012316 kl_loss: 0.000000 normal_loss: 0.012316\n",
      "[070/00029] train_loss: 0.011803 kl_loss: 0.000000 normal_loss: 0.011803\n",
      "[072/00027] train_loss: 0.011014 kl_loss: 0.000000 normal_loss: 0.011014\n",
      "[074/00025] train_loss: 0.011772 kl_loss: 0.000000 normal_loss: 0.011772\n",
      "[076/00023] train_loss: 0.011582 kl_loss: 0.000000 normal_loss: 0.011582\n",
      "[078/00021] train_loss: 0.011229 kl_loss: 0.000000 normal_loss: 0.011229\n",
      "[080/00019] train_loss: 0.011229 kl_loss: 0.000000 normal_loss: 0.011229\n",
      "[082/00017] train_loss: 0.010978 kl_loss: 0.000000 normal_loss: 0.010978\n",
      "[084/00015] train_loss: 0.010512 kl_loss: 0.000000 normal_loss: 0.010512\n",
      "[086/00013] train_loss: 0.010199 kl_loss: 0.000000 normal_loss: 0.010199\n",
      "[088/00011] train_loss: 0.010301 kl_loss: 0.000000 normal_loss: 0.010301\n",
      "[090/00009] train_loss: 0.010272 kl_loss: 0.000000 normal_loss: 0.010272\n",
      "[092/00007] train_loss: 0.010392 kl_loss: 0.000000 normal_loss: 0.010392\n",
      "[094/00005] train_loss: 0.010156 kl_loss: 0.000000 normal_loss: 0.010156\n",
      "[096/00003] train_loss: 0.010084 kl_loss: 0.000000 normal_loss: 0.010084\n",
      "[098/00001] train_loss: 0.009890 kl_loss: 0.000000 normal_loss: 0.009890\n",
      "[099/00050] train_loss: 0.009625 kl_loss: 0.000000 normal_loss: 0.009625\n",
      "[099/00050] IOU 0.8885892022341232\n",
      "[101/00048] train_loss: 0.006687 kl_loss: 0.000000 normal_loss: 0.006687\n",
      "[103/00046] train_loss: 0.006355 kl_loss: 0.000000 normal_loss: 0.006355\n",
      "[105/00044] train_loss: 0.006316 kl_loss: 0.000000 normal_loss: 0.006316\n",
      "[107/00042] train_loss: 0.006515 kl_loss: 0.000000 normal_loss: 0.006515\n",
      "[109/00040] train_loss: 0.006439 kl_loss: 0.000000 normal_loss: 0.006439\n",
      "[111/00038] train_loss: 0.006445 kl_loss: 0.000000 normal_loss: 0.006445\n",
      "[113/00036] train_loss: 0.006852 kl_loss: 0.000000 normal_loss: 0.006852\n",
      "[115/00034] train_loss: 0.006719 kl_loss: 0.000000 normal_loss: 0.006719\n",
      "[117/00032] train_loss: 0.006506 kl_loss: 0.000000 normal_loss: 0.006506\n",
      "[119/00030] train_loss: 0.006467 kl_loss: 0.000000 normal_loss: 0.006467\n",
      "[121/00028] train_loss: 0.006596 kl_loss: 0.000000 normal_loss: 0.006596\n",
      "[123/00026] train_loss: 0.006502 kl_loss: 0.000000 normal_loss: 0.006502\n",
      "[125/00024] train_loss: 0.006630 kl_loss: 0.000000 normal_loss: 0.006630\n",
      "[127/00022] train_loss: 0.006474 kl_loss: 0.000000 normal_loss: 0.006474\n",
      "[129/00020] train_loss: 0.006653 kl_loss: 0.000000 normal_loss: 0.006653\n",
      "[131/00018] train_loss: 0.006524 kl_loss: 0.000000 normal_loss: 0.006524\n",
      "[133/00016] train_loss: 0.006183 kl_loss: 0.000000 normal_loss: 0.006183\n",
      "[135/00014] train_loss: 0.005946 kl_loss: 0.000000 normal_loss: 0.005946\n",
      "[137/00012] train_loss: 0.006370 kl_loss: 0.000000 normal_loss: 0.006370\n",
      "[139/00010] train_loss: 0.006504 kl_loss: 0.000000 normal_loss: 0.006504\n",
      "[141/00008] train_loss: 0.006158 kl_loss: 0.000000 normal_loss: 0.006158\n",
      "[143/00006] train_loss: 0.006420 kl_loss: 0.000000 normal_loss: 0.006420\n",
      "[145/00004] train_loss: 0.006318 kl_loss: 0.000000 normal_loss: 0.006318\n",
      "[147/00002] train_loss: 0.005959 kl_loss: 0.000000 normal_loss: 0.005959\n",
      "[149/00000] train_loss: 0.006167 kl_loss: 0.000000 normal_loss: 0.006167\n",
      "[149/00050] IOU 0.9118488400400937\n",
      "[150/00049] train_loss: 0.006267 kl_loss: 0.000000 normal_loss: 0.006267\n",
      "[152/00047] train_loss: 0.005839 kl_loss: 0.000000 normal_loss: 0.005839\n",
      "[154/00045] train_loss: 0.005782 kl_loss: 0.000000 normal_loss: 0.005782\n",
      "[156/00043] train_loss: 0.005699 kl_loss: 0.000000 normal_loss: 0.005699\n",
      "[158/00041] train_loss: 0.006232 kl_loss: 0.000000 normal_loss: 0.006232\n",
      "[160/00039] train_loss: 0.006133 kl_loss: 0.000000 normal_loss: 0.006133\n",
      "[162/00037] train_loss: 0.005951 kl_loss: 0.000000 normal_loss: 0.005951\n",
      "[164/00035] train_loss: 0.005979 kl_loss: 0.000000 normal_loss: 0.005979\n",
      "[166/00033] train_loss: 0.005948 kl_loss: 0.000000 normal_loss: 0.005948\n",
      "[168/00031] train_loss: 0.005905 kl_loss: 0.000000 normal_loss: 0.005905\n",
      "[170/00029] train_loss: 0.005624 kl_loss: 0.000000 normal_loss: 0.005624\n",
      "[172/00027] train_loss: 0.005861 kl_loss: 0.000000 normal_loss: 0.005861\n",
      "[174/00025] train_loss: 0.005777 kl_loss: 0.000000 normal_loss: 0.005777\n",
      "[176/00023] train_loss: 0.005548 kl_loss: 0.000000 normal_loss: 0.005548\n",
      "[178/00021] train_loss: 0.005477 kl_loss: 0.000000 normal_loss: 0.005477\n",
      "[180/00019] train_loss: 0.005532 kl_loss: 0.000000 normal_loss: 0.005532\n",
      "[182/00017] train_loss: 0.005863 kl_loss: 0.000000 normal_loss: 0.005863\n",
      "[184/00015] train_loss: 0.005802 kl_loss: 0.000000 normal_loss: 0.005802\n",
      "[186/00013] train_loss: 0.005245 kl_loss: 0.000000 normal_loss: 0.005245\n",
      "[188/00011] train_loss: 0.005779 kl_loss: 0.000000 normal_loss: 0.005779\n",
      "[190/00009] train_loss: 0.005693 kl_loss: 0.000000 normal_loss: 0.005693\n",
      "[192/00007] train_loss: 0.005587 kl_loss: 0.000000 normal_loss: 0.005587\n",
      "[194/00005] train_loss: 0.005504 kl_loss: 0.000000 normal_loss: 0.005504\n",
      "[196/00003] train_loss: 0.005209 kl_loss: 0.000000 normal_loss: 0.005209\n",
      "[198/00001] train_loss: 0.005176 kl_loss: 0.000000 normal_loss: 0.005176\n",
      "[199/00050] train_loss: 0.005617 kl_loss: 0.000000 normal_loss: 0.005617\n",
      "[199/00050] IOU 0.9256172117458286\n",
      "[201/00048] train_loss: 0.004190 kl_loss: 0.000000 normal_loss: 0.004190\n",
      "[203/00046] train_loss: 0.004088 kl_loss: 0.000000 normal_loss: 0.004088\n",
      "[205/00044] train_loss: 0.004151 kl_loss: 0.000000 normal_loss: 0.004151\n",
      "[207/00042] train_loss: 0.003992 kl_loss: 0.000000 normal_loss: 0.003992\n",
      "[209/00040] train_loss: 0.003967 kl_loss: 0.000000 normal_loss: 0.003967\n",
      "[211/00038] train_loss: 0.004063 kl_loss: 0.000000 normal_loss: 0.004063\n",
      "[213/00036] train_loss: 0.003931 kl_loss: 0.000000 normal_loss: 0.003931\n",
      "[215/00034] train_loss: 0.004004 kl_loss: 0.000000 normal_loss: 0.004004\n",
      "[217/00032] train_loss: 0.003941 kl_loss: 0.000000 normal_loss: 0.003941\n",
      "[219/00030] train_loss: 0.004066 kl_loss: 0.000000 normal_loss: 0.004066\n",
      "[221/00028] train_loss: 0.003951 kl_loss: 0.000000 normal_loss: 0.003951\n",
      "[223/00026] train_loss: 0.004050 kl_loss: 0.000000 normal_loss: 0.004050\n",
      "[225/00024] train_loss: 0.003784 kl_loss: 0.000000 normal_loss: 0.003784\n",
      "[227/00022] train_loss: 0.004005 kl_loss: 0.000000 normal_loss: 0.004005\n",
      "[229/00020] train_loss: 0.003875 kl_loss: 0.000000 normal_loss: 0.003875\n",
      "[231/00018] train_loss: 0.004033 kl_loss: 0.000000 normal_loss: 0.004033\n",
      "[233/00016] train_loss: 0.003944 kl_loss: 0.000000 normal_loss: 0.003944\n",
      "[235/00014] train_loss: 0.003814 kl_loss: 0.000000 normal_loss: 0.003814\n",
      "[237/00012] train_loss: 0.003859 kl_loss: 0.000000 normal_loss: 0.003859\n",
      "[239/00010] train_loss: 0.003986 kl_loss: 0.000000 normal_loss: 0.003986\n",
      "[241/00008] train_loss: 0.004073 kl_loss: 0.000000 normal_loss: 0.004073\n",
      "[243/00006] train_loss: 0.004000 kl_loss: 0.000000 normal_loss: 0.004000\n",
      "[245/00004] train_loss: 0.003843 kl_loss: 0.000000 normal_loss: 0.003843\n",
      "[247/00002] train_loss: 0.004078 kl_loss: 0.000000 normal_loss: 0.004078\n",
      "[249/00000] train_loss: 0.003961 kl_loss: 0.000000 normal_loss: 0.003961\n",
      "[249/00050] IOU 0.9346959705111123\n",
      "[250/00049] train_loss: 0.003924 kl_loss: 0.000000 normal_loss: 0.003924\n",
      "[252/00047] train_loss: 0.003846 kl_loss: 0.000000 normal_loss: 0.003846\n",
      "[254/00045] train_loss: 0.003735 kl_loss: 0.000000 normal_loss: 0.003735\n",
      "[256/00043] train_loss: 0.003948 kl_loss: 0.000000 normal_loss: 0.003948\n",
      "[258/00041] train_loss: 0.003995 kl_loss: 0.000000 normal_loss: 0.003995\n",
      "[260/00039] train_loss: 0.003818 kl_loss: 0.000000 normal_loss: 0.003818\n",
      "[262/00037] train_loss: 0.003759 kl_loss: 0.000000 normal_loss: 0.003759\n",
      "[264/00035] train_loss: 0.003703 kl_loss: 0.000000 normal_loss: 0.003703\n",
      "[266/00033] train_loss: 0.003788 kl_loss: 0.000000 normal_loss: 0.003788\n",
      "[268/00031] train_loss: 0.003723 kl_loss: 0.000000 normal_loss: 0.003723\n",
      "[270/00029] train_loss: 0.003873 kl_loss: 0.000000 normal_loss: 0.003873\n",
      "[272/00027] train_loss: 0.003660 kl_loss: 0.000000 normal_loss: 0.003660\n",
      "[274/00025] train_loss: 0.003853 kl_loss: 0.000000 normal_loss: 0.003853\n",
      "[276/00023] train_loss: 0.003877 kl_loss: 0.000000 normal_loss: 0.003877\n",
      "[278/00021] train_loss: 0.003803 kl_loss: 0.000000 normal_loss: 0.003803\n",
      "[280/00019] train_loss: 0.003703 kl_loss: 0.000000 normal_loss: 0.003703\n",
      "[282/00017] train_loss: 0.003841 kl_loss: 0.000000 normal_loss: 0.003841\n",
      "[284/00015] train_loss: 0.003895 kl_loss: 0.000000 normal_loss: 0.003895\n",
      "[286/00013] train_loss: 0.003555 kl_loss: 0.000000 normal_loss: 0.003555\n",
      "[288/00011] train_loss: 0.003735 kl_loss: 0.000000 normal_loss: 0.003735\n",
      "[290/00009] train_loss: 0.003763 kl_loss: 0.000000 normal_loss: 0.003763\n",
      "[292/00007] train_loss: 0.003704 kl_loss: 0.000000 normal_loss: 0.003704\n",
      "[294/00005] train_loss: 0.003652 kl_loss: 0.000000 normal_loss: 0.003652\n",
      "[296/00003] train_loss: 0.003586 kl_loss: 0.000000 normal_loss: 0.003586\n",
      "[298/00001] train_loss: 0.003862 kl_loss: 0.000000 normal_loss: 0.003862\n",
      "[299/00050] train_loss: 0.003801 kl_loss: 0.000000 normal_loss: 0.003801\n",
      "[299/00050] IOU 0.9409190300294878\n",
      "[301/00048] train_loss: 0.003255 kl_loss: 0.000000 normal_loss: 0.003255\n",
      "[303/00046] train_loss: 0.003081 kl_loss: 0.000000 normal_loss: 0.003081\n",
      "[305/00044] train_loss: 0.003031 kl_loss: 0.000000 normal_loss: 0.003031\n",
      "[307/00042] train_loss: 0.003017 kl_loss: 0.000000 normal_loss: 0.003017\n",
      "[309/00040] train_loss: 0.003090 kl_loss: 0.000000 normal_loss: 0.003090\n",
      "[311/00038] train_loss: 0.003025 kl_loss: 0.000000 normal_loss: 0.003025\n",
      "[313/00036] train_loss: 0.003138 kl_loss: 0.000000 normal_loss: 0.003138\n",
      "[315/00034] train_loss: 0.003145 kl_loss: 0.000000 normal_loss: 0.003145\n",
      "[317/00032] train_loss: 0.003234 kl_loss: 0.000000 normal_loss: 0.003234\n",
      "[319/00030] train_loss: 0.003039 kl_loss: 0.000000 normal_loss: 0.003039\n",
      "[321/00028] train_loss: 0.003081 kl_loss: 0.000000 normal_loss: 0.003081\n",
      "[323/00026] train_loss: 0.003025 kl_loss: 0.000000 normal_loss: 0.003025\n",
      "[325/00024] train_loss: 0.003036 kl_loss: 0.000000 normal_loss: 0.003036\n",
      "[327/00022] train_loss: 0.002954 kl_loss: 0.000000 normal_loss: 0.002954\n",
      "[329/00020] train_loss: 0.003022 kl_loss: 0.000000 normal_loss: 0.003022\n",
      "[331/00018] train_loss: 0.003104 kl_loss: 0.000000 normal_loss: 0.003104\n",
      "[333/00016] train_loss: 0.003053 kl_loss: 0.000000 normal_loss: 0.003053\n",
      "[335/00014] train_loss: 0.003131 kl_loss: 0.000000 normal_loss: 0.003131\n",
      "[337/00012] train_loss: 0.002940 kl_loss: 0.000000 normal_loss: 0.002940\n",
      "[339/00010] train_loss: 0.003013 kl_loss: 0.000000 normal_loss: 0.003013\n",
      "[341/00008] train_loss: 0.003054 kl_loss: 0.000000 normal_loss: 0.003054\n",
      "[343/00006] train_loss: 0.003020 kl_loss: 0.000000 normal_loss: 0.003020\n",
      "[345/00004] train_loss: 0.003072 kl_loss: 0.000000 normal_loss: 0.003072\n",
      "[347/00002] train_loss: 0.003019 kl_loss: 0.000000 normal_loss: 0.003019\n",
      "[349/00000] train_loss: 0.002970 kl_loss: 0.000000 normal_loss: 0.002970\n",
      "[349/00050] IOU 0.9448994673300438\n",
      "[350/00049] train_loss: 0.002997 kl_loss: 0.000000 normal_loss: 0.002997\n",
      "[352/00047] train_loss: 0.003048 kl_loss: 0.000000 normal_loss: 0.003048\n",
      "[354/00045] train_loss: 0.003040 kl_loss: 0.000000 normal_loss: 0.003040\n",
      "[356/00043] train_loss: 0.002957 kl_loss: 0.000000 normal_loss: 0.002957\n",
      "[358/00041] train_loss: 0.003000 kl_loss: 0.000000 normal_loss: 0.003000\n",
      "[360/00039] train_loss: 0.002947 kl_loss: 0.000000 normal_loss: 0.002947\n",
      "[362/00037] train_loss: 0.002954 kl_loss: 0.000000 normal_loss: 0.002954\n",
      "[364/00035] train_loss: 0.002963 kl_loss: 0.000000 normal_loss: 0.002963\n",
      "[366/00033] train_loss: 0.002984 kl_loss: 0.000000 normal_loss: 0.002984\n",
      "[368/00031] train_loss: 0.003052 kl_loss: 0.000000 normal_loss: 0.003052\n",
      "[370/00029] train_loss: 0.002905 kl_loss: 0.000000 normal_loss: 0.002905\n",
      "[372/00027] train_loss: 0.002975 kl_loss: 0.000000 normal_loss: 0.002975\n",
      "[374/00025] train_loss: 0.002945 kl_loss: 0.000000 normal_loss: 0.002945\n",
      "[376/00023] train_loss: 0.002922 kl_loss: 0.000000 normal_loss: 0.002922\n",
      "[378/00021] train_loss: 0.002909 kl_loss: 0.000000 normal_loss: 0.002909\n",
      "[380/00019] train_loss: 0.002939 kl_loss: 0.000000 normal_loss: 0.002939\n",
      "[382/00017] train_loss: 0.002971 kl_loss: 0.000000 normal_loss: 0.002971\n",
      "[384/00015] train_loss: 0.002892 kl_loss: 0.000000 normal_loss: 0.002892\n",
      "[386/00013] train_loss: 0.002953 kl_loss: 0.000000 normal_loss: 0.002953\n",
      "[388/00011] train_loss: 0.002892 kl_loss: 0.000000 normal_loss: 0.002892\n",
      "[390/00009] train_loss: 0.002880 kl_loss: 0.000000 normal_loss: 0.002880\n",
      "[392/00007] train_loss: 0.002916 kl_loss: 0.000000 normal_loss: 0.002916\n",
      "[394/00005] train_loss: 0.002930 kl_loss: 0.000000 normal_loss: 0.002930\n",
      "[396/00003] train_loss: 0.002926 kl_loss: 0.000000 normal_loss: 0.002926\n",
      "[398/00001] train_loss: 0.002911 kl_loss: 0.000000 normal_loss: 0.002911\n",
      "[399/00050] train_loss: 0.002905 kl_loss: 0.000000 normal_loss: 0.002905\n",
      "[399/00050] IOU 0.9468951126922046\n",
      "[401/00048] train_loss: 0.002722 kl_loss: 0.000000 normal_loss: 0.002722\n",
      "[403/00046] train_loss: 0.002626 kl_loss: 0.000000 normal_loss: 0.002626\n",
      "[405/00044] train_loss: 0.002706 kl_loss: 0.000000 normal_loss: 0.002706\n",
      "[407/00042] train_loss: 0.002621 kl_loss: 0.000000 normal_loss: 0.002621\n",
      "[409/00040] train_loss: 0.002653 kl_loss: 0.000000 normal_loss: 0.002653\n",
      "[411/00038] train_loss: 0.002629 kl_loss: 0.000000 normal_loss: 0.002629\n",
      "[413/00036] train_loss: 0.002617 kl_loss: 0.000000 normal_loss: 0.002617\n",
      "[415/00034] train_loss: 0.002619 kl_loss: 0.000000 normal_loss: 0.002619\n",
      "[417/00032] train_loss: 0.002685 kl_loss: 0.000000 normal_loss: 0.002685\n",
      "[419/00030] train_loss: 0.002677 kl_loss: 0.000000 normal_loss: 0.002677\n",
      "[421/00028] train_loss: 0.002639 kl_loss: 0.000000 normal_loss: 0.002639\n",
      "[423/00026] train_loss: 0.002647 kl_loss: 0.000000 normal_loss: 0.002647\n",
      "[425/00024] train_loss: 0.002607 kl_loss: 0.000000 normal_loss: 0.002607\n",
      "[427/00022] train_loss: 0.002590 kl_loss: 0.000000 normal_loss: 0.002590\n",
      "[429/00020] train_loss: 0.002619 kl_loss: 0.000000 normal_loss: 0.002619\n",
      "[431/00018] train_loss: 0.002590 kl_loss: 0.000000 normal_loss: 0.002590\n",
      "[433/00016] train_loss: 0.002600 kl_loss: 0.000000 normal_loss: 0.002600\n",
      "[435/00014] train_loss: 0.002608 kl_loss: 0.000000 normal_loss: 0.002608\n",
      "[437/00012] train_loss: 0.002611 kl_loss: 0.000000 normal_loss: 0.002611\n",
      "[439/00010] train_loss: 0.002590 kl_loss: 0.000000 normal_loss: 0.002590\n",
      "[441/00008] train_loss: 0.002608 kl_loss: 0.000000 normal_loss: 0.002608\n",
      "[443/00006] train_loss: 0.002603 kl_loss: 0.000000 normal_loss: 0.002603\n",
      "[445/00004] train_loss: 0.002616 kl_loss: 0.000000 normal_loss: 0.002616\n",
      "[447/00002] train_loss: 0.002620 kl_loss: 0.000000 normal_loss: 0.002620\n",
      "[449/00000] train_loss: 0.002606 kl_loss: 0.000000 normal_loss: 0.002606\n",
      "[449/00050] IOU 0.9495383341910665\n",
      "[450/00049] train_loss: 0.002602 kl_loss: 0.000000 normal_loss: 0.002602\n",
      "[452/00047] train_loss: 0.002635 kl_loss: 0.000000 normal_loss: 0.002635\n",
      "[454/00045] train_loss: 0.002679 kl_loss: 0.000000 normal_loss: 0.002679\n",
      "[456/00043] train_loss: 0.002605 kl_loss: 0.000000 normal_loss: 0.002605\n",
      "[458/00041] train_loss: 0.002596 kl_loss: 0.000000 normal_loss: 0.002596\n",
      "[460/00039] train_loss: 0.002581 kl_loss: 0.000000 normal_loss: 0.002581\n",
      "[462/00037] train_loss: 0.002634 kl_loss: 0.000000 normal_loss: 0.002634\n",
      "[464/00035] train_loss: 0.002574 kl_loss: 0.000000 normal_loss: 0.002574\n",
      "[466/00033] train_loss: 0.002574 kl_loss: 0.000000 normal_loss: 0.002574\n",
      "[468/00031] train_loss: 0.002642 kl_loss: 0.000000 normal_loss: 0.002642\n",
      "[470/00029] train_loss: 0.002573 kl_loss: 0.000000 normal_loss: 0.002573\n",
      "[472/00027] train_loss: 0.002558 kl_loss: 0.000000 normal_loss: 0.002558\n",
      "[474/00025] train_loss: 0.002524 kl_loss: 0.000000 normal_loss: 0.002524\n",
      "[476/00023] train_loss: 0.002595 kl_loss: 0.000000 normal_loss: 0.002595\n",
      "[478/00021] train_loss: 0.002551 kl_loss: 0.000000 normal_loss: 0.002551\n",
      "[480/00019] train_loss: 0.002536 kl_loss: 0.000000 normal_loss: 0.002536\n",
      "[482/00017] train_loss: 0.002541 kl_loss: 0.000000 normal_loss: 0.002541\n",
      "[484/00015] train_loss: 0.002522 kl_loss: 0.000000 normal_loss: 0.002522\n",
      "[486/00013] train_loss: 0.002624 kl_loss: 0.000000 normal_loss: 0.002624\n",
      "[488/00011] train_loss: 0.002531 kl_loss: 0.000000 normal_loss: 0.002531\n",
      "[490/00009] train_loss: 0.002525 kl_loss: 0.000000 normal_loss: 0.002525\n",
      "[492/00007] train_loss: 0.002606 kl_loss: 0.000000 normal_loss: 0.002606\n",
      "[494/00005] train_loss: 0.002620 kl_loss: 0.000000 normal_loss: 0.002620\n",
      "[496/00003] train_loss: 0.002541 kl_loss: 0.000000 normal_loss: 0.002541\n",
      "[498/00001] train_loss: 0.002546 kl_loss: 0.000000 normal_loss: 0.002546\n",
      "[499/00050] train_loss: 0.002573 kl_loss: 0.000000 normal_loss: 0.002573\n",
      "[499/00050] IOU 0.9503749401777135\n",
      "[501/00048] train_loss: 0.002475 kl_loss: 0.000000 normal_loss: 0.002475\n",
      "[503/00046] train_loss: 0.002424 kl_loss: 0.000000 normal_loss: 0.002424\n",
      "[505/00044] train_loss: 0.002428 kl_loss: 0.000000 normal_loss: 0.002428\n",
      "[507/00042] train_loss: 0.002423 kl_loss: 0.000000 normal_loss: 0.002423\n",
      "[509/00040] train_loss: 0.002429 kl_loss: 0.000000 normal_loss: 0.002429\n",
      "[511/00038] train_loss: 0.002437 kl_loss: 0.000000 normal_loss: 0.002437\n",
      "[513/00036] train_loss: 0.002428 kl_loss: 0.000000 normal_loss: 0.002428\n",
      "[515/00034] train_loss: 0.002434 kl_loss: 0.000000 normal_loss: 0.002434\n",
      "[517/00032] train_loss: 0.002470 kl_loss: 0.000000 normal_loss: 0.002470\n",
      "[519/00030] train_loss: 0.002429 kl_loss: 0.000000 normal_loss: 0.002429\n",
      "[521/00028] train_loss: 0.002435 kl_loss: 0.000000 normal_loss: 0.002435\n",
      "[523/00026] train_loss: 0.002443 kl_loss: 0.000000 normal_loss: 0.002443\n",
      "[525/00024] train_loss: 0.002432 kl_loss: 0.000000 normal_loss: 0.002432\n",
      "[527/00022] train_loss: 0.002453 kl_loss: 0.000000 normal_loss: 0.002453\n",
      "[529/00020] train_loss: 0.002408 kl_loss: 0.000000 normal_loss: 0.002408\n",
      "[531/00018] train_loss: 0.002432 kl_loss: 0.000000 normal_loss: 0.002432\n",
      "[533/00016] train_loss: 0.002431 kl_loss: 0.000000 normal_loss: 0.002431\n",
      "[535/00014] train_loss: 0.002428 kl_loss: 0.000000 normal_loss: 0.002428\n",
      "[537/00012] train_loss: 0.002444 kl_loss: 0.000000 normal_loss: 0.002444\n",
      "[539/00010] train_loss: 0.002421 kl_loss: 0.000000 normal_loss: 0.002421\n",
      "[541/00008] train_loss: 0.002461 kl_loss: 0.000000 normal_loss: 0.002461\n",
      "[543/00006] train_loss: 0.002450 kl_loss: 0.000000 normal_loss: 0.002450\n",
      "[545/00004] train_loss: 0.002411 kl_loss: 0.000000 normal_loss: 0.002411\n",
      "[547/00002] train_loss: 0.002439 kl_loss: 0.000000 normal_loss: 0.002439\n",
      "[549/00000] train_loss: 0.002399 kl_loss: 0.000000 normal_loss: 0.002399\n",
      "[549/00050] IOU 0.9521024298977351\n",
      "[550/00049] train_loss: 0.002439 kl_loss: 0.000000 normal_loss: 0.002439\n",
      "[552/00047] train_loss: 0.002406 kl_loss: 0.000000 normal_loss: 0.002406\n",
      "[554/00045] train_loss: 0.002416 kl_loss: 0.000000 normal_loss: 0.002416\n",
      "[556/00043] train_loss: 0.002406 kl_loss: 0.000000 normal_loss: 0.002406\n",
      "[558/00041] train_loss: 0.002396 kl_loss: 0.000000 normal_loss: 0.002396\n",
      "[560/00039] train_loss: 0.002409 kl_loss: 0.000000 normal_loss: 0.002409\n",
      "[562/00037] train_loss: 0.002398 kl_loss: 0.000000 normal_loss: 0.002398\n",
      "[564/00035] train_loss: 0.002433 kl_loss: 0.000000 normal_loss: 0.002433\n",
      "[566/00033] train_loss: 0.002401 kl_loss: 0.000000 normal_loss: 0.002401\n",
      "[568/00031] train_loss: 0.002402 kl_loss: 0.000000 normal_loss: 0.002402\n",
      "[570/00029] train_loss: 0.002395 kl_loss: 0.000000 normal_loss: 0.002395\n",
      "[572/00027] train_loss: 0.002397 kl_loss: 0.000000 normal_loss: 0.002397\n",
      "[574/00025] train_loss: 0.002431 kl_loss: 0.000000 normal_loss: 0.002431\n",
      "[576/00023] train_loss: 0.002410 kl_loss: 0.000000 normal_loss: 0.002410\n",
      "[578/00021] train_loss: 0.002402 kl_loss: 0.000000 normal_loss: 0.002402\n",
      "[580/00019] train_loss: 0.002373 kl_loss: 0.000000 normal_loss: 0.002373\n",
      "[582/00017] train_loss: 0.002418 kl_loss: 0.000000 normal_loss: 0.002418\n",
      "[584/00015] train_loss: 0.002380 kl_loss: 0.000000 normal_loss: 0.002380\n",
      "[586/00013] train_loss: 0.002376 kl_loss: 0.000000 normal_loss: 0.002376\n",
      "[588/00011] train_loss: 0.002387 kl_loss: 0.000000 normal_loss: 0.002387\n",
      "[590/00009] train_loss: 0.002386 kl_loss: 0.000000 normal_loss: 0.002386\n",
      "[592/00007] train_loss: 0.002387 kl_loss: 0.000000 normal_loss: 0.002387\n",
      "[594/00005] train_loss: 0.002383 kl_loss: 0.000000 normal_loss: 0.002383\n",
      "[596/00003] train_loss: 0.002383 kl_loss: 0.000000 normal_loss: 0.002383\n",
      "[598/00001] train_loss: 0.002381 kl_loss: 0.000000 normal_loss: 0.002381\n",
      "[599/00050] train_loss: 0.002367 kl_loss: 0.000000 normal_loss: 0.002367\n",
      "[599/00050] IOU 0.9526207224916027\n",
      "[601/00048] train_loss: 0.002342 kl_loss: 0.000000 normal_loss: 0.002342\n",
      "[603/00046] train_loss: 0.002340 kl_loss: 0.000000 normal_loss: 0.002340\n",
      "[605/00044] train_loss: 0.002341 kl_loss: 0.000000 normal_loss: 0.002341\n",
      "[607/00042] train_loss: 0.002323 kl_loss: 0.000000 normal_loss: 0.002323\n",
      "[609/00040] train_loss: 0.002339 kl_loss: 0.000000 normal_loss: 0.002339\n",
      "[611/00038] train_loss: 0.002327 kl_loss: 0.000000 normal_loss: 0.002327\n",
      "[613/00036] train_loss: 0.002320 kl_loss: 0.000000 normal_loss: 0.002320\n",
      "[615/00034] train_loss: 0.002334 kl_loss: 0.000000 normal_loss: 0.002334\n",
      "[617/00032] train_loss: 0.002341 kl_loss: 0.000000 normal_loss: 0.002341\n",
      "[619/00030] train_loss: 0.002330 kl_loss: 0.000000 normal_loss: 0.002330\n",
      "[621/00028] train_loss: 0.002361 kl_loss: 0.000000 normal_loss: 0.002361\n",
      "[623/00026] train_loss: 0.002335 kl_loss: 0.000000 normal_loss: 0.002335\n",
      "[625/00024] train_loss: 0.002327 kl_loss: 0.000000 normal_loss: 0.002327\n",
      "[627/00022] train_loss: 0.002332 kl_loss: 0.000000 normal_loss: 0.002332\n",
      "[629/00020] train_loss: 0.002319 kl_loss: 0.000000 normal_loss: 0.002319\n",
      "[631/00018] train_loss: 0.002322 kl_loss: 0.000000 normal_loss: 0.002322\n",
      "[633/00016] train_loss: 0.002344 kl_loss: 0.000000 normal_loss: 0.002344\n",
      "[635/00014] train_loss: 0.002336 kl_loss: 0.000000 normal_loss: 0.002336\n",
      "[637/00012] train_loss: 0.002314 kl_loss: 0.000000 normal_loss: 0.002314\n",
      "[639/00010] train_loss: 0.002334 kl_loss: 0.000000 normal_loss: 0.002334\n",
      "[641/00008] train_loss: 0.002338 kl_loss: 0.000000 normal_loss: 0.002338\n",
      "[643/00006] train_loss: 0.002299 kl_loss: 0.000000 normal_loss: 0.002299\n",
      "[645/00004] train_loss: 0.002320 kl_loss: 0.000000 normal_loss: 0.002320\n",
      "[647/00002] train_loss: 0.002352 kl_loss: 0.000000 normal_loss: 0.002352\n",
      "[649/00000] train_loss: 0.002341 kl_loss: 0.000000 normal_loss: 0.002341\n",
      "[649/00050] IOU 0.9529927011915427\n",
      "[650/00049] train_loss: 0.002325 kl_loss: 0.000000 normal_loss: 0.002325\n",
      "[652/00047] train_loss: 0.002331 kl_loss: 0.000000 normal_loss: 0.002331\n",
      "[654/00045] train_loss: 0.002317 kl_loss: 0.000000 normal_loss: 0.002317\n",
      "[656/00043] train_loss: 0.002316 kl_loss: 0.000000 normal_loss: 0.002316\n",
      "[658/00041] train_loss: 0.002320 kl_loss: 0.000000 normal_loss: 0.002320\n",
      "[660/00039] train_loss: 0.002321 kl_loss: 0.000000 normal_loss: 0.002321\n",
      "[662/00037] train_loss: 0.002316 kl_loss: 0.000000 normal_loss: 0.002316\n",
      "[664/00035] train_loss: 0.002335 kl_loss: 0.000000 normal_loss: 0.002335\n",
      "[666/00033] train_loss: 0.002310 kl_loss: 0.000000 normal_loss: 0.002310\n",
      "[668/00031] train_loss: 0.002309 kl_loss: 0.000000 normal_loss: 0.002309\n",
      "[670/00029] train_loss: 0.002299 kl_loss: 0.000000 normal_loss: 0.002299\n",
      "[672/00027] train_loss: 0.002338 kl_loss: 0.000000 normal_loss: 0.002338\n",
      "[674/00025] train_loss: 0.002312 kl_loss: 0.000000 normal_loss: 0.002312\n",
      "[676/00023] train_loss: 0.002328 kl_loss: 0.000000 normal_loss: 0.002328\n",
      "[678/00021] train_loss: 0.002328 kl_loss: 0.000000 normal_loss: 0.002328\n",
      "[680/00019] train_loss: 0.002296 kl_loss: 0.000000 normal_loss: 0.002296\n",
      "[682/00017] train_loss: 0.002320 kl_loss: 0.000000 normal_loss: 0.002320\n",
      "[684/00015] train_loss: 0.002309 kl_loss: 0.000000 normal_loss: 0.002309\n",
      "[686/00013] train_loss: 0.002308 kl_loss: 0.000000 normal_loss: 0.002308\n",
      "[688/00011] train_loss: 0.002327 kl_loss: 0.000000 normal_loss: 0.002327\n",
      "[690/00009] train_loss: 0.002322 kl_loss: 0.000000 normal_loss: 0.002322\n",
      "[692/00007] train_loss: 0.002306 kl_loss: 0.000000 normal_loss: 0.002306\n",
      "[694/00005] train_loss: 0.002316 kl_loss: 0.000000 normal_loss: 0.002316\n",
      "[696/00003] train_loss: 0.002305 kl_loss: 0.000000 normal_loss: 0.002305\n",
      "[698/00001] train_loss: 0.002288 kl_loss: 0.000000 normal_loss: 0.002288\n",
      "[699/00050] train_loss: 0.002295 kl_loss: 0.000000 normal_loss: 0.002295\n",
      "[699/00050] IOU 0.9531763271694572\n",
      "[701/00048] train_loss: 0.002288 kl_loss: 0.000000 normal_loss: 0.002288\n",
      "[703/00046] train_loss: 0.002288 kl_loss: 0.000000 normal_loss: 0.002288\n",
      "[705/00044] train_loss: 0.002282 kl_loss: 0.000000 normal_loss: 0.002282\n",
      "[707/00042] train_loss: 0.002268 kl_loss: 0.000000 normal_loss: 0.002268\n",
      "[709/00040] train_loss: 0.002296 kl_loss: 0.000000 normal_loss: 0.002296\n",
      "[711/00038] train_loss: 0.002284 kl_loss: 0.000000 normal_loss: 0.002284\n",
      "[713/00036] train_loss: 0.002287 kl_loss: 0.000000 normal_loss: 0.002287\n",
      "[715/00034] train_loss: 0.002267 kl_loss: 0.000000 normal_loss: 0.002267\n",
      "[717/00032] train_loss: 0.002283 kl_loss: 0.000000 normal_loss: 0.002283\n",
      "[719/00030] train_loss: 0.002273 kl_loss: 0.000000 normal_loss: 0.002273\n",
      "[721/00028] train_loss: 0.002288 kl_loss: 0.000000 normal_loss: 0.002288\n",
      "[723/00026] train_loss: 0.002270 kl_loss: 0.000000 normal_loss: 0.002270\n",
      "[725/00024] train_loss: 0.002286 kl_loss: 0.000000 normal_loss: 0.002286\n",
      "[727/00022] train_loss: 0.002278 kl_loss: 0.000000 normal_loss: 0.002278\n",
      "[729/00020] train_loss: 0.002288 kl_loss: 0.000000 normal_loss: 0.002288\n",
      "[731/00018] train_loss: 0.002272 kl_loss: 0.000000 normal_loss: 0.002272\n",
      "[733/00016] train_loss: 0.002286 kl_loss: 0.000000 normal_loss: 0.002286\n",
      "[735/00014] train_loss: 0.002277 kl_loss: 0.000000 normal_loss: 0.002277\n",
      "[737/00012] train_loss: 0.002294 kl_loss: 0.000000 normal_loss: 0.002294\n",
      "[739/00010] train_loss: 0.002266 kl_loss: 0.000000 normal_loss: 0.002266\n",
      "[741/00008] train_loss: 0.002275 kl_loss: 0.000000 normal_loss: 0.002275\n",
      "[743/00006] train_loss: 0.002277 kl_loss: 0.000000 normal_loss: 0.002277\n",
      "[745/00004] train_loss: 0.002281 kl_loss: 0.000000 normal_loss: 0.002281\n",
      "[747/00002] train_loss: 0.002273 kl_loss: 0.000000 normal_loss: 0.002273\n",
      "[749/00000] train_loss: 0.002277 kl_loss: 0.000000 normal_loss: 0.002277\n",
      "[749/00050] IOU 0.9535995807098075\n",
      "[750/00049] train_loss: 0.002268 kl_loss: 0.000000 normal_loss: 0.002268\n",
      "[752/00047] train_loss: 0.002282 kl_loss: 0.000000 normal_loss: 0.002282\n",
      "[754/00045] train_loss: 0.002279 kl_loss: 0.000000 normal_loss: 0.002279\n",
      "[756/00043] train_loss: 0.002270 kl_loss: 0.000000 normal_loss: 0.002270\n",
      "[758/00041] train_loss: 0.002273 kl_loss: 0.000000 normal_loss: 0.002273\n",
      "[760/00039] train_loss: 0.002280 kl_loss: 0.000000 normal_loss: 0.002280\n",
      "[762/00037] train_loss: 0.002285 kl_loss: 0.000000 normal_loss: 0.002285\n",
      "[764/00035] train_loss: 0.002268 kl_loss: 0.000000 normal_loss: 0.002268\n",
      "[766/00033] train_loss: 0.002265 kl_loss: 0.000000 normal_loss: 0.002265\n",
      "[768/00031] train_loss: 0.002272 kl_loss: 0.000000 normal_loss: 0.002272\n",
      "[770/00029] train_loss: 0.002267 kl_loss: 0.000000 normal_loss: 0.002267\n",
      "[772/00027] train_loss: 0.002270 kl_loss: 0.000000 normal_loss: 0.002270\n",
      "[774/00025] train_loss: 0.002271 kl_loss: 0.000000 normal_loss: 0.002271\n",
      "[776/00023] train_loss: 0.002276 kl_loss: 0.000000 normal_loss: 0.002276\n",
      "[778/00021] train_loss: 0.002266 kl_loss: 0.000000 normal_loss: 0.002266\n",
      "[780/00019] train_loss: 0.002262 kl_loss: 0.000000 normal_loss: 0.002262\n",
      "[782/00017] train_loss: 0.002263 kl_loss: 0.000000 normal_loss: 0.002263\n",
      "[784/00015] train_loss: 0.002270 kl_loss: 0.000000 normal_loss: 0.002270\n",
      "[786/00013] train_loss: 0.002262 kl_loss: 0.000000 normal_loss: 0.002262\n",
      "[788/00011] train_loss: 0.002269 kl_loss: 0.000000 normal_loss: 0.002269\n",
      "[790/00009] train_loss: 0.002265 kl_loss: 0.000000 normal_loss: 0.002265\n",
      "[792/00007] train_loss: 0.002261 kl_loss: 0.000000 normal_loss: 0.002261\n",
      "[794/00005] train_loss: 0.002270 kl_loss: 0.000000 normal_loss: 0.002270\n",
      "[796/00003] train_loss: 0.002255 kl_loss: 0.000000 normal_loss: 0.002255\n",
      "[798/00001] train_loss: 0.002266 kl_loss: 0.000000 normal_loss: 0.002266\n",
      "[799/00050] train_loss: 0.002266 kl_loss: 0.000000 normal_loss: 0.002266\n",
      "[799/00050] IOU 0.9538687331272734\n",
      "[801/00048] train_loss: 0.002250 kl_loss: 0.000000 normal_loss: 0.002250\n",
      "[803/00046] train_loss: 0.002257 kl_loss: 0.000000 normal_loss: 0.002257\n",
      "[805/00044] train_loss: 0.002251 kl_loss: 0.000000 normal_loss: 0.002251\n",
      "[807/00042] train_loss: 0.002244 kl_loss: 0.000000 normal_loss: 0.002244\n",
      "[809/00040] train_loss: 0.002251 kl_loss: 0.000000 normal_loss: 0.002251\n",
      "[811/00038] train_loss: 0.002250 kl_loss: 0.000000 normal_loss: 0.002250\n",
      "[813/00036] train_loss: 0.002259 kl_loss: 0.000000 normal_loss: 0.002259\n",
      "[815/00034] train_loss: 0.002253 kl_loss: 0.000000 normal_loss: 0.002253\n",
      "[817/00032] train_loss: 0.002257 kl_loss: 0.000000 normal_loss: 0.002257\n",
      "[819/00030] train_loss: 0.002242 kl_loss: 0.000000 normal_loss: 0.002242\n",
      "[821/00028] train_loss: 0.002260 kl_loss: 0.000000 normal_loss: 0.002260\n",
      "[823/00026] train_loss: 0.002243 kl_loss: 0.000000 normal_loss: 0.002243\n",
      "[825/00024] train_loss: 0.002261 kl_loss: 0.000000 normal_loss: 0.002261\n",
      "[827/00022] train_loss: 0.002256 kl_loss: 0.000000 normal_loss: 0.002256\n",
      "[829/00020] train_loss: 0.002241 kl_loss: 0.000000 normal_loss: 0.002241\n",
      "[831/00018] train_loss: 0.002257 kl_loss: 0.000000 normal_loss: 0.002257\n",
      "[833/00016] train_loss: 0.002249 kl_loss: 0.000000 normal_loss: 0.002249\n",
      "[835/00014] train_loss: 0.002245 kl_loss: 0.000000 normal_loss: 0.002245\n",
      "[837/00012] train_loss: 0.002250 kl_loss: 0.000000 normal_loss: 0.002250\n",
      "[839/00010] train_loss: 0.002246 kl_loss: 0.000000 normal_loss: 0.002246\n",
      "[841/00008] train_loss: 0.002246 kl_loss: 0.000000 normal_loss: 0.002246\n",
      "[843/00006] train_loss: 0.002241 kl_loss: 0.000000 normal_loss: 0.002241\n",
      "[845/00004] train_loss: 0.002256 kl_loss: 0.000000 normal_loss: 0.002256\n",
      "[847/00002] train_loss: 0.002244 kl_loss: 0.000000 normal_loss: 0.002244\n",
      "[849/00000] train_loss: 0.002255 kl_loss: 0.000000 normal_loss: 0.002255\n",
      "[849/00050] IOU 0.9540121351427436\n",
      "[850/00049] train_loss: 0.002252 kl_loss: 0.000000 normal_loss: 0.002252\n",
      "[852/00047] train_loss: 0.002254 kl_loss: 0.000000 normal_loss: 0.002254\n",
      "[854/00045] train_loss: 0.002251 kl_loss: 0.000000 normal_loss: 0.002251\n",
      "[856/00043] train_loss: 0.002239 kl_loss: 0.000000 normal_loss: 0.002239\n",
      "[858/00041] train_loss: 0.002243 kl_loss: 0.000000 normal_loss: 0.002243\n",
      "[860/00039] train_loss: 0.002257 kl_loss: 0.000000 normal_loss: 0.002257\n",
      "[862/00037] train_loss: 0.002234 kl_loss: 0.000000 normal_loss: 0.002234\n",
      "[864/00035] train_loss: 0.002263 kl_loss: 0.000000 normal_loss: 0.002263\n",
      "[866/00033] train_loss: 0.002239 kl_loss: 0.000000 normal_loss: 0.002239\n",
      "[868/00031] train_loss: 0.002250 kl_loss: 0.000000 normal_loss: 0.002250\n",
      "[870/00029] train_loss: 0.002243 kl_loss: 0.000000 normal_loss: 0.002243\n",
      "[872/00027] train_loss: 0.002244 kl_loss: 0.000000 normal_loss: 0.002244\n",
      "[874/00025] train_loss: 0.002234 kl_loss: 0.000000 normal_loss: 0.002234\n",
      "[876/00023] train_loss: 0.002235 kl_loss: 0.000000 normal_loss: 0.002235\n",
      "[878/00021] train_loss: 0.002252 kl_loss: 0.000000 normal_loss: 0.002252\n",
      "[880/00019] train_loss: 0.002249 kl_loss: 0.000000 normal_loss: 0.002249\n",
      "[882/00017] train_loss: 0.002230 kl_loss: 0.000000 normal_loss: 0.002230\n",
      "[884/00015] train_loss: 0.002256 kl_loss: 0.000000 normal_loss: 0.002256\n",
      "[886/00013] train_loss: 0.002238 kl_loss: 0.000000 normal_loss: 0.002238\n",
      "[888/00011] train_loss: 0.002251 kl_loss: 0.000000 normal_loss: 0.002251\n",
      "[890/00009] train_loss: 0.002238 kl_loss: 0.000000 normal_loss: 0.002238\n",
      "[892/00007] train_loss: 0.002241 kl_loss: 0.000000 normal_loss: 0.002241\n",
      "[894/00005] train_loss: 0.002245 kl_loss: 0.000000 normal_loss: 0.002245\n",
      "[896/00003] train_loss: 0.002248 kl_loss: 0.000000 normal_loss: 0.002248\n",
      "[898/00001] train_loss: 0.002242 kl_loss: 0.000000 normal_loss: 0.002242\n",
      "[899/00050] train_loss: 0.002242 kl_loss: 0.000000 normal_loss: 0.002242\n",
      "[899/00050] IOU 0.954000507337496\n",
      "[901/00048] train_loss: 0.002234 kl_loss: 0.000000 normal_loss: 0.002234\n",
      "[903/00046] train_loss: 0.002244 kl_loss: 0.000000 normal_loss: 0.002244\n",
      "[905/00044] train_loss: 0.002232 kl_loss: 0.000000 normal_loss: 0.002232\n",
      "[907/00042] train_loss: 0.002230 kl_loss: 0.000000 normal_loss: 0.002230\n",
      "[909/00040] train_loss: 0.002236 kl_loss: 0.000000 normal_loss: 0.002236\n",
      "[911/00038] train_loss: 0.002227 kl_loss: 0.000000 normal_loss: 0.002227\n",
      "[913/00036] train_loss: 0.002231 kl_loss: 0.000000 normal_loss: 0.002231\n",
      "[915/00034] train_loss: 0.002243 kl_loss: 0.000000 normal_loss: 0.002243\n",
      "[917/00032] train_loss: 0.002234 kl_loss: 0.000000 normal_loss: 0.002234\n",
      "[919/00030] train_loss: 0.002235 kl_loss: 0.000000 normal_loss: 0.002235\n",
      "[921/00028] train_loss: 0.002223 kl_loss: 0.000000 normal_loss: 0.002223\n",
      "[923/00026] train_loss: 0.002249 kl_loss: 0.000000 normal_loss: 0.002249\n",
      "[925/00024] train_loss: 0.002227 kl_loss: 0.000000 normal_loss: 0.002227\n",
      "[927/00022] train_loss: 0.002234 kl_loss: 0.000000 normal_loss: 0.002234\n",
      "[929/00020] train_loss: 0.002241 kl_loss: 0.000000 normal_loss: 0.002241\n",
      "[931/00018] train_loss: 0.002243 kl_loss: 0.000000 normal_loss: 0.002243\n",
      "[933/00016] train_loss: 0.002236 kl_loss: 0.000000 normal_loss: 0.002236\n",
      "[935/00014] train_loss: 0.002225 kl_loss: 0.000000 normal_loss: 0.002225\n",
      "[937/00012] train_loss: 0.002230 kl_loss: 0.000000 normal_loss: 0.002230\n",
      "[939/00010] train_loss: 0.002234 kl_loss: 0.000000 normal_loss: 0.002234\n",
      "[941/00008] train_loss: 0.002235 kl_loss: 0.000000 normal_loss: 0.002235\n",
      "[943/00006] train_loss: 0.002232 kl_loss: 0.000000 normal_loss: 0.002232\n",
      "[945/00004] train_loss: 0.002229 kl_loss: 0.000000 normal_loss: 0.002229\n",
      "[947/00002] train_loss: 0.002235 kl_loss: 0.000000 normal_loss: 0.002235\n",
      "[949/00000] train_loss: 0.002240 kl_loss: 0.000000 normal_loss: 0.002240\n",
      "[949/00050] IOU 0.9540956982944451\n",
      "[950/00049] train_loss: 0.002231 kl_loss: 0.000000 normal_loss: 0.002231\n",
      "[952/00047] train_loss: 0.002230 kl_loss: 0.000000 normal_loss: 0.002230\n",
      "[954/00045] train_loss: 0.002235 kl_loss: 0.000000 normal_loss: 0.002235\n",
      "[956/00043] train_loss: 0.002227 kl_loss: 0.000000 normal_loss: 0.002227\n",
      "[958/00041] train_loss: 0.002240 kl_loss: 0.000000 normal_loss: 0.002240\n",
      "[960/00039] train_loss: 0.002229 kl_loss: 0.000000 normal_loss: 0.002229\n",
      "[962/00037] train_loss: 0.002232 kl_loss: 0.000000 normal_loss: 0.002232\n",
      "[964/00035] train_loss: 0.002237 kl_loss: 0.000000 normal_loss: 0.002237\n",
      "[966/00033] train_loss: 0.002227 kl_loss: 0.000000 normal_loss: 0.002227\n",
      "[968/00031] train_loss: 0.002230 kl_loss: 0.000000 normal_loss: 0.002230\n",
      "[970/00029] train_loss: 0.002240 kl_loss: 0.000000 normal_loss: 0.002240\n",
      "[972/00027] train_loss: 0.002231 kl_loss: 0.000000 normal_loss: 0.002231\n",
      "[974/00025] train_loss: 0.002229 kl_loss: 0.000000 normal_loss: 0.002229\n",
      "[976/00023] train_loss: 0.002246 kl_loss: 0.000000 normal_loss: 0.002246\n",
      "[978/00021] train_loss: 0.002238 kl_loss: 0.000000 normal_loss: 0.002238\n",
      "[980/00019] train_loss: 0.002237 kl_loss: 0.000000 normal_loss: 0.002237\n",
      "[982/00017] train_loss: 0.002220 kl_loss: 0.000000 normal_loss: 0.002220\n",
      "[984/00015] train_loss: 0.002242 kl_loss: 0.000000 normal_loss: 0.002242\n",
      "[986/00013] train_loss: 0.002223 kl_loss: 0.000000 normal_loss: 0.002223\n",
      "[988/00011] train_loss: 0.002238 kl_loss: 0.000000 normal_loss: 0.002238\n",
      "[990/00009] train_loss: 0.002227 kl_loss: 0.000000 normal_loss: 0.002227\n",
      "[992/00007] train_loss: 0.002235 kl_loss: 0.000000 normal_loss: 0.002235\n",
      "[994/00005] train_loss: 0.002234 kl_loss: 0.000000 normal_loss: 0.002234\n",
      "[996/00003] train_loss: 0.002226 kl_loss: 0.000000 normal_loss: 0.002226\n",
      "[998/00001] train_loss: 0.002232 kl_loss: 0.000000 normal_loss: 0.002232\n",
      "[999/00050] train_loss: 0.002235 kl_loss: 0.000000 normal_loss: 0.002235\n",
      "[999/00050] IOU 0.9541702348421177\n"
     ]
    }
   ],
   "source": [
    "# AIRPLANE AD\n",
    "from scripts import train\n",
    "config = {\n",
    "    'experiment_name': 'airplane_ad',\n",
    "    'device': 'cuda:0',\n",
    "    'is_overfit': False,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate_model': 0.01,\n",
    "    'learning_rate_code': 0.01,\n",
    "    'learning_rate_log_var':0.01,\n",
    "    'max_epochs': 1000,\n",
    "    'print_every_n': 100,\n",
    "    'latent_code_length' : 256,\n",
    "    'scheduler_step_size': 100,\n",
    "    'vad_free' : False,\n",
    "    'test': False,\n",
    "    'kl_weight': 0.03,\n",
    "    'kl_weight_increase_every_epochs': 100,\n",
    "    'kl_weight_increase_value': 0.0,\n",
    "    'iou_every_epoch': 50,\n",
    "    'resume_ckpt': None,\n",
    "    'filter_class': 'airplane',\n",
    "    'decoder_var' : False\n",
    "}\n",
    "train.main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Data length 4800\n",
      "Training params: 2\n",
      "[001/00024] train_loss: 0.168495 kl_loss: 0.000000 normal_loss: 0.168495\n",
      "[002/00049] train_loss: 0.117954 kl_loss: 0.000000 normal_loss: 0.117954\n",
      "[003/00074] train_loss: 0.109562 kl_loss: 0.000000 normal_loss: 0.109562\n",
      "[005/00024] train_loss: 0.105227 kl_loss: 0.000000 normal_loss: 0.105227\n",
      "[006/00049] train_loss: 0.097987 kl_loss: 0.000000 normal_loss: 0.097987\n",
      "[007/00074] train_loss: 0.095581 kl_loss: 0.000000 normal_loss: 0.095581\n",
      "[009/00024] train_loss: 0.091399 kl_loss: 0.000000 normal_loss: 0.091399\n",
      "[010/00049] train_loss: 0.086116 kl_loss: 0.000000 normal_loss: 0.086116\n",
      "[011/00074] train_loss: 0.082822 kl_loss: 0.000000 normal_loss: 0.082822\n",
      "[013/00024] train_loss: 0.076092 kl_loss: 0.000000 normal_loss: 0.076092\n",
      "[014/00049] train_loss: 0.073706 kl_loss: 0.000000 normal_loss: 0.073706\n",
      "[015/00074] train_loss: 0.068664 kl_loss: 0.000000 normal_loss: 0.068664\n",
      "[017/00024] train_loss: 0.065321 kl_loss: 0.000000 normal_loss: 0.065321\n",
      "[018/00049] train_loss: 0.063247 kl_loss: 0.000000 normal_loss: 0.063247\n",
      "[019/00074] train_loss: 0.060584 kl_loss: 0.000000 normal_loss: 0.060584\n",
      "[021/00024] train_loss: 0.057878 kl_loss: 0.000000 normal_loss: 0.057878\n",
      "[022/00049] train_loss: 0.056367 kl_loss: 0.000000 normal_loss: 0.056367\n",
      "[023/00074] train_loss: 0.053790 kl_loss: 0.000000 normal_loss: 0.053790\n",
      "[025/00024] train_loss: 0.051930 kl_loss: 0.000000 normal_loss: 0.051930\n",
      "[026/00049] train_loss: 0.049985 kl_loss: 0.000000 normal_loss: 0.049985\n",
      "[027/00074] train_loss: 0.047572 kl_loss: 0.000000 normal_loss: 0.047572\n",
      "[029/00024] train_loss: 0.047217 kl_loss: 0.000000 normal_loss: 0.047217\n",
      "[030/00049] train_loss: 0.044996 kl_loss: 0.000000 normal_loss: 0.044996\n",
      "[031/00074] train_loss: 0.044526 kl_loss: 0.000000 normal_loss: 0.044526\n",
      "[033/00024] train_loss: 0.042396 kl_loss: 0.000000 normal_loss: 0.042396\n",
      "[034/00049] train_loss: 0.041516 kl_loss: 0.000000 normal_loss: 0.041516\n",
      "[035/00074] train_loss: 0.040286 kl_loss: 0.000000 normal_loss: 0.040286\n",
      "[037/00024] train_loss: 0.039482 kl_loss: 0.000000 normal_loss: 0.039482\n",
      "[038/00049] train_loss: 0.039414 kl_loss: 0.000000 normal_loss: 0.039414\n",
      "[039/00074] train_loss: 0.038704 kl_loss: 0.000000 normal_loss: 0.038704\n",
      "[041/00024] train_loss: 0.037147 kl_loss: 0.000000 normal_loss: 0.037147\n",
      "[042/00049] train_loss: 0.036394 kl_loss: 0.000000 normal_loss: 0.036394\n",
      "[043/00074] train_loss: 0.035746 kl_loss: 0.000000 normal_loss: 0.035746\n",
      "[045/00024] train_loss: 0.034762 kl_loss: 0.000000 normal_loss: 0.034762\n",
      "[046/00049] train_loss: 0.033424 kl_loss: 0.000000 normal_loss: 0.033424\n",
      "[047/00074] train_loss: 0.033722 kl_loss: 0.000000 normal_loss: 0.033722\n",
      "[049/00024] train_loss: 0.033844 kl_loss: 0.000000 normal_loss: 0.033844\n",
      "[049/00074] IOU 0.7622530335048213\n",
      "[050/00049] train_loss: 0.032229 kl_loss: 0.000000 normal_loss: 0.032229\n",
      "[051/00074] train_loss: 0.030781 kl_loss: 0.000000 normal_loss: 0.030781\n",
      "[053/00024] train_loss: 0.030600 kl_loss: 0.000000 normal_loss: 0.030600\n",
      "[054/00049] train_loss: 0.029736 kl_loss: 0.000000 normal_loss: 0.029736\n",
      "[055/00074] train_loss: 0.030456 kl_loss: 0.000000 normal_loss: 0.030456\n",
      "[057/00024] train_loss: 0.029372 kl_loss: 0.000000 normal_loss: 0.029372\n",
      "[058/00049] train_loss: 0.028534 kl_loss: 0.000000 normal_loss: 0.028534\n",
      "[059/00074] train_loss: 0.027996 kl_loss: 0.000000 normal_loss: 0.027996\n",
      "[061/00024] train_loss: 0.027135 kl_loss: 0.000000 normal_loss: 0.027135\n",
      "[062/00049] train_loss: 0.027203 kl_loss: 0.000000 normal_loss: 0.027203\n",
      "[063/00074] train_loss: 0.026554 kl_loss: 0.000000 normal_loss: 0.026554\n",
      "[065/00024] train_loss: 0.026542 kl_loss: 0.000000 normal_loss: 0.026542\n",
      "[066/00049] train_loss: 0.025803 kl_loss: 0.000000 normal_loss: 0.025803\n",
      "[067/00074] train_loss: 0.025319 kl_loss: 0.000000 normal_loss: 0.025319\n",
      "[069/00024] train_loss: 0.025430 kl_loss: 0.000000 normal_loss: 0.025430\n",
      "[070/00049] train_loss: 0.024336 kl_loss: 0.000000 normal_loss: 0.024336\n",
      "[071/00074] train_loss: 0.024208 kl_loss: 0.000000 normal_loss: 0.024208\n",
      "[073/00024] train_loss: 0.023858 kl_loss: 0.000000 normal_loss: 0.023858\n",
      "[074/00049] train_loss: 0.023339 kl_loss: 0.000000 normal_loss: 0.023339\n",
      "[075/00074] train_loss: 0.023397 kl_loss: 0.000000 normal_loss: 0.023397\n",
      "[077/00024] train_loss: 0.022137 kl_loss: 0.000000 normal_loss: 0.022137\n",
      "[078/00049] train_loss: 0.023627 kl_loss: 0.000000 normal_loss: 0.023627\n",
      "[079/00074] train_loss: 0.022821 kl_loss: 0.000000 normal_loss: 0.022821\n",
      "[081/00024] train_loss: 0.021747 kl_loss: 0.000000 normal_loss: 0.021747\n",
      "[082/00049] train_loss: 0.021771 kl_loss: 0.000000 normal_loss: 0.021771\n",
      "[083/00074] train_loss: 0.021447 kl_loss: 0.000000 normal_loss: 0.021447\n",
      "[085/00024] train_loss: 0.021570 kl_loss: 0.000000 normal_loss: 0.021570\n",
      "[086/00049] train_loss: 0.023595 kl_loss: 0.000000 normal_loss: 0.023595\n",
      "[087/00074] train_loss: 0.021081 kl_loss: 0.000000 normal_loss: 0.021081\n",
      "[089/00024] train_loss: 0.021024 kl_loss: 0.000000 normal_loss: 0.021024\n",
      "[090/00049] train_loss: 0.020293 kl_loss: 0.000000 normal_loss: 0.020293\n",
      "[091/00074] train_loss: 0.020695 kl_loss: 0.000000 normal_loss: 0.020695\n",
      "[093/00024] train_loss: 0.020079 kl_loss: 0.000000 normal_loss: 0.020079\n",
      "[094/00049] train_loss: 0.019900 kl_loss: 0.000000 normal_loss: 0.019900\n",
      "[095/00074] train_loss: 0.019607 kl_loss: 0.000000 normal_loss: 0.019607\n",
      "[097/00024] train_loss: 0.019325 kl_loss: 0.000000 normal_loss: 0.019325\n",
      "[098/00049] train_loss: 0.019085 kl_loss: 0.000000 normal_loss: 0.019085\n",
      "[099/00074] train_loss: 0.019873 kl_loss: 0.000000 normal_loss: 0.019873\n",
      "[099/00074] IOU 0.8655713971207539\n",
      "[101/00024] train_loss: 0.016658 kl_loss: 0.000000 normal_loss: 0.016658\n",
      "[102/00049] train_loss: 0.015480 kl_loss: 0.000000 normal_loss: 0.015480\n",
      "[103/00074] train_loss: 0.014648 kl_loss: 0.000000 normal_loss: 0.014648\n",
      "[105/00024] train_loss: 0.014769 kl_loss: 0.000000 normal_loss: 0.014769\n",
      "[106/00049] train_loss: 0.016084 kl_loss: 0.000000 normal_loss: 0.016084\n",
      "[107/00074] train_loss: 0.014534 kl_loss: 0.000000 normal_loss: 0.014534\n",
      "[109/00024] train_loss: 0.014817 kl_loss: 0.000000 normal_loss: 0.014817\n",
      "[110/00049] train_loss: 0.014652 kl_loss: 0.000000 normal_loss: 0.014652\n",
      "[111/00074] train_loss: 0.014367 kl_loss: 0.000000 normal_loss: 0.014367\n",
      "[113/00024] train_loss: 0.014340 kl_loss: 0.000000 normal_loss: 0.014340\n",
      "[114/00049] train_loss: 0.015159 kl_loss: 0.000000 normal_loss: 0.015159\n",
      "[115/00074] train_loss: 0.014448 kl_loss: 0.000000 normal_loss: 0.014448\n",
      "[117/00024] train_loss: 0.014429 kl_loss: 0.000000 normal_loss: 0.014429\n",
      "[118/00049] train_loss: 0.014190 kl_loss: 0.000000 normal_loss: 0.014190\n",
      "[119/00074] train_loss: 0.014278 kl_loss: 0.000000 normal_loss: 0.014278\n",
      "[121/00024] train_loss: 0.014228 kl_loss: 0.000000 normal_loss: 0.014228\n",
      "[122/00049] train_loss: 0.014223 kl_loss: 0.000000 normal_loss: 0.014223\n",
      "[123/00074] train_loss: 0.013981 kl_loss: 0.000000 normal_loss: 0.013981\n",
      "[125/00024] train_loss: 0.013909 kl_loss: 0.000000 normal_loss: 0.013909\n",
      "[126/00049] train_loss: 0.014281 kl_loss: 0.000000 normal_loss: 0.014281\n",
      "[127/00074] train_loss: 0.013830 kl_loss: 0.000000 normal_loss: 0.013830\n",
      "[129/00024] train_loss: 0.014006 kl_loss: 0.000000 normal_loss: 0.014006\n",
      "[130/00049] train_loss: 0.014121 kl_loss: 0.000000 normal_loss: 0.014121\n",
      "[131/00074] train_loss: 0.013807 kl_loss: 0.000000 normal_loss: 0.013807\n",
      "[133/00024] train_loss: 0.013787 kl_loss: 0.000000 normal_loss: 0.013787\n",
      "[134/00049] train_loss: 0.013484 kl_loss: 0.000000 normal_loss: 0.013484\n",
      "[135/00074] train_loss: 0.013499 kl_loss: 0.000000 normal_loss: 0.013499\n",
      "[137/00024] train_loss: 0.013692 kl_loss: 0.000000 normal_loss: 0.013692\n",
      "[138/00049] train_loss: 0.013088 kl_loss: 0.000000 normal_loss: 0.013088\n",
      "[139/00074] train_loss: 0.013704 kl_loss: 0.000000 normal_loss: 0.013704\n",
      "[141/00024] train_loss: 0.013468 kl_loss: 0.000000 normal_loss: 0.013468\n",
      "[142/00049] train_loss: 0.013239 kl_loss: 0.000000 normal_loss: 0.013239\n",
      "[143/00074] train_loss: 0.013199 kl_loss: 0.000000 normal_loss: 0.013199\n",
      "[145/00024] train_loss: 0.013233 kl_loss: 0.000000 normal_loss: 0.013233\n",
      "[146/00049] train_loss: 0.013188 kl_loss: 0.000000 normal_loss: 0.013188\n",
      "[147/00074] train_loss: 0.013026 kl_loss: 0.000000 normal_loss: 0.013026\n",
      "[149/00024] train_loss: 0.013072 kl_loss: 0.000000 normal_loss: 0.013072\n",
      "[149/00074] IOU 0.8918958876344065\n",
      "[150/00049] train_loss: 0.012995 kl_loss: 0.000000 normal_loss: 0.012995\n",
      "[151/00074] train_loss: 0.012918 kl_loss: 0.000000 normal_loss: 0.012918\n",
      "[153/00024] train_loss: 0.013256 kl_loss: 0.000000 normal_loss: 0.013256\n",
      "[154/00049] train_loss: 0.012769 kl_loss: 0.000000 normal_loss: 0.012769\n",
      "[155/00074] train_loss: 0.012903 kl_loss: 0.000000 normal_loss: 0.012903\n",
      "[157/00024] train_loss: 0.012863 kl_loss: 0.000000 normal_loss: 0.012863\n",
      "[158/00049] train_loss: 0.012738 kl_loss: 0.000000 normal_loss: 0.012738\n",
      "[159/00074] train_loss: 0.013069 kl_loss: 0.000000 normal_loss: 0.013069\n",
      "[161/00024] train_loss: 0.012759 kl_loss: 0.000000 normal_loss: 0.012759\n",
      "[162/00049] train_loss: 0.012512 kl_loss: 0.000000 normal_loss: 0.012512\n",
      "[163/00074] train_loss: 0.012702 kl_loss: 0.000000 normal_loss: 0.012702\n",
      "[165/00024] train_loss: 0.012281 kl_loss: 0.000000 normal_loss: 0.012281\n",
      "[166/00049] train_loss: 0.012643 kl_loss: 0.000000 normal_loss: 0.012643\n",
      "[167/00074] train_loss: 0.012493 kl_loss: 0.000000 normal_loss: 0.012493\n",
      "[169/00024] train_loss: 0.012528 kl_loss: 0.000000 normal_loss: 0.012528\n",
      "[170/00049] train_loss: 0.012374 kl_loss: 0.000000 normal_loss: 0.012374\n",
      "[171/00074] train_loss: 0.012414 kl_loss: 0.000000 normal_loss: 0.012414\n",
      "[173/00024] train_loss: 0.012233 kl_loss: 0.000000 normal_loss: 0.012233\n",
      "[174/00049] train_loss: 0.012403 kl_loss: 0.000000 normal_loss: 0.012403\n",
      "[175/00074] train_loss: 0.012256 kl_loss: 0.000000 normal_loss: 0.012256\n",
      "[177/00024] train_loss: 0.012279 kl_loss: 0.000000 normal_loss: 0.012279\n",
      "[178/00049] train_loss: 0.011979 kl_loss: 0.000000 normal_loss: 0.011979\n",
      "[179/00074] train_loss: 0.011892 kl_loss: 0.000000 normal_loss: 0.011892\n",
      "[181/00024] train_loss: 0.012069 kl_loss: 0.000000 normal_loss: 0.012069\n",
      "[182/00049] train_loss: 0.011950 kl_loss: 0.000000 normal_loss: 0.011950\n",
      "[183/00074] train_loss: 0.012135 kl_loss: 0.000000 normal_loss: 0.012135\n",
      "[185/00024] train_loss: 0.012050 kl_loss: 0.000000 normal_loss: 0.012050\n",
      "[186/00049] train_loss: 0.012243 kl_loss: 0.000000 normal_loss: 0.012243\n",
      "[187/00074] train_loss: 0.012127 kl_loss: 0.000000 normal_loss: 0.012127\n",
      "[189/00024] train_loss: 0.011887 kl_loss: 0.000000 normal_loss: 0.011887\n",
      "[190/00049] train_loss: 0.011886 kl_loss: 0.000000 normal_loss: 0.011886\n",
      "[191/00074] train_loss: 0.011742 kl_loss: 0.000000 normal_loss: 0.011742\n",
      "[193/00024] train_loss: 0.011814 kl_loss: 0.000000 normal_loss: 0.011814\n",
      "[194/00049] train_loss: 0.011699 kl_loss: 0.000000 normal_loss: 0.011699\n",
      "[195/00074] train_loss: 0.011788 kl_loss: 0.000000 normal_loss: 0.011788\n",
      "[197/00024] train_loss: 0.011886 kl_loss: 0.000000 normal_loss: 0.011886\n",
      "[198/00049] train_loss: 0.011643 kl_loss: 0.000000 normal_loss: 0.011643\n",
      "[199/00074] train_loss: 0.011573 kl_loss: 0.000000 normal_loss: 0.011573\n",
      "[199/00074] IOU 0.905182747785002\n",
      "[201/00024] train_loss: 0.010377 kl_loss: 0.000000 normal_loss: 0.010377\n",
      "[202/00049] train_loss: 0.009947 kl_loss: 0.000000 normal_loss: 0.009947\n",
      "[203/00074] train_loss: 0.009725 kl_loss: 0.000000 normal_loss: 0.009725\n",
      "[205/00024] train_loss: 0.009883 kl_loss: 0.000000 normal_loss: 0.009883\n",
      "[206/00049] train_loss: 0.009887 kl_loss: 0.000000 normal_loss: 0.009887\n",
      "[207/00074] train_loss: 0.009953 kl_loss: 0.000000 normal_loss: 0.009953\n",
      "[209/00024] train_loss: 0.009872 kl_loss: 0.000000 normal_loss: 0.009872\n",
      "[210/00049] train_loss: 0.010071 kl_loss: 0.000000 normal_loss: 0.010071\n",
      "[211/00074] train_loss: 0.009833 kl_loss: 0.000000 normal_loss: 0.009833\n",
      "[213/00024] train_loss: 0.009793 kl_loss: 0.000000 normal_loss: 0.009793\n",
      "[214/00049] train_loss: 0.009823 kl_loss: 0.000000 normal_loss: 0.009823\n",
      "[215/00074] train_loss: 0.009684 kl_loss: 0.000000 normal_loss: 0.009684\n",
      "[217/00024] train_loss: 0.009797 kl_loss: 0.000000 normal_loss: 0.009797\n",
      "[218/00049] train_loss: 0.009706 kl_loss: 0.000000 normal_loss: 0.009706\n",
      "[219/00074] train_loss: 0.009859 kl_loss: 0.000000 normal_loss: 0.009859\n",
      "[221/00024] train_loss: 0.009833 kl_loss: 0.000000 normal_loss: 0.009833\n",
      "[222/00049] train_loss: 0.009789 kl_loss: 0.000000 normal_loss: 0.009789\n",
      "[223/00074] train_loss: 0.009782 kl_loss: 0.000000 normal_loss: 0.009782\n",
      "[225/00024] train_loss: 0.009711 kl_loss: 0.000000 normal_loss: 0.009711\n",
      "[226/00049] train_loss: 0.009779 kl_loss: 0.000000 normal_loss: 0.009779\n",
      "[227/00074] train_loss: 0.009647 kl_loss: 0.000000 normal_loss: 0.009647\n",
      "[229/00024] train_loss: 0.009610 kl_loss: 0.000000 normal_loss: 0.009610\n",
      "[230/00049] train_loss: 0.009632 kl_loss: 0.000000 normal_loss: 0.009632\n",
      "[231/00074] train_loss: 0.009604 kl_loss: 0.000000 normal_loss: 0.009604\n",
      "[233/00024] train_loss: 0.009519 kl_loss: 0.000000 normal_loss: 0.009519\n",
      "[234/00049] train_loss: 0.009646 kl_loss: 0.000000 normal_loss: 0.009646\n",
      "[235/00074] train_loss: 0.009728 kl_loss: 0.000000 normal_loss: 0.009728\n",
      "[237/00024] train_loss: 0.009822 kl_loss: 0.000000 normal_loss: 0.009822\n",
      "[238/00049] train_loss: 0.009763 kl_loss: 0.000000 normal_loss: 0.009763\n",
      "[239/00074] train_loss: 0.009536 kl_loss: 0.000000 normal_loss: 0.009536\n",
      "[241/00024] train_loss: 0.009630 kl_loss: 0.000000 normal_loss: 0.009630\n",
      "[242/00049] train_loss: 0.009532 kl_loss: 0.000000 normal_loss: 0.009532\n",
      "[243/00074] train_loss: 0.009560 kl_loss: 0.000000 normal_loss: 0.009560\n",
      "[245/00024] train_loss: 0.009768 kl_loss: 0.000000 normal_loss: 0.009768\n",
      "[246/00049] train_loss: 0.009695 kl_loss: 0.000000 normal_loss: 0.009695\n",
      "[247/00074] train_loss: 0.009559 kl_loss: 0.000000 normal_loss: 0.009559\n",
      "[249/00024] train_loss: 0.009581 kl_loss: 0.000000 normal_loss: 0.009581\n",
      "[249/00074] IOU 0.9117270767937103\n",
      "[250/00049] train_loss: 0.009403 kl_loss: 0.000000 normal_loss: 0.009403\n",
      "[251/00074] train_loss: 0.009483 kl_loss: 0.000000 normal_loss: 0.009483\n",
      "[253/00024] train_loss: 0.009401 kl_loss: 0.000000 normal_loss: 0.009401\n",
      "[254/00049] train_loss: 0.009466 kl_loss: 0.000000 normal_loss: 0.009466\n",
      "[255/00074] train_loss: 0.009541 kl_loss: 0.000000 normal_loss: 0.009541\n",
      "[257/00024] train_loss: 0.009438 kl_loss: 0.000000 normal_loss: 0.009438\n",
      "[258/00049] train_loss: 0.009436 kl_loss: 0.000000 normal_loss: 0.009436\n",
      "[259/00074] train_loss: 0.009550 kl_loss: 0.000000 normal_loss: 0.009550\n",
      "[261/00024] train_loss: 0.009406 kl_loss: 0.000000 normal_loss: 0.009406\n",
      "[262/00049] train_loss: 0.009444 kl_loss: 0.000000 normal_loss: 0.009444\n",
      "[263/00074] train_loss: 0.009470 kl_loss: 0.000000 normal_loss: 0.009470\n",
      "[265/00024] train_loss: 0.009471 kl_loss: 0.000000 normal_loss: 0.009471\n",
      "[266/00049] train_loss: 0.009330 kl_loss: 0.000000 normal_loss: 0.009330\n",
      "[267/00074] train_loss: 0.009408 kl_loss: 0.000000 normal_loss: 0.009408\n",
      "[269/00024] train_loss: 0.009331 kl_loss: 0.000000 normal_loss: 0.009331\n",
      "[270/00049] train_loss: 0.009181 kl_loss: 0.000000 normal_loss: 0.009181\n",
      "[271/00074] train_loss: 0.009260 kl_loss: 0.000000 normal_loss: 0.009260\n",
      "[273/00024] train_loss: 0.009280 kl_loss: 0.000000 normal_loss: 0.009280\n",
      "[274/00049] train_loss: 0.009348 kl_loss: 0.000000 normal_loss: 0.009348\n",
      "[275/00074] train_loss: 0.009229 kl_loss: 0.000000 normal_loss: 0.009229\n",
      "[277/00024] train_loss: 0.009139 kl_loss: 0.000000 normal_loss: 0.009139\n",
      "[278/00049] train_loss: 0.009318 kl_loss: 0.000000 normal_loss: 0.009318\n",
      "[279/00074] train_loss: 0.009370 kl_loss: 0.000000 normal_loss: 0.009370\n",
      "[281/00024] train_loss: 0.009266 kl_loss: 0.000000 normal_loss: 0.009266\n",
      "[282/00049] train_loss: 0.009135 kl_loss: 0.000000 normal_loss: 0.009135\n",
      "[283/00074] train_loss: 0.009251 kl_loss: 0.000000 normal_loss: 0.009251\n",
      "[285/00024] train_loss: 0.009162 kl_loss: 0.000000 normal_loss: 0.009162\n",
      "[286/00049] train_loss: 0.009173 kl_loss: 0.000000 normal_loss: 0.009173\n",
      "[287/00074] train_loss: 0.009311 kl_loss: 0.000000 normal_loss: 0.009311\n",
      "[289/00024] train_loss: 0.009150 kl_loss: 0.000000 normal_loss: 0.009150\n",
      "[290/00049] train_loss: 0.009117 kl_loss: 0.000000 normal_loss: 0.009117\n",
      "[291/00074] train_loss: 0.009457 kl_loss: 0.000000 normal_loss: 0.009457\n",
      "[293/00024] train_loss: 0.009151 kl_loss: 0.000000 normal_loss: 0.009151\n",
      "[294/00049] train_loss: 0.009170 kl_loss: 0.000000 normal_loss: 0.009170\n",
      "[295/00074] train_loss: 0.009162 kl_loss: 0.000000 normal_loss: 0.009162\n",
      "[297/00024] train_loss: 0.009070 kl_loss: 0.000000 normal_loss: 0.009070\n",
      "[298/00049] train_loss: 0.009079 kl_loss: 0.000000 normal_loss: 0.009079\n",
      "[299/00074] train_loss: 0.009035 kl_loss: 0.000000 normal_loss: 0.009035\n",
      "[299/00074] IOU 0.918188418423136\n",
      "[301/00024] train_loss: 0.008645 kl_loss: 0.000000 normal_loss: 0.008645\n",
      "[302/00049] train_loss: 0.008626 kl_loss: 0.000000 normal_loss: 0.008626\n",
      "[303/00074] train_loss: 0.008374 kl_loss: 0.000000 normal_loss: 0.008374\n",
      "[305/00024] train_loss: 0.008354 kl_loss: 0.000000 normal_loss: 0.008354\n",
      "[306/00049] train_loss: 0.008309 kl_loss: 0.000000 normal_loss: 0.008309\n",
      "[307/00074] train_loss: 0.008409 kl_loss: 0.000000 normal_loss: 0.008409\n",
      "[309/00024] train_loss: 0.008408 kl_loss: 0.000000 normal_loss: 0.008408\n",
      "[310/00049] train_loss: 0.008270 kl_loss: 0.000000 normal_loss: 0.008270\n",
      "[311/00074] train_loss: 0.008391 kl_loss: 0.000000 normal_loss: 0.008391\n",
      "[313/00024] train_loss: 0.008340 kl_loss: 0.000000 normal_loss: 0.008340\n",
      "[314/00049] train_loss: 0.008402 kl_loss: 0.000000 normal_loss: 0.008402\n",
      "[315/00074] train_loss: 0.008339 kl_loss: 0.000000 normal_loss: 0.008339\n",
      "[317/00024] train_loss: 0.008278 kl_loss: 0.000000 normal_loss: 0.008278\n",
      "[318/00049] train_loss: 0.008322 kl_loss: 0.000000 normal_loss: 0.008322\n",
      "[319/00074] train_loss: 0.008336 kl_loss: 0.000000 normal_loss: 0.008336\n",
      "[321/00024] train_loss: 0.008316 kl_loss: 0.000000 normal_loss: 0.008316\n",
      "[322/00049] train_loss: 0.008351 kl_loss: 0.000000 normal_loss: 0.008351\n",
      "[323/00074] train_loss: 0.008341 kl_loss: 0.000000 normal_loss: 0.008341\n",
      "[325/00024] train_loss: 0.008288 kl_loss: 0.000000 normal_loss: 0.008288\n",
      "[326/00049] train_loss: 0.008339 kl_loss: 0.000000 normal_loss: 0.008339\n",
      "[327/00074] train_loss: 0.008353 kl_loss: 0.000000 normal_loss: 0.008353\n",
      "[329/00024] train_loss: 0.008343 kl_loss: 0.000000 normal_loss: 0.008343\n",
      "[330/00049] train_loss: 0.008359 kl_loss: 0.000000 normal_loss: 0.008359\n",
      "[331/00074] train_loss: 0.008310 kl_loss: 0.000000 normal_loss: 0.008310\n",
      "[333/00024] train_loss: 0.008287 kl_loss: 0.000000 normal_loss: 0.008287\n",
      "[334/00049] train_loss: 0.008249 kl_loss: 0.000000 normal_loss: 0.008249\n",
      "[335/00074] train_loss: 0.008330 kl_loss: 0.000000 normal_loss: 0.008330\n",
      "[337/00024] train_loss: 0.008247 kl_loss: 0.000000 normal_loss: 0.008247\n",
      "[338/00049] train_loss: 0.008313 kl_loss: 0.000000 normal_loss: 0.008313\n",
      "[339/00074] train_loss: 0.008270 kl_loss: 0.000000 normal_loss: 0.008270\n",
      "[341/00024] train_loss: 0.008267 kl_loss: 0.000000 normal_loss: 0.008267\n",
      "[342/00049] train_loss: 0.008220 kl_loss: 0.000000 normal_loss: 0.008220\n",
      "[343/00074] train_loss: 0.008186 kl_loss: 0.000000 normal_loss: 0.008186\n",
      "[345/00024] train_loss: 0.008237 kl_loss: 0.000000 normal_loss: 0.008237\n",
      "[346/00049] train_loss: 0.008186 kl_loss: 0.000000 normal_loss: 0.008186\n",
      "[347/00074] train_loss: 0.008210 kl_loss: 0.000000 normal_loss: 0.008210\n",
      "[349/00024] train_loss: 0.008151 kl_loss: 0.000000 normal_loss: 0.008151\n",
      "[349/00074] IOU 0.9216015450966855\n",
      "[350/00049] train_loss: 0.008175 kl_loss: 0.000000 normal_loss: 0.008175\n",
      "[351/00074] train_loss: 0.008192 kl_loss: 0.000000 normal_loss: 0.008192\n",
      "[353/00024] train_loss: 0.008168 kl_loss: 0.000000 normal_loss: 0.008168\n",
      "[354/00049] train_loss: 0.008103 kl_loss: 0.000000 normal_loss: 0.008103\n",
      "[355/00074] train_loss: 0.008230 kl_loss: 0.000000 normal_loss: 0.008230\n",
      "[357/00024] train_loss: 0.008196 kl_loss: 0.000000 normal_loss: 0.008196\n",
      "[358/00049] train_loss: 0.008185 kl_loss: 0.000000 normal_loss: 0.008185\n",
      "[359/00074] train_loss: 0.008179 kl_loss: 0.000000 normal_loss: 0.008179\n",
      "[361/00024] train_loss: 0.008169 kl_loss: 0.000000 normal_loss: 0.008169\n",
      "[362/00049] train_loss: 0.008159 kl_loss: 0.000000 normal_loss: 0.008159\n",
      "[363/00074] train_loss: 0.008145 kl_loss: 0.000000 normal_loss: 0.008145\n",
      "[365/00024] train_loss: 0.008176 kl_loss: 0.000000 normal_loss: 0.008176\n",
      "[366/00049] train_loss: 0.008138 kl_loss: 0.000000 normal_loss: 0.008138\n",
      "[367/00074] train_loss: 0.008125 kl_loss: 0.000000 normal_loss: 0.008125\n",
      "[369/00024] train_loss: 0.008222 kl_loss: 0.000000 normal_loss: 0.008222\n",
      "[370/00049] train_loss: 0.008111 kl_loss: 0.000000 normal_loss: 0.008111\n",
      "[371/00074] train_loss: 0.008109 kl_loss: 0.000000 normal_loss: 0.008109\n",
      "[373/00024] train_loss: 0.008090 kl_loss: 0.000000 normal_loss: 0.008090\n",
      "[374/00049] train_loss: 0.008116 kl_loss: 0.000000 normal_loss: 0.008116\n",
      "[375/00074] train_loss: 0.008121 kl_loss: 0.000000 normal_loss: 0.008121\n",
      "[377/00024] train_loss: 0.008143 kl_loss: 0.000000 normal_loss: 0.008143\n",
      "[378/00049] train_loss: 0.008087 kl_loss: 0.000000 normal_loss: 0.008087\n",
      "[379/00074] train_loss: 0.008109 kl_loss: 0.000000 normal_loss: 0.008109\n",
      "[381/00024] train_loss: 0.008032 kl_loss: 0.000000 normal_loss: 0.008032\n",
      "[382/00049] train_loss: 0.008130 kl_loss: 0.000000 normal_loss: 0.008130\n",
      "[383/00074] train_loss: 0.008082 kl_loss: 0.000000 normal_loss: 0.008082\n",
      "[385/00024] train_loss: 0.008399 kl_loss: 0.000000 normal_loss: 0.008399\n",
      "[386/00049] train_loss: 0.008161 kl_loss: 0.000000 normal_loss: 0.008161\n",
      "[387/00074] train_loss: 0.008120 kl_loss: 0.000000 normal_loss: 0.008120\n",
      "[389/00024] train_loss: 0.007964 kl_loss: 0.000000 normal_loss: 0.007964\n",
      "[390/00049] train_loss: 0.008060 kl_loss: 0.000000 normal_loss: 0.008060\n",
      "[391/00074] train_loss: 0.008054 kl_loss: 0.000000 normal_loss: 0.008054\n",
      "[393/00024] train_loss: 0.008057 kl_loss: 0.000000 normal_loss: 0.008057\n",
      "[394/00049] train_loss: 0.007999 kl_loss: 0.000000 normal_loss: 0.007999\n",
      "[395/00074] train_loss: 0.008074 kl_loss: 0.000000 normal_loss: 0.008074\n",
      "[397/00024] train_loss: 0.007996 kl_loss: 0.000000 normal_loss: 0.007996\n",
      "[398/00049] train_loss: 0.007980 kl_loss: 0.000000 normal_loss: 0.007980\n",
      "[399/00074] train_loss: 0.007986 kl_loss: 0.000000 normal_loss: 0.007986\n",
      "[399/00074] IOU 0.9229857251731058\n",
      "[401/00024] train_loss: 0.007774 kl_loss: 0.000000 normal_loss: 0.007774\n",
      "[402/00049] train_loss: 0.007787 kl_loss: 0.000000 normal_loss: 0.007787\n",
      "[403/00074] train_loss: 0.007738 kl_loss: 0.000000 normal_loss: 0.007738\n",
      "[405/00024] train_loss: 0.007694 kl_loss: 0.000000 normal_loss: 0.007694\n",
      "[406/00049] train_loss: 0.007777 kl_loss: 0.000000 normal_loss: 0.007777\n",
      "[407/00074] train_loss: 0.007658 kl_loss: 0.000000 normal_loss: 0.007658\n",
      "[409/00024] train_loss: 0.007714 kl_loss: 0.000000 normal_loss: 0.007714\n",
      "[410/00049] train_loss: 0.007657 kl_loss: 0.000000 normal_loss: 0.007657\n",
      "[411/00074] train_loss: 0.007752 kl_loss: 0.000000 normal_loss: 0.007752\n",
      "[413/00024] train_loss: 0.007709 kl_loss: 0.000000 normal_loss: 0.007709\n",
      "[414/00049] train_loss: 0.007831 kl_loss: 0.000000 normal_loss: 0.007831\n",
      "[415/00074] train_loss: 0.007738 kl_loss: 0.000000 normal_loss: 0.007738\n",
      "[417/00024] train_loss: 0.007736 kl_loss: 0.000000 normal_loss: 0.007736\n",
      "[418/00049] train_loss: 0.007679 kl_loss: 0.000000 normal_loss: 0.007679\n",
      "[419/00074] train_loss: 0.007703 kl_loss: 0.000000 normal_loss: 0.007703\n",
      "[421/00024] train_loss: 0.007694 kl_loss: 0.000000 normal_loss: 0.007694\n",
      "[422/00049] train_loss: 0.007706 kl_loss: 0.000000 normal_loss: 0.007706\n",
      "[423/00074] train_loss: 0.007672 kl_loss: 0.000000 normal_loss: 0.007672\n",
      "[425/00024] train_loss: 0.007741 kl_loss: 0.000000 normal_loss: 0.007741\n",
      "[426/00049] train_loss: 0.007712 kl_loss: 0.000000 normal_loss: 0.007712\n",
      "[427/00074] train_loss: 0.007709 kl_loss: 0.000000 normal_loss: 0.007709\n",
      "[429/00024] train_loss: 0.007665 kl_loss: 0.000000 normal_loss: 0.007665\n",
      "[430/00049] train_loss: 0.007666 kl_loss: 0.000000 normal_loss: 0.007666\n",
      "[431/00074] train_loss: 0.007667 kl_loss: 0.000000 normal_loss: 0.007667\n",
      "[433/00024] train_loss: 0.007704 kl_loss: 0.000000 normal_loss: 0.007704\n",
      "[434/00049] train_loss: 0.007652 kl_loss: 0.000000 normal_loss: 0.007652\n",
      "[435/00074] train_loss: 0.007652 kl_loss: 0.000000 normal_loss: 0.007652\n",
      "[437/00024] train_loss: 0.007715 kl_loss: 0.000000 normal_loss: 0.007715\n",
      "[438/00049] train_loss: 0.007689 kl_loss: 0.000000 normal_loss: 0.007689\n",
      "[439/00074] train_loss: 0.007709 kl_loss: 0.000000 normal_loss: 0.007709\n",
      "[441/00024] train_loss: 0.007662 kl_loss: 0.000000 normal_loss: 0.007662\n",
      "[442/00049] train_loss: 0.007702 kl_loss: 0.000000 normal_loss: 0.007702\n",
      "[443/00074] train_loss: 0.007661 kl_loss: 0.000000 normal_loss: 0.007661\n",
      "[445/00024] train_loss: 0.007714 kl_loss: 0.000000 normal_loss: 0.007714\n",
      "[446/00049] train_loss: 0.007593 kl_loss: 0.000000 normal_loss: 0.007593\n",
      "[447/00074] train_loss: 0.007666 kl_loss: 0.000000 normal_loss: 0.007666\n",
      "[449/00024] train_loss: 0.007611 kl_loss: 0.000000 normal_loss: 0.007611\n",
      "[449/00074] IOU 0.9239503654030462\n",
      "[450/00049] train_loss: 0.007604 kl_loss: 0.000000 normal_loss: 0.007604\n",
      "[451/00074] train_loss: 0.007650 kl_loss: 0.000000 normal_loss: 0.007650\n",
      "[453/00024] train_loss: 0.007750 kl_loss: 0.000000 normal_loss: 0.007750\n",
      "[454/00049] train_loss: 0.007654 kl_loss: 0.000000 normal_loss: 0.007654\n",
      "[455/00074] train_loss: 0.007612 kl_loss: 0.000000 normal_loss: 0.007612\n",
      "[457/00024] train_loss: 0.007651 kl_loss: 0.000000 normal_loss: 0.007651\n",
      "[458/00049] train_loss: 0.007642 kl_loss: 0.000000 normal_loss: 0.007642\n",
      "[459/00074] train_loss: 0.007595 kl_loss: 0.000000 normal_loss: 0.007595\n",
      "[461/00024] train_loss: 0.007605 kl_loss: 0.000000 normal_loss: 0.007605\n",
      "[462/00049] train_loss: 0.007568 kl_loss: 0.000000 normal_loss: 0.007568\n",
      "[463/00074] train_loss: 0.007596 kl_loss: 0.000000 normal_loss: 0.007596\n",
      "[465/00024] train_loss: 0.007601 kl_loss: 0.000000 normal_loss: 0.007601\n",
      "[466/00049] train_loss: 0.007634 kl_loss: 0.000000 normal_loss: 0.007634\n",
      "[467/00074] train_loss: 0.007598 kl_loss: 0.000000 normal_loss: 0.007598\n",
      "[469/00024] train_loss: 0.007605 kl_loss: 0.000000 normal_loss: 0.007605\n",
      "[470/00049] train_loss: 0.007650 kl_loss: 0.000000 normal_loss: 0.007650\n",
      "[471/00074] train_loss: 0.007589 kl_loss: 0.000000 normal_loss: 0.007589\n",
      "[473/00024] train_loss: 0.007680 kl_loss: 0.000000 normal_loss: 0.007680\n",
      "[474/00049] train_loss: 0.007506 kl_loss: 0.000000 normal_loss: 0.007506\n",
      "[475/00074] train_loss: 0.007719 kl_loss: 0.000000 normal_loss: 0.007719\n",
      "[477/00024] train_loss: 0.007574 kl_loss: 0.000000 normal_loss: 0.007574\n",
      "[478/00049] train_loss: 0.007602 kl_loss: 0.000000 normal_loss: 0.007602\n",
      "[479/00074] train_loss: 0.007552 kl_loss: 0.000000 normal_loss: 0.007552\n",
      "[481/00024] train_loss: 0.007595 kl_loss: 0.000000 normal_loss: 0.007595\n",
      "[482/00049] train_loss: 0.007643 kl_loss: 0.000000 normal_loss: 0.007643\n",
      "[483/00074] train_loss: 0.007583 kl_loss: 0.000000 normal_loss: 0.007583\n",
      "[485/00024] train_loss: 0.007576 kl_loss: 0.000000 normal_loss: 0.007576\n",
      "[486/00049] train_loss: 0.007607 kl_loss: 0.000000 normal_loss: 0.007607\n",
      "[487/00074] train_loss: 0.007605 kl_loss: 0.000000 normal_loss: 0.007605\n",
      "[489/00024] train_loss: 0.007563 kl_loss: 0.000000 normal_loss: 0.007563\n",
      "[490/00049] train_loss: 0.007519 kl_loss: 0.000000 normal_loss: 0.007519\n",
      "[491/00074] train_loss: 0.007551 kl_loss: 0.000000 normal_loss: 0.007551\n",
      "[493/00024] train_loss: 0.007536 kl_loss: 0.000000 normal_loss: 0.007536\n",
      "[494/00049] train_loss: 0.007555 kl_loss: 0.000000 normal_loss: 0.007555\n",
      "[495/00074] train_loss: 0.007599 kl_loss: 0.000000 normal_loss: 0.007599\n",
      "[497/00024] train_loss: 0.007508 kl_loss: 0.000000 normal_loss: 0.007508\n",
      "[498/00049] train_loss: 0.007557 kl_loss: 0.000000 normal_loss: 0.007557\n",
      "[499/00074] train_loss: 0.007536 kl_loss: 0.000000 normal_loss: 0.007536\n",
      "[499/00074] IOU 0.9246742397360503\n",
      "[501/00024] train_loss: 0.007434 kl_loss: 0.000000 normal_loss: 0.007434\n",
      "[502/00049] train_loss: 0.007427 kl_loss: 0.000000 normal_loss: 0.007427\n",
      "[503/00074] train_loss: 0.007451 kl_loss: 0.000000 normal_loss: 0.007451\n",
      "[505/00024] train_loss: 0.007393 kl_loss: 0.000000 normal_loss: 0.007393\n",
      "[506/00049] train_loss: 0.007461 kl_loss: 0.000000 normal_loss: 0.007461\n",
      "[507/00074] train_loss: 0.007396 kl_loss: 0.000000 normal_loss: 0.007396\n",
      "[509/00024] train_loss: 0.007435 kl_loss: 0.000000 normal_loss: 0.007435\n",
      "[510/00049] train_loss: 0.007399 kl_loss: 0.000000 normal_loss: 0.007399\n",
      "[511/00074] train_loss: 0.007397 kl_loss: 0.000000 normal_loss: 0.007397\n",
      "[513/00024] train_loss: 0.007392 kl_loss: 0.000000 normal_loss: 0.007392\n",
      "[514/00049] train_loss: 0.007383 kl_loss: 0.000000 normal_loss: 0.007383\n",
      "[515/00074] train_loss: 0.007414 kl_loss: 0.000000 normal_loss: 0.007414\n",
      "[517/00024] train_loss: 0.007451 kl_loss: 0.000000 normal_loss: 0.007451\n",
      "[518/00049] train_loss: 0.007426 kl_loss: 0.000000 normal_loss: 0.007426\n",
      "[519/00074] train_loss: 0.007383 kl_loss: 0.000000 normal_loss: 0.007383\n",
      "[521/00024] train_loss: 0.007374 kl_loss: 0.000000 normal_loss: 0.007374\n",
      "[522/00049] train_loss: 0.007368 kl_loss: 0.000000 normal_loss: 0.007368\n",
      "[523/00074] train_loss: 0.007395 kl_loss: 0.000000 normal_loss: 0.007395\n",
      "[525/00024] train_loss: 0.007411 kl_loss: 0.000000 normal_loss: 0.007411\n",
      "[526/00049] train_loss: 0.007370 kl_loss: 0.000000 normal_loss: 0.007370\n",
      "[527/00074] train_loss: 0.007391 kl_loss: 0.000000 normal_loss: 0.007391\n",
      "[529/00024] train_loss: 0.007445 kl_loss: 0.000000 normal_loss: 0.007445\n",
      "[530/00049] train_loss: 0.007336 kl_loss: 0.000000 normal_loss: 0.007336\n",
      "[531/00074] train_loss: 0.007395 kl_loss: 0.000000 normal_loss: 0.007395\n",
      "[533/00024] train_loss: 0.007419 kl_loss: 0.000000 normal_loss: 0.007419\n",
      "[534/00049] train_loss: 0.007384 kl_loss: 0.000000 normal_loss: 0.007384\n",
      "[535/00074] train_loss: 0.007372 kl_loss: 0.000000 normal_loss: 0.007372\n",
      "[537/00024] train_loss: 0.007379 kl_loss: 0.000000 normal_loss: 0.007379\n",
      "[538/00049] train_loss: 0.007354 kl_loss: 0.000000 normal_loss: 0.007354\n",
      "[539/00074] train_loss: 0.007384 kl_loss: 0.000000 normal_loss: 0.007384\n",
      "[541/00024] train_loss: 0.007398 kl_loss: 0.000000 normal_loss: 0.007398\n",
      "[542/00049] train_loss: 0.007352 kl_loss: 0.000000 normal_loss: 0.007352\n",
      "[543/00074] train_loss: 0.007407 kl_loss: 0.000000 normal_loss: 0.007407\n",
      "[545/00024] train_loss: 0.007361 kl_loss: 0.000000 normal_loss: 0.007361\n",
      "[546/00049] train_loss: 0.007383 kl_loss: 0.000000 normal_loss: 0.007383\n",
      "[547/00074] train_loss: 0.007347 kl_loss: 0.000000 normal_loss: 0.007347\n",
      "[549/00024] train_loss: 0.007396 kl_loss: 0.000000 normal_loss: 0.007396\n",
      "[549/00074] IOU 0.9263209449810287\n",
      "[550/00049] train_loss: 0.007383 kl_loss: 0.000000 normal_loss: 0.007383\n",
      "[551/00074] train_loss: 0.007368 kl_loss: 0.000000 normal_loss: 0.007368\n",
      "[553/00024] train_loss: 0.007386 kl_loss: 0.000000 normal_loss: 0.007386\n",
      "[554/00049] train_loss: 0.007384 kl_loss: 0.000000 normal_loss: 0.007384\n",
      "[555/00074] train_loss: 0.007351 kl_loss: 0.000000 normal_loss: 0.007351\n",
      "[557/00024] train_loss: 0.007321 kl_loss: 0.000000 normal_loss: 0.007321\n",
      "[558/00049] train_loss: 0.007414 kl_loss: 0.000000 normal_loss: 0.007414\n",
      "[559/00074] train_loss: 0.007342 kl_loss: 0.000000 normal_loss: 0.007342\n",
      "[561/00024] train_loss: 0.007379 kl_loss: 0.000000 normal_loss: 0.007379\n",
      "[562/00049] train_loss: 0.007362 kl_loss: 0.000000 normal_loss: 0.007362\n",
      "[563/00074] train_loss: 0.007373 kl_loss: 0.000000 normal_loss: 0.007373\n",
      "[565/00024] train_loss: 0.007366 kl_loss: 0.000000 normal_loss: 0.007366\n",
      "[566/00049] train_loss: 0.007343 kl_loss: 0.000000 normal_loss: 0.007343\n",
      "[567/00074] train_loss: 0.007324 kl_loss: 0.000000 normal_loss: 0.007324\n",
      "[569/00024] train_loss: 0.007333 kl_loss: 0.000000 normal_loss: 0.007333\n",
      "[570/00049] train_loss: 0.007323 kl_loss: 0.000000 normal_loss: 0.007323\n",
      "[571/00074] train_loss: 0.007354 kl_loss: 0.000000 normal_loss: 0.007354\n",
      "[573/00024] train_loss: 0.007307 kl_loss: 0.000000 normal_loss: 0.007307\n",
      "[574/00049] train_loss: 0.007354 kl_loss: 0.000000 normal_loss: 0.007354\n",
      "[575/00074] train_loss: 0.007339 kl_loss: 0.000000 normal_loss: 0.007339\n",
      "[577/00024] train_loss: 0.007347 kl_loss: 0.000000 normal_loss: 0.007347\n",
      "[578/00049] train_loss: 0.007352 kl_loss: 0.000000 normal_loss: 0.007352\n",
      "[579/00074] train_loss: 0.007356 kl_loss: 0.000000 normal_loss: 0.007356\n",
      "[581/00024] train_loss: 0.007323 kl_loss: 0.000000 normal_loss: 0.007323\n",
      "[582/00049] train_loss: 0.007302 kl_loss: 0.000000 normal_loss: 0.007302\n",
      "[583/00074] train_loss: 0.007347 kl_loss: 0.000000 normal_loss: 0.007347\n",
      "[585/00024] train_loss: 0.007364 kl_loss: 0.000000 normal_loss: 0.007364\n",
      "[586/00049] train_loss: 0.007350 kl_loss: 0.000000 normal_loss: 0.007350\n",
      "[587/00074] train_loss: 0.007331 kl_loss: 0.000000 normal_loss: 0.007331\n",
      "[589/00024] train_loss: 0.007362 kl_loss: 0.000000 normal_loss: 0.007362\n",
      "[590/00049] train_loss: 0.007291 kl_loss: 0.000000 normal_loss: 0.007291\n",
      "[591/00074] train_loss: 0.007343 kl_loss: 0.000000 normal_loss: 0.007343\n",
      "[593/00024] train_loss: 0.007328 kl_loss: 0.000000 normal_loss: 0.007328\n",
      "[594/00049] train_loss: 0.007301 kl_loss: 0.000000 normal_loss: 0.007301\n",
      "[595/00074] train_loss: 0.007308 kl_loss: 0.000000 normal_loss: 0.007308\n",
      "[597/00024] train_loss: 0.007264 kl_loss: 0.000000 normal_loss: 0.007264\n",
      "[598/00049] train_loss: 0.007352 kl_loss: 0.000000 normal_loss: 0.007352\n",
      "[599/00074] train_loss: 0.007317 kl_loss: 0.000000 normal_loss: 0.007317\n",
      "[599/00074] IOU 0.9263666389447948\n",
      "[601/00024] train_loss: 0.007286 kl_loss: 0.000000 normal_loss: 0.007286\n",
      "[602/00049] train_loss: 0.007254 kl_loss: 0.000000 normal_loss: 0.007254\n",
      "[603/00074] train_loss: 0.007248 kl_loss: 0.000000 normal_loss: 0.007248\n",
      "[605/00024] train_loss: 0.007230 kl_loss: 0.000000 normal_loss: 0.007230\n",
      "[606/00049] train_loss: 0.007265 kl_loss: 0.000000 normal_loss: 0.007265\n",
      "[607/00074] train_loss: 0.007258 kl_loss: 0.000000 normal_loss: 0.007258\n",
      "[609/00024] train_loss: 0.007254 kl_loss: 0.000000 normal_loss: 0.007254\n",
      "[610/00049] train_loss: 0.007280 kl_loss: 0.000000 normal_loss: 0.007280\n",
      "[611/00074] train_loss: 0.007224 kl_loss: 0.000000 normal_loss: 0.007224\n",
      "[613/00024] train_loss: 0.007263 kl_loss: 0.000000 normal_loss: 0.007263\n",
      "[614/00049] train_loss: 0.007219 kl_loss: 0.000000 normal_loss: 0.007219\n",
      "[615/00074] train_loss: 0.007283 kl_loss: 0.000000 normal_loss: 0.007283\n",
      "[617/00024] train_loss: 0.007239 kl_loss: 0.000000 normal_loss: 0.007239\n",
      "[618/00049] train_loss: 0.007256 kl_loss: 0.000000 normal_loss: 0.007256\n",
      "[619/00074] train_loss: 0.007247 kl_loss: 0.000000 normal_loss: 0.007247\n",
      "[621/00024] train_loss: 0.007257 kl_loss: 0.000000 normal_loss: 0.007257\n",
      "[622/00049] train_loss: 0.007282 kl_loss: 0.000000 normal_loss: 0.007282\n",
      "[623/00074] train_loss: 0.007188 kl_loss: 0.000000 normal_loss: 0.007188\n",
      "[625/00024] train_loss: 0.007239 kl_loss: 0.000000 normal_loss: 0.007239\n",
      "[626/00049] train_loss: 0.007256 kl_loss: 0.000000 normal_loss: 0.007256\n",
      "[627/00074] train_loss: 0.007222 kl_loss: 0.000000 normal_loss: 0.007222\n",
      "[629/00024] train_loss: 0.007269 kl_loss: 0.000000 normal_loss: 0.007269\n",
      "[630/00049] train_loss: 0.007226 kl_loss: 0.000000 normal_loss: 0.007226\n",
      "[631/00074] train_loss: 0.007234 kl_loss: 0.000000 normal_loss: 0.007234\n",
      "[633/00024] train_loss: 0.007239 kl_loss: 0.000000 normal_loss: 0.007239\n",
      "[634/00049] train_loss: 0.007219 kl_loss: 0.000000 normal_loss: 0.007219\n",
      "[635/00074] train_loss: 0.007259 kl_loss: 0.000000 normal_loss: 0.007259\n",
      "[637/00024] train_loss: 0.007246 kl_loss: 0.000000 normal_loss: 0.007246\n",
      "[638/00049] train_loss: 0.007253 kl_loss: 0.000000 normal_loss: 0.007253\n",
      "[639/00074] train_loss: 0.007205 kl_loss: 0.000000 normal_loss: 0.007205\n",
      "[641/00024] train_loss: 0.007216 kl_loss: 0.000000 normal_loss: 0.007216\n",
      "[642/00049] train_loss: 0.007246 kl_loss: 0.000000 normal_loss: 0.007246\n",
      "[643/00074] train_loss: 0.007217 kl_loss: 0.000000 normal_loss: 0.007217\n",
      "[645/00024] train_loss: 0.007301 kl_loss: 0.000000 normal_loss: 0.007301\n",
      "[646/00049] train_loss: 0.007160 kl_loss: 0.000000 normal_loss: 0.007160\n",
      "[647/00074] train_loss: 0.007253 kl_loss: 0.000000 normal_loss: 0.007253\n",
      "[649/00024] train_loss: 0.007237 kl_loss: 0.000000 normal_loss: 0.007237\n",
      "[649/00074] IOU 0.9272706339942912\n",
      "[650/00049] train_loss: 0.007217 kl_loss: 0.000000 normal_loss: 0.007217\n",
      "[651/00074] train_loss: 0.007246 kl_loss: 0.000000 normal_loss: 0.007246\n",
      "[653/00024] train_loss: 0.007237 kl_loss: 0.000000 normal_loss: 0.007237\n",
      "[654/00049] train_loss: 0.007201 kl_loss: 0.000000 normal_loss: 0.007201\n",
      "[655/00074] train_loss: 0.007228 kl_loss: 0.000000 normal_loss: 0.007228\n",
      "[657/00024] train_loss: 0.007245 kl_loss: 0.000000 normal_loss: 0.007245\n",
      "[658/00049] train_loss: 0.007193 kl_loss: 0.000000 normal_loss: 0.007193\n",
      "[659/00074] train_loss: 0.007256 kl_loss: 0.000000 normal_loss: 0.007256\n",
      "[661/00024] train_loss: 0.007233 kl_loss: 0.000000 normal_loss: 0.007233\n",
      "[662/00049] train_loss: 0.007232 kl_loss: 0.000000 normal_loss: 0.007232\n",
      "[663/00074] train_loss: 0.007186 kl_loss: 0.000000 normal_loss: 0.007186\n",
      "[665/00024] train_loss: 0.007236 kl_loss: 0.000000 normal_loss: 0.007236\n",
      "[666/00049] train_loss: 0.007266 kl_loss: 0.000000 normal_loss: 0.007266\n",
      "[667/00074] train_loss: 0.007185 kl_loss: 0.000000 normal_loss: 0.007185\n",
      "[669/00024] train_loss: 0.007198 kl_loss: 0.000000 normal_loss: 0.007198\n",
      "[670/00049] train_loss: 0.007224 kl_loss: 0.000000 normal_loss: 0.007224\n",
      "[671/00074] train_loss: 0.007239 kl_loss: 0.000000 normal_loss: 0.007239\n",
      "[673/00024] train_loss: 0.007196 kl_loss: 0.000000 normal_loss: 0.007196\n",
      "[674/00049] train_loss: 0.007254 kl_loss: 0.000000 normal_loss: 0.007254\n",
      "[675/00074] train_loss: 0.007178 kl_loss: 0.000000 normal_loss: 0.007178\n",
      "[677/00024] train_loss: 0.007219 kl_loss: 0.000000 normal_loss: 0.007219\n",
      "[678/00049] train_loss: 0.007209 kl_loss: 0.000000 normal_loss: 0.007209\n",
      "[679/00074] train_loss: 0.007236 kl_loss: 0.000000 normal_loss: 0.007236\n",
      "[681/00024] train_loss: 0.007212 kl_loss: 0.000000 normal_loss: 0.007212\n",
      "[682/00049] train_loss: 0.007176 kl_loss: 0.000000 normal_loss: 0.007176\n",
      "[683/00074] train_loss: 0.007217 kl_loss: 0.000000 normal_loss: 0.007217\n",
      "[685/00024] train_loss: 0.007218 kl_loss: 0.000000 normal_loss: 0.007218\n",
      "[686/00049] train_loss: 0.007216 kl_loss: 0.000000 normal_loss: 0.007216\n",
      "[687/00074] train_loss: 0.007208 kl_loss: 0.000000 normal_loss: 0.007208\n",
      "[689/00024] train_loss: 0.007226 kl_loss: 0.000000 normal_loss: 0.007226\n",
      "[690/00049] train_loss: 0.007194 kl_loss: 0.000000 normal_loss: 0.007194\n",
      "[691/00074] train_loss: 0.007245 kl_loss: 0.000000 normal_loss: 0.007245\n",
      "[693/00024] train_loss: 0.007257 kl_loss: 0.000000 normal_loss: 0.007257\n",
      "[694/00049] train_loss: 0.007140 kl_loss: 0.000000 normal_loss: 0.007140\n",
      "[695/00074] train_loss: 0.007188 kl_loss: 0.000000 normal_loss: 0.007188\n",
      "[697/00024] train_loss: 0.007218 kl_loss: 0.000000 normal_loss: 0.007218\n",
      "[698/00049] train_loss: 0.007209 kl_loss: 0.000000 normal_loss: 0.007209\n",
      "[699/00074] train_loss: 0.007198 kl_loss: 0.000000 normal_loss: 0.007198\n",
      "[699/00074] IOU 0.9275575063253443\n",
      "[701/00024] train_loss: 0.007197 kl_loss: 0.000000 normal_loss: 0.007197\n",
      "[702/00049] train_loss: 0.007110 kl_loss: 0.000000 normal_loss: 0.007110\n",
      "[703/00074] train_loss: 0.007209 kl_loss: 0.000000 normal_loss: 0.007209\n",
      "[705/00024] train_loss: 0.007179 kl_loss: 0.000000 normal_loss: 0.007179\n",
      "[706/00049] train_loss: 0.007147 kl_loss: 0.000000 normal_loss: 0.007147\n",
      "[707/00074] train_loss: 0.007166 kl_loss: 0.000000 normal_loss: 0.007166\n",
      "[709/00024] train_loss: 0.007143 kl_loss: 0.000000 normal_loss: 0.007143\n",
      "[710/00049] train_loss: 0.007157 kl_loss: 0.000000 normal_loss: 0.007157\n",
      "[711/00074] train_loss: 0.007195 kl_loss: 0.000000 normal_loss: 0.007195\n",
      "[713/00024] train_loss: 0.007158 kl_loss: 0.000000 normal_loss: 0.007158\n",
      "[714/00049] train_loss: 0.007186 kl_loss: 0.000000 normal_loss: 0.007186\n",
      "[715/00074] train_loss: 0.007153 kl_loss: 0.000000 normal_loss: 0.007153\n",
      "[717/00024] train_loss: 0.007174 kl_loss: 0.000000 normal_loss: 0.007174\n",
      "[718/00049] train_loss: 0.007123 kl_loss: 0.000000 normal_loss: 0.007123\n",
      "[719/00074] train_loss: 0.007186 kl_loss: 0.000000 normal_loss: 0.007186\n",
      "[721/00024] train_loss: 0.007171 kl_loss: 0.000000 normal_loss: 0.007171\n",
      "[722/00049] train_loss: 0.007155 kl_loss: 0.000000 normal_loss: 0.007155\n",
      "[723/00074] train_loss: 0.007176 kl_loss: 0.000000 normal_loss: 0.007176\n",
      "[725/00024] train_loss: 0.007141 kl_loss: 0.000000 normal_loss: 0.007141\n",
      "[726/00049] train_loss: 0.007173 kl_loss: 0.000000 normal_loss: 0.007173\n",
      "[727/00074] train_loss: 0.007193 kl_loss: 0.000000 normal_loss: 0.007193\n",
      "[729/00024] train_loss: 0.007154 kl_loss: 0.000000 normal_loss: 0.007154\n",
      "[730/00049] train_loss: 0.007188 kl_loss: 0.000000 normal_loss: 0.007188\n",
      "[731/00074] train_loss: 0.007152 kl_loss: 0.000000 normal_loss: 0.007152\n",
      "[733/00024] train_loss: 0.007128 kl_loss: 0.000000 normal_loss: 0.007128\n",
      "[734/00049] train_loss: 0.007203 kl_loss: 0.000000 normal_loss: 0.007203\n",
      "[735/00074] train_loss: 0.007149 kl_loss: 0.000000 normal_loss: 0.007149\n",
      "[737/00024] train_loss: 0.007132 kl_loss: 0.000000 normal_loss: 0.007132\n",
      "[738/00049] train_loss: 0.007196 kl_loss: 0.000000 normal_loss: 0.007196\n",
      "[739/00074] train_loss: 0.007152 kl_loss: 0.000000 normal_loss: 0.007152\n",
      "[741/00024] train_loss: 0.007159 kl_loss: 0.000000 normal_loss: 0.007159\n",
      "[742/00049] train_loss: 0.007177 kl_loss: 0.000000 normal_loss: 0.007177\n",
      "[743/00074] train_loss: 0.007160 kl_loss: 0.000000 normal_loss: 0.007160\n",
      "[745/00024] train_loss: 0.007150 kl_loss: 0.000000 normal_loss: 0.007150\n",
      "[746/00049] train_loss: 0.007154 kl_loss: 0.000000 normal_loss: 0.007154\n",
      "[747/00074] train_loss: 0.007176 kl_loss: 0.000000 normal_loss: 0.007176\n",
      "[749/00024] train_loss: 0.007144 kl_loss: 0.000000 normal_loss: 0.007144\n",
      "[749/00074] IOU 0.9276946818456053\n",
      "[750/00049] train_loss: 0.007147 kl_loss: 0.000000 normal_loss: 0.007147\n",
      "[751/00074] train_loss: 0.007175 kl_loss: 0.000000 normal_loss: 0.007175\n",
      "[753/00024] train_loss: 0.007150 kl_loss: 0.000000 normal_loss: 0.007150\n",
      "[754/00049] train_loss: 0.007184 kl_loss: 0.000000 normal_loss: 0.007184\n",
      "[755/00074] train_loss: 0.007156 kl_loss: 0.000000 normal_loss: 0.007156\n",
      "[757/00024] train_loss: 0.007161 kl_loss: 0.000000 normal_loss: 0.007161\n",
      "[758/00049] train_loss: 0.007139 kl_loss: 0.000000 normal_loss: 0.007139\n",
      "[759/00074] train_loss: 0.007170 kl_loss: 0.000000 normal_loss: 0.007170\n",
      "[761/00024] train_loss: 0.007202 kl_loss: 0.000000 normal_loss: 0.007202\n",
      "[762/00049] train_loss: 0.007122 kl_loss: 0.000000 normal_loss: 0.007122\n",
      "[763/00074] train_loss: 0.007149 kl_loss: 0.000000 normal_loss: 0.007149\n",
      "[765/00024] train_loss: 0.007152 kl_loss: 0.000000 normal_loss: 0.007152\n",
      "[766/00049] train_loss: 0.007146 kl_loss: 0.000000 normal_loss: 0.007146\n",
      "[767/00074] train_loss: 0.007151 kl_loss: 0.000000 normal_loss: 0.007151\n",
      "[769/00024] train_loss: 0.007163 kl_loss: 0.000000 normal_loss: 0.007163\n",
      "[770/00049] train_loss: 0.007175 kl_loss: 0.000000 normal_loss: 0.007175\n",
      "[771/00074] train_loss: 0.007128 kl_loss: 0.000000 normal_loss: 0.007128\n",
      "[773/00024] train_loss: 0.007127 kl_loss: 0.000000 normal_loss: 0.007127\n",
      "[774/00049] train_loss: 0.007169 kl_loss: 0.000000 normal_loss: 0.007169\n",
      "[775/00074] train_loss: 0.007155 kl_loss: 0.000000 normal_loss: 0.007155\n",
      "[777/00024] train_loss: 0.007157 kl_loss: 0.000000 normal_loss: 0.007157\n",
      "[778/00049] train_loss: 0.007163 kl_loss: 0.000000 normal_loss: 0.007163\n",
      "[779/00074] train_loss: 0.007132 kl_loss: 0.000000 normal_loss: 0.007132\n",
      "[781/00024] train_loss: 0.007150 kl_loss: 0.000000 normal_loss: 0.007150\n",
      "[782/00049] train_loss: 0.007141 kl_loss: 0.000000 normal_loss: 0.007141\n",
      "[783/00074] train_loss: 0.007136 kl_loss: 0.000000 normal_loss: 0.007136\n",
      "[785/00024] train_loss: 0.007149 kl_loss: 0.000000 normal_loss: 0.007149\n",
      "[786/00049] train_loss: 0.007129 kl_loss: 0.000000 normal_loss: 0.007129\n",
      "[787/00074] train_loss: 0.007152 kl_loss: 0.000000 normal_loss: 0.007152\n",
      "[789/00024] train_loss: 0.007137 kl_loss: 0.000000 normal_loss: 0.007137\n",
      "[790/00049] train_loss: 0.007197 kl_loss: 0.000000 normal_loss: 0.007197\n",
      "[791/00074] train_loss: 0.007119 kl_loss: 0.000000 normal_loss: 0.007119\n",
      "[793/00024] train_loss: 0.007129 kl_loss: 0.000000 normal_loss: 0.007129\n",
      "[794/00049] train_loss: 0.007191 kl_loss: 0.000000 normal_loss: 0.007191\n",
      "[795/00074] train_loss: 0.007124 kl_loss: 0.000000 normal_loss: 0.007124\n",
      "[797/00024] train_loss: 0.007143 kl_loss: 0.000000 normal_loss: 0.007143\n",
      "[798/00049] train_loss: 0.007144 kl_loss: 0.000000 normal_loss: 0.007144\n",
      "[799/00074] train_loss: 0.007158 kl_loss: 0.000000 normal_loss: 0.007158\n",
      "[799/00074] IOU 0.927694671265781\n",
      "[801/00024] train_loss: 0.007139 kl_loss: 0.000000 normal_loss: 0.007139\n",
      "[802/00049] train_loss: 0.007132 kl_loss: 0.000000 normal_loss: 0.007132\n",
      "[803/00074] train_loss: 0.007102 kl_loss: 0.000000 normal_loss: 0.007102\n",
      "[805/00024] train_loss: 0.007113 kl_loss: 0.000000 normal_loss: 0.007113\n",
      "[806/00049] train_loss: 0.007144 kl_loss: 0.000000 normal_loss: 0.007144\n",
      "[807/00074] train_loss: 0.007125 kl_loss: 0.000000 normal_loss: 0.007125\n",
      "[809/00024] train_loss: 0.007122 kl_loss: 0.000000 normal_loss: 0.007122\n",
      "[810/00049] train_loss: 0.007106 kl_loss: 0.000000 normal_loss: 0.007106\n",
      "[811/00074] train_loss: 0.007134 kl_loss: 0.000000 normal_loss: 0.007134\n",
      "[813/00024] train_loss: 0.007111 kl_loss: 0.000000 normal_loss: 0.007111\n",
      "[814/00049] train_loss: 0.007136 kl_loss: 0.000000 normal_loss: 0.007136\n",
      "[815/00074] train_loss: 0.007112 kl_loss: 0.000000 normal_loss: 0.007112\n",
      "[817/00024] train_loss: 0.007137 kl_loss: 0.000000 normal_loss: 0.007137\n",
      "[818/00049] train_loss: 0.007094 kl_loss: 0.000000 normal_loss: 0.007094\n",
      "[819/00074] train_loss: 0.007149 kl_loss: 0.000000 normal_loss: 0.007149\n",
      "[821/00024] train_loss: 0.007132 kl_loss: 0.000000 normal_loss: 0.007132\n",
      "[822/00049] train_loss: 0.007130 kl_loss: 0.000000 normal_loss: 0.007130\n",
      "[823/00074] train_loss: 0.007136 kl_loss: 0.000000 normal_loss: 0.007136\n",
      "[825/00024] train_loss: 0.007115 kl_loss: 0.000000 normal_loss: 0.007115\n",
      "[826/00049] train_loss: 0.007140 kl_loss: 0.000000 normal_loss: 0.007140\n",
      "[827/00074] train_loss: 0.007091 kl_loss: 0.000000 normal_loss: 0.007091\n",
      "[829/00024] train_loss: 0.007117 kl_loss: 0.000000 normal_loss: 0.007117\n",
      "[830/00049] train_loss: 0.007109 kl_loss: 0.000000 normal_loss: 0.007109\n",
      "[831/00074] train_loss: 0.007138 kl_loss: 0.000000 normal_loss: 0.007138\n",
      "[833/00024] train_loss: 0.007095 kl_loss: 0.000000 normal_loss: 0.007095\n",
      "[834/00049] train_loss: 0.007161 kl_loss: 0.000000 normal_loss: 0.007161\n",
      "[835/00074] train_loss: 0.007124 kl_loss: 0.000000 normal_loss: 0.007124\n",
      "[837/00024] train_loss: 0.007131 kl_loss: 0.000000 normal_loss: 0.007131\n",
      "[838/00049] train_loss: 0.007098 kl_loss: 0.000000 normal_loss: 0.007098\n",
      "[839/00074] train_loss: 0.007124 kl_loss: 0.000000 normal_loss: 0.007124\n",
      "[841/00024] train_loss: 0.007127 kl_loss: 0.000000 normal_loss: 0.007127\n",
      "[842/00049] train_loss: 0.007117 kl_loss: 0.000000 normal_loss: 0.007117\n",
      "[843/00074] train_loss: 0.007112 kl_loss: 0.000000 normal_loss: 0.007112\n",
      "[845/00024] train_loss: 0.007125 kl_loss: 0.000000 normal_loss: 0.007125\n",
      "[846/00049] train_loss: 0.007089 kl_loss: 0.000000 normal_loss: 0.007089\n",
      "[847/00074] train_loss: 0.007136 kl_loss: 0.000000 normal_loss: 0.007136\n",
      "[849/00024] train_loss: 0.007087 kl_loss: 0.000000 normal_loss: 0.007087\n",
      "[849/00074] IOU 0.9279553627471129\n",
      "[850/00049] train_loss: 0.007167 kl_loss: 0.000000 normal_loss: 0.007167\n",
      "[851/00074] train_loss: 0.007110 kl_loss: 0.000000 normal_loss: 0.007110\n",
      "[853/00024] train_loss: 0.007117 kl_loss: 0.000000 normal_loss: 0.007117\n",
      "[854/00049] train_loss: 0.007135 kl_loss: 0.000000 normal_loss: 0.007135\n",
      "[855/00074] train_loss: 0.007108 kl_loss: 0.000000 normal_loss: 0.007108\n",
      "[857/00024] train_loss: 0.007126 kl_loss: 0.000000 normal_loss: 0.007126\n",
      "[858/00049] train_loss: 0.007116 kl_loss: 0.000000 normal_loss: 0.007116\n",
      "[859/00074] train_loss: 0.007101 kl_loss: 0.000000 normal_loss: 0.007101\n",
      "[861/00024] train_loss: 0.007134 kl_loss: 0.000000 normal_loss: 0.007134\n",
      "[862/00049] train_loss: 0.007105 kl_loss: 0.000000 normal_loss: 0.007105\n",
      "[863/00074] train_loss: 0.007096 kl_loss: 0.000000 normal_loss: 0.007096\n",
      "[865/00024] train_loss: 0.007107 kl_loss: 0.000000 normal_loss: 0.007107\n",
      "[866/00049] train_loss: 0.007134 kl_loss: 0.000000 normal_loss: 0.007134\n",
      "[867/00074] train_loss: 0.007116 kl_loss: 0.000000 normal_loss: 0.007116\n",
      "[869/00024] train_loss: 0.007073 kl_loss: 0.000000 normal_loss: 0.007073\n",
      "[870/00049] train_loss: 0.007152 kl_loss: 0.000000 normal_loss: 0.007152\n",
      "[871/00074] train_loss: 0.007114 kl_loss: 0.000000 normal_loss: 0.007114\n",
      "[873/00024] train_loss: 0.007111 kl_loss: 0.000000 normal_loss: 0.007111\n",
      "[874/00049] train_loss: 0.007131 kl_loss: 0.000000 normal_loss: 0.007131\n",
      "[875/00074] train_loss: 0.007132 kl_loss: 0.000000 normal_loss: 0.007132\n",
      "[877/00024] train_loss: 0.007109 kl_loss: 0.000000 normal_loss: 0.007109\n",
      "[878/00049] train_loss: 0.007112 kl_loss: 0.000000 normal_loss: 0.007112\n",
      "[879/00074] train_loss: 0.007132 kl_loss: 0.000000 normal_loss: 0.007132\n",
      "[881/00024] train_loss: 0.007114 kl_loss: 0.000000 normal_loss: 0.007114\n",
      "[882/00049] train_loss: 0.007116 kl_loss: 0.000000 normal_loss: 0.007116\n",
      "[883/00074] train_loss: 0.007122 kl_loss: 0.000000 normal_loss: 0.007122\n",
      "[885/00024] train_loss: 0.007133 kl_loss: 0.000000 normal_loss: 0.007133\n",
      "[886/00049] train_loss: 0.007099 kl_loss: 0.000000 normal_loss: 0.007099\n",
      "[887/00074] train_loss: 0.007109 kl_loss: 0.000000 normal_loss: 0.007109\n",
      "[889/00024] train_loss: 0.007099 kl_loss: 0.000000 normal_loss: 0.007099\n",
      "[890/00049] train_loss: 0.007119 kl_loss: 0.000000 normal_loss: 0.007119\n",
      "[891/00074] train_loss: 0.007108 kl_loss: 0.000000 normal_loss: 0.007108\n",
      "[893/00024] train_loss: 0.007116 kl_loss: 0.000000 normal_loss: 0.007116\n",
      "[894/00049] train_loss: 0.007112 kl_loss: 0.000000 normal_loss: 0.007112\n",
      "[895/00074] train_loss: 0.007110 kl_loss: 0.000000 normal_loss: 0.007110\n",
      "[897/00024] train_loss: 0.007111 kl_loss: 0.000000 normal_loss: 0.007111\n",
      "[898/00049] train_loss: 0.007138 kl_loss: 0.000000 normal_loss: 0.007138\n",
      "[899/00074] train_loss: 0.007094 kl_loss: 0.000000 normal_loss: 0.007094\n",
      "[899/00074] IOU 0.9280677935667336\n",
      "[901/00024] train_loss: 0.007085 kl_loss: 0.000000 normal_loss: 0.007085\n",
      "[902/00049] train_loss: 0.007107 kl_loss: 0.000000 normal_loss: 0.007107\n",
      "[903/00074] train_loss: 0.007112 kl_loss: 0.000000 normal_loss: 0.007112\n",
      "[905/00024] train_loss: 0.007090 kl_loss: 0.000000 normal_loss: 0.007090\n",
      "[906/00049] train_loss: 0.007121 kl_loss: 0.000000 normal_loss: 0.007121\n",
      "[907/00074] train_loss: 0.007096 kl_loss: 0.000000 normal_loss: 0.007096\n",
      "[909/00024] train_loss: 0.007116 kl_loss: 0.000000 normal_loss: 0.007116\n",
      "[910/00049] train_loss: 0.007074 kl_loss: 0.000000 normal_loss: 0.007074\n",
      "[911/00074] train_loss: 0.007118 kl_loss: 0.000000 normal_loss: 0.007118\n",
      "[913/00024] train_loss: 0.007102 kl_loss: 0.000000 normal_loss: 0.007102\n",
      "[914/00049] train_loss: 0.007091 kl_loss: 0.000000 normal_loss: 0.007091\n",
      "[915/00074] train_loss: 0.007105 kl_loss: 0.000000 normal_loss: 0.007105\n",
      "[917/00024] train_loss: 0.007085 kl_loss: 0.000000 normal_loss: 0.007085\n",
      "[918/00049] train_loss: 0.007091 kl_loss: 0.000000 normal_loss: 0.007091\n",
      "[919/00074] train_loss: 0.007129 kl_loss: 0.000000 normal_loss: 0.007129\n",
      "[921/00024] train_loss: 0.007074 kl_loss: 0.000000 normal_loss: 0.007074\n",
      "[922/00049] train_loss: 0.007101 kl_loss: 0.000000 normal_loss: 0.007101\n",
      "[923/00074] train_loss: 0.007127 kl_loss: 0.000000 normal_loss: 0.007127\n",
      "[925/00024] train_loss: 0.007107 kl_loss: 0.000000 normal_loss: 0.007107\n",
      "[926/00049] train_loss: 0.007103 kl_loss: 0.000000 normal_loss: 0.007103\n",
      "[927/00074] train_loss: 0.007088 kl_loss: 0.000000 normal_loss: 0.007088\n",
      "[929/00024] train_loss: 0.007075 kl_loss: 0.000000 normal_loss: 0.007075\n",
      "[930/00049] train_loss: 0.007123 kl_loss: 0.000000 normal_loss: 0.007123\n",
      "[931/00074] train_loss: 0.007108 kl_loss: 0.000000 normal_loss: 0.007108\n",
      "[933/00024] train_loss: 0.007118 kl_loss: 0.000000 normal_loss: 0.007118\n",
      "[934/00049] train_loss: 0.007085 kl_loss: 0.000000 normal_loss: 0.007085\n",
      "[935/00074] train_loss: 0.007096 kl_loss: 0.000000 normal_loss: 0.007096\n",
      "[937/00024] train_loss: 0.007094 kl_loss: 0.000000 normal_loss: 0.007094\n",
      "[938/00049] train_loss: 0.007088 kl_loss: 0.000000 normal_loss: 0.007088\n",
      "[939/00074] train_loss: 0.007106 kl_loss: 0.000000 normal_loss: 0.007106\n",
      "[941/00024] train_loss: 0.007097 kl_loss: 0.000000 normal_loss: 0.007097\n",
      "[942/00049] train_loss: 0.007104 kl_loss: 0.000000 normal_loss: 0.007104\n",
      "[943/00074] train_loss: 0.007086 kl_loss: 0.000000 normal_loss: 0.007086\n",
      "[945/00024] train_loss: 0.007087 kl_loss: 0.000000 normal_loss: 0.007087\n",
      "[946/00049] train_loss: 0.007130 kl_loss: 0.000000 normal_loss: 0.007130\n",
      "[947/00074] train_loss: 0.007092 kl_loss: 0.000000 normal_loss: 0.007092\n",
      "[949/00024] train_loss: 0.007082 kl_loss: 0.000000 normal_loss: 0.007082\n",
      "[949/00074] IOU 0.9280678423928718\n",
      "[950/00049] train_loss: 0.007075 kl_loss: 0.000000 normal_loss: 0.007075\n",
      "[951/00074] train_loss: 0.007134 kl_loss: 0.000000 normal_loss: 0.007134\n",
      "[953/00024] train_loss: 0.007093 kl_loss: 0.000000 normal_loss: 0.007093\n",
      "[954/00049] train_loss: 0.007099 kl_loss: 0.000000 normal_loss: 0.007099\n",
      "[955/00074] train_loss: 0.007108 kl_loss: 0.000000 normal_loss: 0.007108\n",
      "[957/00024] train_loss: 0.007111 kl_loss: 0.000000 normal_loss: 0.007111\n",
      "[958/00049] train_loss: 0.007074 kl_loss: 0.000000 normal_loss: 0.007074\n",
      "[959/00074] train_loss: 0.007098 kl_loss: 0.000000 normal_loss: 0.007098\n",
      "[961/00024] train_loss: 0.007080 kl_loss: 0.000000 normal_loss: 0.007080\n",
      "[962/00049] train_loss: 0.007126 kl_loss: 0.000000 normal_loss: 0.007126\n",
      "[963/00074] train_loss: 0.007079 kl_loss: 0.000000 normal_loss: 0.007079\n",
      "[965/00024] train_loss: 0.007088 kl_loss: 0.000000 normal_loss: 0.007088\n",
      "[966/00049] train_loss: 0.007100 kl_loss: 0.000000 normal_loss: 0.007100\n",
      "[967/00074] train_loss: 0.007113 kl_loss: 0.000000 normal_loss: 0.007113\n",
      "[969/00024] train_loss: 0.007089 kl_loss: 0.000000 normal_loss: 0.007089\n",
      "[970/00049] train_loss: 0.007104 kl_loss: 0.000000 normal_loss: 0.007104\n",
      "[971/00074] train_loss: 0.007089 kl_loss: 0.000000 normal_loss: 0.007089\n",
      "[973/00024] train_loss: 0.007092 kl_loss: 0.000000 normal_loss: 0.007092\n",
      "[974/00049] train_loss: 0.007093 kl_loss: 0.000000 normal_loss: 0.007093\n",
      "[975/00074] train_loss: 0.007088 kl_loss: 0.000000 normal_loss: 0.007088\n",
      "[977/00024] train_loss: 0.007105 kl_loss: 0.000000 normal_loss: 0.007105\n",
      "[978/00049] train_loss: 0.007074 kl_loss: 0.000000 normal_loss: 0.007074\n",
      "[979/00074] train_loss: 0.007100 kl_loss: 0.000000 normal_loss: 0.007100\n",
      "[981/00024] train_loss: 0.007094 kl_loss: 0.000000 normal_loss: 0.007094\n",
      "[982/00049] train_loss: 0.007081 kl_loss: 0.000000 normal_loss: 0.007081\n",
      "[983/00074] train_loss: 0.007102 kl_loss: 0.000000 normal_loss: 0.007102\n",
      "[985/00024] train_loss: 0.007093 kl_loss: 0.000000 normal_loss: 0.007093\n",
      "[986/00049] train_loss: 0.007119 kl_loss: 0.000000 normal_loss: 0.007119\n",
      "[987/00074] train_loss: 0.007078 kl_loss: 0.000000 normal_loss: 0.007078\n",
      "[989/00024] train_loss: 0.007069 kl_loss: 0.000000 normal_loss: 0.007069\n",
      "[990/00049] train_loss: 0.007095 kl_loss: 0.000000 normal_loss: 0.007095\n",
      "[991/00074] train_loss: 0.007117 kl_loss: 0.000000 normal_loss: 0.007117\n",
      "[993/00024] train_loss: 0.007079 kl_loss: 0.000000 normal_loss: 0.007079\n",
      "[994/00049] train_loss: 0.007115 kl_loss: 0.000000 normal_loss: 0.007115\n",
      "[995/00074] train_loss: 0.007091 kl_loss: 0.000000 normal_loss: 0.007091\n",
      "[997/00024] train_loss: 0.007060 kl_loss: 0.000000 normal_loss: 0.007060\n",
      "[998/00049] train_loss: 0.007135 kl_loss: 0.000000 normal_loss: 0.007135\n",
      "[999/00074] train_loss: 0.007098 kl_loss: 0.000000 normal_loss: 0.007098\n",
      "[999/00074] IOU 0.9280581993671755\n"
     ]
    }
   ],
   "source": [
    "# TABLE AD\n",
    "from scripts import train\n",
    "config = {\n",
    "    'experiment_name': 'table_ad',\n",
    "    'device': 'cuda:0',\n",
    "    'is_overfit': False,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate_model': 0.01,\n",
    "    'learning_rate_code': 0.01,\n",
    "    'learning_rate_log_var':0.01,\n",
    "    'max_epochs': 1000,\n",
    "    'print_every_n': 100,\n",
    "    'latent_code_length' : 256,\n",
    "    'scheduler_step_size': 100,\n",
    "    'vad_free' : False,\n",
    "    'test': False,\n",
    "    'kl_weight': 0.03,\n",
    "    'kl_weight_increase_every_epochs': 100,\n",
    "    'kl_weight_increase_value': 0.0,\n",
    "    'iou_every_epoch': 50,\n",
    "    'resume_ckpt': None,\n",
    "    'filter_class': 'table',\n",
    "    'decoder_var' : False\n",
    "}\n",
    "train.main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Data length 4800\n",
      "Training params: 2\n",
      "[001/00024] train_loss: 0.164451 kl_loss: 0.000000 normal_loss: 0.164451\n",
      "[002/00049] train_loss: 0.116169 kl_loss: 0.000000 normal_loss: 0.116169\n",
      "[003/00074] train_loss: 0.113166 kl_loss: 0.000000 normal_loss: 0.113166\n",
      "[005/00024] train_loss: 0.106087 kl_loss: 0.000000 normal_loss: 0.106087\n",
      "[006/00049] train_loss: 0.100100 kl_loss: 0.000000 normal_loss: 0.100100\n",
      "[007/00074] train_loss: 0.095202 kl_loss: 0.000000 normal_loss: 0.095202\n",
      "[009/00024] train_loss: 0.089955 kl_loss: 0.000000 normal_loss: 0.089955\n",
      "[010/00049] train_loss: 0.085373 kl_loss: 0.000000 normal_loss: 0.085373\n",
      "[011/00074] train_loss: 0.082074 kl_loss: 0.000000 normal_loss: 0.082074\n",
      "[013/00024] train_loss: 0.077538 kl_loss: 0.000000 normal_loss: 0.077538\n",
      "[014/00049] train_loss: 0.075404 kl_loss: 0.000000 normal_loss: 0.075404\n",
      "[015/00074] train_loss: 0.071963 kl_loss: 0.000000 normal_loss: 0.071963\n",
      "[017/00024] train_loss: 0.069499 kl_loss: 0.000000 normal_loss: 0.069499\n",
      "[018/00049] train_loss: 0.066746 kl_loss: 0.000000 normal_loss: 0.066746\n",
      "[019/00074] train_loss: 0.064414 kl_loss: 0.000000 normal_loss: 0.064414\n",
      "[021/00024] train_loss: 0.061414 kl_loss: 0.000000 normal_loss: 0.061414\n",
      "[022/00049] train_loss: 0.058761 kl_loss: 0.000000 normal_loss: 0.058761\n",
      "[023/00074] train_loss: 0.057564 kl_loss: 0.000000 normal_loss: 0.057564\n",
      "[025/00024] train_loss: 0.054771 kl_loss: 0.000000 normal_loss: 0.054771\n",
      "[026/00049] train_loss: 0.052876 kl_loss: 0.000000 normal_loss: 0.052876\n",
      "[027/00074] train_loss: 0.051078 kl_loss: 0.000000 normal_loss: 0.051078\n",
      "[029/00024] train_loss: 0.050608 kl_loss: 0.000000 normal_loss: 0.050608\n",
      "[030/00049] train_loss: 0.048213 kl_loss: 0.000000 normal_loss: 0.048213\n",
      "[031/00074] train_loss: 0.046769 kl_loss: 0.000000 normal_loss: 0.046769\n",
      "[033/00024] train_loss: 0.045782 kl_loss: 0.000000 normal_loss: 0.045782\n",
      "[034/00049] train_loss: 0.043948 kl_loss: 0.000000 normal_loss: 0.043948\n",
      "[035/00074] train_loss: 0.044078 kl_loss: 0.000000 normal_loss: 0.044078\n",
      "[037/00024] train_loss: 0.043027 kl_loss: 0.000000 normal_loss: 0.043027\n",
      "[038/00049] train_loss: 0.041322 kl_loss: 0.000000 normal_loss: 0.041322\n",
      "[039/00074] train_loss: 0.040937 kl_loss: 0.000000 normal_loss: 0.040937\n",
      "[041/00024] train_loss: 0.039977 kl_loss: 0.000000 normal_loss: 0.039977\n",
      "[042/00049] train_loss: 0.039429 kl_loss: 0.000000 normal_loss: 0.039429\n",
      "[043/00074] train_loss: 0.037095 kl_loss: 0.000000 normal_loss: 0.037095\n",
      "[045/00024] train_loss: 0.036566 kl_loss: 0.000000 normal_loss: 0.036566\n",
      "[046/00049] train_loss: 0.035893 kl_loss: 0.000000 normal_loss: 0.035893\n",
      "[047/00074] train_loss: 0.034910 kl_loss: 0.000000 normal_loss: 0.034910\n",
      "[049/00024] train_loss: 0.033562 kl_loss: 0.000000 normal_loss: 0.033562\n",
      "[049/00074] IOU 0.7890190244900683\n",
      "[050/00049] train_loss: 0.034636 kl_loss: 0.000000 normal_loss: 0.034636\n",
      "[051/00074] train_loss: 0.032916 kl_loss: 0.000000 normal_loss: 0.032916\n",
      "[053/00024] train_loss: 0.031271 kl_loss: 0.000000 normal_loss: 0.031271\n",
      "[054/00049] train_loss: 0.032771 kl_loss: 0.000000 normal_loss: 0.032771\n",
      "[055/00074] train_loss: 0.030839 kl_loss: 0.000000 normal_loss: 0.030839\n",
      "[057/00024] train_loss: 0.030091 kl_loss: 0.000000 normal_loss: 0.030091\n",
      "[058/00049] train_loss: 0.029720 kl_loss: 0.000000 normal_loss: 0.029720\n",
      "[059/00074] train_loss: 0.028828 kl_loss: 0.000000 normal_loss: 0.028828\n",
      "[061/00024] train_loss: 0.028370 kl_loss: 0.000000 normal_loss: 0.028370\n",
      "[062/00049] train_loss: 0.028777 kl_loss: 0.000000 normal_loss: 0.028777\n",
      "[063/00074] train_loss: 0.027703 kl_loss: 0.000000 normal_loss: 0.027703\n",
      "[065/00024] train_loss: 0.027142 kl_loss: 0.000000 normal_loss: 0.027142\n",
      "[066/00049] train_loss: 0.026743 kl_loss: 0.000000 normal_loss: 0.026743\n",
      "[067/00074] train_loss: 0.026170 kl_loss: 0.000000 normal_loss: 0.026170\n",
      "[069/00024] train_loss: 0.025965 kl_loss: 0.000000 normal_loss: 0.025965\n",
      "[070/00049] train_loss: 0.025977 kl_loss: 0.000000 normal_loss: 0.025977\n",
      "[071/00074] train_loss: 0.025848 kl_loss: 0.000000 normal_loss: 0.025848\n",
      "[073/00024] train_loss: 0.025788 kl_loss: 0.000000 normal_loss: 0.025788\n",
      "[074/00049] train_loss: 0.024837 kl_loss: 0.000000 normal_loss: 0.024837\n",
      "[075/00074] train_loss: 0.025637 kl_loss: 0.000000 normal_loss: 0.025637\n",
      "[077/00024] train_loss: 0.024126 kl_loss: 0.000000 normal_loss: 0.024126\n",
      "[078/00049] train_loss: 0.024836 kl_loss: 0.000000 normal_loss: 0.024836\n",
      "[079/00074] train_loss: 0.023747 kl_loss: 0.000000 normal_loss: 0.023747\n",
      "[081/00024] train_loss: 0.023330 kl_loss: 0.000000 normal_loss: 0.023330\n",
      "[082/00049] train_loss: 0.024536 kl_loss: 0.000000 normal_loss: 0.024536\n",
      "[083/00074] train_loss: 0.023570 kl_loss: 0.000000 normal_loss: 0.023570\n",
      "[085/00024] train_loss: 0.023637 kl_loss: 0.000000 normal_loss: 0.023637\n",
      "[086/00049] train_loss: 0.022628 kl_loss: 0.000000 normal_loss: 0.022628\n",
      "[087/00074] train_loss: 0.022251 kl_loss: 0.000000 normal_loss: 0.022251\n",
      "[089/00024] train_loss: 0.022363 kl_loss: 0.000000 normal_loss: 0.022363\n",
      "[090/00049] train_loss: 0.022950 kl_loss: 0.000000 normal_loss: 0.022950\n",
      "[091/00074] train_loss: 0.022131 kl_loss: 0.000000 normal_loss: 0.022131\n",
      "[093/00024] train_loss: 0.021984 kl_loss: 0.000000 normal_loss: 0.021984\n",
      "[094/00049] train_loss: 0.022061 kl_loss: 0.000000 normal_loss: 0.022061\n",
      "[095/00074] train_loss: 0.021452 kl_loss: 0.000000 normal_loss: 0.021452\n",
      "[097/00024] train_loss: 0.021802 kl_loss: 0.000000 normal_loss: 0.021802\n",
      "[098/00049] train_loss: 0.021225 kl_loss: 0.000000 normal_loss: 0.021225\n",
      "[099/00074] train_loss: 0.020889 kl_loss: 0.000000 normal_loss: 0.020889\n",
      "[099/00074] IOU 0.8662025389696161\n",
      "[101/00024] train_loss: 0.018751 kl_loss: 0.000000 normal_loss: 0.018751\n",
      "[102/00049] train_loss: 0.016807 kl_loss: 0.000000 normal_loss: 0.016807\n",
      "[103/00074] train_loss: 0.016106 kl_loss: 0.000000 normal_loss: 0.016106\n",
      "[105/00024] train_loss: 0.015961 kl_loss: 0.000000 normal_loss: 0.015961\n",
      "[106/00049] train_loss: 0.016184 kl_loss: 0.000000 normal_loss: 0.016184\n",
      "[107/00074] train_loss: 0.015720 kl_loss: 0.000000 normal_loss: 0.015720\n",
      "[109/00024] train_loss: 0.015845 kl_loss: 0.000000 normal_loss: 0.015845\n",
      "[110/00049] train_loss: 0.015781 kl_loss: 0.000000 normal_loss: 0.015781\n",
      "[111/00074] train_loss: 0.016113 kl_loss: 0.000000 normal_loss: 0.016113\n",
      "[113/00024] train_loss: 0.016199 kl_loss: 0.000000 normal_loss: 0.016199\n",
      "[114/00049] train_loss: 0.016084 kl_loss: 0.000000 normal_loss: 0.016084\n",
      "[115/00074] train_loss: 0.015986 kl_loss: 0.000000 normal_loss: 0.015986\n",
      "[117/00024] train_loss: 0.015418 kl_loss: 0.000000 normal_loss: 0.015418\n",
      "[118/00049] train_loss: 0.016162 kl_loss: 0.000000 normal_loss: 0.016162\n",
      "[119/00074] train_loss: 0.016461 kl_loss: 0.000000 normal_loss: 0.016461\n",
      "[121/00024] train_loss: 0.015995 kl_loss: 0.000000 normal_loss: 0.015995\n",
      "[122/00049] train_loss: 0.015734 kl_loss: 0.000000 normal_loss: 0.015734\n",
      "[123/00074] train_loss: 0.015335 kl_loss: 0.000000 normal_loss: 0.015335\n",
      "[125/00024] train_loss: 0.015976 kl_loss: 0.000000 normal_loss: 0.015976\n",
      "[126/00049] train_loss: 0.015941 kl_loss: 0.000000 normal_loss: 0.015941\n",
      "[127/00074] train_loss: 0.015573 kl_loss: 0.000000 normal_loss: 0.015573\n",
      "[129/00024] train_loss: 0.015858 kl_loss: 0.000000 normal_loss: 0.015858\n",
      "[130/00049] train_loss: 0.015334 kl_loss: 0.000000 normal_loss: 0.015334\n",
      "[131/00074] train_loss: 0.015677 kl_loss: 0.000000 normal_loss: 0.015677\n",
      "[133/00024] train_loss: 0.015271 kl_loss: 0.000000 normal_loss: 0.015271\n",
      "[134/00049] train_loss: 0.015364 kl_loss: 0.000000 normal_loss: 0.015364\n",
      "[135/00074] train_loss: 0.015314 kl_loss: 0.000000 normal_loss: 0.015314\n",
      "[137/00024] train_loss: 0.015494 kl_loss: 0.000000 normal_loss: 0.015494\n",
      "[138/00049] train_loss: 0.015551 kl_loss: 0.000000 normal_loss: 0.015551\n",
      "[139/00074] train_loss: 0.015190 kl_loss: 0.000000 normal_loss: 0.015190\n",
      "[141/00024] train_loss: 0.014862 kl_loss: 0.000000 normal_loss: 0.014862\n",
      "[142/00049] train_loss: 0.015344 kl_loss: 0.000000 normal_loss: 0.015344\n",
      "[143/00074] train_loss: 0.015097 kl_loss: 0.000000 normal_loss: 0.015097\n",
      "[145/00024] train_loss: 0.015198 kl_loss: 0.000000 normal_loss: 0.015198\n",
      "[146/00049] train_loss: 0.015145 kl_loss: 0.000000 normal_loss: 0.015145\n",
      "[147/00074] train_loss: 0.014797 kl_loss: 0.000000 normal_loss: 0.014797\n",
      "[149/00024] train_loss: 0.015085 kl_loss: 0.000000 normal_loss: 0.015085\n",
      "[149/00074] IOU 0.8902636351746818\n",
      "[150/00049] train_loss: 0.015042 kl_loss: 0.000000 normal_loss: 0.015042\n",
      "[151/00074] train_loss: 0.014795 kl_loss: 0.000000 normal_loss: 0.014795\n",
      "[153/00024] train_loss: 0.014889 kl_loss: 0.000000 normal_loss: 0.014889\n",
      "[154/00049] train_loss: 0.014328 kl_loss: 0.000000 normal_loss: 0.014328\n",
      "[155/00074] train_loss: 0.014663 kl_loss: 0.000000 normal_loss: 0.014663\n",
      "[157/00024] train_loss: 0.014570 kl_loss: 0.000000 normal_loss: 0.014570\n",
      "[158/00049] train_loss: 0.014872 kl_loss: 0.000000 normal_loss: 0.014872\n",
      "[159/00074] train_loss: 0.014569 kl_loss: 0.000000 normal_loss: 0.014569\n",
      "[161/00024] train_loss: 0.014658 kl_loss: 0.000000 normal_loss: 0.014658\n",
      "[162/00049] train_loss: 0.014701 kl_loss: 0.000000 normal_loss: 0.014701\n",
      "[163/00074] train_loss: 0.014564 kl_loss: 0.000000 normal_loss: 0.014564\n",
      "[165/00024] train_loss: 0.014121 kl_loss: 0.000000 normal_loss: 0.014121\n",
      "[166/00049] train_loss: 0.014525 kl_loss: 0.000000 normal_loss: 0.014525\n",
      "[167/00074] train_loss: 0.014238 kl_loss: 0.000000 normal_loss: 0.014238\n",
      "[169/00024] train_loss: 0.014586 kl_loss: 0.000000 normal_loss: 0.014586\n",
      "[170/00049] train_loss: 0.014109 kl_loss: 0.000000 normal_loss: 0.014109\n",
      "[171/00074] train_loss: 0.014192 kl_loss: 0.000000 normal_loss: 0.014192\n",
      "[173/00024] train_loss: 0.014367 kl_loss: 0.000000 normal_loss: 0.014367\n",
      "[174/00049] train_loss: 0.014173 kl_loss: 0.000000 normal_loss: 0.014173\n",
      "[175/00074] train_loss: 0.014156 kl_loss: 0.000000 normal_loss: 0.014156\n",
      "[177/00024] train_loss: 0.014205 kl_loss: 0.000000 normal_loss: 0.014205\n",
      "[178/00049] train_loss: 0.014131 kl_loss: 0.000000 normal_loss: 0.014131\n",
      "[179/00074] train_loss: 0.014310 kl_loss: 0.000000 normal_loss: 0.014310\n",
      "[181/00024] train_loss: 0.013722 kl_loss: 0.000000 normal_loss: 0.013722\n",
      "[182/00049] train_loss: 0.013985 kl_loss: 0.000000 normal_loss: 0.013985\n",
      "[183/00074] train_loss: 0.014210 kl_loss: 0.000000 normal_loss: 0.014210\n",
      "[185/00024] train_loss: 0.013881 kl_loss: 0.000000 normal_loss: 0.013881\n",
      "[186/00049] train_loss: 0.013712 kl_loss: 0.000000 normal_loss: 0.013712\n",
      "[187/00074] train_loss: 0.013481 kl_loss: 0.000000 normal_loss: 0.013481\n",
      "[189/00024] train_loss: 0.014046 kl_loss: 0.000000 normal_loss: 0.014046\n",
      "[190/00049] train_loss: 0.014026 kl_loss: 0.000000 normal_loss: 0.014026\n",
      "[191/00074] train_loss: 0.014068 kl_loss: 0.000000 normal_loss: 0.014068\n",
      "[193/00024] train_loss: 0.013848 kl_loss: 0.000000 normal_loss: 0.013848\n",
      "[194/00049] train_loss: 0.013905 kl_loss: 0.000000 normal_loss: 0.013905\n",
      "[195/00074] train_loss: 0.013573 kl_loss: 0.000000 normal_loss: 0.013573\n",
      "[197/00024] train_loss: 0.013619 kl_loss: 0.000000 normal_loss: 0.013619\n",
      "[198/00049] train_loss: 0.013699 kl_loss: 0.000000 normal_loss: 0.013699\n",
      "[199/00074] train_loss: 0.013374 kl_loss: 0.000000 normal_loss: 0.013374\n",
      "[199/00074] IOU 0.8991929771751166\n",
      "[201/00024] train_loss: 0.012351 kl_loss: 0.000000 normal_loss: 0.012351\n",
      "[202/00049] train_loss: 0.011701 kl_loss: 0.000000 normal_loss: 0.011701\n",
      "[203/00074] train_loss: 0.011644 kl_loss: 0.000000 normal_loss: 0.011644\n",
      "[205/00024] train_loss: 0.011500 kl_loss: 0.000000 normal_loss: 0.011500\n",
      "[206/00049] train_loss: 0.011616 kl_loss: 0.000000 normal_loss: 0.011616\n",
      "[207/00074] train_loss: 0.011539 kl_loss: 0.000000 normal_loss: 0.011539\n",
      "[209/00024] train_loss: 0.011481 kl_loss: 0.000000 normal_loss: 0.011481\n",
      "[210/00049] train_loss: 0.011602 kl_loss: 0.000000 normal_loss: 0.011602\n",
      "[211/00074] train_loss: 0.011510 kl_loss: 0.000000 normal_loss: 0.011510\n",
      "[213/00024] train_loss: 0.011490 kl_loss: 0.000000 normal_loss: 0.011490\n",
      "[214/00049] train_loss: 0.011511 kl_loss: 0.000000 normal_loss: 0.011511\n",
      "[215/00074] train_loss: 0.011491 kl_loss: 0.000000 normal_loss: 0.011491\n",
      "[217/00024] train_loss: 0.011423 kl_loss: 0.000000 normal_loss: 0.011423\n",
      "[218/00049] train_loss: 0.011675 kl_loss: 0.000000 normal_loss: 0.011675\n",
      "[219/00074] train_loss: 0.011741 kl_loss: 0.000000 normal_loss: 0.011741\n",
      "[221/00024] train_loss: 0.011548 kl_loss: 0.000000 normal_loss: 0.011548\n",
      "[222/00049] train_loss: 0.011584 kl_loss: 0.000000 normal_loss: 0.011584\n",
      "[223/00074] train_loss: 0.011517 kl_loss: 0.000000 normal_loss: 0.011517\n",
      "[225/00024] train_loss: 0.011517 kl_loss: 0.000000 normal_loss: 0.011517\n",
      "[226/00049] train_loss: 0.011440 kl_loss: 0.000000 normal_loss: 0.011440\n",
      "[227/00074] train_loss: 0.011536 kl_loss: 0.000000 normal_loss: 0.011536\n",
      "[229/00024] train_loss: 0.011458 kl_loss: 0.000000 normal_loss: 0.011458\n",
      "[230/00049] train_loss: 0.011424 kl_loss: 0.000000 normal_loss: 0.011424\n",
      "[231/00074] train_loss: 0.011441 kl_loss: 0.000000 normal_loss: 0.011441\n",
      "[233/00024] train_loss: 0.011437 kl_loss: 0.000000 normal_loss: 0.011437\n",
      "[234/00049] train_loss: 0.011520 kl_loss: 0.000000 normal_loss: 0.011520\n",
      "[235/00074] train_loss: 0.011382 kl_loss: 0.000000 normal_loss: 0.011382\n",
      "[237/00024] train_loss: 0.011432 kl_loss: 0.000000 normal_loss: 0.011432\n",
      "[238/00049] train_loss: 0.011508 kl_loss: 0.000000 normal_loss: 0.011508\n",
      "[239/00074] train_loss: 0.011330 kl_loss: 0.000000 normal_loss: 0.011330\n",
      "[241/00024] train_loss: 0.011474 kl_loss: 0.000000 normal_loss: 0.011474\n",
      "[242/00049] train_loss: 0.011459 kl_loss: 0.000000 normal_loss: 0.011459\n",
      "[243/00074] train_loss: 0.011282 kl_loss: 0.000000 normal_loss: 0.011282\n",
      "[245/00024] train_loss: 0.011403 kl_loss: 0.000000 normal_loss: 0.011403\n",
      "[246/00049] train_loss: 0.011354 kl_loss: 0.000000 normal_loss: 0.011354\n",
      "[247/00074] train_loss: 0.011400 kl_loss: 0.000000 normal_loss: 0.011400\n",
      "[249/00024] train_loss: 0.011352 kl_loss: 0.000000 normal_loss: 0.011352\n",
      "[249/00074] IOU 0.9097692750145991\n",
      "[250/00049] train_loss: 0.011393 kl_loss: 0.000000 normal_loss: 0.011393\n",
      "[251/00074] train_loss: 0.011180 kl_loss: 0.000000 normal_loss: 0.011180\n",
      "[253/00024] train_loss: 0.011163 kl_loss: 0.000000 normal_loss: 0.011163\n",
      "[254/00049] train_loss: 0.011223 kl_loss: 0.000000 normal_loss: 0.011223\n",
      "[255/00074] train_loss: 0.011185 kl_loss: 0.000000 normal_loss: 0.011185\n",
      "[257/00024] train_loss: 0.011283 kl_loss: 0.000000 normal_loss: 0.011283\n",
      "[258/00049] train_loss: 0.011216 kl_loss: 0.000000 normal_loss: 0.011216\n",
      "[259/00074] train_loss: 0.011251 kl_loss: 0.000000 normal_loss: 0.011251\n",
      "[261/00024] train_loss: 0.011064 kl_loss: 0.000000 normal_loss: 0.011064\n",
      "[262/00049] train_loss: 0.011278 kl_loss: 0.000000 normal_loss: 0.011278\n",
      "[263/00074] train_loss: 0.011164 kl_loss: 0.000000 normal_loss: 0.011164\n",
      "[265/00024] train_loss: 0.011301 kl_loss: 0.000000 normal_loss: 0.011301\n",
      "[266/00049] train_loss: 0.011068 kl_loss: 0.000000 normal_loss: 0.011068\n",
      "[267/00074] train_loss: 0.011145 kl_loss: 0.000000 normal_loss: 0.011145\n",
      "[269/00024] train_loss: 0.011347 kl_loss: 0.000000 normal_loss: 0.011347\n",
      "[270/00049] train_loss: 0.011098 kl_loss: 0.000000 normal_loss: 0.011098\n",
      "[271/00074] train_loss: 0.011144 kl_loss: 0.000000 normal_loss: 0.011144\n",
      "[273/00024] train_loss: 0.010963 kl_loss: 0.000000 normal_loss: 0.010963\n",
      "[274/00049] train_loss: 0.011172 kl_loss: 0.000000 normal_loss: 0.011172\n",
      "[275/00074] train_loss: 0.011058 kl_loss: 0.000000 normal_loss: 0.011058\n",
      "[277/00024] train_loss: 0.011133 kl_loss: 0.000000 normal_loss: 0.011133\n",
      "[278/00049] train_loss: 0.011219 kl_loss: 0.000000 normal_loss: 0.011219\n",
      "[279/00074] train_loss: 0.011025 kl_loss: 0.000000 normal_loss: 0.011025\n",
      "[281/00024] train_loss: 0.011000 kl_loss: 0.000000 normal_loss: 0.011000\n",
      "[282/00049] train_loss: 0.011118 kl_loss: 0.000000 normal_loss: 0.011118\n",
      "[283/00074] train_loss: 0.011107 kl_loss: 0.000000 normal_loss: 0.011107\n",
      "[285/00024] train_loss: 0.010989 kl_loss: 0.000000 normal_loss: 0.010989\n",
      "[286/00049] train_loss: 0.011106 kl_loss: 0.000000 normal_loss: 0.011106\n",
      "[287/00074] train_loss: 0.010985 kl_loss: 0.000000 normal_loss: 0.010985\n",
      "[289/00024] train_loss: 0.011186 kl_loss: 0.000000 normal_loss: 0.011186\n",
      "[290/00049] train_loss: 0.010873 kl_loss: 0.000000 normal_loss: 0.010873\n",
      "[291/00074] train_loss: 0.010929 kl_loss: 0.000000 normal_loss: 0.010929\n",
      "[293/00024] train_loss: 0.010951 kl_loss: 0.000000 normal_loss: 0.010951\n",
      "[294/00049] train_loss: 0.011059 kl_loss: 0.000000 normal_loss: 0.011059\n",
      "[295/00074] train_loss: 0.011040 kl_loss: 0.000000 normal_loss: 0.011040\n",
      "[297/00024] train_loss: 0.010972 kl_loss: 0.000000 normal_loss: 0.010972\n",
      "[298/00049] train_loss: 0.010871 kl_loss: 0.000000 normal_loss: 0.010871\n",
      "[299/00074] train_loss: 0.010959 kl_loss: 0.000000 normal_loss: 0.010959\n",
      "[299/00074] IOU 0.9090687726127604\n",
      "[301/00024] train_loss: 0.010345 kl_loss: 0.000000 normal_loss: 0.010345\n",
      "[302/00049] train_loss: 0.010154 kl_loss: 0.000000 normal_loss: 0.010154\n",
      "[303/00074] train_loss: 0.010115 kl_loss: 0.000000 normal_loss: 0.010115\n",
      "[305/00024] train_loss: 0.010201 kl_loss: 0.000000 normal_loss: 0.010201\n",
      "[306/00049] train_loss: 0.010100 kl_loss: 0.000000 normal_loss: 0.010100\n",
      "[307/00074] train_loss: 0.010107 kl_loss: 0.000000 normal_loss: 0.010107\n",
      "[309/00024] train_loss: 0.010163 kl_loss: 0.000000 normal_loss: 0.010163\n",
      "[310/00049] train_loss: 0.010034 kl_loss: 0.000000 normal_loss: 0.010034\n",
      "[311/00074] train_loss: 0.010108 kl_loss: 0.000000 normal_loss: 0.010108\n",
      "[313/00024] train_loss: 0.010115 kl_loss: 0.000000 normal_loss: 0.010115\n",
      "[314/00049] train_loss: 0.010149 kl_loss: 0.000000 normal_loss: 0.010149\n",
      "[315/00074] train_loss: 0.010075 kl_loss: 0.000000 normal_loss: 0.010075\n",
      "[317/00024] train_loss: 0.010188 kl_loss: 0.000000 normal_loss: 0.010188\n",
      "[318/00049] train_loss: 0.010170 kl_loss: 0.000000 normal_loss: 0.010170\n",
      "[319/00074] train_loss: 0.010041 kl_loss: 0.000000 normal_loss: 0.010041\n",
      "[321/00024] train_loss: 0.010063 kl_loss: 0.000000 normal_loss: 0.010063\n",
      "[322/00049] train_loss: 0.009991 kl_loss: 0.000000 normal_loss: 0.009991\n",
      "[323/00074] train_loss: 0.010043 kl_loss: 0.000000 normal_loss: 0.010043\n",
      "[325/00024] train_loss: 0.010064 kl_loss: 0.000000 normal_loss: 0.010064\n",
      "[326/00049] train_loss: 0.010069 kl_loss: 0.000000 normal_loss: 0.010069\n",
      "[327/00074] train_loss: 0.010033 kl_loss: 0.000000 normal_loss: 0.010033\n",
      "[329/00024] train_loss: 0.010040 kl_loss: 0.000000 normal_loss: 0.010040\n",
      "[330/00049] train_loss: 0.010082 kl_loss: 0.000000 normal_loss: 0.010082\n",
      "[331/00074] train_loss: 0.010083 kl_loss: 0.000000 normal_loss: 0.010083\n",
      "[333/00024] train_loss: 0.010194 kl_loss: 0.000000 normal_loss: 0.010194\n",
      "[334/00049] train_loss: 0.009973 kl_loss: 0.000000 normal_loss: 0.009973\n",
      "[335/00074] train_loss: 0.010036 kl_loss: 0.000000 normal_loss: 0.010036\n",
      "[337/00024] train_loss: 0.010017 kl_loss: 0.000000 normal_loss: 0.010017\n",
      "[338/00049] train_loss: 0.009979 kl_loss: 0.000000 normal_loss: 0.009979\n",
      "[339/00074] train_loss: 0.010012 kl_loss: 0.000000 normal_loss: 0.010012\n",
      "[341/00024] train_loss: 0.009935 kl_loss: 0.000000 normal_loss: 0.009935\n",
      "[342/00049] train_loss: 0.010071 kl_loss: 0.000000 normal_loss: 0.010071\n",
      "[343/00074] train_loss: 0.009963 kl_loss: 0.000000 normal_loss: 0.009963\n",
      "[345/00024] train_loss: 0.009981 kl_loss: 0.000000 normal_loss: 0.009981\n",
      "[346/00049] train_loss: 0.009955 kl_loss: 0.000000 normal_loss: 0.009955\n",
      "[347/00074] train_loss: 0.009958 kl_loss: 0.000000 normal_loss: 0.009958\n",
      "[349/00024] train_loss: 0.010044 kl_loss: 0.000000 normal_loss: 0.010044\n",
      "[349/00074] IOU 0.9136460893414915\n",
      "[350/00049] train_loss: 0.009924 kl_loss: 0.000000 normal_loss: 0.009924\n",
      "[351/00074] train_loss: 0.009981 kl_loss: 0.000000 normal_loss: 0.009981\n",
      "[353/00024] train_loss: 0.009933 kl_loss: 0.000000 normal_loss: 0.009933\n",
      "[354/00049] train_loss: 0.009890 kl_loss: 0.000000 normal_loss: 0.009890\n",
      "[355/00074] train_loss: 0.009957 kl_loss: 0.000000 normal_loss: 0.009957\n",
      "[357/00024] train_loss: 0.009963 kl_loss: 0.000000 normal_loss: 0.009963\n",
      "[358/00049] train_loss: 0.009960 kl_loss: 0.000000 normal_loss: 0.009960\n",
      "[359/00074] train_loss: 0.009859 kl_loss: 0.000000 normal_loss: 0.009859\n",
      "[361/00024] train_loss: 0.009998 kl_loss: 0.000000 normal_loss: 0.009998\n",
      "[362/00049] train_loss: 0.009995 kl_loss: 0.000000 normal_loss: 0.009995\n",
      "[363/00074] train_loss: 0.009922 kl_loss: 0.000000 normal_loss: 0.009922\n",
      "[365/00024] train_loss: 0.009864 kl_loss: 0.000000 normal_loss: 0.009864\n",
      "[366/00049] train_loss: 0.009954 kl_loss: 0.000000 normal_loss: 0.009954\n",
      "[367/00074] train_loss: 0.009985 kl_loss: 0.000000 normal_loss: 0.009985\n",
      "[369/00024] train_loss: 0.009921 kl_loss: 0.000000 normal_loss: 0.009921\n",
      "[370/00049] train_loss: 0.009901 kl_loss: 0.000000 normal_loss: 0.009901\n",
      "[371/00074] train_loss: 0.009925 kl_loss: 0.000000 normal_loss: 0.009925\n",
      "[373/00024] train_loss: 0.009891 kl_loss: 0.000000 normal_loss: 0.009891\n",
      "[374/00049] train_loss: 0.009865 kl_loss: 0.000000 normal_loss: 0.009865\n",
      "[375/00074] train_loss: 0.009865 kl_loss: 0.000000 normal_loss: 0.009865\n",
      "[377/00024] train_loss: 0.009924 kl_loss: 0.000000 normal_loss: 0.009924\n",
      "[378/00049] train_loss: 0.009788 kl_loss: 0.000000 normal_loss: 0.009788\n",
      "[379/00074] train_loss: 0.009802 kl_loss: 0.000000 normal_loss: 0.009802\n",
      "[381/00024] train_loss: 0.009820 kl_loss: 0.000000 normal_loss: 0.009820\n",
      "[382/00049] train_loss: 0.009806 kl_loss: 0.000000 normal_loss: 0.009806\n",
      "[383/00074] train_loss: 0.009812 kl_loss: 0.000000 normal_loss: 0.009812\n",
      "[385/00024] train_loss: 0.009851 kl_loss: 0.000000 normal_loss: 0.009851\n",
      "[386/00049] train_loss: 0.009822 kl_loss: 0.000000 normal_loss: 0.009822\n",
      "[387/00074] train_loss: 0.009862 kl_loss: 0.000000 normal_loss: 0.009862\n",
      "[389/00024] train_loss: 0.009803 kl_loss: 0.000000 normal_loss: 0.009803\n",
      "[390/00049] train_loss: 0.009755 kl_loss: 0.000000 normal_loss: 0.009755\n",
      "[391/00074] train_loss: 0.009870 kl_loss: 0.000000 normal_loss: 0.009870\n",
      "[393/00024] train_loss: 0.009904 kl_loss: 0.000000 normal_loss: 0.009904\n",
      "[394/00049] train_loss: 0.009875 kl_loss: 0.000000 normal_loss: 0.009875\n",
      "[395/00074] train_loss: 0.009751 kl_loss: 0.000000 normal_loss: 0.009751\n",
      "[397/00024] train_loss: 0.009760 kl_loss: 0.000000 normal_loss: 0.009760\n",
      "[398/00049] train_loss: 0.009743 kl_loss: 0.000000 normal_loss: 0.009743\n",
      "[399/00074] train_loss: 0.009700 kl_loss: 0.000000 normal_loss: 0.009700\n",
      "[399/00074] IOU 0.9167061796349784\n",
      "[401/00024] train_loss: 0.009582 kl_loss: 0.000000 normal_loss: 0.009582\n",
      "[402/00049] train_loss: 0.009484 kl_loss: 0.000000 normal_loss: 0.009484\n",
      "[403/00074] train_loss: 0.009537 kl_loss: 0.000000 normal_loss: 0.009537\n",
      "[405/00024] train_loss: 0.009503 kl_loss: 0.000000 normal_loss: 0.009503\n",
      "[406/00049] train_loss: 0.009487 kl_loss: 0.000000 normal_loss: 0.009487\n",
      "[407/00074] train_loss: 0.009437 kl_loss: 0.000000 normal_loss: 0.009437\n",
      "[409/00024] train_loss: 0.009476 kl_loss: 0.000000 normal_loss: 0.009476\n",
      "[410/00049] train_loss: 0.009451 kl_loss: 0.000000 normal_loss: 0.009451\n",
      "[411/00074] train_loss: 0.009444 kl_loss: 0.000000 normal_loss: 0.009444\n",
      "[413/00024] train_loss: 0.009420 kl_loss: 0.000000 normal_loss: 0.009420\n",
      "[414/00049] train_loss: 0.009469 kl_loss: 0.000000 normal_loss: 0.009469\n",
      "[415/00074] train_loss: 0.009595 kl_loss: 0.000000 normal_loss: 0.009595\n",
      "[417/00024] train_loss: 0.009462 kl_loss: 0.000000 normal_loss: 0.009462\n",
      "[418/00049] train_loss: 0.009431 kl_loss: 0.000000 normal_loss: 0.009431\n",
      "[419/00074] train_loss: 0.009461 kl_loss: 0.000000 normal_loss: 0.009461\n",
      "[421/00024] train_loss: 0.009500 kl_loss: 0.000000 normal_loss: 0.009500\n",
      "[422/00049] train_loss: 0.009395 kl_loss: 0.000000 normal_loss: 0.009395\n",
      "[423/00074] train_loss: 0.009445 kl_loss: 0.000000 normal_loss: 0.009445\n",
      "[425/00024] train_loss: 0.009456 kl_loss: 0.000000 normal_loss: 0.009456\n",
      "[426/00049] train_loss: 0.009399 kl_loss: 0.000000 normal_loss: 0.009399\n",
      "[427/00074] train_loss: 0.009494 kl_loss: 0.000000 normal_loss: 0.009494\n",
      "[429/00024] train_loss: 0.009382 kl_loss: 0.000000 normal_loss: 0.009382\n",
      "[430/00049] train_loss: 0.009525 kl_loss: 0.000000 normal_loss: 0.009525\n",
      "[431/00074] train_loss: 0.009366 kl_loss: 0.000000 normal_loss: 0.009366\n",
      "[433/00024] train_loss: 0.009379 kl_loss: 0.000000 normal_loss: 0.009379\n",
      "[434/00049] train_loss: 0.009400 kl_loss: 0.000000 normal_loss: 0.009400\n",
      "[435/00074] train_loss: 0.009426 kl_loss: 0.000000 normal_loss: 0.009426\n",
      "[437/00024] train_loss: 0.009387 kl_loss: 0.000000 normal_loss: 0.009387\n",
      "[438/00049] train_loss: 0.009469 kl_loss: 0.000000 normal_loss: 0.009469\n",
      "[439/00074] train_loss: 0.009370 kl_loss: 0.000000 normal_loss: 0.009370\n",
      "[441/00024] train_loss: 0.009428 kl_loss: 0.000000 normal_loss: 0.009428\n",
      "[442/00049] train_loss: 0.009426 kl_loss: 0.000000 normal_loss: 0.009426\n",
      "[443/00074] train_loss: 0.009386 kl_loss: 0.000000 normal_loss: 0.009386\n",
      "[445/00024] train_loss: 0.009415 kl_loss: 0.000000 normal_loss: 0.009415\n",
      "[446/00049] train_loss: 0.009388 kl_loss: 0.000000 normal_loss: 0.009388\n",
      "[447/00074] train_loss: 0.009373 kl_loss: 0.000000 normal_loss: 0.009373\n",
      "[449/00024] train_loss: 0.009362 kl_loss: 0.000000 normal_loss: 0.009362\n",
      "[449/00074] IOU 0.9176198591167728\n",
      "[450/00049] train_loss: 0.009342 kl_loss: 0.000000 normal_loss: 0.009342\n",
      "[451/00074] train_loss: 0.009419 kl_loss: 0.000000 normal_loss: 0.009419\n",
      "[453/00024] train_loss: 0.009396 kl_loss: 0.000000 normal_loss: 0.009396\n",
      "[454/00049] train_loss: 0.009279 kl_loss: 0.000000 normal_loss: 0.009279\n",
      "[455/00074] train_loss: 0.009350 kl_loss: 0.000000 normal_loss: 0.009350\n",
      "[457/00024] train_loss: 0.009387 kl_loss: 0.000000 normal_loss: 0.009387\n",
      "[458/00049] train_loss: 0.009380 kl_loss: 0.000000 normal_loss: 0.009380\n",
      "[459/00074] train_loss: 0.009369 kl_loss: 0.000000 normal_loss: 0.009369\n",
      "[461/00024] train_loss: 0.009380 kl_loss: 0.000000 normal_loss: 0.009380\n",
      "[462/00049] train_loss: 0.009346 kl_loss: 0.000000 normal_loss: 0.009346\n",
      "[463/00074] train_loss: 0.009486 kl_loss: 0.000000 normal_loss: 0.009486\n",
      "[465/00024] train_loss: 0.009400 kl_loss: 0.000000 normal_loss: 0.009400\n",
      "[466/00049] train_loss: 0.009361 kl_loss: 0.000000 normal_loss: 0.009361\n",
      "[467/00074] train_loss: 0.009257 kl_loss: 0.000000 normal_loss: 0.009257\n",
      "[469/00024] train_loss: 0.009341 kl_loss: 0.000000 normal_loss: 0.009341\n",
      "[470/00049] train_loss: 0.009389 kl_loss: 0.000000 normal_loss: 0.009389\n",
      "[471/00074] train_loss: 0.009313 kl_loss: 0.000000 normal_loss: 0.009313\n",
      "[473/00024] train_loss: 0.009314 kl_loss: 0.000000 normal_loss: 0.009314\n",
      "[474/00049] train_loss: 0.009491 kl_loss: 0.000000 normal_loss: 0.009491\n",
      "[475/00074] train_loss: 0.009285 kl_loss: 0.000000 normal_loss: 0.009285\n",
      "[477/00024] train_loss: 0.009291 kl_loss: 0.000000 normal_loss: 0.009291\n",
      "[478/00049] train_loss: 0.009256 kl_loss: 0.000000 normal_loss: 0.009256\n",
      "[479/00074] train_loss: 0.009355 kl_loss: 0.000000 normal_loss: 0.009355\n",
      "[481/00024] train_loss: 0.009277 kl_loss: 0.000000 normal_loss: 0.009277\n",
      "[482/00049] train_loss: 0.009281 kl_loss: 0.000000 normal_loss: 0.009281\n",
      "[483/00074] train_loss: 0.009314 kl_loss: 0.000000 normal_loss: 0.009314\n",
      "[485/00024] train_loss: 0.009307 kl_loss: 0.000000 normal_loss: 0.009307\n",
      "[486/00049] train_loss: 0.009324 kl_loss: 0.000000 normal_loss: 0.009324\n",
      "[487/00074] train_loss: 0.009298 kl_loss: 0.000000 normal_loss: 0.009298\n",
      "[489/00024] train_loss: 0.009349 kl_loss: 0.000000 normal_loss: 0.009349\n",
      "[490/00049] train_loss: 0.009310 kl_loss: 0.000000 normal_loss: 0.009310\n",
      "[491/00074] train_loss: 0.009278 kl_loss: 0.000000 normal_loss: 0.009278\n",
      "[493/00024] train_loss: 0.009312 kl_loss: 0.000000 normal_loss: 0.009312\n",
      "[494/00049] train_loss: 0.009280 kl_loss: 0.000000 normal_loss: 0.009280\n",
      "[495/00074] train_loss: 0.009283 kl_loss: 0.000000 normal_loss: 0.009283\n",
      "[497/00024] train_loss: 0.009348 kl_loss: 0.000000 normal_loss: 0.009348\n",
      "[498/00049] train_loss: 0.009276 kl_loss: 0.000000 normal_loss: 0.009276\n",
      "[499/00074] train_loss: 0.009316 kl_loss: 0.000000 normal_loss: 0.009316\n",
      "[499/00074] IOU 0.9187757863290608\n",
      "[501/00024] train_loss: 0.009178 kl_loss: 0.000000 normal_loss: 0.009178\n",
      "[502/00049] train_loss: 0.009143 kl_loss: 0.000000 normal_loss: 0.009143\n",
      "[503/00074] train_loss: 0.009154 kl_loss: 0.000000 normal_loss: 0.009154\n",
      "[505/00024] train_loss: 0.009155 kl_loss: 0.000000 normal_loss: 0.009155\n",
      "[506/00049] train_loss: 0.009105 kl_loss: 0.000000 normal_loss: 0.009105\n",
      "[507/00074] train_loss: 0.009165 kl_loss: 0.000000 normal_loss: 0.009165\n",
      "[509/00024] train_loss: 0.009148 kl_loss: 0.000000 normal_loss: 0.009148\n",
      "[510/00049] train_loss: 0.009087 kl_loss: 0.000000 normal_loss: 0.009087\n",
      "[511/00074] train_loss: 0.009185 kl_loss: 0.000000 normal_loss: 0.009185\n",
      "[513/00024] train_loss: 0.009153 kl_loss: 0.000000 normal_loss: 0.009153\n",
      "[514/00049] train_loss: 0.009177 kl_loss: 0.000000 normal_loss: 0.009177\n",
      "[515/00074] train_loss: 0.009111 kl_loss: 0.000000 normal_loss: 0.009111\n",
      "[517/00024] train_loss: 0.009079 kl_loss: 0.000000 normal_loss: 0.009079\n",
      "[518/00049] train_loss: 0.009156 kl_loss: 0.000000 normal_loss: 0.009156\n",
      "[519/00074] train_loss: 0.009155 kl_loss: 0.000000 normal_loss: 0.009155\n",
      "[521/00024] train_loss: 0.009109 kl_loss: 0.000000 normal_loss: 0.009109\n",
      "[522/00049] train_loss: 0.009177 kl_loss: 0.000000 normal_loss: 0.009177\n",
      "[523/00074] train_loss: 0.009139 kl_loss: 0.000000 normal_loss: 0.009139\n",
      "[525/00024] train_loss: 0.009088 kl_loss: 0.000000 normal_loss: 0.009088\n",
      "[526/00049] train_loss: 0.009088 kl_loss: 0.000000 normal_loss: 0.009088\n",
      "[527/00074] train_loss: 0.009167 kl_loss: 0.000000 normal_loss: 0.009167\n",
      "[529/00024] train_loss: 0.009094 kl_loss: 0.000000 normal_loss: 0.009094\n",
      "[530/00049] train_loss: 0.009168 kl_loss: 0.000000 normal_loss: 0.009168\n",
      "[531/00074] train_loss: 0.009083 kl_loss: 0.000000 normal_loss: 0.009083\n",
      "[533/00024] train_loss: 0.009093 kl_loss: 0.000000 normal_loss: 0.009093\n",
      "[534/00049] train_loss: 0.009144 kl_loss: 0.000000 normal_loss: 0.009144\n",
      "[535/00074] train_loss: 0.009079 kl_loss: 0.000000 normal_loss: 0.009079\n",
      "[537/00024] train_loss: 0.009097 kl_loss: 0.000000 normal_loss: 0.009097\n",
      "[538/00049] train_loss: 0.009092 kl_loss: 0.000000 normal_loss: 0.009092\n",
      "[539/00074] train_loss: 0.009147 kl_loss: 0.000000 normal_loss: 0.009147\n",
      "[541/00024] train_loss: 0.009102 kl_loss: 0.000000 normal_loss: 0.009102\n",
      "[542/00049] train_loss: 0.009146 kl_loss: 0.000000 normal_loss: 0.009146\n",
      "[543/00074] train_loss: 0.009091 kl_loss: 0.000000 normal_loss: 0.009091\n",
      "[545/00024] train_loss: 0.009117 kl_loss: 0.000000 normal_loss: 0.009117\n",
      "[546/00049] train_loss: 0.009158 kl_loss: 0.000000 normal_loss: 0.009158\n",
      "[547/00074] train_loss: 0.009088 kl_loss: 0.000000 normal_loss: 0.009088\n",
      "[549/00024] train_loss: 0.009081 kl_loss: 0.000000 normal_loss: 0.009081\n",
      "[549/00074] IOU 0.9194678045560917\n",
      "[550/00049] train_loss: 0.009057 kl_loss: 0.000000 normal_loss: 0.009057\n",
      "[551/00074] train_loss: 0.009121 kl_loss: 0.000000 normal_loss: 0.009121\n",
      "[553/00024] train_loss: 0.009082 kl_loss: 0.000000 normal_loss: 0.009082\n",
      "[554/00049] train_loss: 0.009158 kl_loss: 0.000000 normal_loss: 0.009158\n",
      "[555/00074] train_loss: 0.009105 kl_loss: 0.000000 normal_loss: 0.009105\n",
      "[557/00024] train_loss: 0.009068 kl_loss: 0.000000 normal_loss: 0.009068\n",
      "[558/00049] train_loss: 0.009112 kl_loss: 0.000000 normal_loss: 0.009112\n",
      "[559/00074] train_loss: 0.009099 kl_loss: 0.000000 normal_loss: 0.009099\n",
      "[561/00024] train_loss: 0.009077 kl_loss: 0.000000 normal_loss: 0.009077\n",
      "[562/00049] train_loss: 0.009059 kl_loss: 0.000000 normal_loss: 0.009059\n",
      "[563/00074] train_loss: 0.009095 kl_loss: 0.000000 normal_loss: 0.009095\n",
      "[565/00024] train_loss: 0.009057 kl_loss: 0.000000 normal_loss: 0.009057\n",
      "[566/00049] train_loss: 0.009075 kl_loss: 0.000000 normal_loss: 0.009075\n",
      "[567/00074] train_loss: 0.009095 kl_loss: 0.000000 normal_loss: 0.009095\n",
      "[569/00024] train_loss: 0.009080 kl_loss: 0.000000 normal_loss: 0.009080\n",
      "[570/00049] train_loss: 0.009121 kl_loss: 0.000000 normal_loss: 0.009121\n",
      "[571/00074] train_loss: 0.009088 kl_loss: 0.000000 normal_loss: 0.009088\n",
      "[573/00024] train_loss: 0.009042 kl_loss: 0.000000 normal_loss: 0.009042\n",
      "[574/00049] train_loss: 0.009119 kl_loss: 0.000000 normal_loss: 0.009119\n",
      "[575/00074] train_loss: 0.009072 kl_loss: 0.000000 normal_loss: 0.009072\n",
      "[577/00024] train_loss: 0.009044 kl_loss: 0.000000 normal_loss: 0.009044\n",
      "[578/00049] train_loss: 0.009084 kl_loss: 0.000000 normal_loss: 0.009084\n",
      "[579/00074] train_loss: 0.009063 kl_loss: 0.000000 normal_loss: 0.009063\n",
      "[581/00024] train_loss: 0.009070 kl_loss: 0.000000 normal_loss: 0.009070\n",
      "[582/00049] train_loss: 0.009110 kl_loss: 0.000000 normal_loss: 0.009110\n",
      "[583/00074] train_loss: 0.009051 kl_loss: 0.000000 normal_loss: 0.009051\n",
      "[585/00024] train_loss: 0.009094 kl_loss: 0.000000 normal_loss: 0.009094\n",
      "[586/00049] train_loss: 0.009072 kl_loss: 0.000000 normal_loss: 0.009072\n",
      "[587/00074] train_loss: 0.009042 kl_loss: 0.000000 normal_loss: 0.009042\n",
      "[589/00024] train_loss: 0.009039 kl_loss: 0.000000 normal_loss: 0.009039\n",
      "[590/00049] train_loss: 0.009043 kl_loss: 0.000000 normal_loss: 0.009043\n",
      "[591/00074] train_loss: 0.009093 kl_loss: 0.000000 normal_loss: 0.009093\n",
      "[593/00024] train_loss: 0.009024 kl_loss: 0.000000 normal_loss: 0.009024\n",
      "[594/00049] train_loss: 0.009068 kl_loss: 0.000000 normal_loss: 0.009068\n",
      "[595/00074] train_loss: 0.009055 kl_loss: 0.000000 normal_loss: 0.009055\n",
      "[597/00024] train_loss: 0.009086 kl_loss: 0.000000 normal_loss: 0.009086\n",
      "[598/00049] train_loss: 0.009089 kl_loss: 0.000000 normal_loss: 0.009089\n",
      "[599/00074] train_loss: 0.009002 kl_loss: 0.000000 normal_loss: 0.009002\n",
      "[599/00074] IOU 0.9207689363136887\n",
      "[601/00024] train_loss: 0.008974 kl_loss: 0.000000 normal_loss: 0.008974\n",
      "[602/00049] train_loss: 0.008986 kl_loss: 0.000000 normal_loss: 0.008986\n",
      "[603/00074] train_loss: 0.009004 kl_loss: 0.000000 normal_loss: 0.009004\n",
      "[605/00024] train_loss: 0.008993 kl_loss: 0.000000 normal_loss: 0.008993\n",
      "[606/00049] train_loss: 0.008920 kl_loss: 0.000000 normal_loss: 0.008920\n",
      "[607/00074] train_loss: 0.008993 kl_loss: 0.000000 normal_loss: 0.008993\n",
      "[609/00024] train_loss: 0.008979 kl_loss: 0.000000 normal_loss: 0.008979\n",
      "[610/00049] train_loss: 0.008967 kl_loss: 0.000000 normal_loss: 0.008967\n",
      "[611/00074] train_loss: 0.008987 kl_loss: 0.000000 normal_loss: 0.008987\n",
      "[613/00024] train_loss: 0.008939 kl_loss: 0.000000 normal_loss: 0.008939\n",
      "[614/00049] train_loss: 0.009030 kl_loss: 0.000000 normal_loss: 0.009030\n",
      "[615/00074] train_loss: 0.008957 kl_loss: 0.000000 normal_loss: 0.008957\n",
      "[617/00024] train_loss: 0.008989 kl_loss: 0.000000 normal_loss: 0.008989\n",
      "[618/00049] train_loss: 0.008979 kl_loss: 0.000000 normal_loss: 0.008979\n",
      "[619/00074] train_loss: 0.008958 kl_loss: 0.000000 normal_loss: 0.008958\n",
      "[621/00024] train_loss: 0.008922 kl_loss: 0.000000 normal_loss: 0.008922\n",
      "[622/00049] train_loss: 0.008992 kl_loss: 0.000000 normal_loss: 0.008992\n",
      "[623/00074] train_loss: 0.008990 kl_loss: 0.000000 normal_loss: 0.008990\n",
      "[625/00024] train_loss: 0.008965 kl_loss: 0.000000 normal_loss: 0.008965\n",
      "[626/00049] train_loss: 0.008937 kl_loss: 0.000000 normal_loss: 0.008937\n",
      "[627/00074] train_loss: 0.008999 kl_loss: 0.000000 normal_loss: 0.008999\n",
      "[629/00024] train_loss: 0.008934 kl_loss: 0.000000 normal_loss: 0.008934\n",
      "[630/00049] train_loss: 0.009042 kl_loss: 0.000000 normal_loss: 0.009042\n",
      "[631/00074] train_loss: 0.008947 kl_loss: 0.000000 normal_loss: 0.008947\n",
      "[633/00024] train_loss: 0.008940 kl_loss: 0.000000 normal_loss: 0.008940\n",
      "[634/00049] train_loss: 0.008986 kl_loss: 0.000000 normal_loss: 0.008986\n",
      "[635/00074] train_loss: 0.008986 kl_loss: 0.000000 normal_loss: 0.008986\n",
      "[637/00024] train_loss: 0.008987 kl_loss: 0.000000 normal_loss: 0.008987\n",
      "[638/00049] train_loss: 0.008953 kl_loss: 0.000000 normal_loss: 0.008953\n",
      "[639/00074] train_loss: 0.008958 kl_loss: 0.000000 normal_loss: 0.008958\n",
      "[641/00024] train_loss: 0.008921 kl_loss: 0.000000 normal_loss: 0.008921\n",
      "[642/00049] train_loss: 0.008987 kl_loss: 0.000000 normal_loss: 0.008987\n",
      "[643/00074] train_loss: 0.008983 kl_loss: 0.000000 normal_loss: 0.008983\n",
      "[645/00024] train_loss: 0.008982 kl_loss: 0.000000 normal_loss: 0.008982\n",
      "[646/00049] train_loss: 0.008947 kl_loss: 0.000000 normal_loss: 0.008947\n",
      "[647/00074] train_loss: 0.008970 kl_loss: 0.000000 normal_loss: 0.008970\n",
      "[649/00024] train_loss: 0.008954 kl_loss: 0.000000 normal_loss: 0.008954\n",
      "[649/00074] IOU 0.9200765140975515\n",
      "[650/00049] train_loss: 0.008913 kl_loss: 0.000000 normal_loss: 0.008913\n",
      "[651/00074] train_loss: 0.008990 kl_loss: 0.000000 normal_loss: 0.008990\n",
      "[653/00024] train_loss: 0.008923 kl_loss: 0.000000 normal_loss: 0.008923\n",
      "[654/00049] train_loss: 0.008993 kl_loss: 0.000000 normal_loss: 0.008993\n",
      "[655/00074] train_loss: 0.008922 kl_loss: 0.000000 normal_loss: 0.008922\n",
      "[657/00024] train_loss: 0.008969 kl_loss: 0.000000 normal_loss: 0.008969\n",
      "[658/00049] train_loss: 0.008977 kl_loss: 0.000000 normal_loss: 0.008977\n",
      "[659/00074] train_loss: 0.008952 kl_loss: 0.000000 normal_loss: 0.008952\n",
      "[661/00024] train_loss: 0.008921 kl_loss: 0.000000 normal_loss: 0.008921\n",
      "[662/00049] train_loss: 0.008931 kl_loss: 0.000000 normal_loss: 0.008931\n",
      "[663/00074] train_loss: 0.008972 kl_loss: 0.000000 normal_loss: 0.008972\n",
      "[665/00024] train_loss: 0.008936 kl_loss: 0.000000 normal_loss: 0.008936\n",
      "[666/00049] train_loss: 0.009000 kl_loss: 0.000000 normal_loss: 0.009000\n",
      "[667/00074] train_loss: 0.008916 kl_loss: 0.000000 normal_loss: 0.008916\n",
      "[669/00024] train_loss: 0.008925 kl_loss: 0.000000 normal_loss: 0.008925\n",
      "[670/00049] train_loss: 0.008915 kl_loss: 0.000000 normal_loss: 0.008915\n",
      "[671/00074] train_loss: 0.008993 kl_loss: 0.000000 normal_loss: 0.008993\n",
      "[673/00024] train_loss: 0.008948 kl_loss: 0.000000 normal_loss: 0.008948\n",
      "[674/00049] train_loss: 0.008964 kl_loss: 0.000000 normal_loss: 0.008964\n",
      "[675/00074] train_loss: 0.008935 kl_loss: 0.000000 normal_loss: 0.008935\n",
      "[677/00024] train_loss: 0.008906 kl_loss: 0.000000 normal_loss: 0.008906\n",
      "[678/00049] train_loss: 0.008982 kl_loss: 0.000000 normal_loss: 0.008982\n",
      "[679/00074] train_loss: 0.008942 kl_loss: 0.000000 normal_loss: 0.008942\n",
      "[681/00024] train_loss: 0.008948 kl_loss: 0.000000 normal_loss: 0.008948\n",
      "[682/00049] train_loss: 0.008919 kl_loss: 0.000000 normal_loss: 0.008919\n",
      "[683/00074] train_loss: 0.008972 kl_loss: 0.000000 normal_loss: 0.008972\n",
      "[685/00024] train_loss: 0.008942 kl_loss: 0.000000 normal_loss: 0.008942\n",
      "[686/00049] train_loss: 0.008912 kl_loss: 0.000000 normal_loss: 0.008912\n",
      "[687/00074] train_loss: 0.008972 kl_loss: 0.000000 normal_loss: 0.008972\n",
      "[689/00024] train_loss: 0.008890 kl_loss: 0.000000 normal_loss: 0.008890\n",
      "[690/00049] train_loss: 0.008965 kl_loss: 0.000000 normal_loss: 0.008965\n",
      "[691/00074] train_loss: 0.008940 kl_loss: 0.000000 normal_loss: 0.008940\n",
      "[693/00024] train_loss: 0.008908 kl_loss: 0.000000 normal_loss: 0.008908\n",
      "[694/00049] train_loss: 0.008959 kl_loss: 0.000000 normal_loss: 0.008959\n",
      "[695/00074] train_loss: 0.008904 kl_loss: 0.000000 normal_loss: 0.008904\n",
      "[697/00024] train_loss: 0.008909 kl_loss: 0.000000 normal_loss: 0.008909\n",
      "[698/00049] train_loss: 0.008904 kl_loss: 0.000000 normal_loss: 0.008904\n",
      "[699/00074] train_loss: 0.008957 kl_loss: 0.000000 normal_loss: 0.008957\n",
      "[699/00074] IOU 0.9203456947021187\n",
      "[701/00024] train_loss: 0.008897 kl_loss: 0.000000 normal_loss: 0.008897\n",
      "[702/00049] train_loss: 0.008879 kl_loss: 0.000000 normal_loss: 0.008879\n",
      "[703/00074] train_loss: 0.008902 kl_loss: 0.000000 normal_loss: 0.008902\n",
      "[705/00024] train_loss: 0.008885 kl_loss: 0.000000 normal_loss: 0.008885\n",
      "[706/00049] train_loss: 0.008929 kl_loss: 0.000000 normal_loss: 0.008929\n",
      "[707/00074] train_loss: 0.008870 kl_loss: 0.000000 normal_loss: 0.008870\n",
      "[709/00024] train_loss: 0.008878 kl_loss: 0.000000 normal_loss: 0.008878\n",
      "[710/00049] train_loss: 0.008897 kl_loss: 0.000000 normal_loss: 0.008897\n",
      "[711/00074] train_loss: 0.008915 kl_loss: 0.000000 normal_loss: 0.008915\n",
      "[713/00024] train_loss: 0.008842 kl_loss: 0.000000 normal_loss: 0.008842\n",
      "[714/00049] train_loss: 0.008908 kl_loss: 0.000000 normal_loss: 0.008908\n",
      "[715/00074] train_loss: 0.008912 kl_loss: 0.000000 normal_loss: 0.008912\n",
      "[717/00024] train_loss: 0.008860 kl_loss: 0.000000 normal_loss: 0.008860\n",
      "[718/00049] train_loss: 0.008933 kl_loss: 0.000000 normal_loss: 0.008933\n",
      "[719/00074] train_loss: 0.008890 kl_loss: 0.000000 normal_loss: 0.008890\n",
      "[721/00024] train_loss: 0.008871 kl_loss: 0.000000 normal_loss: 0.008871\n",
      "[722/00049] train_loss: 0.008932 kl_loss: 0.000000 normal_loss: 0.008932\n",
      "[723/00074] train_loss: 0.008848 kl_loss: 0.000000 normal_loss: 0.008848\n",
      "[725/00024] train_loss: 0.008893 kl_loss: 0.000000 normal_loss: 0.008893\n",
      "[726/00049] train_loss: 0.008910 kl_loss: 0.000000 normal_loss: 0.008910\n",
      "[727/00074] train_loss: 0.008876 kl_loss: 0.000000 normal_loss: 0.008876\n",
      "[729/00024] train_loss: 0.008910 kl_loss: 0.000000 normal_loss: 0.008910\n",
      "[730/00049] train_loss: 0.008856 kl_loss: 0.000000 normal_loss: 0.008856\n",
      "[731/00074] train_loss: 0.008893 kl_loss: 0.000000 normal_loss: 0.008893\n",
      "[733/00024] train_loss: 0.008882 kl_loss: 0.000000 normal_loss: 0.008882\n",
      "[734/00049] train_loss: 0.008915 kl_loss: 0.000000 normal_loss: 0.008915\n",
      "[735/00074] train_loss: 0.008858 kl_loss: 0.000000 normal_loss: 0.008858\n",
      "[737/00024] train_loss: 0.008913 kl_loss: 0.000000 normal_loss: 0.008913\n",
      "[738/00049] train_loss: 0.008847 kl_loss: 0.000000 normal_loss: 0.008847\n",
      "[739/00074] train_loss: 0.008891 kl_loss: 0.000000 normal_loss: 0.008891\n",
      "[741/00024] train_loss: 0.008855 kl_loss: 0.000000 normal_loss: 0.008855\n",
      "[742/00049] train_loss: 0.008925 kl_loss: 0.000000 normal_loss: 0.008925\n",
      "[743/00074] train_loss: 0.008869 kl_loss: 0.000000 normal_loss: 0.008869\n",
      "[745/00024] train_loss: 0.008864 kl_loss: 0.000000 normal_loss: 0.008864\n",
      "[746/00049] train_loss: 0.008849 kl_loss: 0.000000 normal_loss: 0.008849\n",
      "[747/00074] train_loss: 0.008954 kl_loss: 0.000000 normal_loss: 0.008954\n",
      "[749/00024] train_loss: 0.008868 kl_loss: 0.000000 normal_loss: 0.008868\n",
      "[749/00074] IOU 0.9206733241987725\n",
      "[750/00049] train_loss: 0.008890 kl_loss: 0.000000 normal_loss: 0.008890\n",
      "[751/00074] train_loss: 0.008913 kl_loss: 0.000000 normal_loss: 0.008913\n",
      "[753/00024] train_loss: 0.008889 kl_loss: 0.000000 normal_loss: 0.008889\n",
      "[754/00049] train_loss: 0.008861 kl_loss: 0.000000 normal_loss: 0.008861\n",
      "[755/00074] train_loss: 0.008901 kl_loss: 0.000000 normal_loss: 0.008901\n",
      "[757/00024] train_loss: 0.008864 kl_loss: 0.000000 normal_loss: 0.008864\n",
      "[758/00049] train_loss: 0.008924 kl_loss: 0.000000 normal_loss: 0.008924\n",
      "[759/00074] train_loss: 0.008848 kl_loss: 0.000000 normal_loss: 0.008848\n",
      "[761/00024] train_loss: 0.008893 kl_loss: 0.000000 normal_loss: 0.008893\n",
      "[762/00049] train_loss: 0.008885 kl_loss: 0.000000 normal_loss: 0.008885\n",
      "[763/00074] train_loss: 0.008865 kl_loss: 0.000000 normal_loss: 0.008865\n",
      "[765/00024] train_loss: 0.008838 kl_loss: 0.000000 normal_loss: 0.008838\n",
      "[766/00049] train_loss: 0.008929 kl_loss: 0.000000 normal_loss: 0.008929\n",
      "[767/00074] train_loss: 0.008846 kl_loss: 0.000000 normal_loss: 0.008846\n",
      "[769/00024] train_loss: 0.008891 kl_loss: 0.000000 normal_loss: 0.008891\n",
      "[770/00049] train_loss: 0.008853 kl_loss: 0.000000 normal_loss: 0.008853\n",
      "[771/00074] train_loss: 0.008862 kl_loss: 0.000000 normal_loss: 0.008862\n",
      "[773/00024] train_loss: 0.008867 kl_loss: 0.000000 normal_loss: 0.008867\n",
      "[774/00049] train_loss: 0.008847 kl_loss: 0.000000 normal_loss: 0.008847\n",
      "[775/00074] train_loss: 0.008913 kl_loss: 0.000000 normal_loss: 0.008913\n",
      "[777/00024] train_loss: 0.008846 kl_loss: 0.000000 normal_loss: 0.008846\n",
      "[778/00049] train_loss: 0.008896 kl_loss: 0.000000 normal_loss: 0.008896\n",
      "[779/00074] train_loss: 0.008870 kl_loss: 0.000000 normal_loss: 0.008870\n",
      "[781/00024] train_loss: 0.008844 kl_loss: 0.000000 normal_loss: 0.008844\n",
      "[782/00049] train_loss: 0.008896 kl_loss: 0.000000 normal_loss: 0.008896\n",
      "[783/00074] train_loss: 0.008865 kl_loss: 0.000000 normal_loss: 0.008865\n",
      "[785/00024] train_loss: 0.008866 kl_loss: 0.000000 normal_loss: 0.008866\n",
      "[786/00049] train_loss: 0.008879 kl_loss: 0.000000 normal_loss: 0.008879\n",
      "[787/00074] train_loss: 0.008874 kl_loss: 0.000000 normal_loss: 0.008874\n",
      "[789/00024] train_loss: 0.008821 kl_loss: 0.000000 normal_loss: 0.008821\n",
      "[790/00049] train_loss: 0.008920 kl_loss: 0.000000 normal_loss: 0.008920\n",
      "[791/00074] train_loss: 0.008867 kl_loss: 0.000000 normal_loss: 0.008867\n",
      "[793/00024] train_loss: 0.008870 kl_loss: 0.000000 normal_loss: 0.008870\n",
      "[794/00049] train_loss: 0.008847 kl_loss: 0.000000 normal_loss: 0.008847\n",
      "[795/00074] train_loss: 0.008875 kl_loss: 0.000000 normal_loss: 0.008875\n",
      "[797/00024] train_loss: 0.008860 kl_loss: 0.000000 normal_loss: 0.008860\n",
      "[798/00049] train_loss: 0.008857 kl_loss: 0.000000 normal_loss: 0.008857\n",
      "[799/00074] train_loss: 0.008879 kl_loss: 0.000000 normal_loss: 0.008879\n",
      "[799/00074] IOU 0.9212639772891998\n",
      "[801/00024] train_loss: 0.008889 kl_loss: 0.000000 normal_loss: 0.008889\n",
      "[802/00049] train_loss: 0.008834 kl_loss: 0.000000 normal_loss: 0.008834\n",
      "[803/00074] train_loss: 0.008850 kl_loss: 0.000000 normal_loss: 0.008850\n",
      "[805/00024] train_loss: 0.008861 kl_loss: 0.000000 normal_loss: 0.008861\n",
      "[806/00049] train_loss: 0.008835 kl_loss: 0.000000 normal_loss: 0.008835\n",
      "[807/00074] train_loss: 0.008834 kl_loss: 0.000000 normal_loss: 0.008834\n",
      "[809/00024] train_loss: 0.008861 kl_loss: 0.000000 normal_loss: 0.008861\n",
      "[810/00049] train_loss: 0.008841 kl_loss: 0.000000 normal_loss: 0.008841\n",
      "[811/00074] train_loss: 0.008848 kl_loss: 0.000000 normal_loss: 0.008848\n",
      "[813/00024] train_loss: 0.008859 kl_loss: 0.000000 normal_loss: 0.008859\n",
      "[814/00049] train_loss: 0.008855 kl_loss: 0.000000 normal_loss: 0.008855\n",
      "[815/00074] train_loss: 0.008856 kl_loss: 0.000000 normal_loss: 0.008856\n",
      "[817/00024] train_loss: 0.008859 kl_loss: 0.000000 normal_loss: 0.008859\n",
      "[818/00049] train_loss: 0.008881 kl_loss: 0.000000 normal_loss: 0.008881\n",
      "[819/00074] train_loss: 0.008811 kl_loss: 0.000000 normal_loss: 0.008811\n",
      "[821/00024] train_loss: 0.008852 kl_loss: 0.000000 normal_loss: 0.008852\n",
      "[822/00049] train_loss: 0.008847 kl_loss: 0.000000 normal_loss: 0.008847\n",
      "[823/00074] train_loss: 0.008841 kl_loss: 0.000000 normal_loss: 0.008841\n",
      "[825/00024] train_loss: 0.008850 kl_loss: 0.000000 normal_loss: 0.008850\n",
      "[826/00049] train_loss: 0.008864 kl_loss: 0.000000 normal_loss: 0.008864\n",
      "[827/00074] train_loss: 0.008829 kl_loss: 0.000000 normal_loss: 0.008829\n",
      "[829/00024] train_loss: 0.008869 kl_loss: 0.000000 normal_loss: 0.008869\n",
      "[830/00049] train_loss: 0.008801 kl_loss: 0.000000 normal_loss: 0.008801\n",
      "[831/00074] train_loss: 0.008871 kl_loss: 0.000000 normal_loss: 0.008871\n",
      "[833/00024] train_loss: 0.008859 kl_loss: 0.000000 normal_loss: 0.008859\n",
      "[834/00049] train_loss: 0.008835 kl_loss: 0.000000 normal_loss: 0.008835\n",
      "[835/00074] train_loss: 0.008843 kl_loss: 0.000000 normal_loss: 0.008843\n",
      "[837/00024] train_loss: 0.008864 kl_loss: 0.000000 normal_loss: 0.008864\n",
      "[838/00049] train_loss: 0.008798 kl_loss: 0.000000 normal_loss: 0.008798\n",
      "[839/00074] train_loss: 0.008880 kl_loss: 0.000000 normal_loss: 0.008880\n",
      "[841/00024] train_loss: 0.008864 kl_loss: 0.000000 normal_loss: 0.008864\n",
      "[842/00049] train_loss: 0.008808 kl_loss: 0.000000 normal_loss: 0.008808\n",
      "[843/00074] train_loss: 0.008853 kl_loss: 0.000000 normal_loss: 0.008853\n",
      "[845/00024] train_loss: 0.008864 kl_loss: 0.000000 normal_loss: 0.008864\n",
      "[846/00049] train_loss: 0.008835 kl_loss: 0.000000 normal_loss: 0.008835\n",
      "[847/00074] train_loss: 0.008820 kl_loss: 0.000000 normal_loss: 0.008820\n",
      "[849/00024] train_loss: 0.008864 kl_loss: 0.000000 normal_loss: 0.008864\n",
      "[849/00074] IOU 0.9209131120455761\n",
      "[850/00049] train_loss: 0.008826 kl_loss: 0.000000 normal_loss: 0.008826\n",
      "[851/00074] train_loss: 0.008846 kl_loss: 0.000000 normal_loss: 0.008846\n",
      "[853/00024] train_loss: 0.008839 kl_loss: 0.000000 normal_loss: 0.008839\n",
      "[854/00049] train_loss: 0.008852 kl_loss: 0.000000 normal_loss: 0.008852\n",
      "[855/00074] train_loss: 0.008835 kl_loss: 0.000000 normal_loss: 0.008835\n",
      "[857/00024] train_loss: 0.008852 kl_loss: 0.000000 normal_loss: 0.008852\n",
      "[858/00049] train_loss: 0.008877 kl_loss: 0.000000 normal_loss: 0.008877\n",
      "[859/00074] train_loss: 0.008828 kl_loss: 0.000000 normal_loss: 0.008828\n",
      "[861/00024] train_loss: 0.008839 kl_loss: 0.000000 normal_loss: 0.008839\n",
      "[862/00049] train_loss: 0.008820 kl_loss: 0.000000 normal_loss: 0.008820\n",
      "[863/00074] train_loss: 0.008895 kl_loss: 0.000000 normal_loss: 0.008895\n",
      "[865/00024] train_loss: 0.008860 kl_loss: 0.000000 normal_loss: 0.008860\n",
      "[866/00049] train_loss: 0.008825 kl_loss: 0.000000 normal_loss: 0.008825\n",
      "[867/00074] train_loss: 0.008839 kl_loss: 0.000000 normal_loss: 0.008839\n",
      "[869/00024] train_loss: 0.008843 kl_loss: 0.000000 normal_loss: 0.008843\n",
      "[870/00049] train_loss: 0.008852 kl_loss: 0.000000 normal_loss: 0.008852\n",
      "[871/00074] train_loss: 0.008830 kl_loss: 0.000000 normal_loss: 0.008830\n",
      "[873/00024] train_loss: 0.008818 kl_loss: 0.000000 normal_loss: 0.008818\n",
      "[874/00049] train_loss: 0.008880 kl_loss: 0.000000 normal_loss: 0.008880\n",
      "[875/00074] train_loss: 0.008827 kl_loss: 0.000000 normal_loss: 0.008827\n",
      "[877/00024] train_loss: 0.008828 kl_loss: 0.000000 normal_loss: 0.008828\n",
      "[878/00049] train_loss: 0.008855 kl_loss: 0.000000 normal_loss: 0.008855\n",
      "[879/00074] train_loss: 0.008834 kl_loss: 0.000000 normal_loss: 0.008834\n",
      "[881/00024] train_loss: 0.008890 kl_loss: 0.000000 normal_loss: 0.008890\n",
      "[882/00049] train_loss: 0.008822 kl_loss: 0.000000 normal_loss: 0.008822\n",
      "[883/00074] train_loss: 0.008796 kl_loss: 0.000000 normal_loss: 0.008796\n",
      "[885/00024] train_loss: 0.008867 kl_loss: 0.000000 normal_loss: 0.008867\n",
      "[886/00049] train_loss: 0.008846 kl_loss: 0.000000 normal_loss: 0.008846\n",
      "[887/00074] train_loss: 0.008789 kl_loss: 0.000000 normal_loss: 0.008789\n",
      "[889/00024] train_loss: 0.008839 kl_loss: 0.000000 normal_loss: 0.008839\n",
      "[890/00049] train_loss: 0.008831 kl_loss: 0.000000 normal_loss: 0.008831\n",
      "[891/00074] train_loss: 0.008844 kl_loss: 0.000000 normal_loss: 0.008844\n",
      "[893/00024] train_loss: 0.008832 kl_loss: 0.000000 normal_loss: 0.008832\n",
      "[894/00049] train_loss: 0.008781 kl_loss: 0.000000 normal_loss: 0.008781\n",
      "[895/00074] train_loss: 0.008888 kl_loss: 0.000000 normal_loss: 0.008888\n",
      "[897/00024] train_loss: 0.008863 kl_loss: 0.000000 normal_loss: 0.008863\n",
      "[898/00049] train_loss: 0.008773 kl_loss: 0.000000 normal_loss: 0.008773\n",
      "[899/00074] train_loss: 0.008882 kl_loss: 0.000000 normal_loss: 0.008882\n",
      "[899/00074] IOU 0.920868968218565\n",
      "[901/00024] train_loss: 0.008815 kl_loss: 0.000000 normal_loss: 0.008815\n",
      "[902/00049] train_loss: 0.008821 kl_loss: 0.000000 normal_loss: 0.008821\n",
      "[903/00074] train_loss: 0.008823 kl_loss: 0.000000 normal_loss: 0.008823\n",
      "[905/00024] train_loss: 0.008846 kl_loss: 0.000000 normal_loss: 0.008846\n",
      "[906/00049] train_loss: 0.008785 kl_loss: 0.000000 normal_loss: 0.008785\n",
      "[907/00074] train_loss: 0.008859 kl_loss: 0.000000 normal_loss: 0.008859\n",
      "[909/00024] train_loss: 0.008804 kl_loss: 0.000000 normal_loss: 0.008804\n",
      "[910/00049] train_loss: 0.008860 kl_loss: 0.000000 normal_loss: 0.008860\n",
      "[911/00074] train_loss: 0.008784 kl_loss: 0.000000 normal_loss: 0.008784\n",
      "[913/00024] train_loss: 0.008809 kl_loss: 0.000000 normal_loss: 0.008809\n",
      "[914/00049] train_loss: 0.008815 kl_loss: 0.000000 normal_loss: 0.008815\n",
      "[915/00074] train_loss: 0.008861 kl_loss: 0.000000 normal_loss: 0.008861\n",
      "[917/00024] train_loss: 0.008834 kl_loss: 0.000000 normal_loss: 0.008834\n",
      "[918/00049] train_loss: 0.008780 kl_loss: 0.000000 normal_loss: 0.008780\n",
      "[919/00074] train_loss: 0.008858 kl_loss: 0.000000 normal_loss: 0.008858\n",
      "[921/00024] train_loss: 0.008825 kl_loss: 0.000000 normal_loss: 0.008825\n",
      "[922/00049] train_loss: 0.008843 kl_loss: 0.000000 normal_loss: 0.008843\n",
      "[923/00074] train_loss: 0.008824 kl_loss: 0.000000 normal_loss: 0.008824\n",
      "[925/00024] train_loss: 0.008837 kl_loss: 0.000000 normal_loss: 0.008837\n",
      "[926/00049] train_loss: 0.008758 kl_loss: 0.000000 normal_loss: 0.008758\n",
      "[927/00074] train_loss: 0.008868 kl_loss: 0.000000 normal_loss: 0.008868\n",
      "[929/00024] train_loss: 0.008844 kl_loss: 0.000000 normal_loss: 0.008844\n",
      "[930/00049] train_loss: 0.008777 kl_loss: 0.000000 normal_loss: 0.008777\n",
      "[931/00074] train_loss: 0.008839 kl_loss: 0.000000 normal_loss: 0.008839\n",
      "[933/00024] train_loss: 0.008813 kl_loss: 0.000000 normal_loss: 0.008813\n",
      "[934/00049] train_loss: 0.008866 kl_loss: 0.000000 normal_loss: 0.008866\n",
      "[935/00074] train_loss: 0.008775 kl_loss: 0.000000 normal_loss: 0.008775\n",
      "[937/00024] train_loss: 0.008839 kl_loss: 0.000000 normal_loss: 0.008839\n",
      "[938/00049] train_loss: 0.008792 kl_loss: 0.000000 normal_loss: 0.008792\n",
      "[939/00074] train_loss: 0.008833 kl_loss: 0.000000 normal_loss: 0.008833\n",
      "[941/00024] train_loss: 0.008806 kl_loss: 0.000000 normal_loss: 0.008806\n",
      "[942/00049] train_loss: 0.008847 kl_loss: 0.000000 normal_loss: 0.008847\n",
      "[943/00074] train_loss: 0.008811 kl_loss: 0.000000 normal_loss: 0.008811\n",
      "[945/00024] train_loss: 0.008791 kl_loss: 0.000000 normal_loss: 0.008791\n",
      "[946/00049] train_loss: 0.008838 kl_loss: 0.000000 normal_loss: 0.008838\n",
      "[947/00074] train_loss: 0.008817 kl_loss: 0.000000 normal_loss: 0.008817\n",
      "[949/00024] train_loss: 0.008826 kl_loss: 0.000000 normal_loss: 0.008826\n",
      "[949/00074] IOU 0.9210172387460868\n",
      "[950/00049] train_loss: 0.008805 kl_loss: 0.000000 normal_loss: 0.008805\n",
      "[951/00074] train_loss: 0.008831 kl_loss: 0.000000 normal_loss: 0.008831\n",
      "[953/00024] train_loss: 0.008813 kl_loss: 0.000000 normal_loss: 0.008813\n",
      "[954/00049] train_loss: 0.008855 kl_loss: 0.000000 normal_loss: 0.008855\n",
      "[955/00074] train_loss: 0.008788 kl_loss: 0.000000 normal_loss: 0.008788\n",
      "[957/00024] train_loss: 0.008814 kl_loss: 0.000000 normal_loss: 0.008814\n",
      "[958/00049] train_loss: 0.008825 kl_loss: 0.000000 normal_loss: 0.008825\n",
      "[959/00074] train_loss: 0.008822 kl_loss: 0.000000 normal_loss: 0.008822\n",
      "[961/00024] train_loss: 0.008824 kl_loss: 0.000000 normal_loss: 0.008824\n",
      "[962/00049] train_loss: 0.008787 kl_loss: 0.000000 normal_loss: 0.008787\n",
      "[963/00074] train_loss: 0.008850 kl_loss: 0.000000 normal_loss: 0.008850\n",
      "[965/00024] train_loss: 0.008786 kl_loss: 0.000000 normal_loss: 0.008786\n",
      "[966/00049] train_loss: 0.008848 kl_loss: 0.000000 normal_loss: 0.008848\n",
      "[967/00074] train_loss: 0.008827 kl_loss: 0.000000 normal_loss: 0.008827\n",
      "[969/00024] train_loss: 0.008783 kl_loss: 0.000000 normal_loss: 0.008783\n",
      "[970/00049] train_loss: 0.008854 kl_loss: 0.000000 normal_loss: 0.008854\n",
      "[971/00074] train_loss: 0.008793 kl_loss: 0.000000 normal_loss: 0.008793\n",
      "[973/00024] train_loss: 0.008816 kl_loss: 0.000000 normal_loss: 0.008816\n",
      "[974/00049] train_loss: 0.008807 kl_loss: 0.000000 normal_loss: 0.008807\n",
      "[975/00074] train_loss: 0.008841 kl_loss: 0.000000 normal_loss: 0.008841\n",
      "[977/00024] train_loss: 0.008831 kl_loss: 0.000000 normal_loss: 0.008831\n",
      "[978/00049] train_loss: 0.008759 kl_loss: 0.000000 normal_loss: 0.008759\n",
      "[979/00074] train_loss: 0.008853 kl_loss: 0.000000 normal_loss: 0.008853\n",
      "[981/00024] train_loss: 0.008830 kl_loss: 0.000000 normal_loss: 0.008830\n",
      "[982/00049] train_loss: 0.008862 kl_loss: 0.000000 normal_loss: 0.008862\n",
      "[983/00074] train_loss: 0.008783 kl_loss: 0.000000 normal_loss: 0.008783\n",
      "[985/00024] train_loss: 0.008787 kl_loss: 0.000000 normal_loss: 0.008787\n",
      "[986/00049] train_loss: 0.008811 kl_loss: 0.000000 normal_loss: 0.008811\n",
      "[987/00074] train_loss: 0.008839 kl_loss: 0.000000 normal_loss: 0.008839\n",
      "[989/00024] train_loss: 0.008858 kl_loss: 0.000000 normal_loss: 0.008858\n",
      "[990/00049] train_loss: 0.008791 kl_loss: 0.000000 normal_loss: 0.008791\n",
      "[991/00074] train_loss: 0.008812 kl_loss: 0.000000 normal_loss: 0.008812\n",
      "[993/00024] train_loss: 0.008866 kl_loss: 0.000000 normal_loss: 0.008866\n",
      "[994/00049] train_loss: 0.008793 kl_loss: 0.000000 normal_loss: 0.008793\n",
      "[995/00074] train_loss: 0.008821 kl_loss: 0.000000 normal_loss: 0.008821\n",
      "[997/00024] train_loss: 0.008815 kl_loss: 0.000000 normal_loss: 0.008815\n",
      "[998/00049] train_loss: 0.008824 kl_loss: 0.000000 normal_loss: 0.008824\n",
      "[999/00074] train_loss: 0.008800 kl_loss: 0.000000 normal_loss: 0.008800\n",
      "[999/00074] IOU 0.9210172180334727\n"
     ]
    }
   ],
   "source": [
    "# CHAIR AD\n",
    "from scripts import train\n",
    "config = {\n",
    "    'experiment_name': 'chair_ad',\n",
    "    'device': 'cuda:0',\n",
    "    'is_overfit': False,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate_model': 0.01,\n",
    "    'learning_rate_code': 0.01,\n",
    "    'learning_rate_log_var':0.01,\n",
    "    'max_epochs': 1000,\n",
    "    'print_every_n': 100,\n",
    "    'latent_code_length' : 256,\n",
    "    'scheduler_step_size': 100,\n",
    "    'vad_free' : False,\n",
    "    'test': False,\n",
    "    'kl_weight': 0.03,\n",
    "    'kl_weight_increase_every_epochs': 100,\n",
    "    'kl_weight_increase_value': 0.0,\n",
    "    'iou_every_epoch': 50,\n",
    "    'resume_ckpt': None,\n",
    "    'filter_class': 'chair',\n",
    "    'decoder_var' : False\n",
    "}\n",
    "train.main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TABLE VAD\n",
    "from scripts import train\n",
    "config = {\n",
    "    'experiment_name': 'table_vad',\n",
    "    'device': 'cuda:0',\n",
    "    'is_overfit': False,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate_model': 0.01,\n",
    "    'learning_rate_code': 0.01,\n",
    "    'learning_rate_log_var':0.01,\n",
    "    'max_epochs': 1000,\n",
    "    'print_every_n': 100,\n",
    "    'latent_code_length' : 256,\n",
    "    'scheduler_step_size': 100,\n",
    "    'vad_free' : True,\n",
    "    'test': False,\n",
    "    'kl_weight': 0.03,\n",
    "    'kl_weight_increase_every_epochs': 100,\n",
    "    'kl_weight_increase_value': 0.01,\n",
    "    'resume_ckpt': 'table_vad',\n",
    "    'filter_class': 'table',\n",
    "    'decoder_var' : True\n",
    "}\n",
    "train.main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIRPLANE VAD\n",
    "from scripts import train\n",
    "config = {\n",
    "    'experiment_name': 'airplane_vad',\n",
    "    'device': 'cuda:0',\n",
    "    'is_overfit': False,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate_model': 0.01,\n",
    "    'learning_rate_code': 0.01,\n",
    "    'learning_rate_log_var':0.01,\n",
    "    'max_epochs': 1000,\n",
    "    'print_every_n': 100,\n",
    "    'latent_code_length' : 256,\n",
    "    'scheduler_step_size': 100,\n",
    "    'vad_free' : True,\n",
    "    'test': False,\n",
    "    'kl_weight': 0.03,\n",
    "    'kl_weight_increase_every_epochs': 100,\n",
    "    'kl_weight_increase_value': 0.0,\n",
    "    'resume_ckpt': 'airplane_vad',\n",
    "    'filter_class': 'airplane',\n",
    "    'decoder_var' : True\n",
    "}\n",
    "train.main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Data length 4800\n",
      "Training params: 3\n",
      "[001/00024] train_loss: 0.178638 kl_loss: 0.492069 normal_loss: 0.163876\n",
      "[002/00049] train_loss: 0.133184 kl_loss: 0.440588 normal_loss: 0.119966\n",
      "[003/00074] train_loss: 0.126972 kl_loss: 0.387870 normal_loss: 0.115336\n",
      "[005/00024] train_loss: 0.122300 kl_loss: 0.344194 normal_loss: 0.111974\n",
      "[006/00049] train_loss: 0.117572 kl_loss: 0.326850 normal_loss: 0.107766\n",
      "[007/00074] train_loss: 0.114495 kl_loss: 0.316428 normal_loss: 0.105002\n",
      "[009/00024] train_loss: 0.109007 kl_loss: 0.302268 normal_loss: 0.099939\n",
      "[010/00049] train_loss: 0.107026 kl_loss: 0.290253 normal_loss: 0.098318\n",
      "[011/00074] train_loss: 0.105014 kl_loss: 0.278051 normal_loss: 0.096672\n",
      "[013/00024] train_loss: 0.103401 kl_loss: 0.266038 normal_loss: 0.095420\n",
      "[014/00049] train_loss: 0.099887 kl_loss: 0.255598 normal_loss: 0.092219\n",
      "[015/00074] train_loss: 0.098646 kl_loss: 0.247489 normal_loss: 0.091221\n",
      "[017/00024] train_loss: 0.097429 kl_loss: 0.241518 normal_loss: 0.090184\n",
      "[018/00049] train_loss: 0.094537 kl_loss: 0.240299 normal_loss: 0.087328\n",
      "[019/00074] train_loss: 0.092248 kl_loss: 0.237083 normal_loss: 0.085135\n",
      "[021/00024] train_loss: 0.090566 kl_loss: 0.233879 normal_loss: 0.083550\n",
      "[022/00049] train_loss: 0.088628 kl_loss: 0.230393 normal_loss: 0.081716\n",
      "[023/00074] train_loss: 0.087367 kl_loss: 0.229643 normal_loss: 0.080477\n",
      "[025/00024] train_loss: 0.085515 kl_loss: 0.227364 normal_loss: 0.078694\n",
      "[026/00049] train_loss: 0.084186 kl_loss: 0.225406 normal_loss: 0.077423\n",
      "[027/00074] train_loss: 0.082387 kl_loss: 0.224574 normal_loss: 0.075650\n",
      "[029/00024] train_loss: 0.080859 kl_loss: 0.223576 normal_loss: 0.074151\n",
      "[030/00049] train_loss: 0.080671 kl_loss: 0.225389 normal_loss: 0.073910\n",
      "[031/00074] train_loss: 0.078297 kl_loss: 0.224095 normal_loss: 0.071574\n",
      "[033/00024] train_loss: 0.077416 kl_loss: 0.225772 normal_loss: 0.070643\n",
      "[034/00049] train_loss: 0.076505 kl_loss: 0.226039 normal_loss: 0.069724\n",
      "[035/00074] train_loss: 0.076279 kl_loss: 0.226972 normal_loss: 0.069470\n",
      "[037/00024] train_loss: 0.073701 kl_loss: 0.227346 normal_loss: 0.066881\n",
      "[038/00049] train_loss: 0.072637 kl_loss: 0.227411 normal_loss: 0.065814\n",
      "[039/00074] train_loss: 0.071753 kl_loss: 0.228318 normal_loss: 0.064904\n",
      "[041/00024] train_loss: 0.071381 kl_loss: 0.229485 normal_loss: 0.064497\n",
      "[042/00049] train_loss: 0.070086 kl_loss: 0.228875 normal_loss: 0.063220\n",
      "[043/00074] train_loss: 0.068728 kl_loss: 0.229004 normal_loss: 0.061858\n",
      "[045/00024] train_loss: 0.068534 kl_loss: 0.230920 normal_loss: 0.061606\n",
      "[046/00049] train_loss: 0.068384 kl_loss: 0.230847 normal_loss: 0.061459\n",
      "[047/00074] train_loss: 0.066707 kl_loss: 0.232220 normal_loss: 0.059740\n",
      "[049/00024] train_loss: 0.067064 kl_loss: 0.232719 normal_loss: 0.060082\n",
      "[049/00074] MMD 0.00483490526676178\n",
      "[049/00074] TMD 0.058382462710142136\n",
      "[050/00049] train_loss: 0.066090 kl_loss: 0.233780 normal_loss: 0.059077\n",
      "[051/00074] train_loss: 0.065735 kl_loss: 0.235657 normal_loss: 0.058665\n",
      "[053/00024] train_loss: 0.064367 kl_loss: 0.235278 normal_loss: 0.057309\n",
      "[054/00049] train_loss: 0.064141 kl_loss: 0.238040 normal_loss: 0.057000\n",
      "[055/00074] train_loss: 0.064249 kl_loss: 0.238480 normal_loss: 0.057094\n",
      "[057/00024] train_loss: 0.062686 kl_loss: 0.239607 normal_loss: 0.055498\n",
      "[058/00049] train_loss: 0.062306 kl_loss: 0.240559 normal_loss: 0.055089\n",
      "[059/00074] train_loss: 0.062390 kl_loss: 0.242489 normal_loss: 0.055115\n",
      "[061/00024] train_loss: 0.061092 kl_loss: 0.244442 normal_loss: 0.053759\n",
      "[062/00049] train_loss: 0.060578 kl_loss: 0.243492 normal_loss: 0.053273\n",
      "[063/00074] train_loss: 0.060285 kl_loss: 0.247513 normal_loss: 0.052859\n",
      "[065/00024] train_loss: 0.059986 kl_loss: 0.248322 normal_loss: 0.052536\n",
      "[066/00049] train_loss: 0.059700 kl_loss: 0.249850 normal_loss: 0.052205\n",
      "[067/00074] train_loss: 0.058685 kl_loss: 0.250920 normal_loss: 0.051158\n",
      "[069/00024] train_loss: 0.058846 kl_loss: 0.252642 normal_loss: 0.051267\n",
      "[070/00049] train_loss: 0.056994 kl_loss: 0.253884 normal_loss: 0.049377\n",
      "[071/00074] train_loss: 0.058436 kl_loss: 0.255965 normal_loss: 0.050757\n",
      "[073/00024] train_loss: 0.057254 kl_loss: 0.257246 normal_loss: 0.049537\n",
      "[074/00049] train_loss: 0.057324 kl_loss: 0.258666 normal_loss: 0.049564\n",
      "[075/00074] train_loss: 0.056233 kl_loss: 0.259782 normal_loss: 0.048440\n",
      "[077/00024] train_loss: 0.055803 kl_loss: 0.261438 normal_loss: 0.047960\n",
      "[078/00049] train_loss: 0.055530 kl_loss: 0.262924 normal_loss: 0.047642\n",
      "[079/00074] train_loss: 0.055365 kl_loss: 0.263876 normal_loss: 0.047448\n",
      "[081/00024] train_loss: 0.054437 kl_loss: 0.265252 normal_loss: 0.046479\n",
      "[082/00049] train_loss: 0.053687 kl_loss: 0.267364 normal_loss: 0.045666\n",
      "[083/00074] train_loss: 0.053845 kl_loss: 0.268546 normal_loss: 0.045789\n",
      "[085/00024] train_loss: 0.053205 kl_loss: 0.268384 normal_loss: 0.045153\n",
      "[086/00049] train_loss: 0.053422 kl_loss: 0.273187 normal_loss: 0.045226\n",
      "[087/00074] train_loss: 0.052590 kl_loss: 0.270658 normal_loss: 0.044470\n",
      "[089/00024] train_loss: 0.051889 kl_loss: 0.272924 normal_loss: 0.043702\n",
      "[090/00049] train_loss: 0.051732 kl_loss: 0.274924 normal_loss: 0.043484\n",
      "[091/00074] train_loss: 0.051126 kl_loss: 0.275591 normal_loss: 0.042858\n",
      "[093/00024] train_loss: 0.050967 kl_loss: 0.276019 normal_loss: 0.042686\n",
      "[094/00049] train_loss: 0.049827 kl_loss: 0.278587 normal_loss: 0.041469\n",
      "[095/00074] train_loss: 0.050372 kl_loss: 0.277962 normal_loss: 0.042033\n",
      "[097/00024] train_loss: 0.049956 kl_loss: 0.279586 normal_loss: 0.041569\n",
      "[098/00049] train_loss: 0.049669 kl_loss: 0.281057 normal_loss: 0.041237\n",
      "[099/00000] updated kl_weight: 0.03\n",
      "[099/00001] updated kl_weight: 0.03\n",
      "[099/00002] updated kl_weight: 0.03\n",
      "[099/00003] updated kl_weight: 0.03\n",
      "[099/00004] updated kl_weight: 0.03\n",
      "[099/00005] updated kl_weight: 0.03\n",
      "[099/00006] updated kl_weight: 0.03\n",
      "[099/00007] updated kl_weight: 0.03\n",
      "[099/00008] updated kl_weight: 0.03\n",
      "[099/00009] updated kl_weight: 0.03\n",
      "[099/00010] updated kl_weight: 0.03\n",
      "[099/00011] updated kl_weight: 0.03\n",
      "[099/00012] updated kl_weight: 0.03\n",
      "[099/00013] updated kl_weight: 0.03\n",
      "[099/00014] updated kl_weight: 0.03\n",
      "[099/00015] updated kl_weight: 0.03\n",
      "[099/00016] updated kl_weight: 0.03\n",
      "[099/00017] updated kl_weight: 0.03\n",
      "[099/00018] updated kl_weight: 0.03\n",
      "[099/00019] updated kl_weight: 0.03\n",
      "[099/00020] updated kl_weight: 0.03\n",
      "[099/00021] updated kl_weight: 0.03\n",
      "[099/00022] updated kl_weight: 0.03\n",
      "[099/00023] updated kl_weight: 0.03\n",
      "[099/00024] updated kl_weight: 0.03\n",
      "[099/00025] updated kl_weight: 0.03\n",
      "[099/00026] updated kl_weight: 0.03\n",
      "[099/00027] updated kl_weight: 0.03\n",
      "[099/00028] updated kl_weight: 0.03\n",
      "[099/00029] updated kl_weight: 0.03\n",
      "[099/00030] updated kl_weight: 0.03\n",
      "[099/00031] updated kl_weight: 0.03\n",
      "[099/00032] updated kl_weight: 0.03\n",
      "[099/00033] updated kl_weight: 0.03\n",
      "[099/00034] updated kl_weight: 0.03\n",
      "[099/00035] updated kl_weight: 0.03\n",
      "[099/00036] updated kl_weight: 0.03\n",
      "[099/00037] updated kl_weight: 0.03\n",
      "[099/00038] updated kl_weight: 0.03\n",
      "[099/00039] updated kl_weight: 0.03\n",
      "[099/00040] updated kl_weight: 0.03\n",
      "[099/00041] updated kl_weight: 0.03\n",
      "[099/00042] updated kl_weight: 0.03\n",
      "[099/00043] updated kl_weight: 0.03\n",
      "[099/00044] updated kl_weight: 0.03\n",
      "[099/00045] updated kl_weight: 0.03\n",
      "[099/00046] updated kl_weight: 0.03\n",
      "[099/00047] updated kl_weight: 0.03\n",
      "[099/00048] updated kl_weight: 0.03\n",
      "[099/00049] updated kl_weight: 0.03\n",
      "[099/00050] updated kl_weight: 0.03\n",
      "[099/00051] updated kl_weight: 0.03\n",
      "[099/00052] updated kl_weight: 0.03\n",
      "[099/00053] updated kl_weight: 0.03\n",
      "[099/00054] updated kl_weight: 0.03\n",
      "[099/00055] updated kl_weight: 0.03\n",
      "[099/00056] updated kl_weight: 0.03\n",
      "[099/00057] updated kl_weight: 0.03\n",
      "[099/00058] updated kl_weight: 0.03\n",
      "[099/00059] updated kl_weight: 0.03\n",
      "[099/00060] updated kl_weight: 0.03\n",
      "[099/00061] updated kl_weight: 0.03\n",
      "[099/00062] updated kl_weight: 0.03\n",
      "[099/00063] updated kl_weight: 0.03\n",
      "[099/00064] updated kl_weight: 0.03\n",
      "[099/00065] updated kl_weight: 0.03\n",
      "[099/00066] updated kl_weight: 0.03\n",
      "[099/00067] updated kl_weight: 0.03\n",
      "[099/00068] updated kl_weight: 0.03\n",
      "[099/00069] updated kl_weight: 0.03\n",
      "[099/00070] updated kl_weight: 0.03\n",
      "[099/00071] updated kl_weight: 0.03\n",
      "[099/00072] updated kl_weight: 0.03\n",
      "[099/00073] updated kl_weight: 0.03\n",
      "[099/00074] updated kl_weight: 0.03\n",
      "[099/00074] train_loss: 0.049135 kl_loss: 0.282469 normal_loss: 0.040661\n",
      "[099/00074] MMD 0.005458594299852848\n",
      "[099/00074] TMD 0.07454124838113785\n",
      "[101/00024] train_loss: 0.045897 kl_loss: 0.283105 normal_loss: 0.037404\n",
      "[102/00049] train_loss: 0.044594 kl_loss: 0.280281 normal_loss: 0.036186\n",
      "[103/00074] train_loss: 0.044643 kl_loss: 0.278864 normal_loss: 0.036277\n",
      "[105/00024] train_loss: 0.043844 kl_loss: 0.278227 normal_loss: 0.035497\n",
      "[106/00049] train_loss: 0.043249 kl_loss: 0.275947 normal_loss: 0.034970\n",
      "[107/00074] train_loss: 0.043278 kl_loss: 0.273650 normal_loss: 0.035069\n",
      "[109/00024] train_loss: 0.042940 kl_loss: 0.273073 normal_loss: 0.034748\n",
      "[110/00049] train_loss: 0.042730 kl_loss: 0.272346 normal_loss: 0.034560\n",
      "[111/00074] train_loss: 0.042597 kl_loss: 0.271824 normal_loss: 0.034442\n",
      "[113/00024] train_loss: 0.041805 kl_loss: 0.270188 normal_loss: 0.033699\n",
      "[114/00049] train_loss: 0.041912 kl_loss: 0.270082 normal_loss: 0.033810\n",
      "[115/00074] train_loss: 0.041798 kl_loss: 0.269676 normal_loss: 0.033708\n",
      "[117/00024] train_loss: 0.041288 kl_loss: 0.268114 normal_loss: 0.033244\n",
      "[118/00049] train_loss: 0.041133 kl_loss: 0.268787 normal_loss: 0.033069\n",
      "[119/00074] train_loss: 0.040812 kl_loss: 0.267440 normal_loss: 0.032789\n",
      "[121/00024] train_loss: 0.040566 kl_loss: 0.267458 normal_loss: 0.032542\n",
      "[122/00049] train_loss: 0.040457 kl_loss: 0.266486 normal_loss: 0.032462\n",
      "[123/00074] train_loss: 0.040162 kl_loss: 0.267135 normal_loss: 0.032148\n",
      "[125/00024] train_loss: 0.039990 kl_loss: 0.265269 normal_loss: 0.032032\n",
      "[126/00049] train_loss: 0.040169 kl_loss: 0.267219 normal_loss: 0.032152\n",
      "[127/00074] train_loss: 0.039488 kl_loss: 0.266125 normal_loss: 0.031504\n",
      "[129/00024] train_loss: 0.039476 kl_loss: 0.265784 normal_loss: 0.031502\n",
      "[130/00049] train_loss: 0.039218 kl_loss: 0.265952 normal_loss: 0.031240\n",
      "[131/00074] train_loss: 0.039199 kl_loss: 0.265835 normal_loss: 0.031224\n",
      "[133/00024] train_loss: 0.038480 kl_loss: 0.265401 normal_loss: 0.030518\n",
      "[134/00049] train_loss: 0.038635 kl_loss: 0.265674 normal_loss: 0.030665\n",
      "[135/00074] train_loss: 0.038567 kl_loss: 0.265379 normal_loss: 0.030605\n",
      "[137/00024] train_loss: 0.037968 kl_loss: 0.263610 normal_loss: 0.030060\n",
      "[138/00049] train_loss: 0.038265 kl_loss: 0.266732 normal_loss: 0.030263\n",
      "[139/00074] train_loss: 0.038121 kl_loss: 0.266179 normal_loss: 0.030135\n",
      "[141/00024] train_loss: 0.037794 kl_loss: 0.265885 normal_loss: 0.029818\n",
      "[142/00049] train_loss: 0.037855 kl_loss: 0.264694 normal_loss: 0.029914\n",
      "[143/00074] train_loss: 0.037912 kl_loss: 0.266056 normal_loss: 0.029930\n",
      "[145/00024] train_loss: 0.037566 kl_loss: 0.265422 normal_loss: 0.029603\n",
      "[146/00049] train_loss: 0.037347 kl_loss: 0.265990 normal_loss: 0.029367\n",
      "[147/00074] train_loss: 0.037070 kl_loss: 0.266142 normal_loss: 0.029085\n",
      "[149/00024] train_loss: 0.037022 kl_loss: 0.264675 normal_loss: 0.029082\n",
      "[149/00074] MMD 0.005198840983211994\n",
      "[149/00074] TMD 0.06507346779108047\n",
      "[150/00049] train_loss: 0.036466 kl_loss: 0.266540 normal_loss: 0.028470\n",
      "[151/00074] train_loss: 0.036551 kl_loss: 0.266324 normal_loss: 0.028562\n",
      "[153/00024] train_loss: 0.036595 kl_loss: 0.266010 normal_loss: 0.028615\n",
      "[154/00049] train_loss: 0.035992 kl_loss: 0.264564 normal_loss: 0.028055\n",
      "[155/00074] train_loss: 0.036044 kl_loss: 0.266370 normal_loss: 0.028053\n",
      "[157/00024] train_loss: 0.035807 kl_loss: 0.265795 normal_loss: 0.027833\n",
      "[158/00049] train_loss: 0.036194 kl_loss: 0.265590 normal_loss: 0.028226\n",
      "[159/00074] train_loss: 0.035838 kl_loss: 0.265665 normal_loss: 0.027868\n",
      "[161/00024] train_loss: 0.035929 kl_loss: 0.265387 normal_loss: 0.027967\n",
      "[162/00049] train_loss: 0.035451 kl_loss: 0.266251 normal_loss: 0.027463\n",
      "[163/00074] train_loss: 0.035457 kl_loss: 0.265121 normal_loss: 0.027504\n",
      "[165/00024] train_loss: 0.035308 kl_loss: 0.265390 normal_loss: 0.027347\n",
      "[166/00049] train_loss: 0.035376 kl_loss: 0.265349 normal_loss: 0.027416\n",
      "[167/00074] train_loss: 0.034914 kl_loss: 0.265276 normal_loss: 0.026956\n",
      "[169/00024] train_loss: 0.035041 kl_loss: 0.264930 normal_loss: 0.027093\n",
      "[170/00049] train_loss: 0.034796 kl_loss: 0.266332 normal_loss: 0.026806\n",
      "[171/00074] train_loss: 0.034633 kl_loss: 0.264469 normal_loss: 0.026699\n",
      "[173/00024] train_loss: 0.034528 kl_loss: 0.265171 normal_loss: 0.026573\n",
      "[174/00049] train_loss: 0.034311 kl_loss: 0.264892 normal_loss: 0.026365\n",
      "[175/00074] train_loss: 0.034277 kl_loss: 0.264508 normal_loss: 0.026342\n",
      "[177/00024] train_loss: 0.033872 kl_loss: 0.264346 normal_loss: 0.025941\n",
      "[178/00049] train_loss: 0.034102 kl_loss: 0.264509 normal_loss: 0.026167\n",
      "[179/00074] train_loss: 0.034085 kl_loss: 0.264219 normal_loss: 0.026158\n",
      "[181/00024] train_loss: 0.033979 kl_loss: 0.263673 normal_loss: 0.026068\n",
      "[182/00049] train_loss: 0.033731 kl_loss: 0.264715 normal_loss: 0.025790\n",
      "[183/00074] train_loss: 0.033665 kl_loss: 0.263269 normal_loss: 0.025767\n",
      "[185/00024] train_loss: 0.033684 kl_loss: 0.264140 normal_loss: 0.025759\n",
      "[186/00049] train_loss: 0.033647 kl_loss: 0.263288 normal_loss: 0.025748\n",
      "[187/00074] train_loss: 0.033153 kl_loss: 0.262563 normal_loss: 0.025276\n",
      "[189/00024] train_loss: 0.033020 kl_loss: 0.263619 normal_loss: 0.025111\n",
      "[190/00049] train_loss: 0.032779 kl_loss: 0.261699 normal_loss: 0.024928\n",
      "[191/00074] train_loss: 0.033452 kl_loss: 0.263479 normal_loss: 0.025548\n",
      "[193/00024] train_loss: 0.033161 kl_loss: 0.262318 normal_loss: 0.025291\n",
      "[194/00049] train_loss: 0.032559 kl_loss: 0.262425 normal_loss: 0.024686\n",
      "[195/00074] train_loss: 0.032742 kl_loss: 0.262129 normal_loss: 0.024878\n",
      "[197/00024] train_loss: 0.032592 kl_loss: 0.261776 normal_loss: 0.024738\n",
      "[198/00049] train_loss: 0.032493 kl_loss: 0.261043 normal_loss: 0.024662\n",
      "[199/00000] updated kl_weight: 0.03\n",
      "[199/00001] updated kl_weight: 0.03\n",
      "[199/00002] updated kl_weight: 0.03\n",
      "[199/00003] updated kl_weight: 0.03\n",
      "[199/00004] updated kl_weight: 0.03\n",
      "[199/00005] updated kl_weight: 0.03\n",
      "[199/00006] updated kl_weight: 0.03\n",
      "[199/00007] updated kl_weight: 0.03\n",
      "[199/00008] updated kl_weight: 0.03\n",
      "[199/00009] updated kl_weight: 0.03\n",
      "[199/00010] updated kl_weight: 0.03\n",
      "[199/00011] updated kl_weight: 0.03\n",
      "[199/00012] updated kl_weight: 0.03\n",
      "[199/00013] updated kl_weight: 0.03\n",
      "[199/00014] updated kl_weight: 0.03\n",
      "[199/00015] updated kl_weight: 0.03\n",
      "[199/00016] updated kl_weight: 0.03\n",
      "[199/00017] updated kl_weight: 0.03\n",
      "[199/00018] updated kl_weight: 0.03\n",
      "[199/00019] updated kl_weight: 0.03\n",
      "[199/00020] updated kl_weight: 0.03\n",
      "[199/00021] updated kl_weight: 0.03\n",
      "[199/00022] updated kl_weight: 0.03\n",
      "[199/00023] updated kl_weight: 0.03\n",
      "[199/00024] updated kl_weight: 0.03\n",
      "[199/00025] updated kl_weight: 0.03\n",
      "[199/00026] updated kl_weight: 0.03\n",
      "[199/00027] updated kl_weight: 0.03\n",
      "[199/00028] updated kl_weight: 0.03\n",
      "[199/00029] updated kl_weight: 0.03\n",
      "[199/00030] updated kl_weight: 0.03\n",
      "[199/00031] updated kl_weight: 0.03\n",
      "[199/00032] updated kl_weight: 0.03\n",
      "[199/00033] updated kl_weight: 0.03\n",
      "[199/00034] updated kl_weight: 0.03\n",
      "[199/00035] updated kl_weight: 0.03\n",
      "[199/00036] updated kl_weight: 0.03\n",
      "[199/00037] updated kl_weight: 0.03\n",
      "[199/00038] updated kl_weight: 0.03\n",
      "[199/00039] updated kl_weight: 0.03\n",
      "[199/00040] updated kl_weight: 0.03\n",
      "[199/00041] updated kl_weight: 0.03\n",
      "[199/00042] updated kl_weight: 0.03\n",
      "[199/00043] updated kl_weight: 0.03\n",
      "[199/00044] updated kl_weight: 0.03\n",
      "[199/00045] updated kl_weight: 0.03\n",
      "[199/00046] updated kl_weight: 0.03\n",
      "[199/00047] updated kl_weight: 0.03\n",
      "[199/00048] updated kl_weight: 0.03\n",
      "[199/00049] updated kl_weight: 0.03\n",
      "[199/00050] updated kl_weight: 0.03\n",
      "[199/00051] updated kl_weight: 0.03\n",
      "[199/00052] updated kl_weight: 0.03\n",
      "[199/00053] updated kl_weight: 0.03\n",
      "[199/00054] updated kl_weight: 0.03\n",
      "[199/00055] updated kl_weight: 0.03\n",
      "[199/00056] updated kl_weight: 0.03\n",
      "[199/00057] updated kl_weight: 0.03\n",
      "[199/00058] updated kl_weight: 0.03\n",
      "[199/00059] updated kl_weight: 0.03\n",
      "[199/00060] updated kl_weight: 0.03\n",
      "[199/00061] updated kl_weight: 0.03\n",
      "[199/00062] updated kl_weight: 0.03\n",
      "[199/00063] updated kl_weight: 0.03\n",
      "[199/00064] updated kl_weight: 0.03\n",
      "[199/00065] updated kl_weight: 0.03\n",
      "[199/00066] updated kl_weight: 0.03\n",
      "[199/00067] updated kl_weight: 0.03\n",
      "[199/00068] updated kl_weight: 0.03\n",
      "[199/00069] updated kl_weight: 0.03\n",
      "[199/00070] updated kl_weight: 0.03\n",
      "[199/00071] updated kl_weight: 0.03\n",
      "[199/00072] updated kl_weight: 0.03\n",
      "[199/00073] updated kl_weight: 0.03\n",
      "[199/00074] updated kl_weight: 0.03\n",
      "[199/00074] train_loss: 0.032708 kl_loss: 0.261414 normal_loss: 0.024865\n",
      "[199/00074] MMD 0.005202102940529585\n",
      "[199/00074] TMD 0.05481155216693878\n",
      "[201/00024] train_loss: 0.031082 kl_loss: 0.261171 normal_loss: 0.023247\n",
      "[202/00049] train_loss: 0.030734 kl_loss: 0.259696 normal_loss: 0.022943\n",
      "[203/00074] train_loss: 0.030549 kl_loss: 0.259764 normal_loss: 0.022756\n",
      "[205/00024] train_loss: 0.030134 kl_loss: 0.257910 normal_loss: 0.022397\n",
      "[206/00049] train_loss: 0.030215 kl_loss: 0.258801 normal_loss: 0.022451\n",
      "[207/00074] train_loss: 0.030172 kl_loss: 0.258132 normal_loss: 0.022428\n",
      "[209/00024] train_loss: 0.030000 kl_loss: 0.257421 normal_loss: 0.022278\n",
      "[210/00049] train_loss: 0.029797 kl_loss: 0.255861 normal_loss: 0.022121\n",
      "[211/00074] train_loss: 0.029880 kl_loss: 0.255749 normal_loss: 0.022207\n",
      "[213/00024] train_loss: 0.029612 kl_loss: 0.254567 normal_loss: 0.021975\n",
      "[214/00049] train_loss: 0.029673 kl_loss: 0.254710 normal_loss: 0.022031\n",
      "[215/00074] train_loss: 0.029650 kl_loss: 0.254181 normal_loss: 0.022025\n",
      "[217/00024] train_loss: 0.029368 kl_loss: 0.252701 normal_loss: 0.021787\n",
      "[218/00049] train_loss: 0.029619 kl_loss: 0.253140 normal_loss: 0.022024\n",
      "[219/00074] train_loss: 0.029515 kl_loss: 0.252472 normal_loss: 0.021941\n",
      "[221/00024] train_loss: 0.029300 kl_loss: 0.251730 normal_loss: 0.021748\n",
      "[222/00049] train_loss: 0.029453 kl_loss: 0.251196 normal_loss: 0.021917\n",
      "[223/00074] train_loss: 0.029344 kl_loss: 0.250903 normal_loss: 0.021817\n",
      "[225/00024] train_loss: 0.029219 kl_loss: 0.249470 normal_loss: 0.021735\n",
      "[226/00049] train_loss: 0.029164 kl_loss: 0.250925 normal_loss: 0.021636\n",
      "[227/00074] train_loss: 0.029236 kl_loss: 0.249009 normal_loss: 0.021766\n",
      "[229/00024] train_loss: 0.029181 kl_loss: 0.249691 normal_loss: 0.021691\n",
      "[230/00049] train_loss: 0.029030 kl_loss: 0.247650 normal_loss: 0.021600\n",
      "[231/00074] train_loss: 0.028946 kl_loss: 0.248279 normal_loss: 0.021498\n",
      "[233/00024] train_loss: 0.028774 kl_loss: 0.247810 normal_loss: 0.021340\n",
      "[234/00049] train_loss: 0.028894 kl_loss: 0.247338 normal_loss: 0.021474\n",
      "[235/00074] train_loss: 0.028843 kl_loss: 0.246467 normal_loss: 0.021449\n",
      "[237/00024] train_loss: 0.028683 kl_loss: 0.246519 normal_loss: 0.021288\n",
      "[238/00049] train_loss: 0.028816 kl_loss: 0.246357 normal_loss: 0.021426\n",
      "[239/00074] train_loss: 0.028430 kl_loss: 0.245068 normal_loss: 0.021078\n",
      "[241/00024] train_loss: 0.028649 kl_loss: 0.245898 normal_loss: 0.021272\n",
      "[242/00049] train_loss: 0.028471 kl_loss: 0.244009 normal_loss: 0.021150\n",
      "[243/00074] train_loss: 0.028465 kl_loss: 0.244498 normal_loss: 0.021130\n",
      "[245/00024] train_loss: 0.028347 kl_loss: 0.243593 normal_loss: 0.021039\n",
      "[246/00049] train_loss: 0.028472 kl_loss: 0.244354 normal_loss: 0.021142\n",
      "[247/00074] train_loss: 0.028335 kl_loss: 0.243542 normal_loss: 0.021029\n",
      "[249/00024] train_loss: 0.028080 kl_loss: 0.243219 normal_loss: 0.020783\n",
      "[249/00074] MMD 0.005108760204166174\n",
      "[249/00074] TMD 0.05944669991731644\n",
      "[250/00049] train_loss: 0.028192 kl_loss: 0.242270 normal_loss: 0.020924\n",
      "[251/00074] train_loss: 0.028320 kl_loss: 0.242823 normal_loss: 0.021035\n",
      "[253/00024] train_loss: 0.028004 kl_loss: 0.241568 normal_loss: 0.020757\n",
      "[254/00049] train_loss: 0.028353 kl_loss: 0.242681 normal_loss: 0.021072\n",
      "[255/00074] train_loss: 0.028117 kl_loss: 0.241256 normal_loss: 0.020879\n",
      "[257/00024] train_loss: 0.028050 kl_loss: 0.241570 normal_loss: 0.020803\n",
      "[258/00049] train_loss: 0.028076 kl_loss: 0.240221 normal_loss: 0.020870\n",
      "[259/00074] train_loss: 0.027945 kl_loss: 0.241189 normal_loss: 0.020710\n",
      "[261/00024] train_loss: 0.027854 kl_loss: 0.240548 normal_loss: 0.020638\n",
      "[262/00049] train_loss: 0.027956 kl_loss: 0.239937 normal_loss: 0.020758\n",
      "[263/00074] train_loss: 0.027776 kl_loss: 0.239979 normal_loss: 0.020577\n",
      "[265/00024] train_loss: 0.027635 kl_loss: 0.239121 normal_loss: 0.020462\n",
      "[266/00049] train_loss: 0.027725 kl_loss: 0.239911 normal_loss: 0.020527\n",
      "[267/00074] train_loss: 0.027668 kl_loss: 0.238846 normal_loss: 0.020502\n",
      "[269/00024] train_loss: 0.027640 kl_loss: 0.238325 normal_loss: 0.020490\n",
      "[270/00049] train_loss: 0.027602 kl_loss: 0.238505 normal_loss: 0.020447\n",
      "[271/00074] train_loss: 0.027660 kl_loss: 0.238499 normal_loss: 0.020505\n",
      "[273/00024] train_loss: 0.027560 kl_loss: 0.237732 normal_loss: 0.020428\n",
      "[274/00049] train_loss: 0.027600 kl_loss: 0.237858 normal_loss: 0.020464\n",
      "[275/00074] train_loss: 0.027393 kl_loss: 0.237333 normal_loss: 0.020273\n",
      "[277/00024] train_loss: 0.027403 kl_loss: 0.237212 normal_loss: 0.020287\n",
      "[278/00049] train_loss: 0.027360 kl_loss: 0.236706 normal_loss: 0.020259\n",
      "[279/00074] train_loss: 0.027432 kl_loss: 0.236556 normal_loss: 0.020336\n",
      "[281/00024] train_loss: 0.027384 kl_loss: 0.236702 normal_loss: 0.020282\n",
      "[282/00049] train_loss: 0.027254 kl_loss: 0.235805 normal_loss: 0.020180\n",
      "[283/00074] train_loss: 0.026988 kl_loss: 0.235773 normal_loss: 0.019914\n",
      "[285/00024] train_loss: 0.026883 kl_loss: 0.234735 normal_loss: 0.019841\n",
      "[286/00049] train_loss: 0.027239 kl_loss: 0.235838 normal_loss: 0.020164\n",
      "[287/00074] train_loss: 0.027067 kl_loss: 0.235262 normal_loss: 0.020009\n",
      "[289/00024] train_loss: 0.026977 kl_loss: 0.234286 normal_loss: 0.019948\n",
      "[290/00049] train_loss: 0.027222 kl_loss: 0.235221 normal_loss: 0.020166\n",
      "[291/00074] train_loss: 0.026977 kl_loss: 0.234017 normal_loss: 0.019956\n",
      "[293/00024] train_loss: 0.026720 kl_loss: 0.233526 normal_loss: 0.019715\n",
      "[294/00049] train_loss: 0.026898 kl_loss: 0.234191 normal_loss: 0.019872\n",
      "[295/00074] train_loss: 0.026777 kl_loss: 0.233500 normal_loss: 0.019772\n",
      "[297/00024] train_loss: 0.026791 kl_loss: 0.233492 normal_loss: 0.019786\n",
      "[298/00049] train_loss: 0.026856 kl_loss: 0.232661 normal_loss: 0.019876\n",
      "[299/00000] updated kl_weight: 0.03\n",
      "[299/00001] updated kl_weight: 0.03\n",
      "[299/00002] updated kl_weight: 0.03\n",
      "[299/00003] updated kl_weight: 0.03\n",
      "[299/00004] updated kl_weight: 0.03\n",
      "[299/00005] updated kl_weight: 0.03\n",
      "[299/00006] updated kl_weight: 0.03\n",
      "[299/00007] updated kl_weight: 0.03\n",
      "[299/00008] updated kl_weight: 0.03\n",
      "[299/00009] updated kl_weight: 0.03\n",
      "[299/00010] updated kl_weight: 0.03\n",
      "[299/00011] updated kl_weight: 0.03\n",
      "[299/00012] updated kl_weight: 0.03\n",
      "[299/00013] updated kl_weight: 0.03\n",
      "[299/00014] updated kl_weight: 0.03\n",
      "[299/00015] updated kl_weight: 0.03\n",
      "[299/00016] updated kl_weight: 0.03\n",
      "[299/00017] updated kl_weight: 0.03\n",
      "[299/00018] updated kl_weight: 0.03\n",
      "[299/00019] updated kl_weight: 0.03\n",
      "[299/00020] updated kl_weight: 0.03\n",
      "[299/00021] updated kl_weight: 0.03\n",
      "[299/00022] updated kl_weight: 0.03\n",
      "[299/00023] updated kl_weight: 0.03\n",
      "[299/00024] updated kl_weight: 0.03\n",
      "[299/00025] updated kl_weight: 0.03\n",
      "[299/00026] updated kl_weight: 0.03\n",
      "[299/00027] updated kl_weight: 0.03\n",
      "[299/00028] updated kl_weight: 0.03\n",
      "[299/00029] updated kl_weight: 0.03\n",
      "[299/00030] updated kl_weight: 0.03\n",
      "[299/00031] updated kl_weight: 0.03\n",
      "[299/00032] updated kl_weight: 0.03\n",
      "[299/00033] updated kl_weight: 0.03\n",
      "[299/00034] updated kl_weight: 0.03\n",
      "[299/00035] updated kl_weight: 0.03\n",
      "[299/00036] updated kl_weight: 0.03\n",
      "[299/00037] updated kl_weight: 0.03\n",
      "[299/00038] updated kl_weight: 0.03\n",
      "[299/00039] updated kl_weight: 0.03\n",
      "[299/00040] updated kl_weight: 0.03\n",
      "[299/00041] updated kl_weight: 0.03\n",
      "[299/00042] updated kl_weight: 0.03\n",
      "[299/00043] updated kl_weight: 0.03\n",
      "[299/00044] updated kl_weight: 0.03\n",
      "[299/00045] updated kl_weight: 0.03\n",
      "[299/00046] updated kl_weight: 0.03\n",
      "[299/00047] updated kl_weight: 0.03\n",
      "[299/00048] updated kl_weight: 0.03\n",
      "[299/00049] updated kl_weight: 0.03\n",
      "[299/00050] updated kl_weight: 0.03\n",
      "[299/00051] updated kl_weight: 0.03\n",
      "[299/00052] updated kl_weight: 0.03\n",
      "[299/00053] updated kl_weight: 0.03\n",
      "[299/00054] updated kl_weight: 0.03\n",
      "[299/00055] updated kl_weight: 0.03\n",
      "[299/00056] updated kl_weight: 0.03\n",
      "[299/00057] updated kl_weight: 0.03\n",
      "[299/00058] updated kl_weight: 0.03\n",
      "[299/00059] updated kl_weight: 0.03\n",
      "[299/00060] updated kl_weight: 0.03\n",
      "[299/00061] updated kl_weight: 0.03\n",
      "[299/00062] updated kl_weight: 0.03\n",
      "[299/00063] updated kl_weight: 0.03\n",
      "[299/00064] updated kl_weight: 0.03\n",
      "[299/00065] updated kl_weight: 0.03\n",
      "[299/00066] updated kl_weight: 0.03\n",
      "[299/00067] updated kl_weight: 0.03\n",
      "[299/00068] updated kl_weight: 0.03\n",
      "[299/00069] updated kl_weight: 0.03\n",
      "[299/00070] updated kl_weight: 0.03\n",
      "[299/00071] updated kl_weight: 0.03\n",
      "[299/00072] updated kl_weight: 0.03\n",
      "[299/00073] updated kl_weight: 0.03\n",
      "[299/00074] updated kl_weight: 0.03\n",
      "[299/00074] train_loss: 0.026658 kl_loss: 0.232660 normal_loss: 0.019678\n",
      "[299/00074] MMD 0.005370283965021372\n",
      "[299/00074] TMD 0.05886409431695938\n",
      "[301/00024] train_loss: 0.026104 kl_loss: 0.232139 normal_loss: 0.019140\n",
      "[302/00049] train_loss: 0.026049 kl_loss: 0.232662 normal_loss: 0.019069\n",
      "[303/00074] train_loss: 0.025857 kl_loss: 0.231675 normal_loss: 0.018906\n",
      "[305/00024] train_loss: 0.025756 kl_loss: 0.231592 normal_loss: 0.018808\n",
      "[306/00049] train_loss: 0.025864 kl_loss: 0.231065 normal_loss: 0.018932\n",
      "[307/00074] train_loss: 0.025805 kl_loss: 0.231397 normal_loss: 0.018864\n",
      "[309/00024] train_loss: 0.025632 kl_loss: 0.230762 normal_loss: 0.018709\n",
      "[310/00049] train_loss: 0.025700 kl_loss: 0.230884 normal_loss: 0.018773\n",
      "[311/00074] train_loss: 0.025656 kl_loss: 0.230178 normal_loss: 0.018751\n",
      "[313/00024] train_loss: 0.025582 kl_loss: 0.229850 normal_loss: 0.018686\n",
      "[314/00049] train_loss: 0.025607 kl_loss: 0.230137 normal_loss: 0.018702\n",
      "[315/00074] train_loss: 0.025604 kl_loss: 0.229590 normal_loss: 0.018716\n",
      "[317/00024] train_loss: 0.025460 kl_loss: 0.229220 normal_loss: 0.018584\n",
      "[318/00049] train_loss: 0.025527 kl_loss: 0.229412 normal_loss: 0.018645\n",
      "[319/00074] train_loss: 0.025453 kl_loss: 0.228766 normal_loss: 0.018590\n",
      "[321/00024] train_loss: 0.025341 kl_loss: 0.227929 normal_loss: 0.018503\n",
      "[322/00049] train_loss: 0.025472 kl_loss: 0.229070 normal_loss: 0.018600\n",
      "[323/00074] train_loss: 0.025384 kl_loss: 0.228138 normal_loss: 0.018539\n",
      "[325/00024] train_loss: 0.025283 kl_loss: 0.227579 normal_loss: 0.018456\n",
      "[326/00049] train_loss: 0.025400 kl_loss: 0.227878 normal_loss: 0.018564\n",
      "[327/00074] train_loss: 0.025249 kl_loss: 0.227310 normal_loss: 0.018429\n",
      "[329/00024] train_loss: 0.025218 kl_loss: 0.227143 normal_loss: 0.018403\n",
      "[330/00049] train_loss: 0.025257 kl_loss: 0.227026 normal_loss: 0.018446\n",
      "[331/00074] train_loss: 0.025295 kl_loss: 0.226313 normal_loss: 0.018506\n",
      "[333/00024] train_loss: 0.025277 kl_loss: 0.226529 normal_loss: 0.018481\n",
      "[334/00049] train_loss: 0.025153 kl_loss: 0.225826 normal_loss: 0.018379\n",
      "[335/00074] train_loss: 0.025143 kl_loss: 0.226152 normal_loss: 0.018359\n",
      "[337/00024] train_loss: 0.025159 kl_loss: 0.225821 normal_loss: 0.018384\n",
      "[338/00049] train_loss: 0.025207 kl_loss: 0.225659 normal_loss: 0.018438\n",
      "[339/00074] train_loss: 0.025123 kl_loss: 0.224956 normal_loss: 0.018375\n",
      "[341/00024] train_loss: 0.025064 kl_loss: 0.224799 normal_loss: 0.018320\n",
      "[342/00049] train_loss: 0.025139 kl_loss: 0.225702 normal_loss: 0.018368\n",
      "[343/00074] train_loss: 0.024966 kl_loss: 0.224101 normal_loss: 0.018243\n",
      "[345/00024] train_loss: 0.024880 kl_loss: 0.224277 normal_loss: 0.018151\n",
      "[346/00049] train_loss: 0.025045 kl_loss: 0.224640 normal_loss: 0.018306\n",
      "[347/00074] train_loss: 0.024892 kl_loss: 0.223764 normal_loss: 0.018179\n",
      "[349/00024] train_loss: 0.024955 kl_loss: 0.223719 normal_loss: 0.018244\n",
      "[349/00074] MMD 0.004884112626314163\n",
      "[349/00074] TMD 0.0640522688627243\n",
      "[350/00049] train_loss: 0.024894 kl_loss: 0.223650 normal_loss: 0.018184\n",
      "[351/00074] train_loss: 0.024909 kl_loss: 0.223482 normal_loss: 0.018205\n",
      "[353/00024] train_loss: 0.024888 kl_loss: 0.223474 normal_loss: 0.018184\n",
      "[354/00049] train_loss: 0.024730 kl_loss: 0.222558 normal_loss: 0.018053\n",
      "[355/00074] train_loss: 0.024869 kl_loss: 0.222944 normal_loss: 0.018181\n",
      "[357/00024] train_loss: 0.024795 kl_loss: 0.222451 normal_loss: 0.018121\n",
      "[358/00049] train_loss: 0.024850 kl_loss: 0.222371 normal_loss: 0.018179\n",
      "[359/00074] train_loss: 0.024881 kl_loss: 0.222427 normal_loss: 0.018208\n",
      "[361/00024] train_loss: 0.024795 kl_loss: 0.222391 normal_loss: 0.018123\n",
      "[362/00049] train_loss: 0.024721 kl_loss: 0.222334 normal_loss: 0.018051\n",
      "[363/00074] train_loss: 0.024555 kl_loss: 0.220793 normal_loss: 0.017932\n",
      "[365/00024] train_loss: 0.024670 kl_loss: 0.221668 normal_loss: 0.018020\n",
      "[366/00049] train_loss: 0.024615 kl_loss: 0.220942 normal_loss: 0.017987\n",
      "[367/00074] train_loss: 0.024638 kl_loss: 0.221064 normal_loss: 0.018006\n",
      "[369/00024] train_loss: 0.024634 kl_loss: 0.220812 normal_loss: 0.018009\n",
      "[370/00049] train_loss: 0.024548 kl_loss: 0.220429 normal_loss: 0.017935\n",
      "[371/00074] train_loss: 0.024547 kl_loss: 0.220769 normal_loss: 0.017924\n",
      "[373/00024] train_loss: 0.024592 kl_loss: 0.220504 normal_loss: 0.017977\n",
      "[374/00049] train_loss: 0.024534 kl_loss: 0.219897 normal_loss: 0.017937\n",
      "[375/00074] train_loss: 0.024524 kl_loss: 0.219849 normal_loss: 0.017929\n",
      "[377/00024] train_loss: 0.024513 kl_loss: 0.219344 normal_loss: 0.017933\n",
      "[378/00049] train_loss: 0.024515 kl_loss: 0.220105 normal_loss: 0.017912\n",
      "[379/00074] train_loss: 0.024400 kl_loss: 0.219199 normal_loss: 0.017824\n",
      "[381/00024] train_loss: 0.024417 kl_loss: 0.219015 normal_loss: 0.017847\n",
      "[382/00049] train_loss: 0.024427 kl_loss: 0.219013 normal_loss: 0.017856\n",
      "[383/00074] train_loss: 0.024390 kl_loss: 0.219008 normal_loss: 0.017820\n",
      "[385/00024] train_loss: 0.024346 kl_loss: 0.218221 normal_loss: 0.017799\n",
      "[386/00049] train_loss: 0.024354 kl_loss: 0.219091 normal_loss: 0.017781\n",
      "[387/00074] train_loss: 0.024382 kl_loss: 0.218194 normal_loss: 0.017836\n",
      "[389/00024] train_loss: 0.024300 kl_loss: 0.217866 normal_loss: 0.017764\n",
      "[390/00049] train_loss: 0.024410 kl_loss: 0.218435 normal_loss: 0.017857\n",
      "[391/00074] train_loss: 0.024219 kl_loss: 0.217742 normal_loss: 0.017687\n",
      "[393/00024] train_loss: 0.024268 kl_loss: 0.217946 normal_loss: 0.017730\n",
      "[394/00049] train_loss: 0.024216 kl_loss: 0.217171 normal_loss: 0.017701\n",
      "[395/00074] train_loss: 0.024148 kl_loss: 0.217513 normal_loss: 0.017623\n",
      "[397/00024] train_loss: 0.024178 kl_loss: 0.216754 normal_loss: 0.017676\n",
      "[398/00049] train_loss: 0.024324 kl_loss: 0.217747 normal_loss: 0.017791\n",
      "[399/00000] updated kl_weight: 0.03\n",
      "[399/00001] updated kl_weight: 0.03\n",
      "[399/00002] updated kl_weight: 0.03\n",
      "[399/00003] updated kl_weight: 0.03\n",
      "[399/00004] updated kl_weight: 0.03\n",
      "[399/00005] updated kl_weight: 0.03\n",
      "[399/00006] updated kl_weight: 0.03\n",
      "[399/00007] updated kl_weight: 0.03\n",
      "[399/00008] updated kl_weight: 0.03\n",
      "[399/00009] updated kl_weight: 0.03\n",
      "[399/00010] updated kl_weight: 0.03\n",
      "[399/00011] updated kl_weight: 0.03\n",
      "[399/00012] updated kl_weight: 0.03\n",
      "[399/00013] updated kl_weight: 0.03\n",
      "[399/00014] updated kl_weight: 0.03\n",
      "[399/00015] updated kl_weight: 0.03\n",
      "[399/00016] updated kl_weight: 0.03\n",
      "[399/00017] updated kl_weight: 0.03\n",
      "[399/00018] updated kl_weight: 0.03\n",
      "[399/00019] updated kl_weight: 0.03\n",
      "[399/00020] updated kl_weight: 0.03\n",
      "[399/00021] updated kl_weight: 0.03\n",
      "[399/00022] updated kl_weight: 0.03\n",
      "[399/00023] updated kl_weight: 0.03\n",
      "[399/00024] updated kl_weight: 0.03\n",
      "[399/00025] updated kl_weight: 0.03\n",
      "[399/00026] updated kl_weight: 0.03\n",
      "[399/00027] updated kl_weight: 0.03\n",
      "[399/00028] updated kl_weight: 0.03\n",
      "[399/00029] updated kl_weight: 0.03\n",
      "[399/00030] updated kl_weight: 0.03\n",
      "[399/00031] updated kl_weight: 0.03\n",
      "[399/00032] updated kl_weight: 0.03\n",
      "[399/00033] updated kl_weight: 0.03\n",
      "[399/00034] updated kl_weight: 0.03\n",
      "[399/00035] updated kl_weight: 0.03\n",
      "[399/00036] updated kl_weight: 0.03\n",
      "[399/00037] updated kl_weight: 0.03\n",
      "[399/00038] updated kl_weight: 0.03\n",
      "[399/00039] updated kl_weight: 0.03\n",
      "[399/00040] updated kl_weight: 0.03\n",
      "[399/00041] updated kl_weight: 0.03\n",
      "[399/00042] updated kl_weight: 0.03\n",
      "[399/00043] updated kl_weight: 0.03\n",
      "[399/00044] updated kl_weight: 0.03\n",
      "[399/00045] updated kl_weight: 0.03\n",
      "[399/00046] updated kl_weight: 0.03\n",
      "[399/00047] updated kl_weight: 0.03\n",
      "[399/00048] updated kl_weight: 0.03\n",
      "[399/00049] updated kl_weight: 0.03\n",
      "[399/00050] updated kl_weight: 0.03\n",
      "[399/00051] updated kl_weight: 0.03\n",
      "[399/00052] updated kl_weight: 0.03\n",
      "[399/00053] updated kl_weight: 0.03\n",
      "[399/00054] updated kl_weight: 0.03\n",
      "[399/00055] updated kl_weight: 0.03\n",
      "[399/00056] updated kl_weight: 0.03\n",
      "[399/00057] updated kl_weight: 0.03\n",
      "[399/00058] updated kl_weight: 0.03\n",
      "[399/00059] updated kl_weight: 0.03\n",
      "[399/00060] updated kl_weight: 0.03\n",
      "[399/00061] updated kl_weight: 0.03\n",
      "[399/00062] updated kl_weight: 0.03\n",
      "[399/00063] updated kl_weight: 0.03\n",
      "[399/00064] updated kl_weight: 0.03\n",
      "[399/00065] updated kl_weight: 0.03\n",
      "[399/00066] updated kl_weight: 0.03\n",
      "[399/00067] updated kl_weight: 0.03\n",
      "[399/00068] updated kl_weight: 0.03\n",
      "[399/00069] updated kl_weight: 0.03\n",
      "[399/00070] updated kl_weight: 0.03\n",
      "[399/00071] updated kl_weight: 0.03\n",
      "[399/00072] updated kl_weight: 0.03\n",
      "[399/00073] updated kl_weight: 0.03\n",
      "[399/00074] updated kl_weight: 0.03\n",
      "[399/00074] train_loss: 0.024137 kl_loss: 0.216698 normal_loss: 0.017636\n",
      "[399/00074] MMD 0.004945943597704172\n",
      "[399/00074] TMD 0.05976533144712448\n",
      "[401/00024] train_loss: 0.023902 kl_loss: 0.216592 normal_loss: 0.017404\n",
      "[402/00049] train_loss: 0.023836 kl_loss: 0.216462 normal_loss: 0.017342\n",
      "[403/00074] train_loss: 0.023851 kl_loss: 0.216892 normal_loss: 0.017345\n",
      "[405/00024] train_loss: 0.023707 kl_loss: 0.216410 normal_loss: 0.017215\n",
      "[406/00049] train_loss: 0.023811 kl_loss: 0.216322 normal_loss: 0.017322\n",
      "[407/00074] train_loss: 0.023798 kl_loss: 0.216137 normal_loss: 0.017314\n",
      "[409/00024] train_loss: 0.023782 kl_loss: 0.215486 normal_loss: 0.017317\n",
      "[410/00049] train_loss: 0.023729 kl_loss: 0.216108 normal_loss: 0.017246\n",
      "[411/00074] train_loss: 0.023697 kl_loss: 0.216238 normal_loss: 0.017210\n",
      "[413/00024] train_loss: 0.023715 kl_loss: 0.215715 normal_loss: 0.017244\n",
      "[414/00049] train_loss: 0.023708 kl_loss: 0.215934 normal_loss: 0.017230\n",
      "[415/00074] train_loss: 0.023721 kl_loss: 0.215099 normal_loss: 0.017268\n",
      "[417/00024] train_loss: 0.023641 kl_loss: 0.214911 normal_loss: 0.017193\n",
      "[418/00049] train_loss: 0.023709 kl_loss: 0.215611 normal_loss: 0.017241\n",
      "[419/00074] train_loss: 0.023622 kl_loss: 0.215224 normal_loss: 0.017165\n",
      "[421/00024] train_loss: 0.023551 kl_loss: 0.214741 normal_loss: 0.017109\n",
      "[422/00049] train_loss: 0.023616 kl_loss: 0.215133 normal_loss: 0.017162\n",
      "[423/00074] train_loss: 0.023586 kl_loss: 0.214868 normal_loss: 0.017140\n",
      "[425/00024] train_loss: 0.023529 kl_loss: 0.214673 normal_loss: 0.017089\n",
      "[426/00049] train_loss: 0.023609 kl_loss: 0.214655 normal_loss: 0.017169\n",
      "[427/00074] train_loss: 0.023583 kl_loss: 0.214332 normal_loss: 0.017153\n",
      "[429/00024] train_loss: 0.023464 kl_loss: 0.213837 normal_loss: 0.017049\n",
      "[430/00049] train_loss: 0.023629 kl_loss: 0.214824 normal_loss: 0.017184\n",
      "[431/00074] train_loss: 0.023534 kl_loss: 0.214015 normal_loss: 0.017113\n",
      "[433/00024] train_loss: 0.023463 kl_loss: 0.213575 normal_loss: 0.017056\n",
      "[434/00049] train_loss: 0.023476 kl_loss: 0.214047 normal_loss: 0.017055\n",
      "[435/00074] train_loss: 0.023517 kl_loss: 0.214040 normal_loss: 0.017096\n",
      "[437/00024] train_loss: 0.023471 kl_loss: 0.213425 normal_loss: 0.017068\n",
      "[438/00049] train_loss: 0.023464 kl_loss: 0.213490 normal_loss: 0.017059\n",
      "[439/00074] train_loss: 0.023468 kl_loss: 0.213732 normal_loss: 0.017056\n",
      "[441/00024] train_loss: 0.023467 kl_loss: 0.213502 normal_loss: 0.017062\n",
      "[442/00049] train_loss: 0.023451 kl_loss: 0.213459 normal_loss: 0.017048\n",
      "[443/00074] train_loss: 0.023413 kl_loss: 0.212742 normal_loss: 0.017031\n",
      "[445/00024] train_loss: 0.023313 kl_loss: 0.212825 normal_loss: 0.016929\n",
      "[446/00049] train_loss: 0.023376 kl_loss: 0.212580 normal_loss: 0.016999\n",
      "[447/00074] train_loss: 0.023450 kl_loss: 0.213320 normal_loss: 0.017050\n",
      "[449/00024] train_loss: 0.023344 kl_loss: 0.212856 normal_loss: 0.016959\n",
      "[449/00074] MMD 0.005230878945440054\n",
      "[449/00074] TMD 0.0789671465754509\n",
      "[450/00049] train_loss: 0.023429 kl_loss: 0.212711 normal_loss: 0.017048\n",
      "[451/00074] train_loss: 0.023323 kl_loss: 0.212227 normal_loss: 0.016956\n",
      "[453/00024] train_loss: 0.023287 kl_loss: 0.212451 normal_loss: 0.016914\n",
      "[454/00049] train_loss: 0.023258 kl_loss: 0.211959 normal_loss: 0.016899\n",
      "[455/00074] train_loss: 0.023361 kl_loss: 0.212424 normal_loss: 0.016988\n",
      "[457/00024] train_loss: 0.023279 kl_loss: 0.212252 normal_loss: 0.016912\n",
      "[458/00049] train_loss: 0.023238 kl_loss: 0.211582 normal_loss: 0.016891\n",
      "[459/00074] train_loss: 0.023291 kl_loss: 0.212044 normal_loss: 0.016930\n",
      "[461/00024] train_loss: 0.023162 kl_loss: 0.211218 normal_loss: 0.016825\n",
      "[462/00049] train_loss: 0.023320 kl_loss: 0.212132 normal_loss: 0.016956\n",
      "[463/00074] train_loss: 0.023269 kl_loss: 0.211598 normal_loss: 0.016921\n",
      "[465/00024] train_loss: 0.023213 kl_loss: 0.211234 normal_loss: 0.016876\n",
      "[466/00049] train_loss: 0.023281 kl_loss: 0.211361 normal_loss: 0.016940\n",
      "[467/00074] train_loss: 0.023199 kl_loss: 0.211447 normal_loss: 0.016856\n",
      "[469/00024] train_loss: 0.023339 kl_loss: 0.211660 normal_loss: 0.016989\n",
      "[470/00049] train_loss: 0.023043 kl_loss: 0.209940 normal_loss: 0.016745\n",
      "[471/00074] train_loss: 0.023265 kl_loss: 0.211571 normal_loss: 0.016918\n",
      "[473/00024] train_loss: 0.023102 kl_loss: 0.210651 normal_loss: 0.016782\n",
      "[474/00049] train_loss: 0.023238 kl_loss: 0.210973 normal_loss: 0.016909\n",
      "[475/00074] train_loss: 0.023221 kl_loss: 0.210702 normal_loss: 0.016900\n",
      "[477/00024] train_loss: 0.023042 kl_loss: 0.209973 normal_loss: 0.016743\n",
      "[478/00049] train_loss: 0.023196 kl_loss: 0.210898 normal_loss: 0.016869\n",
      "[479/00074] train_loss: 0.023195 kl_loss: 0.210594 normal_loss: 0.016877\n",
      "[481/00024] train_loss: 0.023095 kl_loss: 0.210207 normal_loss: 0.016789\n",
      "[482/00049] train_loss: 0.023120 kl_loss: 0.210594 normal_loss: 0.016802\n",
      "[483/00074] train_loss: 0.023111 kl_loss: 0.209805 normal_loss: 0.016817\n",
      "[485/00024] train_loss: 0.023049 kl_loss: 0.210037 normal_loss: 0.016748\n",
      "[486/00049] train_loss: 0.023150 kl_loss: 0.210125 normal_loss: 0.016846\n",
      "[487/00074] train_loss: 0.023101 kl_loss: 0.209611 normal_loss: 0.016813\n",
      "[489/00024] train_loss: 0.023083 kl_loss: 0.209893 normal_loss: 0.016786\n",
      "[490/00049] train_loss: 0.022924 kl_loss: 0.208981 normal_loss: 0.016655\n",
      "[491/00074] train_loss: 0.023134 kl_loss: 0.210077 normal_loss: 0.016831\n",
      "[493/00024] train_loss: 0.023033 kl_loss: 0.209375 normal_loss: 0.016752\n",
      "[494/00049] train_loss: 0.023081 kl_loss: 0.210094 normal_loss: 0.016778\n",
      "[495/00074] train_loss: 0.022992 kl_loss: 0.208677 normal_loss: 0.016732\n",
      "[497/00024] train_loss: 0.022966 kl_loss: 0.209233 normal_loss: 0.016689\n",
      "[498/00049] train_loss: 0.022955 kl_loss: 0.209501 normal_loss: 0.016669\n",
      "[499/00000] updated kl_weight: 0.03\n",
      "[499/00001] updated kl_weight: 0.03\n",
      "[499/00002] updated kl_weight: 0.03\n",
      "[499/00003] updated kl_weight: 0.03\n",
      "[499/00004] updated kl_weight: 0.03\n",
      "[499/00005] updated kl_weight: 0.03\n",
      "[499/00006] updated kl_weight: 0.03\n",
      "[499/00007] updated kl_weight: 0.03\n",
      "[499/00008] updated kl_weight: 0.03\n",
      "[499/00009] updated kl_weight: 0.03\n",
      "[499/00010] updated kl_weight: 0.03\n",
      "[499/00011] updated kl_weight: 0.03\n",
      "[499/00012] updated kl_weight: 0.03\n",
      "[499/00013] updated kl_weight: 0.03\n",
      "[499/00014] updated kl_weight: 0.03\n",
      "[499/00015] updated kl_weight: 0.03\n",
      "[499/00016] updated kl_weight: 0.03\n",
      "[499/00017] updated kl_weight: 0.03\n",
      "[499/00018] updated kl_weight: 0.03\n",
      "[499/00019] updated kl_weight: 0.03\n",
      "[499/00020] updated kl_weight: 0.03\n",
      "[499/00021] updated kl_weight: 0.03\n",
      "[499/00022] updated kl_weight: 0.03\n",
      "[499/00023] updated kl_weight: 0.03\n",
      "[499/00024] updated kl_weight: 0.03\n",
      "[499/00025] updated kl_weight: 0.03\n",
      "[499/00026] updated kl_weight: 0.03\n",
      "[499/00027] updated kl_weight: 0.03\n",
      "[499/00028] updated kl_weight: 0.03\n",
      "[499/00029] updated kl_weight: 0.03\n",
      "[499/00030] updated kl_weight: 0.03\n",
      "[499/00031] updated kl_weight: 0.03\n",
      "[499/00032] updated kl_weight: 0.03\n",
      "[499/00033] updated kl_weight: 0.03\n",
      "[499/00034] updated kl_weight: 0.03\n",
      "[499/00035] updated kl_weight: 0.03\n",
      "[499/00036] updated kl_weight: 0.03\n",
      "[499/00037] updated kl_weight: 0.03\n",
      "[499/00038] updated kl_weight: 0.03\n",
      "[499/00039] updated kl_weight: 0.03\n",
      "[499/00040] updated kl_weight: 0.03\n",
      "[499/00041] updated kl_weight: 0.03\n",
      "[499/00042] updated kl_weight: 0.03\n",
      "[499/00043] updated kl_weight: 0.03\n",
      "[499/00044] updated kl_weight: 0.03\n",
      "[499/00045] updated kl_weight: 0.03\n",
      "[499/00046] updated kl_weight: 0.03\n",
      "[499/00047] updated kl_weight: 0.03\n",
      "[499/00048] updated kl_weight: 0.03\n",
      "[499/00049] updated kl_weight: 0.03\n",
      "[499/00050] updated kl_weight: 0.03\n",
      "[499/00051] updated kl_weight: 0.03\n",
      "[499/00052] updated kl_weight: 0.03\n",
      "[499/00053] updated kl_weight: 0.03\n",
      "[499/00054] updated kl_weight: 0.03\n",
      "[499/00055] updated kl_weight: 0.03\n",
      "[499/00056] updated kl_weight: 0.03\n",
      "[499/00057] updated kl_weight: 0.03\n",
      "[499/00058] updated kl_weight: 0.03\n",
      "[499/00059] updated kl_weight: 0.03\n",
      "[499/00060] updated kl_weight: 0.03\n",
      "[499/00061] updated kl_weight: 0.03\n",
      "[499/00062] updated kl_weight: 0.03\n",
      "[499/00063] updated kl_weight: 0.03\n",
      "[499/00064] updated kl_weight: 0.03\n",
      "[499/00065] updated kl_weight: 0.03\n",
      "[499/00066] updated kl_weight: 0.03\n",
      "[499/00067] updated kl_weight: 0.03\n",
      "[499/00068] updated kl_weight: 0.03\n",
      "[499/00069] updated kl_weight: 0.03\n",
      "[499/00070] updated kl_weight: 0.03\n",
      "[499/00071] updated kl_weight: 0.03\n",
      "[499/00072] updated kl_weight: 0.03\n",
      "[499/00073] updated kl_weight: 0.03\n",
      "[499/00074] updated kl_weight: 0.03\n",
      "[499/00074] train_loss: 0.022958 kl_loss: 0.208578 normal_loss: 0.016701\n",
      "[499/00074] MMD 0.0050292606465518475\n",
      "[499/00074] TMD 0.07114793360233307\n",
      "[501/00024] train_loss: 0.022878 kl_loss: 0.208997 normal_loss: 0.016609\n",
      "[502/00049] train_loss: 0.022843 kl_loss: 0.208846 normal_loss: 0.016578\n",
      "[503/00074] train_loss: 0.022865 kl_loss: 0.208797 normal_loss: 0.016601\n",
      "[505/00024] train_loss: 0.022783 kl_loss: 0.208710 normal_loss: 0.016522\n",
      "[506/00049] train_loss: 0.022810 kl_loss: 0.208573 normal_loss: 0.016553\n",
      "[507/00074] train_loss: 0.022861 kl_loss: 0.208903 normal_loss: 0.016594\n",
      "[509/00024] train_loss: 0.022796 kl_loss: 0.208205 normal_loss: 0.016550\n",
      "[510/00049] train_loss: 0.022792 kl_loss: 0.209191 normal_loss: 0.016516\n",
      "[511/00074] train_loss: 0.022722 kl_loss: 0.208273 normal_loss: 0.016474\n",
      "[513/00024] train_loss: 0.022747 kl_loss: 0.208093 normal_loss: 0.016505\n",
      "[514/00049] train_loss: 0.022776 kl_loss: 0.208802 normal_loss: 0.016512\n",
      "[515/00074] train_loss: 0.022746 kl_loss: 0.208249 normal_loss: 0.016499\n",
      "[517/00024] train_loss: 0.022772 kl_loss: 0.208067 normal_loss: 0.016530\n",
      "[518/00049] train_loss: 0.022737 kl_loss: 0.208503 normal_loss: 0.016482\n",
      "[519/00074] train_loss: 0.022738 kl_loss: 0.208087 normal_loss: 0.016496\n",
      "[521/00024] train_loss: 0.022760 kl_loss: 0.208318 normal_loss: 0.016511\n",
      "[522/00049] train_loss: 0.022716 kl_loss: 0.207961 normal_loss: 0.016478\n",
      "[523/00074] train_loss: 0.022711 kl_loss: 0.207868 normal_loss: 0.016475\n",
      "[525/00024] train_loss: 0.022689 kl_loss: 0.208140 normal_loss: 0.016444\n",
      "[526/00049] train_loss: 0.022796 kl_loss: 0.208333 normal_loss: 0.016546\n",
      "[527/00074] train_loss: 0.022584 kl_loss: 0.207168 normal_loss: 0.016369\n",
      "[529/00024] train_loss: 0.022774 kl_loss: 0.208106 normal_loss: 0.016530\n",
      "[530/00049] train_loss: 0.022723 kl_loss: 0.207877 normal_loss: 0.016487\n",
      "[531/00074] train_loss: 0.022579 kl_loss: 0.207171 normal_loss: 0.016364\n",
      "[533/00024] train_loss: 0.022626 kl_loss: 0.207695 normal_loss: 0.016395\n",
      "[534/00049] train_loss: 0.022691 kl_loss: 0.207591 normal_loss: 0.016464\n",
      "[535/00074] train_loss: 0.022654 kl_loss: 0.207345 normal_loss: 0.016433\n",
      "[537/00024] train_loss: 0.022689 kl_loss: 0.207674 normal_loss: 0.016459\n",
      "[538/00049] train_loss: 0.022538 kl_loss: 0.206831 normal_loss: 0.016333\n",
      "[539/00074] train_loss: 0.022739 kl_loss: 0.207643 normal_loss: 0.016509\n",
      "[541/00024] train_loss: 0.022606 kl_loss: 0.207794 normal_loss: 0.016372\n",
      "[542/00049] train_loss: 0.022584 kl_loss: 0.206753 normal_loss: 0.016382\n",
      "[543/00074] train_loss: 0.022618 kl_loss: 0.207112 normal_loss: 0.016405\n",
      "[545/00024] train_loss: 0.022642 kl_loss: 0.207414 normal_loss: 0.016420\n",
      "[546/00049] train_loss: 0.022539 kl_loss: 0.206185 normal_loss: 0.016353\n",
      "[547/00074] train_loss: 0.022662 kl_loss: 0.207572 normal_loss: 0.016435\n",
      "[549/00024] train_loss: 0.022543 kl_loss: 0.206222 normal_loss: 0.016356\n",
      "[549/00074] MMD 0.005278234835714102\n",
      "[549/00074] TMD 0.05892890691757202\n",
      "[550/00049] train_loss: 0.022586 kl_loss: 0.207289 normal_loss: 0.016367\n",
      "[551/00074] train_loss: 0.022633 kl_loss: 0.207181 normal_loss: 0.016418\n",
      "[553/00024] train_loss: 0.022584 kl_loss: 0.206867 normal_loss: 0.016378\n",
      "[554/00049] train_loss: 0.022654 kl_loss: 0.206981 normal_loss: 0.016444\n",
      "[555/00074] train_loss: 0.022558 kl_loss: 0.206352 normal_loss: 0.016367\n",
      "[557/00024] train_loss: 0.022570 kl_loss: 0.206474 normal_loss: 0.016375\n",
      "[558/00049] train_loss: 0.022582 kl_loss: 0.206672 normal_loss: 0.016382\n",
      "[559/00074] train_loss: 0.022602 kl_loss: 0.206595 normal_loss: 0.016404\n",
      "[561/00024] train_loss: 0.022595 kl_loss: 0.206681 normal_loss: 0.016394\n",
      "[562/00049] train_loss: 0.022665 kl_loss: 0.206672 normal_loss: 0.016465\n",
      "[563/00074] train_loss: 0.022501 kl_loss: 0.205961 normal_loss: 0.016322\n",
      "[565/00024] train_loss: 0.022533 kl_loss: 0.206145 normal_loss: 0.016349\n",
      "[566/00049] train_loss: 0.022537 kl_loss: 0.206442 normal_loss: 0.016344\n",
      "[567/00074] train_loss: 0.022537 kl_loss: 0.206302 normal_loss: 0.016348\n",
      "[569/00024] train_loss: 0.022479 kl_loss: 0.206188 normal_loss: 0.016294\n",
      "[570/00049] train_loss: 0.022581 kl_loss: 0.206224 normal_loss: 0.016394\n",
      "[571/00074] train_loss: 0.022507 kl_loss: 0.206008 normal_loss: 0.016327\n",
      "[573/00024] train_loss: 0.022521 kl_loss: 0.206170 normal_loss: 0.016336\n",
      "[574/00049] train_loss: 0.022464 kl_loss: 0.205632 normal_loss: 0.016295\n",
      "[575/00074] train_loss: 0.022532 kl_loss: 0.206191 normal_loss: 0.016347\n",
      "[577/00024] train_loss: 0.022415 kl_loss: 0.205356 normal_loss: 0.016255\n",
      "[578/00049] train_loss: 0.022531 kl_loss: 0.206232 normal_loss: 0.016344\n",
      "[579/00074] train_loss: 0.022499 kl_loss: 0.205944 normal_loss: 0.016320\n",
      "[581/00024] train_loss: 0.022447 kl_loss: 0.205736 normal_loss: 0.016275\n",
      "[582/00049] train_loss: 0.022483 kl_loss: 0.205964 normal_loss: 0.016304\n",
      "[583/00074] train_loss: 0.022441 kl_loss: 0.205387 normal_loss: 0.016280\n",
      "[585/00024] train_loss: 0.022499 kl_loss: 0.205628 normal_loss: 0.016331\n",
      "[586/00049] train_loss: 0.022423 kl_loss: 0.205432 normal_loss: 0.016260\n",
      "[587/00074] train_loss: 0.022453 kl_loss: 0.205577 normal_loss: 0.016286\n",
      "[589/00024] train_loss: 0.022439 kl_loss: 0.204929 normal_loss: 0.016291\n",
      "[590/00049] train_loss: 0.022554 kl_loss: 0.206632 normal_loss: 0.016355\n",
      "[591/00074] train_loss: 0.022369 kl_loss: 0.204644 normal_loss: 0.016229\n",
      "[593/00024] train_loss: 0.022354 kl_loss: 0.205346 normal_loss: 0.016194\n",
      "[594/00049] train_loss: 0.022469 kl_loss: 0.205178 normal_loss: 0.016314\n",
      "[595/00074] train_loss: 0.022364 kl_loss: 0.205248 normal_loss: 0.016207\n",
      "[597/00024] train_loss: 0.022405 kl_loss: 0.205538 normal_loss: 0.016239\n",
      "[598/00049] train_loss: 0.022395 kl_loss: 0.204641 normal_loss: 0.016255\n",
      "[599/00000] updated kl_weight: 0.03\n",
      "[599/00001] updated kl_weight: 0.03\n",
      "[599/00002] updated kl_weight: 0.03\n",
      "[599/00003] updated kl_weight: 0.03\n",
      "[599/00004] updated kl_weight: 0.03\n",
      "[599/00005] updated kl_weight: 0.03\n",
      "[599/00006] updated kl_weight: 0.03\n",
      "[599/00007] updated kl_weight: 0.03\n",
      "[599/00008] updated kl_weight: 0.03\n",
      "[599/00009] updated kl_weight: 0.03\n",
      "[599/00010] updated kl_weight: 0.03\n",
      "[599/00011] updated kl_weight: 0.03\n",
      "[599/00012] updated kl_weight: 0.03\n",
      "[599/00013] updated kl_weight: 0.03\n",
      "[599/00014] updated kl_weight: 0.03\n",
      "[599/00015] updated kl_weight: 0.03\n",
      "[599/00016] updated kl_weight: 0.03\n",
      "[599/00017] updated kl_weight: 0.03\n",
      "[599/00018] updated kl_weight: 0.03\n",
      "[599/00019] updated kl_weight: 0.03\n",
      "[599/00020] updated kl_weight: 0.03\n",
      "[599/00021] updated kl_weight: 0.03\n",
      "[599/00022] updated kl_weight: 0.03\n",
      "[599/00023] updated kl_weight: 0.03\n",
      "[599/00024] updated kl_weight: 0.03\n",
      "[599/00025] updated kl_weight: 0.03\n",
      "[599/00026] updated kl_weight: 0.03\n",
      "[599/00027] updated kl_weight: 0.03\n",
      "[599/00028] updated kl_weight: 0.03\n",
      "[599/00029] updated kl_weight: 0.03\n",
      "[599/00030] updated kl_weight: 0.03\n",
      "[599/00031] updated kl_weight: 0.03\n",
      "[599/00032] updated kl_weight: 0.03\n",
      "[599/00033] updated kl_weight: 0.03\n",
      "[599/00034] updated kl_weight: 0.03\n",
      "[599/00035] updated kl_weight: 0.03\n",
      "[599/00036] updated kl_weight: 0.03\n",
      "[599/00037] updated kl_weight: 0.03\n",
      "[599/00038] updated kl_weight: 0.03\n",
      "[599/00039] updated kl_weight: 0.03\n",
      "[599/00040] updated kl_weight: 0.03\n",
      "[599/00041] updated kl_weight: 0.03\n",
      "[599/00042] updated kl_weight: 0.03\n",
      "[599/00043] updated kl_weight: 0.03\n",
      "[599/00044] updated kl_weight: 0.03\n",
      "[599/00045] updated kl_weight: 0.03\n",
      "[599/00046] updated kl_weight: 0.03\n",
      "[599/00047] updated kl_weight: 0.03\n",
      "[599/00048] updated kl_weight: 0.03\n",
      "[599/00049] updated kl_weight: 0.03\n",
      "[599/00050] updated kl_weight: 0.03\n",
      "[599/00051] updated kl_weight: 0.03\n",
      "[599/00052] updated kl_weight: 0.03\n",
      "[599/00053] updated kl_weight: 0.03\n",
      "[599/00054] updated kl_weight: 0.03\n",
      "[599/00055] updated kl_weight: 0.03\n",
      "[599/00056] updated kl_weight: 0.03\n",
      "[599/00057] updated kl_weight: 0.03\n",
      "[599/00058] updated kl_weight: 0.03\n",
      "[599/00059] updated kl_weight: 0.03\n",
      "[599/00060] updated kl_weight: 0.03\n",
      "[599/00061] updated kl_weight: 0.03\n",
      "[599/00062] updated kl_weight: 0.03\n",
      "[599/00063] updated kl_weight: 0.03\n",
      "[599/00064] updated kl_weight: 0.03\n",
      "[599/00065] updated kl_weight: 0.03\n",
      "[599/00066] updated kl_weight: 0.03\n",
      "[599/00067] updated kl_weight: 0.03\n",
      "[599/00068] updated kl_weight: 0.03\n",
      "[599/00069] updated kl_weight: 0.03\n",
      "[599/00070] updated kl_weight: 0.03\n",
      "[599/00071] updated kl_weight: 0.03\n",
      "[599/00072] updated kl_weight: 0.03\n",
      "[599/00073] updated kl_weight: 0.03\n",
      "[599/00074] updated kl_weight: 0.03\n",
      "[599/00074] train_loss: 0.022380 kl_loss: 0.205128 normal_loss: 0.016226\n",
      "[599/00074] MMD 0.004921461921185255\n",
      "[599/00074] TMD 0.05919303745031357\n",
      "[601/00024] train_loss: 0.022314 kl_loss: 0.204713 normal_loss: 0.016173\n",
      "[602/00049] train_loss: 0.022311 kl_loss: 0.205386 normal_loss: 0.016149\n",
      "[603/00074] train_loss: 0.022363 kl_loss: 0.204854 normal_loss: 0.016217\n",
      "[605/00024] train_loss: 0.022278 kl_loss: 0.204744 normal_loss: 0.016135\n",
      "[606/00049] train_loss: 0.022347 kl_loss: 0.204964 normal_loss: 0.016198\n",
      "[607/00074] train_loss: 0.022292 kl_loss: 0.205004 normal_loss: 0.016142\n",
      "[609/00024] train_loss: 0.022383 kl_loss: 0.205440 normal_loss: 0.016219\n",
      "[610/00049] train_loss: 0.022312 kl_loss: 0.204581 normal_loss: 0.016174\n",
      "[611/00074] train_loss: 0.022222 kl_loss: 0.204445 normal_loss: 0.016089\n",
      "[613/00024] train_loss: 0.022276 kl_loss: 0.204417 normal_loss: 0.016143\n",
      "[614/00049] train_loss: 0.022393 kl_loss: 0.205491 normal_loss: 0.016228\n",
      "[615/00074] train_loss: 0.022266 kl_loss: 0.204313 normal_loss: 0.016136\n",
      "[617/00024] train_loss: 0.022246 kl_loss: 0.204516 normal_loss: 0.016111\n",
      "[618/00049] train_loss: 0.022350 kl_loss: 0.205068 normal_loss: 0.016198\n",
      "[619/00074] train_loss: 0.022280 kl_loss: 0.204408 normal_loss: 0.016148\n",
      "[621/00024] train_loss: 0.022272 kl_loss: 0.204488 normal_loss: 0.016137\n",
      "[622/00049] train_loss: 0.022230 kl_loss: 0.204338 normal_loss: 0.016100\n",
      "[623/00074] train_loss: 0.022318 kl_loss: 0.204933 normal_loss: 0.016170\n",
      "[625/00024] train_loss: 0.022207 kl_loss: 0.204479 normal_loss: 0.016072\n",
      "[626/00049] train_loss: 0.022262 kl_loss: 0.204560 normal_loss: 0.016125\n",
      "[627/00074] train_loss: 0.022265 kl_loss: 0.204478 normal_loss: 0.016131\n",
      "[629/00024] train_loss: 0.022213 kl_loss: 0.203762 normal_loss: 0.016100\n",
      "[630/00049] train_loss: 0.022336 kl_loss: 0.205459 normal_loss: 0.016172\n",
      "[631/00074] train_loss: 0.022213 kl_loss: 0.204049 normal_loss: 0.016092\n",
      "[633/00024] train_loss: 0.022266 kl_loss: 0.204416 normal_loss: 0.016133\n",
      "[634/00049] train_loss: 0.022228 kl_loss: 0.204251 normal_loss: 0.016100\n",
      "[635/00074] train_loss: 0.022205 kl_loss: 0.204374 normal_loss: 0.016074\n",
      "[637/00024] train_loss: 0.022194 kl_loss: 0.203950 normal_loss: 0.016076\n",
      "[638/00049] train_loss: 0.022244 kl_loss: 0.204767 normal_loss: 0.016101\n",
      "[639/00074] train_loss: 0.022228 kl_loss: 0.204066 normal_loss: 0.016106\n",
      "[641/00024] train_loss: 0.022181 kl_loss: 0.204110 normal_loss: 0.016057\n",
      "[642/00049] train_loss: 0.022212 kl_loss: 0.204162 normal_loss: 0.016087\n",
      "[643/00074] train_loss: 0.022199 kl_loss: 0.204268 normal_loss: 0.016071\n",
      "[645/00024] train_loss: 0.022222 kl_loss: 0.203984 normal_loss: 0.016103\n",
      "[646/00049] train_loss: 0.022185 kl_loss: 0.204066 normal_loss: 0.016063\n",
      "[647/00074] train_loss: 0.022256 kl_loss: 0.204240 normal_loss: 0.016128\n",
      "[649/00024] train_loss: 0.022205 kl_loss: 0.204296 normal_loss: 0.016077\n",
      "[649/00074] MMD 0.005192305892705917\n",
      "[649/00074] TMD 0.06799919903278351\n",
      "[650/00049] train_loss: 0.022180 kl_loss: 0.203593 normal_loss: 0.016072\n",
      "[651/00074] train_loss: 0.022237 kl_loss: 0.204157 normal_loss: 0.016113\n",
      "[653/00024] train_loss: 0.022243 kl_loss: 0.203871 normal_loss: 0.016127\n",
      "[654/00049] train_loss: 0.022104 kl_loss: 0.203224 normal_loss: 0.016007\n",
      "[655/00074] train_loss: 0.022348 kl_loss: 0.204728 normal_loss: 0.016206\n",
      "[657/00024] train_loss: 0.022193 kl_loss: 0.203762 normal_loss: 0.016080\n",
      "[658/00049] train_loss: 0.022295 kl_loss: 0.204075 normal_loss: 0.016173\n",
      "[659/00074] train_loss: 0.022138 kl_loss: 0.203763 normal_loss: 0.016025\n",
      "[661/00024] train_loss: 0.022196 kl_loss: 0.204283 normal_loss: 0.016068\n",
      "[662/00049] train_loss: 0.022143 kl_loss: 0.203469 normal_loss: 0.016039\n",
      "[663/00074] train_loss: 0.022200 kl_loss: 0.203609 normal_loss: 0.016091\n",
      "[665/00024] train_loss: 0.022189 kl_loss: 0.203729 normal_loss: 0.016077\n",
      "[666/00049] train_loss: 0.022091 kl_loss: 0.203541 normal_loss: 0.015984\n",
      "[667/00074] train_loss: 0.022223 kl_loss: 0.203861 normal_loss: 0.016107\n",
      "[669/00024] train_loss: 0.022076 kl_loss: 0.203469 normal_loss: 0.015972\n",
      "[670/00049] train_loss: 0.022268 kl_loss: 0.204141 normal_loss: 0.016144\n",
      "[671/00074] train_loss: 0.022131 kl_loss: 0.203283 normal_loss: 0.016032\n",
      "[673/00024] train_loss: 0.022160 kl_loss: 0.203601 normal_loss: 0.016052\n",
      "[674/00049] train_loss: 0.022089 kl_loss: 0.203109 normal_loss: 0.015996\n",
      "[675/00074] train_loss: 0.022189 kl_loss: 0.203944 normal_loss: 0.016071\n",
      "[677/00024] train_loss: 0.022122 kl_loss: 0.203325 normal_loss: 0.016023\n",
      "[678/00049] train_loss: 0.022180 kl_loss: 0.203514 normal_loss: 0.016074\n",
      "[679/00074] train_loss: 0.022118 kl_loss: 0.203563 normal_loss: 0.016011\n",
      "[681/00024] train_loss: 0.022178 kl_loss: 0.203405 normal_loss: 0.016076\n",
      "[682/00049] train_loss: 0.022078 kl_loss: 0.203112 normal_loss: 0.015984\n",
      "[683/00074] train_loss: 0.022219 kl_loss: 0.203660 normal_loss: 0.016109\n",
      "[685/00024] train_loss: 0.022112 kl_loss: 0.203653 normal_loss: 0.016002\n",
      "[686/00049] train_loss: 0.022047 kl_loss: 0.202901 normal_loss: 0.015960\n",
      "[687/00074] train_loss: 0.022118 kl_loss: 0.203396 normal_loss: 0.016016\n",
      "[689/00024] train_loss: 0.022083 kl_loss: 0.202816 normal_loss: 0.015999\n",
      "[690/00049] train_loss: 0.022148 kl_loss: 0.203847 normal_loss: 0.016032\n",
      "[691/00074] train_loss: 0.022152 kl_loss: 0.203056 normal_loss: 0.016060\n",
      "[693/00024] train_loss: 0.022081 kl_loss: 0.203301 normal_loss: 0.015981\n",
      "[694/00049] train_loss: 0.022200 kl_loss: 0.203393 normal_loss: 0.016099\n",
      "[695/00074] train_loss: 0.022082 kl_loss: 0.202784 normal_loss: 0.015998\n",
      "[697/00024] train_loss: 0.022099 kl_loss: 0.203148 normal_loss: 0.016004\n",
      "[698/00049] train_loss: 0.022122 kl_loss: 0.203207 normal_loss: 0.016026\n",
      "[699/00000] updated kl_weight: 0.03\n",
      "[699/00001] updated kl_weight: 0.03\n",
      "[699/00002] updated kl_weight: 0.03\n",
      "[699/00003] updated kl_weight: 0.03\n",
      "[699/00004] updated kl_weight: 0.03\n",
      "[699/00005] updated kl_weight: 0.03\n",
      "[699/00006] updated kl_weight: 0.03\n",
      "[699/00007] updated kl_weight: 0.03\n",
      "[699/00008] updated kl_weight: 0.03\n",
      "[699/00009] updated kl_weight: 0.03\n",
      "[699/00010] updated kl_weight: 0.03\n",
      "[699/00011] updated kl_weight: 0.03\n",
      "[699/00012] updated kl_weight: 0.03\n",
      "[699/00013] updated kl_weight: 0.03\n",
      "[699/00014] updated kl_weight: 0.03\n",
      "[699/00015] updated kl_weight: 0.03\n",
      "[699/00016] updated kl_weight: 0.03\n",
      "[699/00017] updated kl_weight: 0.03\n",
      "[699/00018] updated kl_weight: 0.03\n",
      "[699/00019] updated kl_weight: 0.03\n",
      "[699/00020] updated kl_weight: 0.03\n",
      "[699/00021] updated kl_weight: 0.03\n",
      "[699/00022] updated kl_weight: 0.03\n",
      "[699/00023] updated kl_weight: 0.03\n",
      "[699/00024] updated kl_weight: 0.03\n",
      "[699/00025] updated kl_weight: 0.03\n",
      "[699/00026] updated kl_weight: 0.03\n",
      "[699/00027] updated kl_weight: 0.03\n",
      "[699/00028] updated kl_weight: 0.03\n",
      "[699/00029] updated kl_weight: 0.03\n",
      "[699/00030] updated kl_weight: 0.03\n",
      "[699/00031] updated kl_weight: 0.03\n",
      "[699/00032] updated kl_weight: 0.03\n",
      "[699/00033] updated kl_weight: 0.03\n",
      "[699/00034] updated kl_weight: 0.03\n",
      "[699/00035] updated kl_weight: 0.03\n",
      "[699/00036] updated kl_weight: 0.03\n",
      "[699/00037] updated kl_weight: 0.03\n",
      "[699/00038] updated kl_weight: 0.03\n",
      "[699/00039] updated kl_weight: 0.03\n",
      "[699/00040] updated kl_weight: 0.03\n",
      "[699/00041] updated kl_weight: 0.03\n",
      "[699/00042] updated kl_weight: 0.03\n",
      "[699/00043] updated kl_weight: 0.03\n",
      "[699/00044] updated kl_weight: 0.03\n",
      "[699/00045] updated kl_weight: 0.03\n",
      "[699/00046] updated kl_weight: 0.03\n",
      "[699/00047] updated kl_weight: 0.03\n",
      "[699/00048] updated kl_weight: 0.03\n",
      "[699/00049] updated kl_weight: 0.03\n",
      "[699/00050] updated kl_weight: 0.03\n",
      "[699/00051] updated kl_weight: 0.03\n",
      "[699/00052] updated kl_weight: 0.03\n",
      "[699/00053] updated kl_weight: 0.03\n",
      "[699/00054] updated kl_weight: 0.03\n",
      "[699/00055] updated kl_weight: 0.03\n",
      "[699/00056] updated kl_weight: 0.03\n",
      "[699/00057] updated kl_weight: 0.03\n",
      "[699/00058] updated kl_weight: 0.03\n",
      "[699/00059] updated kl_weight: 0.03\n",
      "[699/00060] updated kl_weight: 0.03\n",
      "[699/00061] updated kl_weight: 0.03\n",
      "[699/00062] updated kl_weight: 0.03\n",
      "[699/00063] updated kl_weight: 0.03\n",
      "[699/00064] updated kl_weight: 0.03\n",
      "[699/00065] updated kl_weight: 0.03\n",
      "[699/00066] updated kl_weight: 0.03\n",
      "[699/00067] updated kl_weight: 0.03\n",
      "[699/00068] updated kl_weight: 0.03\n",
      "[699/00069] updated kl_weight: 0.03\n",
      "[699/00070] updated kl_weight: 0.03\n",
      "[699/00071] updated kl_weight: 0.03\n",
      "[699/00072] updated kl_weight: 0.03\n",
      "[699/00073] updated kl_weight: 0.03\n",
      "[699/00074] updated kl_weight: 0.03\n",
      "[699/00074] train_loss: 0.022057 kl_loss: 0.202884 normal_loss: 0.015971\n",
      "[699/00074] MMD 0.005001270677894354\n",
      "[699/00074] TMD 0.06325970590114594\n",
      "[701/00024] train_loss: 0.022127 kl_loss: 0.203467 normal_loss: 0.016023\n",
      "[702/00049] train_loss: 0.022055 kl_loss: 0.202846 normal_loss: 0.015969\n",
      "[703/00074] train_loss: 0.022049 kl_loss: 0.202736 normal_loss: 0.015967\n",
      "[705/00024] train_loss: 0.022067 kl_loss: 0.202852 normal_loss: 0.015982\n",
      "[706/00049] train_loss: 0.022095 kl_loss: 0.203414 normal_loss: 0.015993\n",
      "[707/00074] train_loss: 0.022004 kl_loss: 0.202667 normal_loss: 0.015924\n",
      "[709/00024] train_loss: 0.022072 kl_loss: 0.202780 normal_loss: 0.015988\n",
      "[710/00049] train_loss: 0.022031 kl_loss: 0.203042 normal_loss: 0.015940\n",
      "[711/00074] train_loss: 0.022080 kl_loss: 0.202988 normal_loss: 0.015990\n",
      "[713/00024] train_loss: 0.022138 kl_loss: 0.203468 normal_loss: 0.016034\n",
      "[714/00049] train_loss: 0.021956 kl_loss: 0.202012 normal_loss: 0.015895\n",
      "[715/00074] train_loss: 0.022131 kl_loss: 0.203216 normal_loss: 0.016035\n",
      "[717/00024] train_loss: 0.022123 kl_loss: 0.203344 normal_loss: 0.016023\n",
      "[718/00049] train_loss: 0.022004 kl_loss: 0.202620 normal_loss: 0.015925\n",
      "[719/00074] train_loss: 0.022038 kl_loss: 0.202620 normal_loss: 0.015959\n",
      "[721/00024] train_loss: 0.022101 kl_loss: 0.203147 normal_loss: 0.016007\n",
      "[722/00049] train_loss: 0.021973 kl_loss: 0.202135 normal_loss: 0.015909\n",
      "[723/00074] train_loss: 0.022141 kl_loss: 0.203182 normal_loss: 0.016046\n",
      "[725/00024] train_loss: 0.022009 kl_loss: 0.202902 normal_loss: 0.015922\n",
      "[726/00049] train_loss: 0.022068 kl_loss: 0.202685 normal_loss: 0.015988\n",
      "[727/00074] train_loss: 0.022074 kl_loss: 0.202760 normal_loss: 0.015991\n",
      "[729/00024] train_loss: 0.022001 kl_loss: 0.202411 normal_loss: 0.015929\n",
      "[730/00049] train_loss: 0.022086 kl_loss: 0.203169 normal_loss: 0.015991\n",
      "[731/00074] train_loss: 0.022086 kl_loss: 0.202648 normal_loss: 0.016006\n",
      "[733/00024] train_loss: 0.022061 kl_loss: 0.203002 normal_loss: 0.015971\n",
      "[734/00049] train_loss: 0.022074 kl_loss: 0.202743 normal_loss: 0.015992\n",
      "[735/00074] train_loss: 0.021939 kl_loss: 0.202375 normal_loss: 0.015868\n",
      "[737/00024] train_loss: 0.022015 kl_loss: 0.202471 normal_loss: 0.015941\n",
      "[738/00049] train_loss: 0.022035 kl_loss: 0.202680 normal_loss: 0.015955\n",
      "[739/00074] train_loss: 0.022021 kl_loss: 0.202854 normal_loss: 0.015936\n",
      "[741/00024] train_loss: 0.022108 kl_loss: 0.202836 normal_loss: 0.016023\n",
      "[742/00049] train_loss: 0.022020 kl_loss: 0.202810 normal_loss: 0.015935\n",
      "[743/00074] train_loss: 0.021968 kl_loss: 0.202241 normal_loss: 0.015901\n",
      "[745/00024] train_loss: 0.022050 kl_loss: 0.202787 normal_loss: 0.015967\n",
      "[746/00049] train_loss: 0.021949 kl_loss: 0.202075 normal_loss: 0.015887\n",
      "[747/00074] train_loss: 0.022064 kl_loss: 0.202908 normal_loss: 0.015977\n",
      "[749/00024] train_loss: 0.022053 kl_loss: 0.202603 normal_loss: 0.015975\n",
      "[749/00074] MMD 0.004948913585394621\n",
      "[749/00074] TMD 0.05819888412952423\n",
      "[750/00049] train_loss: 0.021989 kl_loss: 0.202695 normal_loss: 0.015908\n",
      "[751/00074] train_loss: 0.022007 kl_loss: 0.202355 normal_loss: 0.015937\n",
      "[753/00024] train_loss: 0.021970 kl_loss: 0.202091 normal_loss: 0.015907\n",
      "[754/00049] train_loss: 0.022007 kl_loss: 0.202887 normal_loss: 0.015921\n",
      "[755/00074] train_loss: 0.022061 kl_loss: 0.202551 normal_loss: 0.015984\n",
      "[757/00024] train_loss: 0.022006 kl_loss: 0.202480 normal_loss: 0.015932\n",
      "[758/00049] train_loss: 0.022066 kl_loss: 0.202428 normal_loss: 0.015993\n",
      "[759/00074] train_loss: 0.022000 kl_loss: 0.202502 normal_loss: 0.015925\n",
      "[761/00024] train_loss: 0.021999 kl_loss: 0.202739 normal_loss: 0.015916\n",
      "[762/00049] train_loss: 0.021986 kl_loss: 0.202241 normal_loss: 0.015919\n",
      "[763/00074] train_loss: 0.021991 kl_loss: 0.202313 normal_loss: 0.015921\n",
      "[765/00024] train_loss: 0.022051 kl_loss: 0.202509 normal_loss: 0.015976\n",
      "[766/00049] train_loss: 0.022025 kl_loss: 0.202517 normal_loss: 0.015950\n",
      "[767/00074] train_loss: 0.021934 kl_loss: 0.202149 normal_loss: 0.015870\n",
      "[769/00024] train_loss: 0.022048 kl_loss: 0.202349 normal_loss: 0.015977\n",
      "[770/00049] train_loss: 0.021901 kl_loss: 0.202047 normal_loss: 0.015840\n",
      "[771/00074] train_loss: 0.021988 kl_loss: 0.202668 normal_loss: 0.015908\n",
      "[773/00024] train_loss: 0.022013 kl_loss: 0.202478 normal_loss: 0.015939\n",
      "[774/00049] train_loss: 0.021952 kl_loss: 0.202321 normal_loss: 0.015882\n",
      "[775/00074] train_loss: 0.022018 kl_loss: 0.202146 normal_loss: 0.015953\n",
      "[777/00024] train_loss: 0.021945 kl_loss: 0.202060 normal_loss: 0.015883\n",
      "[778/00049] train_loss: 0.022059 kl_loss: 0.202393 normal_loss: 0.015987\n",
      "[779/00074] train_loss: 0.022021 kl_loss: 0.202381 normal_loss: 0.015949\n",
      "[781/00024] train_loss: 0.021903 kl_loss: 0.201908 normal_loss: 0.015846\n",
      "[782/00049] train_loss: 0.021987 kl_loss: 0.202345 normal_loss: 0.015916\n",
      "[783/00074] train_loss: 0.021981 kl_loss: 0.202472 normal_loss: 0.015907\n",
      "[785/00024] train_loss: 0.022022 kl_loss: 0.202538 normal_loss: 0.015946\n",
      "[786/00049] train_loss: 0.021880 kl_loss: 0.201999 normal_loss: 0.015820\n",
      "[787/00074] train_loss: 0.021948 kl_loss: 0.202071 normal_loss: 0.015886\n",
      "[789/00024] train_loss: 0.021946 kl_loss: 0.202111 normal_loss: 0.015883\n",
      "[790/00049] train_loss: 0.021921 kl_loss: 0.201821 normal_loss: 0.015866\n",
      "[791/00074] train_loss: 0.022034 kl_loss: 0.202556 normal_loss: 0.015958\n",
      "[793/00024] train_loss: 0.022012 kl_loss: 0.202303 normal_loss: 0.015943\n",
      "[794/00049] train_loss: 0.021940 kl_loss: 0.202059 normal_loss: 0.015878\n",
      "[795/00074] train_loss: 0.021914 kl_loss: 0.202014 normal_loss: 0.015853\n",
      "[797/00024] train_loss: 0.021930 kl_loss: 0.201999 normal_loss: 0.015870\n",
      "[798/00049] train_loss: 0.021970 kl_loss: 0.202173 normal_loss: 0.015904\n",
      "[799/00000] updated kl_weight: 0.03\n",
      "[799/00001] updated kl_weight: 0.03\n",
      "[799/00002] updated kl_weight: 0.03\n",
      "[799/00003] updated kl_weight: 0.03\n",
      "[799/00004] updated kl_weight: 0.03\n",
      "[799/00005] updated kl_weight: 0.03\n",
      "[799/00006] updated kl_weight: 0.03\n",
      "[799/00007] updated kl_weight: 0.03\n",
      "[799/00008] updated kl_weight: 0.03\n",
      "[799/00009] updated kl_weight: 0.03\n",
      "[799/00010] updated kl_weight: 0.03\n",
      "[799/00011] updated kl_weight: 0.03\n",
      "[799/00012] updated kl_weight: 0.03\n",
      "[799/00013] updated kl_weight: 0.03\n",
      "[799/00014] updated kl_weight: 0.03\n",
      "[799/00015] updated kl_weight: 0.03\n",
      "[799/00016] updated kl_weight: 0.03\n",
      "[799/00017] updated kl_weight: 0.03\n",
      "[799/00018] updated kl_weight: 0.03\n",
      "[799/00019] updated kl_weight: 0.03\n",
      "[799/00020] updated kl_weight: 0.03\n",
      "[799/00021] updated kl_weight: 0.03\n",
      "[799/00022] updated kl_weight: 0.03\n",
      "[799/00023] updated kl_weight: 0.03\n",
      "[799/00024] updated kl_weight: 0.03\n",
      "[799/00025] updated kl_weight: 0.03\n",
      "[799/00026] updated kl_weight: 0.03\n",
      "[799/00027] updated kl_weight: 0.03\n",
      "[799/00028] updated kl_weight: 0.03\n",
      "[799/00029] updated kl_weight: 0.03\n",
      "[799/00030] updated kl_weight: 0.03\n",
      "[799/00031] updated kl_weight: 0.03\n",
      "[799/00032] updated kl_weight: 0.03\n",
      "[799/00033] updated kl_weight: 0.03\n",
      "[799/00034] updated kl_weight: 0.03\n",
      "[799/00035] updated kl_weight: 0.03\n",
      "[799/00036] updated kl_weight: 0.03\n",
      "[799/00037] updated kl_weight: 0.03\n",
      "[799/00038] updated kl_weight: 0.03\n",
      "[799/00039] updated kl_weight: 0.03\n",
      "[799/00040] updated kl_weight: 0.03\n",
      "[799/00041] updated kl_weight: 0.03\n",
      "[799/00042] updated kl_weight: 0.03\n",
      "[799/00043] updated kl_weight: 0.03\n",
      "[799/00044] updated kl_weight: 0.03\n",
      "[799/00045] updated kl_weight: 0.03\n",
      "[799/00046] updated kl_weight: 0.03\n",
      "[799/00047] updated kl_weight: 0.03\n",
      "[799/00048] updated kl_weight: 0.03\n",
      "[799/00049] updated kl_weight: 0.03\n",
      "[799/00050] updated kl_weight: 0.03\n",
      "[799/00051] updated kl_weight: 0.03\n",
      "[799/00052] updated kl_weight: 0.03\n",
      "[799/00053] updated kl_weight: 0.03\n",
      "[799/00054] updated kl_weight: 0.03\n",
      "[799/00055] updated kl_weight: 0.03\n",
      "[799/00056] updated kl_weight: 0.03\n",
      "[799/00057] updated kl_weight: 0.03\n",
      "[799/00058] updated kl_weight: 0.03\n",
      "[799/00059] updated kl_weight: 0.03\n",
      "[799/00060] updated kl_weight: 0.03\n",
      "[799/00061] updated kl_weight: 0.03\n",
      "[799/00062] updated kl_weight: 0.03\n",
      "[799/00063] updated kl_weight: 0.03\n",
      "[799/00064] updated kl_weight: 0.03\n",
      "[799/00065] updated kl_weight: 0.03\n",
      "[799/00066] updated kl_weight: 0.03\n",
      "[799/00067] updated kl_weight: 0.03\n",
      "[799/00068] updated kl_weight: 0.03\n",
      "[799/00069] updated kl_weight: 0.03\n",
      "[799/00070] updated kl_weight: 0.03\n",
      "[799/00071] updated kl_weight: 0.03\n",
      "[799/00072] updated kl_weight: 0.03\n",
      "[799/00073] updated kl_weight: 0.03\n",
      "[799/00074] updated kl_weight: 0.03\n",
      "[799/00074] train_loss: 0.021928 kl_loss: 0.202086 normal_loss: 0.015866\n",
      "[799/00074] MMD 0.0052238330245018005\n",
      "[799/00074] TMD 0.06622792780399323\n",
      "[801/00024] train_loss: 0.021970 kl_loss: 0.202201 normal_loss: 0.015904\n",
      "[802/00049] train_loss: 0.021913 kl_loss: 0.201886 normal_loss: 0.015856\n",
      "[803/00074] train_loss: 0.021924 kl_loss: 0.202068 normal_loss: 0.015862\n",
      "[805/00024] train_loss: 0.021951 kl_loss: 0.201995 normal_loss: 0.015891\n",
      "[806/00049] train_loss: 0.021887 kl_loss: 0.201945 normal_loss: 0.015828\n",
      "[807/00074] train_loss: 0.021950 kl_loss: 0.202154 normal_loss: 0.015885\n",
      "[809/00024] train_loss: 0.021902 kl_loss: 0.201985 normal_loss: 0.015842\n",
      "[810/00049] train_loss: 0.022017 kl_loss: 0.202485 normal_loss: 0.015942\n",
      "[811/00074] train_loss: 0.021891 kl_loss: 0.201562 normal_loss: 0.015844\n",
      "[813/00024] train_loss: 0.021887 kl_loss: 0.201796 normal_loss: 0.015833\n",
      "[814/00049] train_loss: 0.022067 kl_loss: 0.202740 normal_loss: 0.015984\n",
      "[815/00074] train_loss: 0.021890 kl_loss: 0.201439 normal_loss: 0.015847\n",
      "[817/00024] train_loss: 0.021879 kl_loss: 0.202061 normal_loss: 0.015817\n",
      "[818/00049] train_loss: 0.021873 kl_loss: 0.201554 normal_loss: 0.015826\n",
      "[819/00074] train_loss: 0.021987 kl_loss: 0.202300 normal_loss: 0.015918\n",
      "[821/00024] train_loss: 0.021986 kl_loss: 0.201943 normal_loss: 0.015928\n",
      "[822/00049] train_loss: 0.021957 kl_loss: 0.202103 normal_loss: 0.015894\n",
      "[823/00074] train_loss: 0.021916 kl_loss: 0.201811 normal_loss: 0.015861\n",
      "[825/00024] train_loss: 0.021961 kl_loss: 0.202127 normal_loss: 0.015897\n",
      "[826/00049] train_loss: 0.021953 kl_loss: 0.202250 normal_loss: 0.015886\n",
      "[827/00074] train_loss: 0.021861 kl_loss: 0.201425 normal_loss: 0.015818\n",
      "[829/00024] train_loss: 0.021878 kl_loss: 0.201779 normal_loss: 0.015825\n",
      "[830/00049] train_loss: 0.022020 kl_loss: 0.202468 normal_loss: 0.015946\n",
      "[831/00074] train_loss: 0.021846 kl_loss: 0.201498 normal_loss: 0.015801\n",
      "[833/00024] train_loss: 0.021977 kl_loss: 0.202385 normal_loss: 0.015906\n",
      "[834/00049] train_loss: 0.021802 kl_loss: 0.201659 normal_loss: 0.015752\n",
      "[835/00074] train_loss: 0.021874 kl_loss: 0.201637 normal_loss: 0.015825\n",
      "[837/00024] train_loss: 0.021875 kl_loss: 0.201597 normal_loss: 0.015827\n",
      "[838/00049] train_loss: 0.021939 kl_loss: 0.202304 normal_loss: 0.015870\n",
      "[839/00074] train_loss: 0.021916 kl_loss: 0.201716 normal_loss: 0.015865\n",
      "[841/00024] train_loss: 0.021913 kl_loss: 0.201639 normal_loss: 0.015864\n",
      "[842/00049] train_loss: 0.021915 kl_loss: 0.201921 normal_loss: 0.015857\n",
      "[843/00074] train_loss: 0.021927 kl_loss: 0.201995 normal_loss: 0.015867\n",
      "[845/00024] train_loss: 0.021888 kl_loss: 0.201575 normal_loss: 0.015840\n",
      "[846/00049] train_loss: 0.021929 kl_loss: 0.202059 normal_loss: 0.015867\n",
      "[847/00074] train_loss: 0.021872 kl_loss: 0.201862 normal_loss: 0.015816\n",
      "[849/00024] train_loss: 0.021898 kl_loss: 0.202158 normal_loss: 0.015834\n",
      "[849/00074] MMD 0.0049630519933998585\n",
      "[849/00074] TMD 0.07152298837900162\n",
      "[850/00049] train_loss: 0.021815 kl_loss: 0.201062 normal_loss: 0.015783\n",
      "[851/00074] train_loss: 0.022000 kl_loss: 0.202211 normal_loss: 0.015933\n",
      "[853/00024] train_loss: 0.021930 kl_loss: 0.202043 normal_loss: 0.015869\n",
      "[854/00049] train_loss: 0.021954 kl_loss: 0.201693 normal_loss: 0.015903\n",
      "[855/00074] train_loss: 0.021883 kl_loss: 0.201637 normal_loss: 0.015834\n",
      "[857/00024] train_loss: 0.021923 kl_loss: 0.201800 normal_loss: 0.015869\n",
      "[858/00049] train_loss: 0.021937 kl_loss: 0.201836 normal_loss: 0.015882\n",
      "[859/00074] train_loss: 0.021867 kl_loss: 0.201683 normal_loss: 0.015816\n",
      "[861/00024] train_loss: 0.021853 kl_loss: 0.201496 normal_loss: 0.015809\n",
      "[862/00049] train_loss: 0.022010 kl_loss: 0.202669 normal_loss: 0.015930\n",
      "[863/00074] train_loss: 0.021797 kl_loss: 0.201096 normal_loss: 0.015764\n",
      "[865/00024] train_loss: 0.021889 kl_loss: 0.201775 normal_loss: 0.015836\n",
      "[866/00049] train_loss: 0.021965 kl_loss: 0.201991 normal_loss: 0.015905\n",
      "[867/00074] train_loss: 0.021822 kl_loss: 0.201433 normal_loss: 0.015779\n",
      "[869/00024] train_loss: 0.021860 kl_loss: 0.201323 normal_loss: 0.015821\n",
      "[870/00049] train_loss: 0.021915 kl_loss: 0.201836 normal_loss: 0.015860\n",
      "[871/00074] train_loss: 0.021927 kl_loss: 0.201980 normal_loss: 0.015867\n",
      "[873/00024] train_loss: 0.021836 kl_loss: 0.201324 normal_loss: 0.015796\n",
      "[874/00049] train_loss: 0.022019 kl_loss: 0.202694 normal_loss: 0.015938\n",
      "[875/00074] train_loss: 0.021856 kl_loss: 0.201063 normal_loss: 0.015824\n",
      "[877/00024] train_loss: 0.021907 kl_loss: 0.201991 normal_loss: 0.015847\n",
      "[878/00049] train_loss: 0.021871 kl_loss: 0.201334 normal_loss: 0.015831\n",
      "[879/00074] train_loss: 0.021895 kl_loss: 0.201696 normal_loss: 0.015844\n",
      "[881/00024] train_loss: 0.021875 kl_loss: 0.201576 normal_loss: 0.015828\n",
      "[882/00049] train_loss: 0.021969 kl_loss: 0.201948 normal_loss: 0.015910\n",
      "[883/00074] train_loss: 0.021863 kl_loss: 0.201439 normal_loss: 0.015820\n",
      "[885/00024] train_loss: 0.021900 kl_loss: 0.201873 normal_loss: 0.015843\n",
      "[886/00049] train_loss: 0.021917 kl_loss: 0.201452 normal_loss: 0.015874\n",
      "[887/00074] train_loss: 0.021844 kl_loss: 0.201578 normal_loss: 0.015796\n",
      "[889/00024] train_loss: 0.021813 kl_loss: 0.201035 normal_loss: 0.015782\n",
      "[890/00049] train_loss: 0.021958 kl_loss: 0.202160 normal_loss: 0.015893\n",
      "[891/00074] train_loss: 0.021853 kl_loss: 0.201650 normal_loss: 0.015803\n",
      "[893/00024] train_loss: 0.021932 kl_loss: 0.201776 normal_loss: 0.015878\n",
      "[894/00049] train_loss: 0.021766 kl_loss: 0.200839 normal_loss: 0.015741\n",
      "[895/00074] train_loss: 0.021994 kl_loss: 0.202170 normal_loss: 0.015929\n",
      "[897/00024] train_loss: 0.021856 kl_loss: 0.201241 normal_loss: 0.015819\n",
      "[898/00049] train_loss: 0.021918 kl_loss: 0.201887 normal_loss: 0.015862\n",
      "[899/00000] updated kl_weight: 0.03\n",
      "[899/00001] updated kl_weight: 0.03\n",
      "[899/00002] updated kl_weight: 0.03\n",
      "[899/00003] updated kl_weight: 0.03\n",
      "[899/00004] updated kl_weight: 0.03\n",
      "[899/00005] updated kl_weight: 0.03\n",
      "[899/00006] updated kl_weight: 0.03\n",
      "[899/00007] updated kl_weight: 0.03\n",
      "[899/00008] updated kl_weight: 0.03\n",
      "[899/00009] updated kl_weight: 0.03\n",
      "[899/00010] updated kl_weight: 0.03\n",
      "[899/00011] updated kl_weight: 0.03\n",
      "[899/00012] updated kl_weight: 0.03\n",
      "[899/00013] updated kl_weight: 0.03\n",
      "[899/00014] updated kl_weight: 0.03\n",
      "[899/00015] updated kl_weight: 0.03\n",
      "[899/00016] updated kl_weight: 0.03\n",
      "[899/00017] updated kl_weight: 0.03\n",
      "[899/00018] updated kl_weight: 0.03\n",
      "[899/00019] updated kl_weight: 0.03\n",
      "[899/00020] updated kl_weight: 0.03\n",
      "[899/00021] updated kl_weight: 0.03\n",
      "[899/00022] updated kl_weight: 0.03\n",
      "[899/00023] updated kl_weight: 0.03\n",
      "[899/00024] updated kl_weight: 0.03\n",
      "[899/00025] updated kl_weight: 0.03\n",
      "[899/00026] updated kl_weight: 0.03\n",
      "[899/00027] updated kl_weight: 0.03\n",
      "[899/00028] updated kl_weight: 0.03\n",
      "[899/00029] updated kl_weight: 0.03\n",
      "[899/00030] updated kl_weight: 0.03\n",
      "[899/00031] updated kl_weight: 0.03\n",
      "[899/00032] updated kl_weight: 0.03\n",
      "[899/00033] updated kl_weight: 0.03\n",
      "[899/00034] updated kl_weight: 0.03\n",
      "[899/00035] updated kl_weight: 0.03\n",
      "[899/00036] updated kl_weight: 0.03\n",
      "[899/00037] updated kl_weight: 0.03\n",
      "[899/00038] updated kl_weight: 0.03\n",
      "[899/00039] updated kl_weight: 0.03\n",
      "[899/00040] updated kl_weight: 0.03\n",
      "[899/00041] updated kl_weight: 0.03\n",
      "[899/00042] updated kl_weight: 0.03\n",
      "[899/00043] updated kl_weight: 0.03\n",
      "[899/00044] updated kl_weight: 0.03\n",
      "[899/00045] updated kl_weight: 0.03\n",
      "[899/00046] updated kl_weight: 0.03\n",
      "[899/00047] updated kl_weight: 0.03\n",
      "[899/00048] updated kl_weight: 0.03\n",
      "[899/00049] updated kl_weight: 0.03\n",
      "[899/00050] updated kl_weight: 0.03\n",
      "[899/00051] updated kl_weight: 0.03\n",
      "[899/00052] updated kl_weight: 0.03\n",
      "[899/00053] updated kl_weight: 0.03\n",
      "[899/00054] updated kl_weight: 0.03\n",
      "[899/00055] updated kl_weight: 0.03\n",
      "[899/00056] updated kl_weight: 0.03\n",
      "[899/00057] updated kl_weight: 0.03\n",
      "[899/00058] updated kl_weight: 0.03\n",
      "[899/00059] updated kl_weight: 0.03\n",
      "[899/00060] updated kl_weight: 0.03\n",
      "[899/00061] updated kl_weight: 0.03\n",
      "[899/00062] updated kl_weight: 0.03\n",
      "[899/00063] updated kl_weight: 0.03\n",
      "[899/00064] updated kl_weight: 0.03\n",
      "[899/00065] updated kl_weight: 0.03\n",
      "[899/00066] updated kl_weight: 0.03\n",
      "[899/00067] updated kl_weight: 0.03\n",
      "[899/00068] updated kl_weight: 0.03\n",
      "[899/00069] updated kl_weight: 0.03\n",
      "[899/00070] updated kl_weight: 0.03\n",
      "[899/00071] updated kl_weight: 0.03\n",
      "[899/00072] updated kl_weight: 0.03\n",
      "[899/00073] updated kl_weight: 0.03\n",
      "[899/00074] updated kl_weight: 0.03\n",
      "[899/00074] train_loss: 0.021926 kl_loss: 0.201600 normal_loss: 0.015878\n",
      "[899/00074] MMD 0.005077994894236326\n",
      "[899/00074] TMD 0.058784738183021545\n",
      "[901/00024] train_loss: 0.021838 kl_loss: 0.201432 normal_loss: 0.015795\n",
      "[902/00049] train_loss: 0.021824 kl_loss: 0.201557 normal_loss: 0.015777\n",
      "[903/00074] train_loss: 0.021897 kl_loss: 0.201690 normal_loss: 0.015846\n",
      "[905/00024] train_loss: 0.021829 kl_loss: 0.201441 normal_loss: 0.015786\n",
      "[906/00049] train_loss: 0.021872 kl_loss: 0.201493 normal_loss: 0.015827\n",
      "[907/00074] train_loss: 0.021924 kl_loss: 0.201717 normal_loss: 0.015873\n",
      "[909/00024] train_loss: 0.021845 kl_loss: 0.201446 normal_loss: 0.015802\n",
      "[910/00049] train_loss: 0.021972 kl_loss: 0.202259 normal_loss: 0.015904\n",
      "[911/00074] train_loss: 0.021798 kl_loss: 0.200916 normal_loss: 0.015771\n",
      "[913/00024] train_loss: 0.021888 kl_loss: 0.201561 normal_loss: 0.015841\n",
      "[914/00049] train_loss: 0.021899 kl_loss: 0.201723 normal_loss: 0.015848\n",
      "[915/00074] train_loss: 0.021820 kl_loss: 0.201308 normal_loss: 0.015781\n",
      "[917/00024] train_loss: 0.021876 kl_loss: 0.201381 normal_loss: 0.015834\n",
      "[918/00049] train_loss: 0.021890 kl_loss: 0.201803 normal_loss: 0.015836\n",
      "[919/00074] train_loss: 0.021899 kl_loss: 0.201378 normal_loss: 0.015858\n",
      "[921/00024] train_loss: 0.021884 kl_loss: 0.201454 normal_loss: 0.015841\n",
      "[922/00049] train_loss: 0.021881 kl_loss: 0.201483 normal_loss: 0.015837\n",
      "[923/00074] train_loss: 0.021843 kl_loss: 0.201598 normal_loss: 0.015795\n",
      "[925/00024] train_loss: 0.021866 kl_loss: 0.201726 normal_loss: 0.015814\n",
      "[926/00049] train_loss: 0.021896 kl_loss: 0.201455 normal_loss: 0.015852\n",
      "[927/00074] train_loss: 0.021817 kl_loss: 0.201324 normal_loss: 0.015777\n",
      "[929/00024] train_loss: 0.021904 kl_loss: 0.201708 normal_loss: 0.015853\n",
      "[930/00049] train_loss: 0.021829 kl_loss: 0.201659 normal_loss: 0.015779\n",
      "[931/00074] train_loss: 0.021793 kl_loss: 0.201108 normal_loss: 0.015760\n",
      "[933/00024] train_loss: 0.021869 kl_loss: 0.201418 normal_loss: 0.015826\n",
      "[934/00049] train_loss: 0.021900 kl_loss: 0.201450 normal_loss: 0.015856\n",
      "[935/00074] train_loss: 0.021886 kl_loss: 0.201576 normal_loss: 0.015839\n",
      "[937/00024] train_loss: 0.021967 kl_loss: 0.201604 normal_loss: 0.015919\n",
      "[938/00049] train_loss: 0.021762 kl_loss: 0.201173 normal_loss: 0.015727\n",
      "[939/00074] train_loss: 0.021919 kl_loss: 0.201639 normal_loss: 0.015870\n",
      "[941/00024] train_loss: 0.021897 kl_loss: 0.202152 normal_loss: 0.015832\n",
      "[942/00049] train_loss: 0.021730 kl_loss: 0.200636 normal_loss: 0.015711\n",
      "[943/00074] train_loss: 0.021901 kl_loss: 0.201597 normal_loss: 0.015853\n",
      "[945/00024] train_loss: 0.021846 kl_loss: 0.201370 normal_loss: 0.015805\n",
      "[946/00049] train_loss: 0.021841 kl_loss: 0.201624 normal_loss: 0.015792\n",
      "[947/00074] train_loss: 0.021832 kl_loss: 0.201363 normal_loss: 0.015791\n",
      "[949/00024] train_loss: 0.021842 kl_loss: 0.201443 normal_loss: 0.015798\n",
      "[949/00074] MMD 0.005082705058157444\n",
      "[949/00074] TMD 0.06526490300893784\n",
      "[950/00049] train_loss: 0.021879 kl_loss: 0.201466 normal_loss: 0.015836\n",
      "[951/00074] train_loss: 0.021870 kl_loss: 0.201417 normal_loss: 0.015828\n",
      "[953/00024] train_loss: 0.021770 kl_loss: 0.200925 normal_loss: 0.015743\n",
      "[954/00049] train_loss: 0.021942 kl_loss: 0.201919 normal_loss: 0.015884\n",
      "[955/00074] train_loss: 0.021909 kl_loss: 0.201452 normal_loss: 0.015865\n",
      "[957/00024] train_loss: 0.021840 kl_loss: 0.201206 normal_loss: 0.015804\n",
      "[958/00049] train_loss: 0.021943 kl_loss: 0.201479 normal_loss: 0.015899\n",
      "[959/00074] train_loss: 0.021869 kl_loss: 0.201582 normal_loss: 0.015821\n",
      "[961/00024] train_loss: 0.021762 kl_loss: 0.201274 normal_loss: 0.015723\n",
      "[962/00049] train_loss: 0.021996 kl_loss: 0.201971 normal_loss: 0.015937\n",
      "[963/00074] train_loss: 0.021798 kl_loss: 0.200994 normal_loss: 0.015769\n",
      "[965/00024] train_loss: 0.021895 kl_loss: 0.201924 normal_loss: 0.015838\n",
      "[966/00049] train_loss: 0.021806 kl_loss: 0.200930 normal_loss: 0.015778\n",
      "[967/00074] train_loss: 0.021864 kl_loss: 0.201355 normal_loss: 0.015823\n",
      "[969/00024] train_loss: 0.021907 kl_loss: 0.201683 normal_loss: 0.015856\n",
      "[970/00049] train_loss: 0.021799 kl_loss: 0.201086 normal_loss: 0.015767\n",
      "[971/00074] train_loss: 0.021851 kl_loss: 0.201412 normal_loss: 0.015809\n",
      "[973/00024] train_loss: 0.021854 kl_loss: 0.201270 normal_loss: 0.015816\n",
      "[974/00049] train_loss: 0.021847 kl_loss: 0.201327 normal_loss: 0.015807\n",
      "[975/00074] train_loss: 0.021862 kl_loss: 0.201554 normal_loss: 0.015816\n",
      "[977/00024] train_loss: 0.021817 kl_loss: 0.201061 normal_loss: 0.015785\n",
      "[978/00049] train_loss: 0.021881 kl_loss: 0.201692 normal_loss: 0.015830\n",
      "[979/00074] train_loss: 0.021861 kl_loss: 0.201369 normal_loss: 0.015820\n",
      "[981/00024] train_loss: 0.021816 kl_loss: 0.201142 normal_loss: 0.015782\n",
      "[982/00049] train_loss: 0.021905 kl_loss: 0.201893 normal_loss: 0.015848\n",
      "[983/00074] train_loss: 0.021840 kl_loss: 0.201058 normal_loss: 0.015808\n",
      "[985/00024] train_loss: 0.021914 kl_loss: 0.201728 normal_loss: 0.015862\n",
      "[986/00049] train_loss: 0.021847 kl_loss: 0.201192 normal_loss: 0.015811\n",
      "[987/00074] train_loss: 0.021816 kl_loss: 0.201143 normal_loss: 0.015781\n",
      "[989/00024] train_loss: 0.021841 kl_loss: 0.201233 normal_loss: 0.015804\n",
      "[990/00049] train_loss: 0.021988 kl_loss: 0.201757 normal_loss: 0.015935\n",
      "[991/00074] train_loss: 0.021793 kl_loss: 0.201045 normal_loss: 0.015762\n",
      "[993/00024] train_loss: 0.021830 kl_loss: 0.201149 normal_loss: 0.015796\n",
      "[994/00049] train_loss: 0.021897 kl_loss: 0.201895 normal_loss: 0.015840\n",
      "[995/00074] train_loss: 0.021830 kl_loss: 0.200962 normal_loss: 0.015802\n",
      "[997/00024] train_loss: 0.021845 kl_loss: 0.201386 normal_loss: 0.015804\n",
      "[998/00049] train_loss: 0.021814 kl_loss: 0.201077 normal_loss: 0.015781\n",
      "[999/00000] updated kl_weight: 0.03\n",
      "[999/00001] updated kl_weight: 0.03\n",
      "[999/00002] updated kl_weight: 0.03\n",
      "[999/00003] updated kl_weight: 0.03\n",
      "[999/00004] updated kl_weight: 0.03\n",
      "[999/00005] updated kl_weight: 0.03\n",
      "[999/00006] updated kl_weight: 0.03\n",
      "[999/00007] updated kl_weight: 0.03\n",
      "[999/00008] updated kl_weight: 0.03\n",
      "[999/00009] updated kl_weight: 0.03\n",
      "[999/00010] updated kl_weight: 0.03\n",
      "[999/00011] updated kl_weight: 0.03\n",
      "[999/00012] updated kl_weight: 0.03\n",
      "[999/00013] updated kl_weight: 0.03\n",
      "[999/00014] updated kl_weight: 0.03\n",
      "[999/00015] updated kl_weight: 0.03\n",
      "[999/00016] updated kl_weight: 0.03\n",
      "[999/00017] updated kl_weight: 0.03\n",
      "[999/00018] updated kl_weight: 0.03\n",
      "[999/00019] updated kl_weight: 0.03\n",
      "[999/00020] updated kl_weight: 0.03\n",
      "[999/00021] updated kl_weight: 0.03\n",
      "[999/00022] updated kl_weight: 0.03\n",
      "[999/00023] updated kl_weight: 0.03\n",
      "[999/00024] updated kl_weight: 0.03\n",
      "[999/00025] updated kl_weight: 0.03\n",
      "[999/00026] updated kl_weight: 0.03\n",
      "[999/00027] updated kl_weight: 0.03\n",
      "[999/00028] updated kl_weight: 0.03\n",
      "[999/00029] updated kl_weight: 0.03\n",
      "[999/00030] updated kl_weight: 0.03\n",
      "[999/00031] updated kl_weight: 0.03\n",
      "[999/00032] updated kl_weight: 0.03\n",
      "[999/00033] updated kl_weight: 0.03\n",
      "[999/00034] updated kl_weight: 0.03\n",
      "[999/00035] updated kl_weight: 0.03\n",
      "[999/00036] updated kl_weight: 0.03\n",
      "[999/00037] updated kl_weight: 0.03\n",
      "[999/00038] updated kl_weight: 0.03\n",
      "[999/00039] updated kl_weight: 0.03\n",
      "[999/00040] updated kl_weight: 0.03\n",
      "[999/00041] updated kl_weight: 0.03\n",
      "[999/00042] updated kl_weight: 0.03\n",
      "[999/00043] updated kl_weight: 0.03\n",
      "[999/00044] updated kl_weight: 0.03\n",
      "[999/00045] updated kl_weight: 0.03\n",
      "[999/00046] updated kl_weight: 0.03\n",
      "[999/00047] updated kl_weight: 0.03\n",
      "[999/00048] updated kl_weight: 0.03\n",
      "[999/00049] updated kl_weight: 0.03\n",
      "[999/00050] updated kl_weight: 0.03\n",
      "[999/00051] updated kl_weight: 0.03\n",
      "[999/00052] updated kl_weight: 0.03\n",
      "[999/00053] updated kl_weight: 0.03\n",
      "[999/00054] updated kl_weight: 0.03\n",
      "[999/00055] updated kl_weight: 0.03\n",
      "[999/00056] updated kl_weight: 0.03\n",
      "[999/00057] updated kl_weight: 0.03\n",
      "[999/00058] updated kl_weight: 0.03\n",
      "[999/00059] updated kl_weight: 0.03\n",
      "[999/00060] updated kl_weight: 0.03\n",
      "[999/00061] updated kl_weight: 0.03\n",
      "[999/00062] updated kl_weight: 0.03\n",
      "[999/00063] updated kl_weight: 0.03\n",
      "[999/00064] updated kl_weight: 0.03\n",
      "[999/00065] updated kl_weight: 0.03\n",
      "[999/00066] updated kl_weight: 0.03\n",
      "[999/00067] updated kl_weight: 0.03\n",
      "[999/00068] updated kl_weight: 0.03\n",
      "[999/00069] updated kl_weight: 0.03\n",
      "[999/00070] updated kl_weight: 0.03\n",
      "[999/00071] updated kl_weight: 0.03\n",
      "[999/00072] updated kl_weight: 0.03\n",
      "[999/00073] updated kl_weight: 0.03\n",
      "[999/00074] updated kl_weight: 0.03\n",
      "[999/00074] train_loss: 0.021876 kl_loss: 0.201513 normal_loss: 0.015830\n",
      "[999/00074] MMD 0.005058863200247288\n",
      "[999/00074] TMD 0.06404420733451843\n"
     ]
    }
   ],
   "source": [
    "# CHAIR VAD\n",
    "from scripts import train\n",
    "config = {\n",
    "    'experiment_name': 'chair_vad',\n",
    "    'device': 'cuda:0',\n",
    "    'is_overfit': False,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate_model': 0.01,\n",
    "    'learning_rate_code': 0.01,\n",
    "    'learning_rate_log_var':0.01,\n",
    "    'max_epochs': 1000,\n",
    "    'print_every_n': 100,\n",
    "    'latent_code_length' : 256,\n",
    "    'scheduler_step_size': 100,\n",
    "    'vad_free' : True,\n",
    "    'test': False,\n",
    "    'kl_weight': 0.03,\n",
    "    'kl_weight_increase_every_epochs': 100,\n",
    "    'kl_weight_increase_value': 0.0,\n",
    "    'mmd_every_epoch': 50,\n",
    "    'tmd_every_epoch': 50,\n",
    "    'iou_every_epoch': 10,\n",
    "    'resume_ckpt': None,\n",
    "    'filter_class': 'chair',\n",
    "    'decoder_var' : True\n",
    "}\n",
    "train.main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Data length 4800\n",
      "Training params: 3\n",
      "[001/00024] train_loss: 0.191461 kl_loss: 0.489047 normal_loss: 0.167009\n",
      "[002/00049] train_loss: 0.140902 kl_loss: 0.431867 normal_loss: 0.119309\n",
      "[003/00074] train_loss: 0.134114 kl_loss: 0.373703 normal_loss: 0.115429\n",
      "[005/00024] train_loss: 0.127796 kl_loss: 0.320461 normal_loss: 0.111773\n",
      "[006/00049] train_loss: 0.126211 kl_loss: 0.293880 normal_loss: 0.111517\n",
      "[007/00074] train_loss: 0.120764 kl_loss: 0.279733 normal_loss: 0.106777\n",
      "[009/00024] train_loss: 0.115604 kl_loss: 0.259998 normal_loss: 0.102604\n",
      "[010/00049] train_loss: 0.110620 kl_loss: 0.244606 normal_loss: 0.098390\n",
      "[011/00074] train_loss: 0.108912 kl_loss: 0.229203 normal_loss: 0.097452\n",
      "[013/00024] train_loss: 0.105591 kl_loss: 0.212820 normal_loss: 0.094950\n",
      "[014/00049] train_loss: 0.105521 kl_loss: 0.200961 normal_loss: 0.095473\n",
      "[015/00074] train_loss: 0.103065 kl_loss: 0.190483 normal_loss: 0.093541\n",
      "[017/00024] train_loss: 0.099156 kl_loss: 0.183402 normal_loss: 0.089985\n",
      "[018/00049] train_loss: 0.096704 kl_loss: 0.180475 normal_loss: 0.087680\n",
      "[019/00074] train_loss: 0.096036 kl_loss: 0.175056 normal_loss: 0.087284\n",
      "[021/00024] train_loss: 0.093384 kl_loss: 0.171327 normal_loss: 0.084818\n",
      "[022/00049] train_loss: 0.090744 kl_loss: 0.167280 normal_loss: 0.082380\n",
      "[023/00074] train_loss: 0.089570 kl_loss: 0.164347 normal_loss: 0.081353\n",
      "[025/00024] train_loss: 0.089292 kl_loss: 0.161032 normal_loss: 0.081240\n",
      "[026/00049] train_loss: 0.087050 kl_loss: 0.156851 normal_loss: 0.079208\n",
      "[027/00074] train_loss: 0.085116 kl_loss: 0.155366 normal_loss: 0.077348\n",
      "[029/00024] train_loss: 0.084744 kl_loss: 0.154589 normal_loss: 0.077015\n",
      "[030/00049] train_loss: 0.083072 kl_loss: 0.153966 normal_loss: 0.075374\n",
      "[031/00074] train_loss: 0.081248 kl_loss: 0.154229 normal_loss: 0.073536\n",
      "[033/00024] train_loss: 0.081332 kl_loss: 0.155411 normal_loss: 0.073561\n",
      "[034/00049] train_loss: 0.079855 kl_loss: 0.155237 normal_loss: 0.072093\n",
      "[035/00074] train_loss: 0.078575 kl_loss: 0.155751 normal_loss: 0.070787\n",
      "[037/00024] train_loss: 0.077851 kl_loss: 0.156746 normal_loss: 0.070014\n",
      "[038/00049] train_loss: 0.076579 kl_loss: 0.156711 normal_loss: 0.068743\n",
      "[039/00074] train_loss: 0.075793 kl_loss: 0.157207 normal_loss: 0.067933\n",
      "[041/00024] train_loss: 0.075226 kl_loss: 0.157686 normal_loss: 0.067342\n",
      "[042/00049] train_loss: 0.073635 kl_loss: 0.158199 normal_loss: 0.065725\n",
      "[043/00074] train_loss: 0.074050 kl_loss: 0.159147 normal_loss: 0.066093\n",
      "[045/00024] train_loss: 0.072659 kl_loss: 0.159545 normal_loss: 0.064682\n",
      "[046/00049] train_loss: 0.072495 kl_loss: 0.161593 normal_loss: 0.064416\n",
      "[047/00074] train_loss: 0.071676 kl_loss: 0.162092 normal_loss: 0.063571\n",
      "[049/00024] train_loss: 0.071598 kl_loss: 0.163504 normal_loss: 0.063423\n",
      "[049/00074] MMD 0.005202087108045816\n",
      "[049/00074] TMD 0.05903511494398117\n",
      "[050/00049] train_loss: 0.070211 kl_loss: 0.163646 normal_loss: 0.062029\n",
      "[051/00074] train_loss: 0.069568 kl_loss: 0.165369 normal_loss: 0.061299\n",
      "[053/00024] train_loss: 0.068898 kl_loss: 0.166524 normal_loss: 0.060571\n",
      "[054/00049] train_loss: 0.068011 kl_loss: 0.165713 normal_loss: 0.059725\n",
      "[055/00074] train_loss: 0.068994 kl_loss: 0.169536 normal_loss: 0.060518\n",
      "[057/00024] train_loss: 0.067160 kl_loss: 0.170067 normal_loss: 0.058657\n",
      "[058/00049] train_loss: 0.067690 kl_loss: 0.171490 normal_loss: 0.059116\n",
      "[059/00074] train_loss: 0.065929 kl_loss: 0.171686 normal_loss: 0.057345\n",
      "[061/00024] train_loss: 0.066051 kl_loss: 0.174247 normal_loss: 0.057338\n",
      "[062/00049] train_loss: 0.065192 kl_loss: 0.173559 normal_loss: 0.056514\n",
      "[063/00074] train_loss: 0.064915 kl_loss: 0.176507 normal_loss: 0.056090\n",
      "[065/00024] train_loss: 0.064503 kl_loss: 0.176727 normal_loss: 0.055667\n",
      "[066/00049] train_loss: 0.063930 kl_loss: 0.178992 normal_loss: 0.054980\n",
      "[067/00074] train_loss: 0.063940 kl_loss: 0.179219 normal_loss: 0.054979\n",
      "[069/00024] train_loss: 0.063102 kl_loss: 0.181194 normal_loss: 0.054042\n",
      "[070/00049] train_loss: 0.063190 kl_loss: 0.182245 normal_loss: 0.054078\n",
      "[071/00074] train_loss: 0.062581 kl_loss: 0.183771 normal_loss: 0.053393\n",
      "[073/00024] train_loss: 0.062588 kl_loss: 0.184462 normal_loss: 0.053365\n",
      "[074/00049] train_loss: 0.060987 kl_loss: 0.186551 normal_loss: 0.051659\n",
      "[075/00074] train_loss: 0.060898 kl_loss: 0.186714 normal_loss: 0.051562\n",
      "[077/00024] train_loss: 0.061310 kl_loss: 0.188202 normal_loss: 0.051900\n",
      "[078/00049] train_loss: 0.060728 kl_loss: 0.189387 normal_loss: 0.051258\n",
      "[079/00074] train_loss: 0.060561 kl_loss: 0.189744 normal_loss: 0.051074\n",
      "[081/00024] train_loss: 0.059486 kl_loss: 0.191240 normal_loss: 0.049924\n",
      "[082/00049] train_loss: 0.059290 kl_loss: 0.192131 normal_loss: 0.049683\n",
      "[083/00074] train_loss: 0.059754 kl_loss: 0.192391 normal_loss: 0.050134\n",
      "[085/00024] train_loss: 0.058511 kl_loss: 0.194336 normal_loss: 0.048794\n",
      "[086/00049] train_loss: 0.058061 kl_loss: 0.194705 normal_loss: 0.048326\n",
      "[087/00074] train_loss: 0.058466 kl_loss: 0.195957 normal_loss: 0.048669\n",
      "[089/00024] train_loss: 0.057879 kl_loss: 0.197062 normal_loss: 0.048026\n",
      "[090/00049] train_loss: 0.057230 kl_loss: 0.196975 normal_loss: 0.047381\n",
      "[091/00074] train_loss: 0.057180 kl_loss: 0.199956 normal_loss: 0.047182\n",
      "[093/00024] train_loss: 0.056349 kl_loss: 0.199624 normal_loss: 0.046368\n",
      "[094/00049] train_loss: 0.056422 kl_loss: 0.200875 normal_loss: 0.046379\n",
      "[095/00074] train_loss: 0.055491 kl_loss: 0.202240 normal_loss: 0.045379\n",
      "[097/00024] train_loss: 0.056190 kl_loss: 0.202541 normal_loss: 0.046063\n",
      "[098/00049] train_loss: 0.055443 kl_loss: 0.203837 normal_loss: 0.045251\n",
      "[099/00000] updated kl_weight: 0.05\n",
      "[099/00001] updated kl_weight: 0.05\n",
      "[099/00002] updated kl_weight: 0.05\n",
      "[099/00003] updated kl_weight: 0.05\n",
      "[099/00004] updated kl_weight: 0.05\n",
      "[099/00005] updated kl_weight: 0.05\n",
      "[099/00006] updated kl_weight: 0.05\n",
      "[099/00007] updated kl_weight: 0.05\n",
      "[099/00008] updated kl_weight: 0.05\n",
      "[099/00009] updated kl_weight: 0.05\n",
      "[099/00010] updated kl_weight: 0.05\n",
      "[099/00011] updated kl_weight: 0.05\n",
      "[099/00012] updated kl_weight: 0.05\n",
      "[099/00013] updated kl_weight: 0.05\n",
      "[099/00014] updated kl_weight: 0.05\n",
      "[099/00015] updated kl_weight: 0.05\n",
      "[099/00016] updated kl_weight: 0.05\n",
      "[099/00017] updated kl_weight: 0.05\n",
      "[099/00018] updated kl_weight: 0.05\n",
      "[099/00019] updated kl_weight: 0.05\n",
      "[099/00020] updated kl_weight: 0.05\n",
      "[099/00021] updated kl_weight: 0.05\n",
      "[099/00022] updated kl_weight: 0.05\n",
      "[099/00023] updated kl_weight: 0.05\n",
      "[099/00024] updated kl_weight: 0.05\n",
      "[099/00025] updated kl_weight: 0.05\n",
      "[099/00026] updated kl_weight: 0.05\n",
      "[099/00027] updated kl_weight: 0.05\n",
      "[099/00028] updated kl_weight: 0.05\n",
      "[099/00029] updated kl_weight: 0.05\n",
      "[099/00030] updated kl_weight: 0.05\n",
      "[099/00031] updated kl_weight: 0.05\n",
      "[099/00032] updated kl_weight: 0.05\n",
      "[099/00033] updated kl_weight: 0.05\n",
      "[099/00034] updated kl_weight: 0.05\n",
      "[099/00035] updated kl_weight: 0.05\n",
      "[099/00036] updated kl_weight: 0.05\n",
      "[099/00037] updated kl_weight: 0.05\n",
      "[099/00038] updated kl_weight: 0.05\n",
      "[099/00039] updated kl_weight: 0.05\n",
      "[099/00040] updated kl_weight: 0.05\n",
      "[099/00041] updated kl_weight: 0.05\n",
      "[099/00042] updated kl_weight: 0.05\n",
      "[099/00043] updated kl_weight: 0.05\n",
      "[099/00044] updated kl_weight: 0.05\n",
      "[099/00045] updated kl_weight: 0.05\n",
      "[099/00046] updated kl_weight: 0.05\n",
      "[099/00047] updated kl_weight: 0.05\n",
      "[099/00048] updated kl_weight: 0.05\n",
      "[099/00049] updated kl_weight: 0.05\n",
      "[099/00050] updated kl_weight: 0.05\n",
      "[099/00051] updated kl_weight: 0.05\n",
      "[099/00052] updated kl_weight: 0.05\n",
      "[099/00053] updated kl_weight: 0.05\n",
      "[099/00054] updated kl_weight: 0.05\n",
      "[099/00055] updated kl_weight: 0.05\n",
      "[099/00056] updated kl_weight: 0.05\n",
      "[099/00057] updated kl_weight: 0.05\n",
      "[099/00058] updated kl_weight: 0.05\n",
      "[099/00059] updated kl_weight: 0.05\n",
      "[099/00060] updated kl_weight: 0.05\n",
      "[099/00061] updated kl_weight: 0.05\n",
      "[099/00062] updated kl_weight: 0.05\n",
      "[099/00063] updated kl_weight: 0.05\n",
      "[099/00064] updated kl_weight: 0.05\n",
      "[099/00065] updated kl_weight: 0.05\n",
      "[099/00066] updated kl_weight: 0.05\n",
      "[099/00067] updated kl_weight: 0.05\n",
      "[099/00068] updated kl_weight: 0.05\n",
      "[099/00069] updated kl_weight: 0.05\n",
      "[099/00070] updated kl_weight: 0.05\n",
      "[099/00071] updated kl_weight: 0.05\n",
      "[099/00072] updated kl_weight: 0.05\n",
      "[099/00073] updated kl_weight: 0.05\n",
      "[099/00074] updated kl_weight: 0.05\n",
      "[099/00074] train_loss: 0.055625 kl_loss: 0.204918 normal_loss: 0.045379\n",
      "[099/00074] MMD 0.005021609365940094\n",
      "[099/00074] TMD 0.06067657098174095\n",
      "[101/00024] train_loss: 0.052218 kl_loss: 0.204885 normal_loss: 0.041974\n",
      "[102/00049] train_loss: 0.051057 kl_loss: 0.203102 normal_loss: 0.040902\n",
      "[103/00074] train_loss: 0.050515 kl_loss: 0.200403 normal_loss: 0.040494\n",
      "[105/00024] train_loss: 0.050257 kl_loss: 0.198618 normal_loss: 0.040326\n",
      "[106/00049] train_loss: 0.050082 kl_loss: 0.198377 normal_loss: 0.040164\n",
      "[107/00074] train_loss: 0.049517 kl_loss: 0.196317 normal_loss: 0.039701\n",
      "[109/00024] train_loss: 0.048866 kl_loss: 0.194975 normal_loss: 0.039118\n",
      "[110/00049] train_loss: 0.048870 kl_loss: 0.194852 normal_loss: 0.039127\n",
      "[111/00074] train_loss: 0.048411 kl_loss: 0.193800 normal_loss: 0.038721\n",
      "[113/00024] train_loss: 0.048453 kl_loss: 0.193099 normal_loss: 0.038798\n",
      "[114/00049] train_loss: 0.047979 kl_loss: 0.192172 normal_loss: 0.038370\n",
      "[115/00074] train_loss: 0.047798 kl_loss: 0.192071 normal_loss: 0.038195\n",
      "[117/00024] train_loss: 0.047822 kl_loss: 0.191987 normal_loss: 0.038222\n",
      "[118/00049] train_loss: 0.047290 kl_loss: 0.190886 normal_loss: 0.037746\n",
      "[119/00074] train_loss: 0.047152 kl_loss: 0.190791 normal_loss: 0.037612\n",
      "[121/00024] train_loss: 0.046859 kl_loss: 0.191199 normal_loss: 0.037299\n",
      "[122/00049] train_loss: 0.046942 kl_loss: 0.190346 normal_loss: 0.037425\n",
      "[123/00074] train_loss: 0.046890 kl_loss: 0.190670 normal_loss: 0.037356\n",
      "[125/00024] train_loss: 0.046498 kl_loss: 0.190668 normal_loss: 0.036965\n",
      "[126/00049] train_loss: 0.046304 kl_loss: 0.189868 normal_loss: 0.036811\n",
      "[127/00074] train_loss: 0.046039 kl_loss: 0.191150 normal_loss: 0.036481\n",
      "[129/00024] train_loss: 0.045567 kl_loss: 0.190774 normal_loss: 0.036028\n",
      "[130/00049] train_loss: 0.045875 kl_loss: 0.191116 normal_loss: 0.036319\n",
      "[131/00074] train_loss: 0.045567 kl_loss: 0.190414 normal_loss: 0.036047\n",
      "[133/00024] train_loss: 0.045299 kl_loss: 0.191766 normal_loss: 0.035710\n",
      "[134/00049] train_loss: 0.044934 kl_loss: 0.190541 normal_loss: 0.035407\n",
      "[135/00074] train_loss: 0.044675 kl_loss: 0.191195 normal_loss: 0.035115\n",
      "[137/00024] train_loss: 0.044536 kl_loss: 0.191256 normal_loss: 0.034974\n",
      "[138/00049] train_loss: 0.044340 kl_loss: 0.191676 normal_loss: 0.034756\n",
      "[139/00074] train_loss: 0.044304 kl_loss: 0.191910 normal_loss: 0.034709\n",
      "[141/00024] train_loss: 0.044235 kl_loss: 0.192023 normal_loss: 0.034633\n",
      "[142/00049] train_loss: 0.044255 kl_loss: 0.192588 normal_loss: 0.034626\n",
      "[143/00074] train_loss: 0.043906 kl_loss: 0.191800 normal_loss: 0.034317\n",
      "[145/00024] train_loss: 0.043836 kl_loss: 0.192020 normal_loss: 0.034235\n",
      "[146/00049] train_loss: 0.043657 kl_loss: 0.192378 normal_loss: 0.034038\n",
      "[147/00074] train_loss: 0.043370 kl_loss: 0.193247 normal_loss: 0.033707\n",
      "[149/00024] train_loss: 0.043197 kl_loss: 0.193363 normal_loss: 0.033528\n",
      "[149/00074] MMD 0.005345713812857866\n",
      "[149/00074] TMD 0.05969274044036865\n",
      "[150/00049] train_loss: 0.043044 kl_loss: 0.192131 normal_loss: 0.033438\n",
      "[151/00074] train_loss: 0.043396 kl_loss: 0.193627 normal_loss: 0.033714\n",
      "[153/00024] train_loss: 0.042725 kl_loss: 0.193863 normal_loss: 0.033032\n",
      "[154/00049] train_loss: 0.042568 kl_loss: 0.193263 normal_loss: 0.032905\n",
      "[155/00074] train_loss: 0.042699 kl_loss: 0.193356 normal_loss: 0.033032\n",
      "[157/00024] train_loss: 0.042267 kl_loss: 0.193834 normal_loss: 0.032575\n",
      "[158/00049] train_loss: 0.042446 kl_loss: 0.193723 normal_loss: 0.032759\n",
      "[159/00074] train_loss: 0.041642 kl_loss: 0.193910 normal_loss: 0.031947\n",
      "[161/00024] train_loss: 0.041982 kl_loss: 0.194401 normal_loss: 0.032262\n",
      "[162/00049] train_loss: 0.041840 kl_loss: 0.194183 normal_loss: 0.032131\n",
      "[163/00074] train_loss: 0.041564 kl_loss: 0.194528 normal_loss: 0.031838\n",
      "[165/00024] train_loss: 0.041366 kl_loss: 0.194504 normal_loss: 0.031640\n",
      "[166/00049] train_loss: 0.041081 kl_loss: 0.194589 normal_loss: 0.031352\n",
      "[167/00074] train_loss: 0.041643 kl_loss: 0.194837 normal_loss: 0.031901\n",
      "[169/00024] train_loss: 0.041255 kl_loss: 0.194764 normal_loss: 0.031516\n",
      "[170/00049] train_loss: 0.041305 kl_loss: 0.195460 normal_loss: 0.031532\n",
      "[171/00074] train_loss: 0.040663 kl_loss: 0.194301 normal_loss: 0.030948\n",
      "[173/00024] train_loss: 0.040641 kl_loss: 0.194792 normal_loss: 0.030901\n",
      "[174/00049] train_loss: 0.040772 kl_loss: 0.195407 normal_loss: 0.031002\n",
      "[175/00074] train_loss: 0.040400 kl_loss: 0.194637 normal_loss: 0.030668\n",
      "[177/00024] train_loss: 0.040434 kl_loss: 0.194756 normal_loss: 0.030696\n",
      "[178/00049] train_loss: 0.040551 kl_loss: 0.195837 normal_loss: 0.030759\n",
      "[179/00074] train_loss: 0.040324 kl_loss: 0.194928 normal_loss: 0.030577\n",
      "[181/00024] train_loss: 0.039536 kl_loss: 0.194606 normal_loss: 0.029806\n",
      "[182/00049] train_loss: 0.039831 kl_loss: 0.195963 normal_loss: 0.030032\n",
      "[183/00074] train_loss: 0.039512 kl_loss: 0.195505 normal_loss: 0.029737\n",
      "[185/00024] train_loss: 0.039896 kl_loss: 0.195449 normal_loss: 0.030124\n",
      "[186/00049] train_loss: 0.039715 kl_loss: 0.195497 normal_loss: 0.029940\n",
      "[187/00074] train_loss: 0.039139 kl_loss: 0.194804 normal_loss: 0.029399\n",
      "[189/00024] train_loss: 0.039562 kl_loss: 0.195158 normal_loss: 0.029804\n",
      "[190/00049] train_loss: 0.039439 kl_loss: 0.195755 normal_loss: 0.029651\n",
      "[191/00074] train_loss: 0.039147 kl_loss: 0.194153 normal_loss: 0.029440\n",
      "[193/00024] train_loss: 0.038850 kl_loss: 0.195147 normal_loss: 0.029093\n",
      "[194/00049] train_loss: 0.038890 kl_loss: 0.194716 normal_loss: 0.029154\n",
      "[195/00074] train_loss: 0.038895 kl_loss: 0.194916 normal_loss: 0.029150\n",
      "[197/00024] train_loss: 0.038694 kl_loss: 0.195755 normal_loss: 0.028906\n",
      "[198/00049] train_loss: 0.038394 kl_loss: 0.194198 normal_loss: 0.028684\n",
      "[199/00000] updated kl_weight: 0.05\n",
      "[199/00001] updated kl_weight: 0.05\n",
      "[199/00002] updated kl_weight: 0.05\n",
      "[199/00003] updated kl_weight: 0.05\n",
      "[199/00004] updated kl_weight: 0.05\n",
      "[199/00005] updated kl_weight: 0.05\n",
      "[199/00006] updated kl_weight: 0.05\n",
      "[199/00007] updated kl_weight: 0.05\n",
      "[199/00008] updated kl_weight: 0.05\n",
      "[199/00009] updated kl_weight: 0.05\n",
      "[199/00010] updated kl_weight: 0.05\n",
      "[199/00011] updated kl_weight: 0.05\n",
      "[199/00012] updated kl_weight: 0.05\n",
      "[199/00013] updated kl_weight: 0.05\n",
      "[199/00014] updated kl_weight: 0.05\n",
      "[199/00015] updated kl_weight: 0.05\n",
      "[199/00016] updated kl_weight: 0.05\n",
      "[199/00017] updated kl_weight: 0.05\n",
      "[199/00018] updated kl_weight: 0.05\n",
      "[199/00019] updated kl_weight: 0.05\n",
      "[199/00020] updated kl_weight: 0.05\n",
      "[199/00021] updated kl_weight: 0.05\n",
      "[199/00022] updated kl_weight: 0.05\n",
      "[199/00023] updated kl_weight: 0.05\n",
      "[199/00024] updated kl_weight: 0.05\n",
      "[199/00025] updated kl_weight: 0.05\n",
      "[199/00026] updated kl_weight: 0.05\n",
      "[199/00027] updated kl_weight: 0.05\n",
      "[199/00028] updated kl_weight: 0.05\n",
      "[199/00029] updated kl_weight: 0.05\n",
      "[199/00030] updated kl_weight: 0.05\n",
      "[199/00031] updated kl_weight: 0.05\n",
      "[199/00032] updated kl_weight: 0.05\n",
      "[199/00033] updated kl_weight: 0.05\n",
      "[199/00034] updated kl_weight: 0.05\n",
      "[199/00035] updated kl_weight: 0.05\n",
      "[199/00036] updated kl_weight: 0.05\n",
      "[199/00037] updated kl_weight: 0.05\n",
      "[199/00038] updated kl_weight: 0.05\n",
      "[199/00039] updated kl_weight: 0.05\n",
      "[199/00040] updated kl_weight: 0.05\n",
      "[199/00041] updated kl_weight: 0.05\n",
      "[199/00042] updated kl_weight: 0.05\n",
      "[199/00043] updated kl_weight: 0.05\n",
      "[199/00044] updated kl_weight: 0.05\n",
      "[199/00045] updated kl_weight: 0.05\n",
      "[199/00046] updated kl_weight: 0.05\n",
      "[199/00047] updated kl_weight: 0.05\n",
      "[199/00048] updated kl_weight: 0.05\n",
      "[199/00049] updated kl_weight: 0.05\n",
      "[199/00050] updated kl_weight: 0.05\n",
      "[199/00051] updated kl_weight: 0.05\n",
      "[199/00052] updated kl_weight: 0.05\n",
      "[199/00053] updated kl_weight: 0.05\n",
      "[199/00054] updated kl_weight: 0.05\n",
      "[199/00055] updated kl_weight: 0.05\n",
      "[199/00056] updated kl_weight: 0.05\n",
      "[199/00057] updated kl_weight: 0.05\n",
      "[199/00058] updated kl_weight: 0.05\n",
      "[199/00059] updated kl_weight: 0.05\n",
      "[199/00060] updated kl_weight: 0.05\n",
      "[199/00061] updated kl_weight: 0.05\n",
      "[199/00062] updated kl_weight: 0.05\n",
      "[199/00063] updated kl_weight: 0.05\n",
      "[199/00064] updated kl_weight: 0.05\n",
      "[199/00065] updated kl_weight: 0.05\n",
      "[199/00066] updated kl_weight: 0.05\n",
      "[199/00067] updated kl_weight: 0.05\n",
      "[199/00068] updated kl_weight: 0.05\n",
      "[199/00069] updated kl_weight: 0.05\n",
      "[199/00070] updated kl_weight: 0.05\n",
      "[199/00071] updated kl_weight: 0.05\n",
      "[199/00072] updated kl_weight: 0.05\n",
      "[199/00073] updated kl_weight: 0.05\n",
      "[199/00074] updated kl_weight: 0.05\n",
      "[199/00074] train_loss: 0.038606 kl_loss: 0.194148 normal_loss: 0.028898\n",
      "[199/00074] MMD 0.005295352078974247\n",
      "[199/00074] TMD 0.05962818115949631\n",
      "[201/00024] train_loss: 0.037051 kl_loss: 0.194026 normal_loss: 0.027349\n",
      "[202/00049] train_loss: 0.036632 kl_loss: 0.194252 normal_loss: 0.026919\n",
      "[203/00074] train_loss: 0.036447 kl_loss: 0.193314 normal_loss: 0.026781\n",
      "[205/00024] train_loss: 0.036091 kl_loss: 0.192326 normal_loss: 0.026475\n",
      "[206/00049] train_loss: 0.036164 kl_loss: 0.192586 normal_loss: 0.026534\n",
      "[207/00074] train_loss: 0.036030 kl_loss: 0.191478 normal_loss: 0.026456\n",
      "[209/00024] train_loss: 0.035953 kl_loss: 0.191740 normal_loss: 0.026366\n",
      "[210/00049] train_loss: 0.035684 kl_loss: 0.190031 normal_loss: 0.026183\n",
      "[211/00074] train_loss: 0.035628 kl_loss: 0.189876 normal_loss: 0.026135\n",
      "[213/00024] train_loss: 0.035602 kl_loss: 0.189755 normal_loss: 0.026114\n",
      "[214/00049] train_loss: 0.035433 kl_loss: 0.188323 normal_loss: 0.026017\n",
      "[215/00074] train_loss: 0.035563 kl_loss: 0.189075 normal_loss: 0.026109\n",
      "[217/00024] train_loss: 0.035345 kl_loss: 0.188096 normal_loss: 0.025940\n",
      "[218/00049] train_loss: 0.035147 kl_loss: 0.187327 normal_loss: 0.025780\n",
      "[219/00074] train_loss: 0.035488 kl_loss: 0.188065 normal_loss: 0.026085\n",
      "[221/00024] train_loss: 0.035016 kl_loss: 0.186608 normal_loss: 0.025686\n",
      "[222/00049] train_loss: 0.035113 kl_loss: 0.186743 normal_loss: 0.025776\n",
      "[223/00074] train_loss: 0.034959 kl_loss: 0.186767 normal_loss: 0.025620\n",
      "[225/00024] train_loss: 0.034978 kl_loss: 0.186357 normal_loss: 0.025660\n",
      "[226/00049] train_loss: 0.034884 kl_loss: 0.185464 normal_loss: 0.025610\n",
      "[227/00074] train_loss: 0.034834 kl_loss: 0.185403 normal_loss: 0.025564\n",
      "[229/00024] train_loss: 0.034865 kl_loss: 0.185318 normal_loss: 0.025599\n",
      "[230/00049] train_loss: 0.034616 kl_loss: 0.184027 normal_loss: 0.025415\n",
      "[231/00074] train_loss: 0.034773 kl_loss: 0.185371 normal_loss: 0.025504\n",
      "[233/00024] train_loss: 0.034484 kl_loss: 0.184379 normal_loss: 0.025265\n",
      "[234/00049] train_loss: 0.034485 kl_loss: 0.184020 normal_loss: 0.025284\n",
      "[235/00074] train_loss: 0.034490 kl_loss: 0.184032 normal_loss: 0.025288\n",
      "[237/00024] train_loss: 0.034269 kl_loss: 0.183444 normal_loss: 0.025097\n",
      "[238/00049] train_loss: 0.034351 kl_loss: 0.183248 normal_loss: 0.025189\n",
      "[239/00074] train_loss: 0.034372 kl_loss: 0.183702 normal_loss: 0.025187\n",
      "[241/00024] train_loss: 0.034231 kl_loss: 0.182487 normal_loss: 0.025107\n",
      "[242/00049] train_loss: 0.034326 kl_loss: 0.183851 normal_loss: 0.025134\n",
      "[243/00074] train_loss: 0.034119 kl_loss: 0.182031 normal_loss: 0.025017\n",
      "[245/00024] train_loss: 0.034121 kl_loss: 0.182349 normal_loss: 0.025004\n",
      "[246/00049] train_loss: 0.034003 kl_loss: 0.181852 normal_loss: 0.024910\n",
      "[247/00074] train_loss: 0.034138 kl_loss: 0.182322 normal_loss: 0.025022\n",
      "[249/00024] train_loss: 0.033791 kl_loss: 0.181767 normal_loss: 0.024703\n",
      "[249/00074] MMD 0.005048416089266539\n",
      "[249/00074] TMD 0.05533239245414734\n",
      "[250/00049] train_loss: 0.033890 kl_loss: 0.181259 normal_loss: 0.024827\n",
      "[251/00074] train_loss: 0.033854 kl_loss: 0.181628 normal_loss: 0.024772\n",
      "[253/00024] train_loss: 0.033661 kl_loss: 0.180974 normal_loss: 0.024613\n",
      "[254/00049] train_loss: 0.033670 kl_loss: 0.181285 normal_loss: 0.024605\n",
      "[255/00074] train_loss: 0.033657 kl_loss: 0.180690 normal_loss: 0.024622\n",
      "[257/00024] train_loss: 0.033710 kl_loss: 0.181037 normal_loss: 0.024658\n",
      "[258/00049] train_loss: 0.033317 kl_loss: 0.180104 normal_loss: 0.024312\n",
      "[259/00074] train_loss: 0.033473 kl_loss: 0.180286 normal_loss: 0.024458\n",
      "[261/00024] train_loss: 0.033606 kl_loss: 0.180743 normal_loss: 0.024569\n",
      "[262/00049] train_loss: 0.033245 kl_loss: 0.180115 normal_loss: 0.024239\n",
      "[263/00074] train_loss: 0.033240 kl_loss: 0.179007 normal_loss: 0.024290\n",
      "[265/00024] train_loss: 0.033327 kl_loss: 0.179114 normal_loss: 0.024372\n",
      "[266/00049] train_loss: 0.033275 kl_loss: 0.180036 normal_loss: 0.024273\n",
      "[267/00074] train_loss: 0.033207 kl_loss: 0.179318 normal_loss: 0.024241\n",
      "[269/00024] train_loss: 0.033044 kl_loss: 0.178961 normal_loss: 0.024096\n",
      "[270/00049] train_loss: 0.033024 kl_loss: 0.179153 normal_loss: 0.024066\n",
      "[271/00074] train_loss: 0.032987 kl_loss: 0.179271 normal_loss: 0.024023\n",
      "[273/00024] train_loss: 0.032984 kl_loss: 0.178899 normal_loss: 0.024039\n",
      "[274/00049] train_loss: 0.033007 kl_loss: 0.178909 normal_loss: 0.024061\n",
      "[275/00074] train_loss: 0.032863 kl_loss: 0.178291 normal_loss: 0.023948\n",
      "[277/00024] train_loss: 0.032855 kl_loss: 0.179121 normal_loss: 0.023899\n",
      "[278/00049] train_loss: 0.032642 kl_loss: 0.177401 normal_loss: 0.023771\n",
      "[279/00074] train_loss: 0.032654 kl_loss: 0.178289 normal_loss: 0.023740\n",
      "[281/00024] train_loss: 0.032708 kl_loss: 0.178146 normal_loss: 0.023801\n",
      "[282/00049] train_loss: 0.032608 kl_loss: 0.177661 normal_loss: 0.023725\n",
      "[283/00074] train_loss: 0.032656 kl_loss: 0.177417 normal_loss: 0.023786\n",
      "[285/00024] train_loss: 0.032575 kl_loss: 0.178099 normal_loss: 0.023670\n",
      "[286/00049] train_loss: 0.032352 kl_loss: 0.177006 normal_loss: 0.023502\n",
      "[287/00074] train_loss: 0.032436 kl_loss: 0.176916 normal_loss: 0.023590\n",
      "[289/00024] train_loss: 0.032398 kl_loss: 0.177508 normal_loss: 0.023522\n",
      "[290/00049] train_loss: 0.032343 kl_loss: 0.176643 normal_loss: 0.023511\n",
      "[291/00074] train_loss: 0.032464 kl_loss: 0.176816 normal_loss: 0.023624\n",
      "[293/00024] train_loss: 0.032176 kl_loss: 0.176682 normal_loss: 0.023342\n",
      "[294/00049] train_loss: 0.032165 kl_loss: 0.176304 normal_loss: 0.023350\n",
      "[295/00074] train_loss: 0.032294 kl_loss: 0.176841 normal_loss: 0.023452\n",
      "[297/00024] train_loss: 0.031973 kl_loss: 0.176103 normal_loss: 0.023168\n",
      "[298/00049] train_loss: 0.032009 kl_loss: 0.176568 normal_loss: 0.023181\n",
      "[299/00000] updated kl_weight: 0.05\n",
      "[299/00001] updated kl_weight: 0.05\n",
      "[299/00002] updated kl_weight: 0.05\n",
      "[299/00003] updated kl_weight: 0.05\n",
      "[299/00004] updated kl_weight: 0.05\n",
      "[299/00005] updated kl_weight: 0.05\n",
      "[299/00006] updated kl_weight: 0.05\n",
      "[299/00007] updated kl_weight: 0.05\n",
      "[299/00008] updated kl_weight: 0.05\n",
      "[299/00009] updated kl_weight: 0.05\n",
      "[299/00010] updated kl_weight: 0.05\n",
      "[299/00011] updated kl_weight: 0.05\n",
      "[299/00012] updated kl_weight: 0.05\n",
      "[299/00013] updated kl_weight: 0.05\n",
      "[299/00014] updated kl_weight: 0.05\n",
      "[299/00015] updated kl_weight: 0.05\n",
      "[299/00016] updated kl_weight: 0.05\n",
      "[299/00017] updated kl_weight: 0.05\n",
      "[299/00018] updated kl_weight: 0.05\n",
      "[299/00019] updated kl_weight: 0.05\n",
      "[299/00020] updated kl_weight: 0.05\n",
      "[299/00021] updated kl_weight: 0.05\n",
      "[299/00022] updated kl_weight: 0.05\n",
      "[299/00023] updated kl_weight: 0.05\n",
      "[299/00024] updated kl_weight: 0.05\n",
      "[299/00025] updated kl_weight: 0.05\n",
      "[299/00026] updated kl_weight: 0.05\n",
      "[299/00027] updated kl_weight: 0.05\n",
      "[299/00028] updated kl_weight: 0.05\n",
      "[299/00029] updated kl_weight: 0.05\n",
      "[299/00030] updated kl_weight: 0.05\n",
      "[299/00031] updated kl_weight: 0.05\n",
      "[299/00032] updated kl_weight: 0.05\n",
      "[299/00033] updated kl_weight: 0.05\n",
      "[299/00034] updated kl_weight: 0.05\n",
      "[299/00035] updated kl_weight: 0.05\n",
      "[299/00036] updated kl_weight: 0.05\n",
      "[299/00037] updated kl_weight: 0.05\n",
      "[299/00038] updated kl_weight: 0.05\n",
      "[299/00039] updated kl_weight: 0.05\n",
      "[299/00040] updated kl_weight: 0.05\n",
      "[299/00041] updated kl_weight: 0.05\n",
      "[299/00042] updated kl_weight: 0.05\n",
      "[299/00043] updated kl_weight: 0.05\n",
      "[299/00044] updated kl_weight: 0.05\n",
      "[299/00045] updated kl_weight: 0.05\n",
      "[299/00046] updated kl_weight: 0.05\n",
      "[299/00047] updated kl_weight: 0.05\n",
      "[299/00048] updated kl_weight: 0.05\n",
      "[299/00049] updated kl_weight: 0.05\n",
      "[299/00050] updated kl_weight: 0.05\n",
      "[299/00051] updated kl_weight: 0.05\n",
      "[299/00052] updated kl_weight: 0.05\n",
      "[299/00053] updated kl_weight: 0.05\n",
      "[299/00054] updated kl_weight: 0.05\n",
      "[299/00055] updated kl_weight: 0.05\n",
      "[299/00056] updated kl_weight: 0.05\n",
      "[299/00057] updated kl_weight: 0.05\n",
      "[299/00058] updated kl_weight: 0.05\n",
      "[299/00059] updated kl_weight: 0.05\n",
      "[299/00060] updated kl_weight: 0.05\n",
      "[299/00061] updated kl_weight: 0.05\n",
      "[299/00062] updated kl_weight: 0.05\n",
      "[299/00063] updated kl_weight: 0.05\n",
      "[299/00064] updated kl_weight: 0.05\n",
      "[299/00065] updated kl_weight: 0.05\n",
      "[299/00066] updated kl_weight: 0.05\n",
      "[299/00067] updated kl_weight: 0.05\n",
      "[299/00068] updated kl_weight: 0.05\n",
      "[299/00069] updated kl_weight: 0.05\n",
      "[299/00070] updated kl_weight: 0.05\n",
      "[299/00071] updated kl_weight: 0.05\n",
      "[299/00072] updated kl_weight: 0.05\n",
      "[299/00073] updated kl_weight: 0.05\n",
      "[299/00074] updated kl_weight: 0.05\n",
      "[299/00074] train_loss: 0.032051 kl_loss: 0.175699 normal_loss: 0.023266\n",
      "[299/00074] MMD 0.00504768081009388\n",
      "[299/00074] TMD 0.053506284952163696\n",
      "[301/00024] train_loss: 0.031461 kl_loss: 0.175726 normal_loss: 0.022675\n",
      "[302/00049] train_loss: 0.031355 kl_loss: 0.176063 normal_loss: 0.022552\n",
      "[303/00074] train_loss: 0.031110 kl_loss: 0.174969 normal_loss: 0.022362\n",
      "[305/00024] train_loss: 0.031008 kl_loss: 0.174541 normal_loss: 0.022281\n",
      "[306/00049] train_loss: 0.031181 kl_loss: 0.175385 normal_loss: 0.022412\n",
      "[307/00074] train_loss: 0.031036 kl_loss: 0.174883 normal_loss: 0.022292\n",
      "[309/00024] train_loss: 0.030887 kl_loss: 0.174468 normal_loss: 0.022164\n",
      "[310/00049] train_loss: 0.030992 kl_loss: 0.174414 normal_loss: 0.022271\n",
      "[311/00074] train_loss: 0.030955 kl_loss: 0.174053 normal_loss: 0.022252\n",
      "[313/00024] train_loss: 0.030929 kl_loss: 0.174019 normal_loss: 0.022228\n",
      "[314/00049] train_loss: 0.030909 kl_loss: 0.173426 normal_loss: 0.022237\n",
      "[315/00074] train_loss: 0.030802 kl_loss: 0.173708 normal_loss: 0.022116\n",
      "[317/00024] train_loss: 0.030789 kl_loss: 0.173552 normal_loss: 0.022112\n",
      "[318/00049] train_loss: 0.030456 kl_loss: 0.172081 normal_loss: 0.021852\n",
      "[319/00074] train_loss: 0.030850 kl_loss: 0.173784 normal_loss: 0.022160\n",
      "[321/00024] train_loss: 0.030489 kl_loss: 0.172784 normal_loss: 0.021849\n",
      "[322/00049] train_loss: 0.030665 kl_loss: 0.172802 normal_loss: 0.022025\n",
      "[323/00074] train_loss: 0.030555 kl_loss: 0.172088 normal_loss: 0.021951\n",
      "[325/00024] train_loss: 0.030581 kl_loss: 0.172463 normal_loss: 0.021958\n",
      "[326/00049] train_loss: 0.030345 kl_loss: 0.171860 normal_loss: 0.021752\n",
      "[327/00074] train_loss: 0.030513 kl_loss: 0.171668 normal_loss: 0.021930\n",
      "[329/00024] train_loss: 0.030483 kl_loss: 0.171590 normal_loss: 0.021904\n",
      "[330/00049] train_loss: 0.030487 kl_loss: 0.171029 normal_loss: 0.021936\n",
      "[331/00074] train_loss: 0.030403 kl_loss: 0.171911 normal_loss: 0.021807\n",
      "[333/00024] train_loss: 0.030521 kl_loss: 0.171564 normal_loss: 0.021943\n",
      "[334/00049] train_loss: 0.030239 kl_loss: 0.170547 normal_loss: 0.021712\n",
      "[335/00074] train_loss: 0.030269 kl_loss: 0.170937 normal_loss: 0.021722\n",
      "[337/00024] train_loss: 0.030253 kl_loss: 0.170615 normal_loss: 0.021723\n",
      "[338/00049] train_loss: 0.030349 kl_loss: 0.170799 normal_loss: 0.021809\n",
      "[339/00074] train_loss: 0.030141 kl_loss: 0.170209 normal_loss: 0.021631\n",
      "[341/00024] train_loss: 0.030184 kl_loss: 0.170121 normal_loss: 0.021678\n",
      "[342/00049] train_loss: 0.030280 kl_loss: 0.170893 normal_loss: 0.021736\n",
      "[343/00074] train_loss: 0.030096 kl_loss: 0.169144 normal_loss: 0.021638\n",
      "[345/00024] train_loss: 0.030091 kl_loss: 0.169970 normal_loss: 0.021593\n",
      "[346/00049] train_loss: 0.029968 kl_loss: 0.169304 normal_loss: 0.021502\n",
      "[347/00074] train_loss: 0.030183 kl_loss: 0.169438 normal_loss: 0.021711\n",
      "[349/00024] train_loss: 0.029933 kl_loss: 0.168879 normal_loss: 0.021489\n",
      "[349/00074] MMD 0.0052010915242135525\n",
      "[349/00074] TMD 0.06301707774400711\n",
      "[350/00049] train_loss: 0.029993 kl_loss: 0.169400 normal_loss: 0.021523\n",
      "[351/00074] train_loss: 0.030126 kl_loss: 0.169167 normal_loss: 0.021668\n",
      "[353/00024] train_loss: 0.030006 kl_loss: 0.169015 normal_loss: 0.021555\n",
      "[354/00049] train_loss: 0.030048 kl_loss: 0.168914 normal_loss: 0.021602\n",
      "[355/00074] train_loss: 0.029830 kl_loss: 0.168457 normal_loss: 0.021407\n",
      "[357/00024] train_loss: 0.029740 kl_loss: 0.168339 normal_loss: 0.021323\n",
      "[358/00049] train_loss: 0.030059 kl_loss: 0.169000 normal_loss: 0.021609\n",
      "[359/00074] train_loss: 0.029813 kl_loss: 0.167868 normal_loss: 0.021420\n",
      "[361/00024] train_loss: 0.029744 kl_loss: 0.168104 normal_loss: 0.021339\n",
      "[362/00049] train_loss: 0.029761 kl_loss: 0.167956 normal_loss: 0.021364\n",
      "[363/00074] train_loss: 0.029782 kl_loss: 0.168035 normal_loss: 0.021380\n",
      "[365/00024] train_loss: 0.029610 kl_loss: 0.167626 normal_loss: 0.021229\n",
      "[366/00049] train_loss: 0.029743 kl_loss: 0.167871 normal_loss: 0.021349\n",
      "[367/00074] train_loss: 0.029749 kl_loss: 0.167507 normal_loss: 0.021374\n",
      "[369/00024] train_loss: 0.029725 kl_loss: 0.167259 normal_loss: 0.021362\n",
      "[370/00049] train_loss: 0.029661 kl_loss: 0.167651 normal_loss: 0.021278\n",
      "[371/00074] train_loss: 0.029610 kl_loss: 0.167058 normal_loss: 0.021257\n",
      "[373/00024] train_loss: 0.029539 kl_loss: 0.167319 normal_loss: 0.021173\n",
      "[374/00049] train_loss: 0.029492 kl_loss: 0.166853 normal_loss: 0.021149\n",
      "[375/00074] train_loss: 0.029631 kl_loss: 0.166766 normal_loss: 0.021293\n",
      "[377/00024] train_loss: 0.029415 kl_loss: 0.166708 normal_loss: 0.021080\n",
      "[378/00049] train_loss: 0.029530 kl_loss: 0.166828 normal_loss: 0.021189\n",
      "[379/00074] train_loss: 0.029347 kl_loss: 0.166382 normal_loss: 0.021028\n",
      "[381/00024] train_loss: 0.029400 kl_loss: 0.166436 normal_loss: 0.021078\n",
      "[382/00049] train_loss: 0.029364 kl_loss: 0.166292 normal_loss: 0.021050\n",
      "[383/00074] train_loss: 0.029439 kl_loss: 0.166162 normal_loss: 0.021131\n",
      "[385/00024] train_loss: 0.029403 kl_loss: 0.166167 normal_loss: 0.021095\n",
      "[386/00049] train_loss: 0.029276 kl_loss: 0.165811 normal_loss: 0.020985\n",
      "[387/00074] train_loss: 0.029307 kl_loss: 0.165926 normal_loss: 0.021011\n",
      "[389/00024] train_loss: 0.029215 kl_loss: 0.165002 normal_loss: 0.020965\n",
      "[390/00049] train_loss: 0.029484 kl_loss: 0.166778 normal_loss: 0.021145\n",
      "[391/00074] train_loss: 0.029202 kl_loss: 0.165202 normal_loss: 0.020942\n",
      "[393/00024] train_loss: 0.029314 kl_loss: 0.165695 normal_loss: 0.021029\n",
      "[394/00049] train_loss: 0.029108 kl_loss: 0.164987 normal_loss: 0.020859\n",
      "[395/00074] train_loss: 0.029210 kl_loss: 0.165377 normal_loss: 0.020941\n",
      "[397/00024] train_loss: 0.029149 kl_loss: 0.165402 normal_loss: 0.020879\n",
      "[398/00049] train_loss: 0.028961 kl_loss: 0.164658 normal_loss: 0.020728\n",
      "[399/00000] updated kl_weight: 0.05\n",
      "[399/00001] updated kl_weight: 0.05\n",
      "[399/00002] updated kl_weight: 0.05\n",
      "[399/00003] updated kl_weight: 0.05\n",
      "[399/00004] updated kl_weight: 0.05\n",
      "[399/00005] updated kl_weight: 0.05\n",
      "[399/00006] updated kl_weight: 0.05\n",
      "[399/00007] updated kl_weight: 0.05\n",
      "[399/00008] updated kl_weight: 0.05\n",
      "[399/00009] updated kl_weight: 0.05\n",
      "[399/00010] updated kl_weight: 0.05\n",
      "[399/00011] updated kl_weight: 0.05\n",
      "[399/00012] updated kl_weight: 0.05\n",
      "[399/00013] updated kl_weight: 0.05\n",
      "[399/00014] updated kl_weight: 0.05\n",
      "[399/00015] updated kl_weight: 0.05\n",
      "[399/00016] updated kl_weight: 0.05\n",
      "[399/00017] updated kl_weight: 0.05\n",
      "[399/00018] updated kl_weight: 0.05\n",
      "[399/00019] updated kl_weight: 0.05\n",
      "[399/00020] updated kl_weight: 0.05\n",
      "[399/00021] updated kl_weight: 0.05\n",
      "[399/00022] updated kl_weight: 0.05\n",
      "[399/00023] updated kl_weight: 0.05\n",
      "[399/00024] updated kl_weight: 0.05\n",
      "[399/00025] updated kl_weight: 0.05\n",
      "[399/00026] updated kl_weight: 0.05\n",
      "[399/00027] updated kl_weight: 0.05\n",
      "[399/00028] updated kl_weight: 0.05\n",
      "[399/00029] updated kl_weight: 0.05\n",
      "[399/00030] updated kl_weight: 0.05\n",
      "[399/00031] updated kl_weight: 0.05\n",
      "[399/00032] updated kl_weight: 0.05\n",
      "[399/00033] updated kl_weight: 0.05\n",
      "[399/00034] updated kl_weight: 0.05\n",
      "[399/00035] updated kl_weight: 0.05\n",
      "[399/00036] updated kl_weight: 0.05\n",
      "[399/00037] updated kl_weight: 0.05\n",
      "[399/00038] updated kl_weight: 0.05\n",
      "[399/00039] updated kl_weight: 0.05\n",
      "[399/00040] updated kl_weight: 0.05\n",
      "[399/00041] updated kl_weight: 0.05\n",
      "[399/00042] updated kl_weight: 0.05\n",
      "[399/00043] updated kl_weight: 0.05\n",
      "[399/00044] updated kl_weight: 0.05\n",
      "[399/00045] updated kl_weight: 0.05\n",
      "[399/00046] updated kl_weight: 0.05\n",
      "[399/00047] updated kl_weight: 0.05\n",
      "[399/00048] updated kl_weight: 0.05\n",
      "[399/00049] updated kl_weight: 0.05\n",
      "[399/00050] updated kl_weight: 0.05\n",
      "[399/00051] updated kl_weight: 0.05\n",
      "[399/00052] updated kl_weight: 0.05\n",
      "[399/00053] updated kl_weight: 0.05\n",
      "[399/00054] updated kl_weight: 0.05\n",
      "[399/00055] updated kl_weight: 0.05\n",
      "[399/00056] updated kl_weight: 0.05\n",
      "[399/00057] updated kl_weight: 0.05\n",
      "[399/00058] updated kl_weight: 0.05\n",
      "[399/00059] updated kl_weight: 0.05\n",
      "[399/00060] updated kl_weight: 0.05\n",
      "[399/00061] updated kl_weight: 0.05\n",
      "[399/00062] updated kl_weight: 0.05\n",
      "[399/00063] updated kl_weight: 0.05\n",
      "[399/00064] updated kl_weight: 0.05\n",
      "[399/00065] updated kl_weight: 0.05\n",
      "[399/00066] updated kl_weight: 0.05\n",
      "[399/00067] updated kl_weight: 0.05\n",
      "[399/00068] updated kl_weight: 0.05\n",
      "[399/00069] updated kl_weight: 0.05\n",
      "[399/00070] updated kl_weight: 0.05\n",
      "[399/00071] updated kl_weight: 0.05\n",
      "[399/00072] updated kl_weight: 0.05\n",
      "[399/00073] updated kl_weight: 0.05\n",
      "[399/00074] updated kl_weight: 0.05\n",
      "[399/00074] train_loss: 0.029163 kl_loss: 0.165070 normal_loss: 0.020909\n",
      "[399/00074] MMD 0.0050043403171002865\n",
      "[399/00074] TMD 0.06578873842954636\n",
      "[401/00024] train_loss: 0.028784 kl_loss: 0.164867 normal_loss: 0.020540\n",
      "[402/00049] train_loss: 0.028837 kl_loss: 0.164454 normal_loss: 0.020614\n",
      "[403/00074] train_loss: 0.028796 kl_loss: 0.164950 normal_loss: 0.020548\n",
      "[405/00024] train_loss: 0.028772 kl_loss: 0.164409 normal_loss: 0.020551\n",
      "[406/00049] train_loss: 0.028766 kl_loss: 0.164929 normal_loss: 0.020520\n",
      "[407/00074] train_loss: 0.028633 kl_loss: 0.164183 normal_loss: 0.020424\n",
      "[409/00024] train_loss: 0.028596 kl_loss: 0.164226 normal_loss: 0.020385\n",
      "[410/00049] train_loss: 0.028665 kl_loss: 0.164521 normal_loss: 0.020439\n",
      "[411/00074] train_loss: 0.028567 kl_loss: 0.164023 normal_loss: 0.020366\n",
      "[413/00024] train_loss: 0.028564 kl_loss: 0.163626 normal_loss: 0.020383\n",
      "[414/00049] train_loss: 0.028537 kl_loss: 0.164193 normal_loss: 0.020327\n",
      "[415/00074] train_loss: 0.028615 kl_loss: 0.164122 normal_loss: 0.020409\n",
      "[417/00024] train_loss: 0.028523 kl_loss: 0.163668 normal_loss: 0.020340\n",
      "[418/00049] train_loss: 0.028602 kl_loss: 0.163836 normal_loss: 0.020410\n",
      "[419/00074] train_loss: 0.028393 kl_loss: 0.163632 normal_loss: 0.020211\n",
      "[421/00024] train_loss: 0.028445 kl_loss: 0.163473 normal_loss: 0.020271\n",
      "[422/00049] train_loss: 0.028496 kl_loss: 0.163286 normal_loss: 0.020332\n",
      "[423/00074] train_loss: 0.028498 kl_loss: 0.163556 normal_loss: 0.020321\n",
      "[425/00024] train_loss: 0.028454 kl_loss: 0.163497 normal_loss: 0.020279\n",
      "[426/00049] train_loss: 0.028490 kl_loss: 0.163077 normal_loss: 0.020336\n",
      "[427/00074] train_loss: 0.028336 kl_loss: 0.162981 normal_loss: 0.020187\n",
      "[429/00024] train_loss: 0.028402 kl_loss: 0.163124 normal_loss: 0.020246\n",
      "[430/00049] train_loss: 0.028355 kl_loss: 0.162834 normal_loss: 0.020213\n",
      "[431/00074] train_loss: 0.028420 kl_loss: 0.162846 normal_loss: 0.020277\n",
      "[433/00024] train_loss: 0.028454 kl_loss: 0.162764 normal_loss: 0.020316\n",
      "[434/00049] train_loss: 0.028191 kl_loss: 0.162750 normal_loss: 0.020054\n",
      "[435/00074] train_loss: 0.028304 kl_loss: 0.162591 normal_loss: 0.020175\n",
      "[437/00024] train_loss: 0.028386 kl_loss: 0.162728 normal_loss: 0.020250\n",
      "[438/00049] train_loss: 0.028251 kl_loss: 0.162578 normal_loss: 0.020122\n",
      "[439/00074] train_loss: 0.028280 kl_loss: 0.162066 normal_loss: 0.020176\n",
      "[441/00024] train_loss: 0.028282 kl_loss: 0.162452 normal_loss: 0.020159\n",
      "[442/00049] train_loss: 0.028249 kl_loss: 0.162155 normal_loss: 0.020142\n",
      "[443/00074] train_loss: 0.028301 kl_loss: 0.162094 normal_loss: 0.020196\n",
      "[445/00024] train_loss: 0.028262 kl_loss: 0.162337 normal_loss: 0.020145\n",
      "[446/00049] train_loss: 0.028304 kl_loss: 0.162302 normal_loss: 0.020188\n",
      "[447/00074] train_loss: 0.028236 kl_loss: 0.161436 normal_loss: 0.020164\n",
      "[449/00024] train_loss: 0.028249 kl_loss: 0.162001 normal_loss: 0.020149\n",
      "[449/00074] MMD 0.005008353851735592\n",
      "[449/00074] TMD 0.05142264813184738\n",
      "[450/00049] train_loss: 0.028105 kl_loss: 0.161785 normal_loss: 0.020016\n",
      "[451/00074] train_loss: 0.028169 kl_loss: 0.161673 normal_loss: 0.020085\n",
      "[453/00024] train_loss: 0.028217 kl_loss: 0.162063 normal_loss: 0.020113\n",
      "[454/00049] train_loss: 0.028136 kl_loss: 0.161226 normal_loss: 0.020074\n",
      "[455/00074] train_loss: 0.028188 kl_loss: 0.161531 normal_loss: 0.020111\n",
      "[457/00024] train_loss: 0.028194 kl_loss: 0.161743 normal_loss: 0.020107\n",
      "[458/00049] train_loss: 0.028049 kl_loss: 0.160875 normal_loss: 0.020005\n",
      "[459/00074] train_loss: 0.028122 kl_loss: 0.161609 normal_loss: 0.020041\n",
      "[461/00024] train_loss: 0.028168 kl_loss: 0.161636 normal_loss: 0.020086\n",
      "[462/00049] train_loss: 0.028117 kl_loss: 0.161366 normal_loss: 0.020048\n",
      "[463/00074] train_loss: 0.028049 kl_loss: 0.160633 normal_loss: 0.020017\n",
      "[465/00024] train_loss: 0.027980 kl_loss: 0.160993 normal_loss: 0.019930\n",
      "[466/00049] train_loss: 0.028108 kl_loss: 0.161242 normal_loss: 0.020046\n",
      "[467/00074] train_loss: 0.028040 kl_loss: 0.160838 normal_loss: 0.019998\n",
      "[469/00024] train_loss: 0.028001 kl_loss: 0.160426 normal_loss: 0.019980\n",
      "[470/00049] train_loss: 0.028069 kl_loss: 0.161392 normal_loss: 0.019999\n",
      "[471/00074] train_loss: 0.027980 kl_loss: 0.160659 normal_loss: 0.019947\n",
      "[473/00024] train_loss: 0.028028 kl_loss: 0.161015 normal_loss: 0.019977\n",
      "[474/00049] train_loss: 0.027884 kl_loss: 0.160474 normal_loss: 0.019860\n",
      "[475/00074] train_loss: 0.027928 kl_loss: 0.160450 normal_loss: 0.019905\n",
      "[477/00024] train_loss: 0.027974 kl_loss: 0.160596 normal_loss: 0.019944\n",
      "[478/00049] train_loss: 0.027850 kl_loss: 0.160624 normal_loss: 0.019819\n",
      "[479/00074] train_loss: 0.027881 kl_loss: 0.160148 normal_loss: 0.019874\n",
      "[481/00024] train_loss: 0.027773 kl_loss: 0.160143 normal_loss: 0.019765\n",
      "[482/00049] train_loss: 0.027911 kl_loss: 0.160251 normal_loss: 0.019898\n",
      "[483/00074] train_loss: 0.028006 kl_loss: 0.160405 normal_loss: 0.019985\n",
      "[485/00024] train_loss: 0.027679 kl_loss: 0.159558 normal_loss: 0.019701\n",
      "[486/00049] train_loss: 0.028024 kl_loss: 0.160716 normal_loss: 0.019988\n",
      "[487/00074] train_loss: 0.027852 kl_loss: 0.159980 normal_loss: 0.019853\n",
      "[489/00024] train_loss: 0.027872 kl_loss: 0.159886 normal_loss: 0.019878\n",
      "[490/00049] train_loss: 0.027796 kl_loss: 0.159889 normal_loss: 0.019802\n",
      "[491/00074] train_loss: 0.027844 kl_loss: 0.160002 normal_loss: 0.019844\n",
      "[493/00024] train_loss: 0.027680 kl_loss: 0.159617 normal_loss: 0.019700\n",
      "[494/00049] train_loss: 0.027793 kl_loss: 0.159795 normal_loss: 0.019803\n",
      "[495/00074] train_loss: 0.027849 kl_loss: 0.159858 normal_loss: 0.019856\n",
      "[497/00024] train_loss: 0.027739 kl_loss: 0.159613 normal_loss: 0.019758\n",
      "[498/00049] train_loss: 0.027762 kl_loss: 0.159802 normal_loss: 0.019772\n",
      "[499/00000] updated kl_weight: 0.05\n",
      "[499/00001] updated kl_weight: 0.05\n",
      "[499/00002] updated kl_weight: 0.05\n",
      "[499/00003] updated kl_weight: 0.05\n",
      "[499/00004] updated kl_weight: 0.05\n",
      "[499/00005] updated kl_weight: 0.05\n",
      "[499/00006] updated kl_weight: 0.05\n",
      "[499/00007] updated kl_weight: 0.05\n",
      "[499/00008] updated kl_weight: 0.05\n",
      "[499/00009] updated kl_weight: 0.05\n",
      "[499/00010] updated kl_weight: 0.05\n",
      "[499/00011] updated kl_weight: 0.05\n",
      "[499/00012] updated kl_weight: 0.05\n",
      "[499/00013] updated kl_weight: 0.05\n",
      "[499/00014] updated kl_weight: 0.05\n",
      "[499/00015] updated kl_weight: 0.05\n",
      "[499/00016] updated kl_weight: 0.05\n",
      "[499/00017] updated kl_weight: 0.05\n",
      "[499/00018] updated kl_weight: 0.05\n",
      "[499/00019] updated kl_weight: 0.05\n",
      "[499/00020] updated kl_weight: 0.05\n",
      "[499/00021] updated kl_weight: 0.05\n",
      "[499/00022] updated kl_weight: 0.05\n",
      "[499/00023] updated kl_weight: 0.05\n",
      "[499/00024] updated kl_weight: 0.05\n",
      "[499/00025] updated kl_weight: 0.05\n",
      "[499/00026] updated kl_weight: 0.05\n",
      "[499/00027] updated kl_weight: 0.05\n",
      "[499/00028] updated kl_weight: 0.05\n",
      "[499/00029] updated kl_weight: 0.05\n",
      "[499/00030] updated kl_weight: 0.05\n",
      "[499/00031] updated kl_weight: 0.05\n",
      "[499/00032] updated kl_weight: 0.05\n",
      "[499/00033] updated kl_weight: 0.05\n",
      "[499/00034] updated kl_weight: 0.05\n",
      "[499/00035] updated kl_weight: 0.05\n",
      "[499/00036] updated kl_weight: 0.05\n",
      "[499/00037] updated kl_weight: 0.05\n",
      "[499/00038] updated kl_weight: 0.05\n",
      "[499/00039] updated kl_weight: 0.05\n",
      "[499/00040] updated kl_weight: 0.05\n",
      "[499/00041] updated kl_weight: 0.05\n",
      "[499/00042] updated kl_weight: 0.05\n",
      "[499/00043] updated kl_weight: 0.05\n",
      "[499/00044] updated kl_weight: 0.05\n",
      "[499/00045] updated kl_weight: 0.05\n",
      "[499/00046] updated kl_weight: 0.05\n",
      "[499/00047] updated kl_weight: 0.05\n",
      "[499/00048] updated kl_weight: 0.05\n",
      "[499/00049] updated kl_weight: 0.05\n",
      "[499/00050] updated kl_weight: 0.05\n",
      "[499/00051] updated kl_weight: 0.05\n",
      "[499/00052] updated kl_weight: 0.05\n",
      "[499/00053] updated kl_weight: 0.05\n",
      "[499/00054] updated kl_weight: 0.05\n",
      "[499/00055] updated kl_weight: 0.05\n",
      "[499/00056] updated kl_weight: 0.05\n",
      "[499/00057] updated kl_weight: 0.05\n",
      "[499/00058] updated kl_weight: 0.05\n",
      "[499/00059] updated kl_weight: 0.05\n",
      "[499/00060] updated kl_weight: 0.05\n",
      "[499/00061] updated kl_weight: 0.05\n",
      "[499/00062] updated kl_weight: 0.05\n",
      "[499/00063] updated kl_weight: 0.05\n",
      "[499/00064] updated kl_weight: 0.05\n",
      "[499/00065] updated kl_weight: 0.05\n",
      "[499/00066] updated kl_weight: 0.05\n",
      "[499/00067] updated kl_weight: 0.05\n",
      "[499/00068] updated kl_weight: 0.05\n",
      "[499/00069] updated kl_weight: 0.05\n",
      "[499/00070] updated kl_weight: 0.05\n",
      "[499/00071] updated kl_weight: 0.05\n",
      "[499/00072] updated kl_weight: 0.05\n",
      "[499/00073] updated kl_weight: 0.05\n",
      "[499/00074] updated kl_weight: 0.05\n",
      "[499/00074] train_loss: 0.027723 kl_loss: 0.159388 normal_loss: 0.019754\n",
      "[499/00074] MMD 0.0048997290432453156\n",
      "[499/00074] TMD 0.058455757796764374\n",
      "[501/00024] train_loss: 0.027730 kl_loss: 0.159951 normal_loss: 0.019733\n",
      "[502/00049] train_loss: 0.027486 kl_loss: 0.159157 normal_loss: 0.019528\n",
      "[503/00074] train_loss: 0.027550 kl_loss: 0.159270 normal_loss: 0.019587\n",
      "[505/00024] train_loss: 0.027516 kl_loss: 0.159329 normal_loss: 0.019549\n",
      "[506/00049] train_loss: 0.027461 kl_loss: 0.158707 normal_loss: 0.019525\n",
      "[507/00074] train_loss: 0.027654 kl_loss: 0.159993 normal_loss: 0.019654\n",
      "[509/00024] train_loss: 0.027530 kl_loss: 0.159003 normal_loss: 0.019579\n",
      "[510/00049] train_loss: 0.027525 kl_loss: 0.159765 normal_loss: 0.019537\n",
      "[511/00074] train_loss: 0.027426 kl_loss: 0.158912 normal_loss: 0.019481\n",
      "[513/00024] train_loss: 0.027432 kl_loss: 0.158847 normal_loss: 0.019490\n",
      "[514/00049] train_loss: 0.027611 kl_loss: 0.159720 normal_loss: 0.019625\n",
      "[515/00074] train_loss: 0.027444 kl_loss: 0.158740 normal_loss: 0.019507\n",
      "[517/00024] train_loss: 0.027510 kl_loss: 0.158681 normal_loss: 0.019576\n",
      "[518/00049] train_loss: 0.027502 kl_loss: 0.159040 normal_loss: 0.019550\n",
      "[519/00074] train_loss: 0.027445 kl_loss: 0.159241 normal_loss: 0.019483\n",
      "[521/00024] train_loss: 0.027425 kl_loss: 0.159230 normal_loss: 0.019464\n",
      "[522/00049] train_loss: 0.027465 kl_loss: 0.158762 normal_loss: 0.019527\n",
      "[523/00074] train_loss: 0.027409 kl_loss: 0.158606 normal_loss: 0.019478\n",
      "[525/00024] train_loss: 0.027347 kl_loss: 0.158677 normal_loss: 0.019413\n",
      "[526/00049] train_loss: 0.027497 kl_loss: 0.159229 normal_loss: 0.019536\n",
      "[527/00074] train_loss: 0.027412 kl_loss: 0.158351 normal_loss: 0.019494\n",
      "[529/00024] train_loss: 0.027335 kl_loss: 0.158419 normal_loss: 0.019414\n",
      "[530/00049] train_loss: 0.027445 kl_loss: 0.158940 normal_loss: 0.019498\n",
      "[531/00074] train_loss: 0.027350 kl_loss: 0.158554 normal_loss: 0.019423\n",
      "[533/00024] train_loss: 0.027424 kl_loss: 0.158326 normal_loss: 0.019507\n",
      "[534/00049] train_loss: 0.027393 kl_loss: 0.158609 normal_loss: 0.019462\n",
      "[535/00074] train_loss: 0.027317 kl_loss: 0.158639 normal_loss: 0.019385\n",
      "[537/00024] train_loss: 0.027449 kl_loss: 0.158804 normal_loss: 0.019509\n",
      "[538/00049] train_loss: 0.027143 kl_loss: 0.157405 normal_loss: 0.019273\n",
      "[539/00074] train_loss: 0.027553 kl_loss: 0.158998 normal_loss: 0.019603\n",
      "[541/00024] train_loss: 0.027296 kl_loss: 0.158153 normal_loss: 0.019388\n",
      "[542/00049] train_loss: 0.027453 kl_loss: 0.158580 normal_loss: 0.019524\n",
      "[543/00074] train_loss: 0.027362 kl_loss: 0.158156 normal_loss: 0.019454\n",
      "[545/00024] train_loss: 0.027385 kl_loss: 0.158273 normal_loss: 0.019471\n",
      "[546/00049] train_loss: 0.027237 kl_loss: 0.157858 normal_loss: 0.019344\n",
      "[547/00074] train_loss: 0.027250 kl_loss: 0.158438 normal_loss: 0.019328\n",
      "[549/00024] train_loss: 0.027323 kl_loss: 0.158016 normal_loss: 0.019423\n",
      "[549/00074] MMD 0.0049570705741643906\n",
      "[549/00074] TMD 0.05959930643439293\n",
      "[550/00049] train_loss: 0.027272 kl_loss: 0.158343 normal_loss: 0.019355\n",
      "[551/00074] train_loss: 0.027322 kl_loss: 0.157857 normal_loss: 0.019429\n",
      "[553/00024] train_loss: 0.027302 kl_loss: 0.158302 normal_loss: 0.019387\n",
      "[554/00049] train_loss: 0.027269 kl_loss: 0.157728 normal_loss: 0.019383\n",
      "[555/00074] train_loss: 0.027259 kl_loss: 0.157877 normal_loss: 0.019365\n",
      "[557/00024] train_loss: 0.027319 kl_loss: 0.157722 normal_loss: 0.019433\n",
      "[558/00049] train_loss: 0.027211 kl_loss: 0.158353 normal_loss: 0.019294\n",
      "[559/00074] train_loss: 0.027186 kl_loss: 0.157509 normal_loss: 0.019311\n",
      "[561/00024] train_loss: 0.027218 kl_loss: 0.158092 normal_loss: 0.019313\n",
      "[562/00049] train_loss: 0.027190 kl_loss: 0.157421 normal_loss: 0.019319\n",
      "[563/00074] train_loss: 0.027306 kl_loss: 0.157739 normal_loss: 0.019419\n",
      "[565/00024] train_loss: 0.027188 kl_loss: 0.157571 normal_loss: 0.019309\n",
      "[566/00049] train_loss: 0.027186 kl_loss: 0.157661 normal_loss: 0.019303\n",
      "[567/00074] train_loss: 0.027232 kl_loss: 0.157712 normal_loss: 0.019347\n",
      "[569/00024] train_loss: 0.027220 kl_loss: 0.157598 normal_loss: 0.019341\n",
      "[570/00049] train_loss: 0.027252 kl_loss: 0.157787 normal_loss: 0.019363\n",
      "[571/00074] train_loss: 0.027174 kl_loss: 0.157242 normal_loss: 0.019312\n",
      "[573/00024] train_loss: 0.027286 kl_loss: 0.157835 normal_loss: 0.019395\n",
      "[574/00049] train_loss: 0.027078 kl_loss: 0.156958 normal_loss: 0.019230\n",
      "[575/00074] train_loss: 0.027142 kl_loss: 0.157522 normal_loss: 0.019265\n",
      "[577/00024] train_loss: 0.027114 kl_loss: 0.157485 normal_loss: 0.019240\n",
      "[578/00049] train_loss: 0.027115 kl_loss: 0.157269 normal_loss: 0.019251\n",
      "[579/00074] train_loss: 0.027103 kl_loss: 0.157230 normal_loss: 0.019242\n",
      "[581/00024] train_loss: 0.027277 kl_loss: 0.157594 normal_loss: 0.019398\n",
      "[582/00049] train_loss: 0.027025 kl_loss: 0.156704 normal_loss: 0.019190\n",
      "[583/00074] train_loss: 0.027226 kl_loss: 0.157388 normal_loss: 0.019357\n",
      "[585/00024] train_loss: 0.027096 kl_loss: 0.157196 normal_loss: 0.019236\n",
      "[586/00049] train_loss: 0.027082 kl_loss: 0.156908 normal_loss: 0.019237\n",
      "[587/00074] train_loss: 0.027077 kl_loss: 0.157285 normal_loss: 0.019213\n",
      "[589/00024] train_loss: 0.027116 kl_loss: 0.157379 normal_loss: 0.019247\n",
      "[590/00049] train_loss: 0.027057 kl_loss: 0.156788 normal_loss: 0.019218\n",
      "[591/00074] train_loss: 0.027123 kl_loss: 0.156902 normal_loss: 0.019278\n",
      "[593/00024] train_loss: 0.027064 kl_loss: 0.156971 normal_loss: 0.019216\n",
      "[594/00049] train_loss: 0.027030 kl_loss: 0.156735 normal_loss: 0.019193\n",
      "[595/00074] train_loss: 0.027024 kl_loss: 0.157076 normal_loss: 0.019171\n",
      "[597/00024] train_loss: 0.027134 kl_loss: 0.157071 normal_loss: 0.019280\n",
      "[598/00049] train_loss: 0.027052 kl_loss: 0.156452 normal_loss: 0.019230\n",
      "[599/00000] updated kl_weight: 0.05\n",
      "[599/00001] updated kl_weight: 0.05\n",
      "[599/00002] updated kl_weight: 0.05\n",
      "[599/00003] updated kl_weight: 0.05\n",
      "[599/00004] updated kl_weight: 0.05\n",
      "[599/00005] updated kl_weight: 0.05\n",
      "[599/00006] updated kl_weight: 0.05\n",
      "[599/00007] updated kl_weight: 0.05\n",
      "[599/00008] updated kl_weight: 0.05\n",
      "[599/00009] updated kl_weight: 0.05\n",
      "[599/00010] updated kl_weight: 0.05\n",
      "[599/00011] updated kl_weight: 0.05\n",
      "[599/00012] updated kl_weight: 0.05\n",
      "[599/00013] updated kl_weight: 0.05\n",
      "[599/00014] updated kl_weight: 0.05\n",
      "[599/00015] updated kl_weight: 0.05\n",
      "[599/00016] updated kl_weight: 0.05\n",
      "[599/00017] updated kl_weight: 0.05\n",
      "[599/00018] updated kl_weight: 0.05\n",
      "[599/00019] updated kl_weight: 0.05\n",
      "[599/00020] updated kl_weight: 0.05\n",
      "[599/00021] updated kl_weight: 0.05\n",
      "[599/00022] updated kl_weight: 0.05\n",
      "[599/00023] updated kl_weight: 0.05\n",
      "[599/00024] updated kl_weight: 0.05\n",
      "[599/00025] updated kl_weight: 0.05\n",
      "[599/00026] updated kl_weight: 0.05\n",
      "[599/00027] updated kl_weight: 0.05\n",
      "[599/00028] updated kl_weight: 0.05\n",
      "[599/00029] updated kl_weight: 0.05\n",
      "[599/00030] updated kl_weight: 0.05\n",
      "[599/00031] updated kl_weight: 0.05\n",
      "[599/00032] updated kl_weight: 0.05\n",
      "[599/00033] updated kl_weight: 0.05\n",
      "[599/00034] updated kl_weight: 0.05\n",
      "[599/00035] updated kl_weight: 0.05\n",
      "[599/00036] updated kl_weight: 0.05\n",
      "[599/00037] updated kl_weight: 0.05\n",
      "[599/00038] updated kl_weight: 0.05\n",
      "[599/00039] updated kl_weight: 0.05\n",
      "[599/00040] updated kl_weight: 0.05\n",
      "[599/00041] updated kl_weight: 0.05\n",
      "[599/00042] updated kl_weight: 0.05\n",
      "[599/00043] updated kl_weight: 0.05\n",
      "[599/00044] updated kl_weight: 0.05\n",
      "[599/00045] updated kl_weight: 0.05\n",
      "[599/00046] updated kl_weight: 0.05\n",
      "[599/00047] updated kl_weight: 0.05\n",
      "[599/00048] updated kl_weight: 0.05\n",
      "[599/00049] updated kl_weight: 0.05\n",
      "[599/00050] updated kl_weight: 0.05\n",
      "[599/00051] updated kl_weight: 0.05\n",
      "[599/00052] updated kl_weight: 0.05\n",
      "[599/00053] updated kl_weight: 0.05\n",
      "[599/00054] updated kl_weight: 0.05\n",
      "[599/00055] updated kl_weight: 0.05\n",
      "[599/00056] updated kl_weight: 0.05\n",
      "[599/00057] updated kl_weight: 0.05\n",
      "[599/00058] updated kl_weight: 0.05\n",
      "[599/00059] updated kl_weight: 0.05\n",
      "[599/00060] updated kl_weight: 0.05\n",
      "[599/00061] updated kl_weight: 0.05\n",
      "[599/00062] updated kl_weight: 0.05\n",
      "[599/00063] updated kl_weight: 0.05\n",
      "[599/00064] updated kl_weight: 0.05\n",
      "[599/00065] updated kl_weight: 0.05\n",
      "[599/00066] updated kl_weight: 0.05\n",
      "[599/00067] updated kl_weight: 0.05\n",
      "[599/00068] updated kl_weight: 0.05\n",
      "[599/00069] updated kl_weight: 0.05\n",
      "[599/00070] updated kl_weight: 0.05\n",
      "[599/00071] updated kl_weight: 0.05\n",
      "[599/00072] updated kl_weight: 0.05\n",
      "[599/00073] updated kl_weight: 0.05\n",
      "[599/00074] updated kl_weight: 0.05\n",
      "[599/00074] train_loss: 0.027076 kl_loss: 0.156973 normal_loss: 0.019228\n",
      "[599/00074] MMD 0.005250429268926382\n",
      "[599/00074] TMD 0.060155920684337616\n",
      "[601/00024] train_loss: 0.026896 kl_loss: 0.156291 normal_loss: 0.019082\n",
      "[602/00049] train_loss: 0.027186 kl_loss: 0.157590 normal_loss: 0.019306\n",
      "[603/00074] train_loss: 0.026867 kl_loss: 0.156379 normal_loss: 0.019048\n",
      "[605/00024] train_loss: 0.026968 kl_loss: 0.156563 normal_loss: 0.019140\n",
      "[606/00049] train_loss: 0.026906 kl_loss: 0.156965 normal_loss: 0.019058\n",
      "[607/00074] train_loss: 0.026902 kl_loss: 0.156553 normal_loss: 0.019074\n",
      "[609/00024] train_loss: 0.026986 kl_loss: 0.156822 normal_loss: 0.019145\n",
      "[610/00049] train_loss: 0.026896 kl_loss: 0.156664 normal_loss: 0.019063\n",
      "[611/00074] train_loss: 0.026933 kl_loss: 0.156412 normal_loss: 0.019112\n",
      "[613/00024] train_loss: 0.026858 kl_loss: 0.156393 normal_loss: 0.019039\n",
      "[614/00049] train_loss: 0.026959 kl_loss: 0.156758 normal_loss: 0.019122\n",
      "[615/00074] train_loss: 0.026966 kl_loss: 0.156566 normal_loss: 0.019138\n",
      "[617/00024] train_loss: 0.026973 kl_loss: 0.156549 normal_loss: 0.019146\n",
      "[618/00049] train_loss: 0.026828 kl_loss: 0.156184 normal_loss: 0.019019\n",
      "[619/00074] train_loss: 0.026965 kl_loss: 0.156819 normal_loss: 0.019124\n",
      "[621/00024] train_loss: 0.026843 kl_loss: 0.156275 normal_loss: 0.019029\n",
      "[622/00049] train_loss: 0.027008 kl_loss: 0.156776 normal_loss: 0.019169\n",
      "[623/00074] train_loss: 0.026863 kl_loss: 0.156336 normal_loss: 0.019046\n",
      "[625/00024] train_loss: 0.026907 kl_loss: 0.156348 normal_loss: 0.019090\n",
      "[626/00049] train_loss: 0.026857 kl_loss: 0.156365 normal_loss: 0.019039\n",
      "[627/00074] train_loss: 0.026869 kl_loss: 0.156510 normal_loss: 0.019044\n",
      "[629/00024] train_loss: 0.026889 kl_loss: 0.156795 normal_loss: 0.019050\n",
      "[630/00049] train_loss: 0.026882 kl_loss: 0.156187 normal_loss: 0.019073\n",
      "[631/00074] train_loss: 0.026906 kl_loss: 0.156056 normal_loss: 0.019103\n",
      "[633/00024] train_loss: 0.026858 kl_loss: 0.156233 normal_loss: 0.019046\n",
      "[634/00049] train_loss: 0.026849 kl_loss: 0.156028 normal_loss: 0.019048\n",
      "[635/00074] train_loss: 0.026925 kl_loss: 0.156609 normal_loss: 0.019094\n",
      "[637/00024] train_loss: 0.026955 kl_loss: 0.156443 normal_loss: 0.019132\n",
      "[638/00049] train_loss: 0.026808 kl_loss: 0.155965 normal_loss: 0.019010\n",
      "[639/00074] train_loss: 0.026880 kl_loss: 0.156295 normal_loss: 0.019066\n",
      "[641/00024] train_loss: 0.026910 kl_loss: 0.156393 normal_loss: 0.019091\n",
      "[642/00049] train_loss: 0.026694 kl_loss: 0.155883 normal_loss: 0.018900\n",
      "[643/00074] train_loss: 0.026928 kl_loss: 0.156262 normal_loss: 0.019115\n",
      "[645/00024] train_loss: 0.026863 kl_loss: 0.156235 normal_loss: 0.019052\n",
      "[646/00049] train_loss: 0.026920 kl_loss: 0.156452 normal_loss: 0.019098\n",
      "[647/00074] train_loss: 0.026782 kl_loss: 0.155674 normal_loss: 0.018999\n",
      "[649/00024] train_loss: 0.026756 kl_loss: 0.155618 normal_loss: 0.018975\n",
      "[649/00074] MMD 0.004930701572448015\n",
      "[649/00074] TMD 0.0652347058057785\n",
      "[650/00049] train_loss: 0.026916 kl_loss: 0.156639 normal_loss: 0.019084\n",
      "[651/00074] train_loss: 0.026858 kl_loss: 0.155947 normal_loss: 0.019061\n",
      "[653/00024] train_loss: 0.026818 kl_loss: 0.155542 normal_loss: 0.019040\n",
      "[654/00049] train_loss: 0.026877 kl_loss: 0.156547 normal_loss: 0.019050\n",
      "[655/00074] train_loss: 0.026783 kl_loss: 0.155951 normal_loss: 0.018985\n",
      "[657/00024] train_loss: 0.026781 kl_loss: 0.155767 normal_loss: 0.018993\n",
      "[658/00049] train_loss: 0.026725 kl_loss: 0.155717 normal_loss: 0.018939\n",
      "[659/00074] train_loss: 0.026799 kl_loss: 0.156381 normal_loss: 0.018980\n",
      "[661/00024] train_loss: 0.026753 kl_loss: 0.155773 normal_loss: 0.018964\n",
      "[662/00049] train_loss: 0.026851 kl_loss: 0.156415 normal_loss: 0.019030\n",
      "[663/00074] train_loss: 0.026785 kl_loss: 0.155487 normal_loss: 0.019011\n",
      "[665/00024] train_loss: 0.026819 kl_loss: 0.155970 normal_loss: 0.019020\n",
      "[666/00049] train_loss: 0.026689 kl_loss: 0.155602 normal_loss: 0.018908\n",
      "[667/00074] train_loss: 0.026833 kl_loss: 0.155946 normal_loss: 0.019036\n",
      "[669/00024] train_loss: 0.026844 kl_loss: 0.156078 normal_loss: 0.019040\n",
      "[670/00049] train_loss: 0.026758 kl_loss: 0.155358 normal_loss: 0.018990\n",
      "[671/00074] train_loss: 0.026823 kl_loss: 0.155937 normal_loss: 0.019026\n",
      "[673/00024] train_loss: 0.026799 kl_loss: 0.155907 normal_loss: 0.019004\n",
      "[674/00049] train_loss: 0.026770 kl_loss: 0.155896 normal_loss: 0.018975\n",
      "[675/00074] train_loss: 0.026790 kl_loss: 0.155411 normal_loss: 0.019019\n",
      "[677/00024] train_loss: 0.026760 kl_loss: 0.155610 normal_loss: 0.018980\n",
      "[678/00049] train_loss: 0.026689 kl_loss: 0.155731 normal_loss: 0.018902\n",
      "[679/00074] train_loss: 0.026797 kl_loss: 0.155720 normal_loss: 0.019011\n",
      "[681/00024] train_loss: 0.026686 kl_loss: 0.155624 normal_loss: 0.018904\n",
      "[682/00049] train_loss: 0.026824 kl_loss: 0.155625 normal_loss: 0.019042\n",
      "[683/00074] train_loss: 0.026826 kl_loss: 0.155650 normal_loss: 0.019043\n",
      "[685/00024] train_loss: 0.026728 kl_loss: 0.155600 normal_loss: 0.018948\n",
      "[686/00049] train_loss: 0.026787 kl_loss: 0.155487 normal_loss: 0.019013\n",
      "[687/00074] train_loss: 0.026754 kl_loss: 0.155667 normal_loss: 0.018971\n",
      "[689/00024] train_loss: 0.026639 kl_loss: 0.155496 normal_loss: 0.018864\n",
      "[690/00049] train_loss: 0.026771 kl_loss: 0.155400 normal_loss: 0.019001\n",
      "[691/00074] train_loss: 0.026778 kl_loss: 0.155710 normal_loss: 0.018993\n",
      "[693/00024] train_loss: 0.026724 kl_loss: 0.155484 normal_loss: 0.018950\n",
      "[694/00049] train_loss: 0.026595 kl_loss: 0.155069 normal_loss: 0.018841\n",
      "[695/00074] train_loss: 0.026842 kl_loss: 0.155902 normal_loss: 0.019047\n",
      "[697/00024] train_loss: 0.026757 kl_loss: 0.155468 normal_loss: 0.018984\n",
      "[698/00049] train_loss: 0.026602 kl_loss: 0.155540 normal_loss: 0.018825\n",
      "[699/00000] updated kl_weight: 0.05\n",
      "[699/00001] updated kl_weight: 0.05\n",
      "[699/00002] updated kl_weight: 0.05\n",
      "[699/00003] updated kl_weight: 0.05\n",
      "[699/00004] updated kl_weight: 0.05\n",
      "[699/00005] updated kl_weight: 0.05\n",
      "[699/00006] updated kl_weight: 0.05\n",
      "[699/00007] updated kl_weight: 0.05\n",
      "[699/00008] updated kl_weight: 0.05\n",
      "[699/00009] updated kl_weight: 0.05\n",
      "[699/00010] updated kl_weight: 0.05\n",
      "[699/00011] updated kl_weight: 0.05\n",
      "[699/00012] updated kl_weight: 0.05\n",
      "[699/00013] updated kl_weight: 0.05\n",
      "[699/00014] updated kl_weight: 0.05\n",
      "[699/00015] updated kl_weight: 0.05\n",
      "[699/00016] updated kl_weight: 0.05\n",
      "[699/00017] updated kl_weight: 0.05\n",
      "[699/00018] updated kl_weight: 0.05\n",
      "[699/00019] updated kl_weight: 0.05\n",
      "[699/00020] updated kl_weight: 0.05\n",
      "[699/00021] updated kl_weight: 0.05\n",
      "[699/00022] updated kl_weight: 0.05\n",
      "[699/00023] updated kl_weight: 0.05\n",
      "[699/00024] updated kl_weight: 0.05\n",
      "[699/00025] updated kl_weight: 0.05\n",
      "[699/00026] updated kl_weight: 0.05\n",
      "[699/00027] updated kl_weight: 0.05\n",
      "[699/00028] updated kl_weight: 0.05\n",
      "[699/00029] updated kl_weight: 0.05\n",
      "[699/00030] updated kl_weight: 0.05\n",
      "[699/00031] updated kl_weight: 0.05\n",
      "[699/00032] updated kl_weight: 0.05\n",
      "[699/00033] updated kl_weight: 0.05\n",
      "[699/00034] updated kl_weight: 0.05\n",
      "[699/00035] updated kl_weight: 0.05\n",
      "[699/00036] updated kl_weight: 0.05\n",
      "[699/00037] updated kl_weight: 0.05\n",
      "[699/00038] updated kl_weight: 0.05\n",
      "[699/00039] updated kl_weight: 0.05\n",
      "[699/00040] updated kl_weight: 0.05\n",
      "[699/00041] updated kl_weight: 0.05\n",
      "[699/00042] updated kl_weight: 0.05\n",
      "[699/00043] updated kl_weight: 0.05\n",
      "[699/00044] updated kl_weight: 0.05\n",
      "[699/00045] updated kl_weight: 0.05\n",
      "[699/00046] updated kl_weight: 0.05\n",
      "[699/00047] updated kl_weight: 0.05\n",
      "[699/00048] updated kl_weight: 0.05\n",
      "[699/00049] updated kl_weight: 0.05\n",
      "[699/00050] updated kl_weight: 0.05\n",
      "[699/00051] updated kl_weight: 0.05\n",
      "[699/00052] updated kl_weight: 0.05\n",
      "[699/00053] updated kl_weight: 0.05\n",
      "[699/00054] updated kl_weight: 0.05\n",
      "[699/00055] updated kl_weight: 0.05\n",
      "[699/00056] updated kl_weight: 0.05\n",
      "[699/00057] updated kl_weight: 0.05\n",
      "[699/00058] updated kl_weight: 0.05\n",
      "[699/00059] updated kl_weight: 0.05\n",
      "[699/00060] updated kl_weight: 0.05\n",
      "[699/00061] updated kl_weight: 0.05\n",
      "[699/00062] updated kl_weight: 0.05\n",
      "[699/00063] updated kl_weight: 0.05\n",
      "[699/00064] updated kl_weight: 0.05\n",
      "[699/00065] updated kl_weight: 0.05\n",
      "[699/00066] updated kl_weight: 0.05\n",
      "[699/00067] updated kl_weight: 0.05\n",
      "[699/00068] updated kl_weight: 0.05\n",
      "[699/00069] updated kl_weight: 0.05\n",
      "[699/00070] updated kl_weight: 0.05\n",
      "[699/00071] updated kl_weight: 0.05\n",
      "[699/00072] updated kl_weight: 0.05\n",
      "[699/00073] updated kl_weight: 0.05\n",
      "[699/00074] updated kl_weight: 0.05\n",
      "[699/00074] train_loss: 0.026763 kl_loss: 0.155295 normal_loss: 0.018998\n",
      "[699/00074] MMD 0.005130420438945293\n",
      "[699/00074] TMD 0.053835660219192505\n",
      "[701/00024] train_loss: 0.026696 kl_loss: 0.155284 normal_loss: 0.018932\n",
      "[702/00049] train_loss: 0.026933 kl_loss: 0.156171 normal_loss: 0.019125\n",
      "[703/00074] train_loss: 0.026584 kl_loss: 0.154730 normal_loss: 0.018848\n",
      "[705/00024] train_loss: 0.026692 kl_loss: 0.155396 normal_loss: 0.018922\n",
      "[706/00049] train_loss: 0.026550 kl_loss: 0.154877 normal_loss: 0.018807\n",
      "[707/00074] train_loss: 0.026717 kl_loss: 0.155836 normal_loss: 0.018925\n",
      "[709/00024] train_loss: 0.026664 kl_loss: 0.155283 normal_loss: 0.018900\n",
      "[710/00049] train_loss: 0.026594 kl_loss: 0.155195 normal_loss: 0.018834\n",
      "[711/00074] train_loss: 0.026661 kl_loss: 0.155544 normal_loss: 0.018884\n",
      "[713/00024] train_loss: 0.026701 kl_loss: 0.155193 normal_loss: 0.018941\n",
      "[714/00049] train_loss: 0.026694 kl_loss: 0.155555 normal_loss: 0.018916\n",
      "[715/00074] train_loss: 0.026709 kl_loss: 0.155191 normal_loss: 0.018950\n",
      "[717/00024] train_loss: 0.026600 kl_loss: 0.155123 normal_loss: 0.018844\n",
      "[718/00049] train_loss: 0.026764 kl_loss: 0.155792 normal_loss: 0.018974\n",
      "[719/00074] train_loss: 0.026628 kl_loss: 0.154948 normal_loss: 0.018881\n",
      "[721/00024] train_loss: 0.026713 kl_loss: 0.155643 normal_loss: 0.018931\n",
      "[722/00049] train_loss: 0.026626 kl_loss: 0.154810 normal_loss: 0.018885\n",
      "[723/00074] train_loss: 0.026622 kl_loss: 0.155338 normal_loss: 0.018856\n",
      "[725/00024] train_loss: 0.026536 kl_loss: 0.154934 normal_loss: 0.018789\n",
      "[726/00049] train_loss: 0.026732 kl_loss: 0.155730 normal_loss: 0.018946\n",
      "[727/00074] train_loss: 0.026599 kl_loss: 0.155044 normal_loss: 0.018847\n",
      "[729/00024] train_loss: 0.026755 kl_loss: 0.155710 normal_loss: 0.018969\n",
      "[730/00049] train_loss: 0.026616 kl_loss: 0.155014 normal_loss: 0.018865\n",
      "[731/00074] train_loss: 0.026573 kl_loss: 0.154900 normal_loss: 0.018828\n",
      "[733/00024] train_loss: 0.026636 kl_loss: 0.155379 normal_loss: 0.018867\n",
      "[734/00049] train_loss: 0.026561 kl_loss: 0.154714 normal_loss: 0.018826\n",
      "[735/00074] train_loss: 0.026643 kl_loss: 0.155456 normal_loss: 0.018870\n",
      "[737/00024] train_loss: 0.026578 kl_loss: 0.154915 normal_loss: 0.018832\n",
      "[738/00049] train_loss: 0.026600 kl_loss: 0.155350 normal_loss: 0.018833\n",
      "[739/00074] train_loss: 0.026630 kl_loss: 0.155200 normal_loss: 0.018870\n",
      "[741/00024] train_loss: 0.026627 kl_loss: 0.155249 normal_loss: 0.018864\n",
      "[742/00049] train_loss: 0.026625 kl_loss: 0.154861 normal_loss: 0.018882\n",
      "[743/00074] train_loss: 0.026680 kl_loss: 0.155274 normal_loss: 0.018916\n",
      "[745/00024] train_loss: 0.026601 kl_loss: 0.155080 normal_loss: 0.018847\n",
      "[746/00049] train_loss: 0.026648 kl_loss: 0.154937 normal_loss: 0.018901\n",
      "[747/00074] train_loss: 0.026591 kl_loss: 0.155296 normal_loss: 0.018826\n",
      "[749/00024] train_loss: 0.026537 kl_loss: 0.155151 normal_loss: 0.018780\n",
      "[749/00074] MMD 0.005028392653912306\n",
      "[749/00074] TMD 0.05772531405091286\n",
      "[750/00049] train_loss: 0.026545 kl_loss: 0.155037 normal_loss: 0.018793\n",
      "[751/00074] train_loss: 0.026643 kl_loss: 0.155042 normal_loss: 0.018891\n",
      "[753/00024] train_loss: 0.026579 kl_loss: 0.155066 normal_loss: 0.018826\n",
      "[754/00049] train_loss: 0.026560 kl_loss: 0.155039 normal_loss: 0.018808\n",
      "[755/00074] train_loss: 0.026567 kl_loss: 0.155044 normal_loss: 0.018815\n",
      "[757/00024] train_loss: 0.026613 kl_loss: 0.155081 normal_loss: 0.018859\n",
      "[758/00049] train_loss: 0.026549 kl_loss: 0.154411 normal_loss: 0.018829\n",
      "[759/00074] train_loss: 0.026642 kl_loss: 0.155575 normal_loss: 0.018864\n",
      "[761/00024] train_loss: 0.026586 kl_loss: 0.154960 normal_loss: 0.018838\n",
      "[762/00049] train_loss: 0.026646 kl_loss: 0.155099 normal_loss: 0.018891\n",
      "[763/00074] train_loss: 0.026579 kl_loss: 0.154931 normal_loss: 0.018833\n",
      "[765/00024] train_loss: 0.026577 kl_loss: 0.155135 normal_loss: 0.018821\n",
      "[766/00049] train_loss: 0.026616 kl_loss: 0.155243 normal_loss: 0.018854\n",
      "[767/00074] train_loss: 0.026439 kl_loss: 0.154531 normal_loss: 0.018713\n",
      "[769/00024] train_loss: 0.026689 kl_loss: 0.155275 normal_loss: 0.018925\n",
      "[770/00049] train_loss: 0.026610 kl_loss: 0.154637 normal_loss: 0.018878\n",
      "[771/00074] train_loss: 0.026571 kl_loss: 0.154916 normal_loss: 0.018825\n",
      "[773/00024] train_loss: 0.026532 kl_loss: 0.154799 normal_loss: 0.018793\n",
      "[774/00049] train_loss: 0.026578 kl_loss: 0.155202 normal_loss: 0.018818\n",
      "[775/00074] train_loss: 0.026586 kl_loss: 0.154753 normal_loss: 0.018849\n",
      "[777/00024] train_loss: 0.026537 kl_loss: 0.154997 normal_loss: 0.018787\n",
      "[778/00049] train_loss: 0.026642 kl_loss: 0.155015 normal_loss: 0.018892\n",
      "[779/00074] train_loss: 0.026479 kl_loss: 0.154657 normal_loss: 0.018746\n",
      "[781/00024] train_loss: 0.026554 kl_loss: 0.154659 normal_loss: 0.018821\n",
      "[782/00049] train_loss: 0.026650 kl_loss: 0.155257 normal_loss: 0.018887\n",
      "[783/00074] train_loss: 0.026522 kl_loss: 0.154671 normal_loss: 0.018789\n",
      "[785/00024] train_loss: 0.026657 kl_loss: 0.154678 normal_loss: 0.018923\n",
      "[786/00049] train_loss: 0.026640 kl_loss: 0.155238 normal_loss: 0.018878\n",
      "[787/00074] train_loss: 0.026545 kl_loss: 0.154596 normal_loss: 0.018815\n",
      "[789/00024] train_loss: 0.026555 kl_loss: 0.155012 normal_loss: 0.018805\n",
      "[790/00049] train_loss: 0.026576 kl_loss: 0.154668 normal_loss: 0.018843\n",
      "[791/00074] train_loss: 0.026533 kl_loss: 0.154758 normal_loss: 0.018795\n",
      "[793/00024] train_loss: 0.026616 kl_loss: 0.155142 normal_loss: 0.018859\n",
      "[794/00049] train_loss: 0.026465 kl_loss: 0.154862 normal_loss: 0.018721\n",
      "[795/00074] train_loss: 0.026403 kl_loss: 0.154356 normal_loss: 0.018685\n",
      "[797/00024] train_loss: 0.026546 kl_loss: 0.154701 normal_loss: 0.018811\n",
      "[798/00049] train_loss: 0.026565 kl_loss: 0.155073 normal_loss: 0.018811\n",
      "[799/00000] updated kl_weight: 0.05\n",
      "[799/00001] updated kl_weight: 0.05\n",
      "[799/00002] updated kl_weight: 0.05\n",
      "[799/00003] updated kl_weight: 0.05\n",
      "[799/00004] updated kl_weight: 0.05\n",
      "[799/00005] updated kl_weight: 0.05\n",
      "[799/00006] updated kl_weight: 0.05\n",
      "[799/00007] updated kl_weight: 0.05\n",
      "[799/00008] updated kl_weight: 0.05\n",
      "[799/00009] updated kl_weight: 0.05\n",
      "[799/00010] updated kl_weight: 0.05\n",
      "[799/00011] updated kl_weight: 0.05\n",
      "[799/00012] updated kl_weight: 0.05\n",
      "[799/00013] updated kl_weight: 0.05\n",
      "[799/00014] updated kl_weight: 0.05\n",
      "[799/00015] updated kl_weight: 0.05\n",
      "[799/00016] updated kl_weight: 0.05\n",
      "[799/00017] updated kl_weight: 0.05\n",
      "[799/00018] updated kl_weight: 0.05\n",
      "[799/00019] updated kl_weight: 0.05\n",
      "[799/00020] updated kl_weight: 0.05\n",
      "[799/00021] updated kl_weight: 0.05\n",
      "[799/00022] updated kl_weight: 0.05\n",
      "[799/00023] updated kl_weight: 0.05\n",
      "[799/00024] updated kl_weight: 0.05\n",
      "[799/00025] updated kl_weight: 0.05\n",
      "[799/00026] updated kl_weight: 0.05\n",
      "[799/00027] updated kl_weight: 0.05\n",
      "[799/00028] updated kl_weight: 0.05\n",
      "[799/00029] updated kl_weight: 0.05\n",
      "[799/00030] updated kl_weight: 0.05\n",
      "[799/00031] updated kl_weight: 0.05\n",
      "[799/00032] updated kl_weight: 0.05\n",
      "[799/00033] updated kl_weight: 0.05\n",
      "[799/00034] updated kl_weight: 0.05\n",
      "[799/00035] updated kl_weight: 0.05\n",
      "[799/00036] updated kl_weight: 0.05\n",
      "[799/00037] updated kl_weight: 0.05\n",
      "[799/00038] updated kl_weight: 0.05\n",
      "[799/00039] updated kl_weight: 0.05\n",
      "[799/00040] updated kl_weight: 0.05\n",
      "[799/00041] updated kl_weight: 0.05\n",
      "[799/00042] updated kl_weight: 0.05\n",
      "[799/00043] updated kl_weight: 0.05\n",
      "[799/00044] updated kl_weight: 0.05\n",
      "[799/00045] updated kl_weight: 0.05\n",
      "[799/00046] updated kl_weight: 0.05\n",
      "[799/00047] updated kl_weight: 0.05\n",
      "[799/00048] updated kl_weight: 0.05\n",
      "[799/00049] updated kl_weight: 0.05\n",
      "[799/00050] updated kl_weight: 0.05\n",
      "[799/00051] updated kl_weight: 0.05\n",
      "[799/00052] updated kl_weight: 0.05\n",
      "[799/00053] updated kl_weight: 0.05\n",
      "[799/00054] updated kl_weight: 0.05\n",
      "[799/00055] updated kl_weight: 0.05\n",
      "[799/00056] updated kl_weight: 0.05\n",
      "[799/00057] updated kl_weight: 0.05\n",
      "[799/00058] updated kl_weight: 0.05\n",
      "[799/00059] updated kl_weight: 0.05\n",
      "[799/00060] updated kl_weight: 0.05\n",
      "[799/00061] updated kl_weight: 0.05\n",
      "[799/00062] updated kl_weight: 0.05\n",
      "[799/00063] updated kl_weight: 0.05\n",
      "[799/00064] updated kl_weight: 0.05\n",
      "[799/00065] updated kl_weight: 0.05\n",
      "[799/00066] updated kl_weight: 0.05\n",
      "[799/00067] updated kl_weight: 0.05\n",
      "[799/00068] updated kl_weight: 0.05\n",
      "[799/00069] updated kl_weight: 0.05\n",
      "[799/00070] updated kl_weight: 0.05\n",
      "[799/00071] updated kl_weight: 0.05\n",
      "[799/00072] updated kl_weight: 0.05\n",
      "[799/00073] updated kl_weight: 0.05\n",
      "[799/00074] updated kl_weight: 0.05\n",
      "[799/00074] train_loss: 0.026511 kl_loss: 0.154495 normal_loss: 0.018787\n",
      "[799/00074] MMD 0.0049097612500190735\n",
      "[799/00074] TMD 0.0697641670703888\n",
      "[801/00024] train_loss: 0.026566 kl_loss: 0.154697 normal_loss: 0.018831\n",
      "[802/00049] train_loss: 0.026536 kl_loss: 0.154706 normal_loss: 0.018801\n",
      "[803/00074] train_loss: 0.026584 kl_loss: 0.154800 normal_loss: 0.018844\n",
      "[805/00024] train_loss: 0.026443 kl_loss: 0.154435 normal_loss: 0.018721\n",
      "[806/00049] train_loss: 0.026557 kl_loss: 0.154881 normal_loss: 0.018813\n",
      "[807/00074] train_loss: 0.026574 kl_loss: 0.154847 normal_loss: 0.018832\n",
      "[809/00024] train_loss: 0.026435 kl_loss: 0.154378 normal_loss: 0.018716\n",
      "[810/00049] train_loss: 0.026599 kl_loss: 0.155399 normal_loss: 0.018829\n",
      "[811/00074] train_loss: 0.026513 kl_loss: 0.154347 normal_loss: 0.018796\n",
      "[813/00024] train_loss: 0.026502 kl_loss: 0.154662 normal_loss: 0.018769\n",
      "[814/00049] train_loss: 0.026475 kl_loss: 0.154877 normal_loss: 0.018731\n",
      "[815/00074] train_loss: 0.026481 kl_loss: 0.154544 normal_loss: 0.018754\n",
      "[817/00024] train_loss: 0.026449 kl_loss: 0.154636 normal_loss: 0.018717\n",
      "[818/00049] train_loss: 0.026593 kl_loss: 0.155497 normal_loss: 0.018818\n",
      "[819/00074] train_loss: 0.026406 kl_loss: 0.153907 normal_loss: 0.018711\n",
      "[821/00024] train_loss: 0.026558 kl_loss: 0.154693 normal_loss: 0.018823\n",
      "[822/00049] train_loss: 0.026392 kl_loss: 0.154423 normal_loss: 0.018671\n",
      "[823/00074] train_loss: 0.026548 kl_loss: 0.154881 normal_loss: 0.018804\n",
      "[825/00024] train_loss: 0.026515 kl_loss: 0.154834 normal_loss: 0.018773\n",
      "[826/00049] train_loss: 0.026455 kl_loss: 0.154367 normal_loss: 0.018736\n",
      "[827/00074] train_loss: 0.026539 kl_loss: 0.154752 normal_loss: 0.018802\n",
      "[829/00024] train_loss: 0.026483 kl_loss: 0.154568 normal_loss: 0.018755\n",
      "[830/00049] train_loss: 0.026443 kl_loss: 0.154374 normal_loss: 0.018724\n",
      "[831/00074] train_loss: 0.026512 kl_loss: 0.154971 normal_loss: 0.018763\n",
      "[833/00024] train_loss: 0.026519 kl_loss: 0.154710 normal_loss: 0.018784\n",
      "[834/00049] train_loss: 0.026400 kl_loss: 0.154589 normal_loss: 0.018671\n",
      "[835/00074] train_loss: 0.026469 kl_loss: 0.154573 normal_loss: 0.018740\n",
      "[837/00024] train_loss: 0.026549 kl_loss: 0.154717 normal_loss: 0.018814\n",
      "[838/00049] train_loss: 0.026612 kl_loss: 0.154888 normal_loss: 0.018867\n",
      "[839/00074] train_loss: 0.026350 kl_loss: 0.154225 normal_loss: 0.018639\n",
      "[841/00024] train_loss: 0.026524 kl_loss: 0.154892 normal_loss: 0.018780\n",
      "[842/00049] train_loss: 0.026472 kl_loss: 0.154173 normal_loss: 0.018763\n",
      "[843/00074] train_loss: 0.026488 kl_loss: 0.154724 normal_loss: 0.018752\n",
      "[845/00024] train_loss: 0.026427 kl_loss: 0.154405 normal_loss: 0.018706\n",
      "[846/00049] train_loss: 0.026595 kl_loss: 0.155307 normal_loss: 0.018830\n",
      "[847/00074] train_loss: 0.026418 kl_loss: 0.154035 normal_loss: 0.018716\n",
      "[849/00024] train_loss: 0.026437 kl_loss: 0.154667 normal_loss: 0.018704\n",
      "[849/00074] MMD 0.0050461022183299065\n",
      "[849/00074] TMD 0.08243072777986526\n",
      "[850/00049] train_loss: 0.026578 kl_loss: 0.154579 normal_loss: 0.018849\n",
      "[851/00074] train_loss: 0.026406 kl_loss: 0.154457 normal_loss: 0.018683\n",
      "[853/00024] train_loss: 0.026474 kl_loss: 0.154403 normal_loss: 0.018754\n",
      "[854/00049] train_loss: 0.026524 kl_loss: 0.154668 normal_loss: 0.018791\n",
      "[855/00074] train_loss: 0.026490 kl_loss: 0.154592 normal_loss: 0.018761\n",
      "[857/00024] train_loss: 0.026460 kl_loss: 0.154654 normal_loss: 0.018727\n",
      "[858/00049] train_loss: 0.026332 kl_loss: 0.154003 normal_loss: 0.018632\n",
      "[859/00074] train_loss: 0.026521 kl_loss: 0.154963 normal_loss: 0.018772\n",
      "[861/00024] train_loss: 0.026499 kl_loss: 0.154678 normal_loss: 0.018765\n",
      "[862/00049] train_loss: 0.026434 kl_loss: 0.154587 normal_loss: 0.018704\n",
      "[863/00074] train_loss: 0.026473 kl_loss: 0.154309 normal_loss: 0.018758\n",
      "[865/00024] train_loss: 0.026409 kl_loss: 0.154225 normal_loss: 0.018698\n",
      "[866/00049] train_loss: 0.026625 kl_loss: 0.155159 normal_loss: 0.018867\n",
      "[867/00074] train_loss: 0.026282 kl_loss: 0.154148 normal_loss: 0.018574\n",
      "[869/00024] train_loss: 0.026370 kl_loss: 0.154223 normal_loss: 0.018659\n",
      "[870/00049] train_loss: 0.026588 kl_loss: 0.155090 normal_loss: 0.018833\n",
      "[871/00074] train_loss: 0.026381 kl_loss: 0.154173 normal_loss: 0.018672\n",
      "[873/00024] train_loss: 0.026502 kl_loss: 0.154587 normal_loss: 0.018773\n",
      "[874/00049] train_loss: 0.026478 kl_loss: 0.154532 normal_loss: 0.018751\n",
      "[875/00074] train_loss: 0.026543 kl_loss: 0.154324 normal_loss: 0.018827\n",
      "[877/00024] train_loss: 0.026511 kl_loss: 0.154822 normal_loss: 0.018770\n",
      "[878/00049] train_loss: 0.026447 kl_loss: 0.154257 normal_loss: 0.018734\n",
      "[879/00074] train_loss: 0.026429 kl_loss: 0.154324 normal_loss: 0.018713\n",
      "[881/00024] train_loss: 0.026402 kl_loss: 0.154257 normal_loss: 0.018689\n",
      "[882/00049] train_loss: 0.026591 kl_loss: 0.154758 normal_loss: 0.018853\n",
      "[883/00074] train_loss: 0.026387 kl_loss: 0.154348 normal_loss: 0.018669\n",
      "[885/00024] train_loss: 0.026419 kl_loss: 0.154383 normal_loss: 0.018700\n",
      "[886/00049] train_loss: 0.026583 kl_loss: 0.154715 normal_loss: 0.018847\n",
      "[887/00074] train_loss: 0.026298 kl_loss: 0.154222 normal_loss: 0.018587\n",
      "[889/00024] train_loss: 0.026364 kl_loss: 0.154313 normal_loss: 0.018648\n",
      "[890/00049] train_loss: 0.026496 kl_loss: 0.154556 normal_loss: 0.018768\n",
      "[891/00074] train_loss: 0.026500 kl_loss: 0.154406 normal_loss: 0.018779\n",
      "[893/00024] train_loss: 0.026379 kl_loss: 0.154143 normal_loss: 0.018672\n",
      "[894/00049] train_loss: 0.026476 kl_loss: 0.154379 normal_loss: 0.018757\n",
      "[895/00074] train_loss: 0.026499 kl_loss: 0.154714 normal_loss: 0.018764\n",
      "[897/00024] train_loss: 0.026485 kl_loss: 0.154512 normal_loss: 0.018759\n",
      "[898/00049] train_loss: 0.026379 kl_loss: 0.154269 normal_loss: 0.018666\n",
      "[899/00000] updated kl_weight: 0.05\n",
      "[899/00001] updated kl_weight: 0.05\n",
      "[899/00002] updated kl_weight: 0.05\n",
      "[899/00003] updated kl_weight: 0.05\n",
      "[899/00004] updated kl_weight: 0.05\n",
      "[899/00005] updated kl_weight: 0.05\n",
      "[899/00006] updated kl_weight: 0.05\n",
      "[899/00007] updated kl_weight: 0.05\n",
      "[899/00008] updated kl_weight: 0.05\n",
      "[899/00009] updated kl_weight: 0.05\n",
      "[899/00010] updated kl_weight: 0.05\n",
      "[899/00011] updated kl_weight: 0.05\n",
      "[899/00012] updated kl_weight: 0.05\n",
      "[899/00013] updated kl_weight: 0.05\n",
      "[899/00014] updated kl_weight: 0.05\n",
      "[899/00015] updated kl_weight: 0.05\n",
      "[899/00016] updated kl_weight: 0.05\n",
      "[899/00017] updated kl_weight: 0.05\n",
      "[899/00018] updated kl_weight: 0.05\n",
      "[899/00019] updated kl_weight: 0.05\n",
      "[899/00020] updated kl_weight: 0.05\n",
      "[899/00021] updated kl_weight: 0.05\n",
      "[899/00022] updated kl_weight: 0.05\n",
      "[899/00023] updated kl_weight: 0.05\n",
      "[899/00024] updated kl_weight: 0.05\n",
      "[899/00025] updated kl_weight: 0.05\n",
      "[899/00026] updated kl_weight: 0.05\n",
      "[899/00027] updated kl_weight: 0.05\n",
      "[899/00028] updated kl_weight: 0.05\n",
      "[899/00029] updated kl_weight: 0.05\n",
      "[899/00030] updated kl_weight: 0.05\n",
      "[899/00031] updated kl_weight: 0.05\n",
      "[899/00032] updated kl_weight: 0.05\n",
      "[899/00033] updated kl_weight: 0.05\n",
      "[899/00034] updated kl_weight: 0.05\n",
      "[899/00035] updated kl_weight: 0.05\n",
      "[899/00036] updated kl_weight: 0.05\n",
      "[899/00037] updated kl_weight: 0.05\n",
      "[899/00038] updated kl_weight: 0.05\n",
      "[899/00039] updated kl_weight: 0.05\n",
      "[899/00040] updated kl_weight: 0.05\n",
      "[899/00041] updated kl_weight: 0.05\n",
      "[899/00042] updated kl_weight: 0.05\n",
      "[899/00043] updated kl_weight: 0.05\n",
      "[899/00044] updated kl_weight: 0.05\n",
      "[899/00045] updated kl_weight: 0.05\n",
      "[899/00046] updated kl_weight: 0.05\n",
      "[899/00047] updated kl_weight: 0.05\n",
      "[899/00048] updated kl_weight: 0.05\n",
      "[899/00049] updated kl_weight: 0.05\n",
      "[899/00050] updated kl_weight: 0.05\n",
      "[899/00051] updated kl_weight: 0.05\n",
      "[899/00052] updated kl_weight: 0.05\n",
      "[899/00053] updated kl_weight: 0.05\n",
      "[899/00054] updated kl_weight: 0.05\n",
      "[899/00055] updated kl_weight: 0.05\n",
      "[899/00056] updated kl_weight: 0.05\n",
      "[899/00057] updated kl_weight: 0.05\n",
      "[899/00058] updated kl_weight: 0.05\n",
      "[899/00059] updated kl_weight: 0.05\n",
      "[899/00060] updated kl_weight: 0.05\n",
      "[899/00061] updated kl_weight: 0.05\n",
      "[899/00062] updated kl_weight: 0.05\n",
      "[899/00063] updated kl_weight: 0.05\n",
      "[899/00064] updated kl_weight: 0.05\n",
      "[899/00065] updated kl_weight: 0.05\n",
      "[899/00066] updated kl_weight: 0.05\n",
      "[899/00067] updated kl_weight: 0.05\n",
      "[899/00068] updated kl_weight: 0.05\n",
      "[899/00069] updated kl_weight: 0.05\n",
      "[899/00070] updated kl_weight: 0.05\n",
      "[899/00071] updated kl_weight: 0.05\n",
      "[899/00072] updated kl_weight: 0.05\n",
      "[899/00073] updated kl_weight: 0.05\n",
      "[899/00074] updated kl_weight: 0.05\n",
      "[899/00074] train_loss: 0.026410 kl_loss: 0.154416 normal_loss: 0.018689\n",
      "[899/00074] MMD 0.0050826589576900005\n",
      "[899/00074] TMD 0.06414811313152313\n",
      "[901/00024] train_loss: 0.026485 kl_loss: 0.154630 normal_loss: 0.018754\n",
      "[902/00049] train_loss: 0.026508 kl_loss: 0.154387 normal_loss: 0.018789\n",
      "[903/00074] train_loss: 0.026423 kl_loss: 0.154147 normal_loss: 0.018716\n",
      "[905/00024] train_loss: 0.026496 kl_loss: 0.154627 normal_loss: 0.018765\n",
      "[906/00049] train_loss: 0.026477 kl_loss: 0.154130 normal_loss: 0.018770\n",
      "[907/00074] train_loss: 0.026420 kl_loss: 0.154385 normal_loss: 0.018701\n",
      "[909/00024] train_loss: 0.026362 kl_loss: 0.154056 normal_loss: 0.018659\n",
      "[910/00049] train_loss: 0.026522 kl_loss: 0.154609 normal_loss: 0.018792\n",
      "[911/00074] train_loss: 0.026427 kl_loss: 0.154455 normal_loss: 0.018705\n",
      "[913/00024] train_loss: 0.026428 kl_loss: 0.154399 normal_loss: 0.018708\n",
      "[914/00049] train_loss: 0.026337 kl_loss: 0.153901 normal_loss: 0.018641\n",
      "[915/00074] train_loss: 0.026449 kl_loss: 0.154800 normal_loss: 0.018709\n",
      "[917/00024] train_loss: 0.026486 kl_loss: 0.154514 normal_loss: 0.018761\n",
      "[918/00049] train_loss: 0.026424 kl_loss: 0.154512 normal_loss: 0.018698\n",
      "[919/00074] train_loss: 0.026396 kl_loss: 0.154051 normal_loss: 0.018693\n",
      "[921/00024] train_loss: 0.026415 kl_loss: 0.154255 normal_loss: 0.018703\n",
      "[922/00049] train_loss: 0.026508 kl_loss: 0.154795 normal_loss: 0.018769\n",
      "[923/00074] train_loss: 0.026350 kl_loss: 0.154006 normal_loss: 0.018650\n",
      "[925/00024] train_loss: 0.026440 kl_loss: 0.154013 normal_loss: 0.018739\n",
      "[926/00049] train_loss: 0.026418 kl_loss: 0.154585 normal_loss: 0.018689\n",
      "[927/00074] train_loss: 0.026495 kl_loss: 0.154439 normal_loss: 0.018773\n",
      "[929/00024] train_loss: 0.026352 kl_loss: 0.154227 normal_loss: 0.018641\n",
      "[930/00049] train_loss: 0.026351 kl_loss: 0.154138 normal_loss: 0.018644\n",
      "[931/00074] train_loss: 0.026454 kl_loss: 0.154651 normal_loss: 0.018722\n",
      "[933/00024] train_loss: 0.026469 kl_loss: 0.154446 normal_loss: 0.018746\n",
      "[934/00049] train_loss: 0.026459 kl_loss: 0.154399 normal_loss: 0.018739\n",
      "[935/00074] train_loss: 0.026389 kl_loss: 0.154148 normal_loss: 0.018682\n",
      "[937/00024] train_loss: 0.026489 kl_loss: 0.154408 normal_loss: 0.018768\n",
      "[938/00049] train_loss: 0.026324 kl_loss: 0.154308 normal_loss: 0.018609\n",
      "[939/00074] train_loss: 0.026492 kl_loss: 0.154256 normal_loss: 0.018779\n",
      "[941/00024] train_loss: 0.026502 kl_loss: 0.154661 normal_loss: 0.018769\n",
      "[942/00049] train_loss: 0.026350 kl_loss: 0.154040 normal_loss: 0.018648\n",
      "[943/00074] train_loss: 0.026423 kl_loss: 0.154251 normal_loss: 0.018711\n",
      "[945/00024] train_loss: 0.026295 kl_loss: 0.153642 normal_loss: 0.018613\n",
      "[946/00049] train_loss: 0.026576 kl_loss: 0.155330 normal_loss: 0.018809\n",
      "[947/00074] train_loss: 0.026345 kl_loss: 0.153958 normal_loss: 0.018647\n",
      "[949/00024] train_loss: 0.026463 kl_loss: 0.154506 normal_loss: 0.018737\n",
      "[949/00074] MMD 0.004882458131760359\n",
      "[949/00074] TMD 0.054297689348459244\n",
      "[950/00049] train_loss: 0.026377 kl_loss: 0.154328 normal_loss: 0.018660\n",
      "[951/00074] train_loss: 0.026395 kl_loss: 0.154074 normal_loss: 0.018692\n",
      "[953/00024] train_loss: 0.026325 kl_loss: 0.153789 normal_loss: 0.018635\n",
      "[954/00049] train_loss: 0.026539 kl_loss: 0.154883 normal_loss: 0.018795\n",
      "[955/00074] train_loss: 0.026370 kl_loss: 0.154214 normal_loss: 0.018659\n",
      "[957/00024] train_loss: 0.026457 kl_loss: 0.154304 normal_loss: 0.018742\n",
      "[958/00049] train_loss: 0.026403 kl_loss: 0.154482 normal_loss: 0.018679\n",
      "[959/00074] train_loss: 0.026384 kl_loss: 0.154078 normal_loss: 0.018680\n",
      "[961/00024] train_loss: 0.026415 kl_loss: 0.154374 normal_loss: 0.018696\n",
      "[962/00049] train_loss: 0.026414 kl_loss: 0.154054 normal_loss: 0.018711\n",
      "[963/00074] train_loss: 0.026364 kl_loss: 0.154415 normal_loss: 0.018644\n",
      "[965/00024] train_loss: 0.026396 kl_loss: 0.153982 normal_loss: 0.018696\n",
      "[966/00049] train_loss: 0.026487 kl_loss: 0.154841 normal_loss: 0.018745\n",
      "[967/00074] train_loss: 0.026402 kl_loss: 0.153999 normal_loss: 0.018702\n",
      "[969/00024] train_loss: 0.026487 kl_loss: 0.154297 normal_loss: 0.018772\n",
      "[970/00049] train_loss: 0.026302 kl_loss: 0.154419 normal_loss: 0.018581\n",
      "[971/00074] train_loss: 0.026382 kl_loss: 0.154085 normal_loss: 0.018678\n",
      "[973/00024] train_loss: 0.026375 kl_loss: 0.154383 normal_loss: 0.018656\n",
      "[974/00049] train_loss: 0.026408 kl_loss: 0.153983 normal_loss: 0.018709\n",
      "[975/00074] train_loss: 0.026428 kl_loss: 0.154413 normal_loss: 0.018707\n",
      "[977/00024] train_loss: 0.026304 kl_loss: 0.154266 normal_loss: 0.018591\n",
      "[978/00049] train_loss: 0.026407 kl_loss: 0.154198 normal_loss: 0.018697\n",
      "[979/00074] train_loss: 0.026505 kl_loss: 0.154292 normal_loss: 0.018790\n",
      "[981/00024] train_loss: 0.026372 kl_loss: 0.153970 normal_loss: 0.018674\n",
      "[982/00049] train_loss: 0.026423 kl_loss: 0.154172 normal_loss: 0.018714\n",
      "[983/00074] train_loss: 0.026508 kl_loss: 0.154594 normal_loss: 0.018779\n",
      "[985/00024] train_loss: 0.026508 kl_loss: 0.154513 normal_loss: 0.018782\n",
      "[986/00049] train_loss: 0.026375 kl_loss: 0.154059 normal_loss: 0.018672\n",
      "[987/00074] train_loss: 0.026452 kl_loss: 0.154147 normal_loss: 0.018744\n",
      "[989/00024] train_loss: 0.026270 kl_loss: 0.154077 normal_loss: 0.018566\n",
      "[990/00049] train_loss: 0.026445 kl_loss: 0.154228 normal_loss: 0.018734\n",
      "[991/00074] train_loss: 0.026448 kl_loss: 0.154394 normal_loss: 0.018729\n",
      "[993/00024] train_loss: 0.026491 kl_loss: 0.154264 normal_loss: 0.018778\n",
      "[994/00049] train_loss: 0.026335 kl_loss: 0.153886 normal_loss: 0.018640\n",
      "[995/00074] train_loss: 0.026508 kl_loss: 0.154529 normal_loss: 0.018782\n",
      "[997/00024] train_loss: 0.026496 kl_loss: 0.154563 normal_loss: 0.018768\n",
      "[998/00049] train_loss: 0.026347 kl_loss: 0.153962 normal_loss: 0.018648\n",
      "[999/00000] updated kl_weight: 0.05\n",
      "[999/00001] updated kl_weight: 0.05\n",
      "[999/00002] updated kl_weight: 0.05\n",
      "[999/00003] updated kl_weight: 0.05\n",
      "[999/00004] updated kl_weight: 0.05\n",
      "[999/00005] updated kl_weight: 0.05\n",
      "[999/00006] updated kl_weight: 0.05\n",
      "[999/00007] updated kl_weight: 0.05\n",
      "[999/00008] updated kl_weight: 0.05\n",
      "[999/00009] updated kl_weight: 0.05\n",
      "[999/00010] updated kl_weight: 0.05\n",
      "[999/00011] updated kl_weight: 0.05\n",
      "[999/00012] updated kl_weight: 0.05\n",
      "[999/00013] updated kl_weight: 0.05\n",
      "[999/00014] updated kl_weight: 0.05\n",
      "[999/00015] updated kl_weight: 0.05\n",
      "[999/00016] updated kl_weight: 0.05\n",
      "[999/00017] updated kl_weight: 0.05\n",
      "[999/00018] updated kl_weight: 0.05\n",
      "[999/00019] updated kl_weight: 0.05\n",
      "[999/00020] updated kl_weight: 0.05\n",
      "[999/00021] updated kl_weight: 0.05\n",
      "[999/00022] updated kl_weight: 0.05\n",
      "[999/00023] updated kl_weight: 0.05\n",
      "[999/00024] updated kl_weight: 0.05\n",
      "[999/00025] updated kl_weight: 0.05\n",
      "[999/00026] updated kl_weight: 0.05\n",
      "[999/00027] updated kl_weight: 0.05\n",
      "[999/00028] updated kl_weight: 0.05\n",
      "[999/00029] updated kl_weight: 0.05\n",
      "[999/00030] updated kl_weight: 0.05\n",
      "[999/00031] updated kl_weight: 0.05\n",
      "[999/00032] updated kl_weight: 0.05\n",
      "[999/00033] updated kl_weight: 0.05\n",
      "[999/00034] updated kl_weight: 0.05\n",
      "[999/00035] updated kl_weight: 0.05\n",
      "[999/00036] updated kl_weight: 0.05\n",
      "[999/00037] updated kl_weight: 0.05\n",
      "[999/00038] updated kl_weight: 0.05\n",
      "[999/00039] updated kl_weight: 0.05\n",
      "[999/00040] updated kl_weight: 0.05\n",
      "[999/00041] updated kl_weight: 0.05\n",
      "[999/00042] updated kl_weight: 0.05\n",
      "[999/00043] updated kl_weight: 0.05\n",
      "[999/00044] updated kl_weight: 0.05\n",
      "[999/00045] updated kl_weight: 0.05\n",
      "[999/00046] updated kl_weight: 0.05\n",
      "[999/00047] updated kl_weight: 0.05\n",
      "[999/00048] updated kl_weight: 0.05\n",
      "[999/00049] updated kl_weight: 0.05\n",
      "[999/00050] updated kl_weight: 0.05\n",
      "[999/00051] updated kl_weight: 0.05\n",
      "[999/00052] updated kl_weight: 0.05\n",
      "[999/00053] updated kl_weight: 0.05\n",
      "[999/00054] updated kl_weight: 0.05\n",
      "[999/00055] updated kl_weight: 0.05\n",
      "[999/00056] updated kl_weight: 0.05\n",
      "[999/00057] updated kl_weight: 0.05\n",
      "[999/00058] updated kl_weight: 0.05\n",
      "[999/00059] updated kl_weight: 0.05\n",
      "[999/00060] updated kl_weight: 0.05\n",
      "[999/00061] updated kl_weight: 0.05\n",
      "[999/00062] updated kl_weight: 0.05\n",
      "[999/00063] updated kl_weight: 0.05\n",
      "[999/00064] updated kl_weight: 0.05\n",
      "[999/00065] updated kl_weight: 0.05\n",
      "[999/00066] updated kl_weight: 0.05\n",
      "[999/00067] updated kl_weight: 0.05\n",
      "[999/00068] updated kl_weight: 0.05\n",
      "[999/00069] updated kl_weight: 0.05\n",
      "[999/00070] updated kl_weight: 0.05\n",
      "[999/00071] updated kl_weight: 0.05\n",
      "[999/00072] updated kl_weight: 0.05\n",
      "[999/00073] updated kl_weight: 0.05\n",
      "[999/00074] updated kl_weight: 0.05\n",
      "[999/00074] train_loss: 0.026423 kl_loss: 0.154134 normal_loss: 0.018717\n",
      "[999/00074] MMD 0.004902235697954893\n",
      "[999/00074] TMD 0.062358465045690536\n"
     ]
    }
   ],
   "source": [
    "# CHAIR VAD\n",
    "from scripts import train\n",
    "config = {\n",
    "    'experiment_name': 'chair_vad_0.05kl',\n",
    "    'device': 'cuda:0',\n",
    "    'is_overfit': False,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate_model': 0.01,\n",
    "    'learning_rate_code': 0.01,\n",
    "    'learning_rate_log_var':0.01,\n",
    "    'max_epochs': 1000,\n",
    "    'print_every_n': 100,\n",
    "    'latent_code_length' : 256,\n",
    "    'scheduler_step_size': 100,\n",
    "    'vad_free' : True,\n",
    "    'test': False,\n",
    "    'kl_weight': 0.05,\n",
    "    'kl_weight_increase_every_epochs': 100,\n",
    "    'kl_weight_increase_value': 0.0,\n",
    "    'mmd_every_epoch': 50,\n",
    "    'tmd_every_epoch': 50,\n",
    "    'iou_every_epoch': 10,\n",
    "    'resume_ckpt': None,\n",
    "    'filter_class': 'chair',\n",
    "    'decoder_var' : True\n",
    "}\n",
    "train.main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "#                   #\n",
    "#    VISUALIZING    #\n",
    "#                   #\n",
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.visualize import visualize_dataset_sample, visualize_ad, visualize_vad, visualize_vad_norm, visualize_vad_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5793103df1284b7ab4f9be8337a3cde7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "experiment = \"airplane_vad\"\n",
    "experiment2 = \"sofa_ad\"\n",
    "# experiment2 = \"sofa_ad\"\n",
    "filter_class = \"airplane\"\n",
    "index = 4123\n",
    "index1 = random.choice(range(len(ShapeNet('train', filter_class = \"airplane\"))))\n",
    "index2 = random.choice(range(len(ShapeNet('train', filter_class = filter_class))))\n",
    "a1 = 0.5\n",
    "a2 = 1 - a1\n",
    "#-------\n",
    "# visualize_ad(\"airplane_ad\", index1)\n",
    "#-------\n",
    "visualize_vad_norm(\"chair_vad_0.05kl\")\n",
    "# visualize_vad_norm(experiment)\n",
    "# visualize_ad(experiment, index1)\n",
    "# visualize_vad_norm(experiment2)\n",
    "# visualize_ad(experiment, index)\n",
    "#-------\n",
    "# visualize_vad_norm(experiment)\n",
    "# visualize_vad_norm(experiment2)\n",
    "# visualize_dataset_sample(filter_class, index)\n",
    "#-------\n",
    "# visualize_interpolation_ad(experiment, index1, index2, a1, a2)\n",
    "# visualize_ad(experiment, index1)\n",
    "# visualize_ad(experiment, index2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "#                  #\n",
    "#    EVALUATION    #\n",
    "#                  #\n",
    "####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.evaluate import generate_samples, convert_df_to_point_cloud, chamfer_distance, MMD, convert_set_to_point_cloud, visualize_point_cloud, _mmd, TMD, IOU, min_sample\n",
    "from util.visualization import visualize_mesh\n",
    "from skimage.measure import marching_cubes\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MMD\n",
    "mmd, mmds = MMD('airplane_vad', 'val', 'airplane', n_samples=10, device=torch.device('cuda:0'))\n",
    "mmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TMD\n",
    "tmd, samples = TMD('airplane_vad', n_samples=10, device=torch.device('cuda:0'))\n",
    "tmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "#                  #\n",
    "#    PLAYGROUND    #\n",
    "#                  #\n",
    "####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIN SAMPLE\n",
    "# generate n new samples\n",
    "n = 10\n",
    "samples = generate_samples('airplane_vad', n)\n",
    "samples = samples.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b65789cc1ff546d081cba9841fc2596e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51425643c9246ec9b5474ad6e3e18bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get min cf distance to val\n",
    "index = 0\n",
    "sample, cf_distance = min_sample('val', 'airplane', samples[index], device=torch.device('cuda:0'))\n",
    "# visualize\n",
    "input_mesh = marching_cubes(sample.cpu().detach().numpy(), level=1)\n",
    "visualize_mesh(input_mesh[0], input_mesh[1], flip_axes=True)\n",
    "input_mesh = marching_cubes(samples[index].cpu().detach().numpy(), level=1)\n",
    "visualize_mesh(input_mesh[0], input_mesh[1], flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0019, device='cuda:0')"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0016)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chamfer_distance(convert_df_to_point_cloud(sample), convert_df_to_point_cloud(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = []\n",
    "val_dataset = ShapeNet('val', filter_class='airplane')\n",
    "for data_dict in val_dataset:\n",
    "    target_df = torch.from_numpy(data_dict['target_df']).float()\n",
    "    val.append(target_df)\n",
    "val = torch.stack(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs = convert_set_to_point_cloud(val[:1])\n",
    "pcs2 = convert_set_to_point_cloud(val[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0016])"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_mmd(pcs, pcs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c07b06cf854b4e888d79e6b8f2c53ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 5\n",
    "input_mesh = marching_cubes(samples[index].cpu().detach().numpy(), level=1)\n",
    "visualize_mesh(input_mesh[0], input_mesh[1], flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate n new samples\n",
    "n = 10\n",
    "samples = generate_samples('table_vad', n)\n",
    "samples = samples.squeeze(1)\n",
    "# convert_set_to_point_cloud(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd33410c3d30460da76090db6fd40007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 8\n",
    "input_mesh = marching_cubes(samples[index].detach().numpy(), level=1)\n",
    "visualize_mesh(input_mesh[0], input_mesh[1], flip_axes=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8edcb304c74d7de69396267fdd221ef1d3cdc7db9124f1020d58ca6af5038c14"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('adl4cv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

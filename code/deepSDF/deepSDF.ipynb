{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e44551f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import k3d\n",
    "import trimesh\n",
    "import torch\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c1d054d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec1c87a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.deepsdf import DeepSDFDecoder\n",
    "from util.model import summarize_model\n",
    "from training import train_deepsdf\n",
    "from data.shape_implicit import ShapeImplicit\n",
    "from util.visualization import visualize_mesh, visualize_pointcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7d63fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | Name      | Type           | Params \n",
      "-----------------------------------------------\n",
      "0  | layer1    | Sequential     | 790010 \n",
      "1  | layer1.0  | Linear         | 133632 \n",
      "2  | layer1.1  | Dropout        | 0      \n",
      "3  | layer1.2  | ReLU           | 0      \n",
      "4  | layer1.3  | Linear         | 263168 \n",
      "5  | layer1.4  | Dropout        | 0      \n",
      "6  | layer1.5  | ReLU           | 0      \n",
      "7  | layer1.6  | Linear         | 263168 \n",
      "8  | layer1.7  | Dropout        | 0      \n",
      "9  | layer1.8  | ReLU           | 0      \n",
      "10 | layer1.9  | Linear         | 130042 \n",
      "11 | layer1.10 | Dropout        | 0      \n",
      "12 | layer1.11 | ReLU           | 0      \n",
      "13 | layer2    | Sequential     | 1053186\n",
      "14 | layer2.0  | Linear         | 263168 \n",
      "15 | layer2.1  | Dropout        | 0      \n",
      "16 | layer2.2  | ReLU           | 0      \n",
      "17 | layer2.3  | Linear         | 263168 \n",
      "18 | layer2.4  | Dropout        | 0      \n",
      "19 | layer2.5  | ReLU           | 0      \n",
      "20 | layer2.6  | Linear         | 263168 \n",
      "21 | layer2.7  | Dropout        | 0      \n",
      "22 | layer2.8  | ReLU           | 0      \n",
      "23 | layer2.9  | Linear         | 263168 \n",
      "24 | layer2.10 | Dropout        | 0      \n",
      "25 | layer2.11 | ReLU           | 0      \n",
      "26 | layer2.12 | Linear         | 514    \n",
      "27 | TOTAL     | DeepSDFDecoder | 1843196\n",
      "\n",
      "Output tensor shape:  torch.Size([4096, 1])\n",
      "\n",
      "Number of traininable params: 1.84M\n"
     ]
    }
   ],
   "source": [
    "\n",
    "deepsdf = DeepSDFDecoder(latent_size=256)\n",
    "print(summarize_model(deepsdf))\n",
    "\n",
    "# input to the network is a concatenation of point coordinates (3) and the latent code (256 in this example);\n",
    "# here we use a batch of 4096 points\n",
    "input_tensor = torch.randn(4096, 3 + 256)\n",
    "predictions = deepsdf(input_tensor)\n",
    "\n",
    "print('\\nOutput tensor shape: ', predictions.shape)  # expected output: 4096, 1\n",
    "\n",
    "num_trainable_params = sum(p.numel() for p in deepsdf.parameters() if p.requires_grad) / 1e6\n",
    "print(f'\\nNumber of traininable params: {num_trainable_params:.2f}M')  # expected output: ~1.8M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53d5a1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "[049/00000] train_loss: 0.035846\n",
      "[099/00000] train_loss: 0.023321\n",
      "[149/00000] train_loss: 0.016326\n",
      "[199/00000] train_loss: 0.012821\n",
      "[249/00000] train_loss: 0.011374\n",
      "[299/00000] train_loss: 0.010310\n",
      "[349/00000] train_loss: 0.009544\n",
      "[399/00000] train_loss: 0.009031\n",
      "[449/00000] train_loss: 0.008525\n",
      "[499/00000] train_loss: 0.008322\n",
      "[549/00000] train_loss: 0.007706\n",
      "[599/00000] train_loss: 0.007494\n",
      "[649/00000] train_loss: 0.007348\n",
      "[699/00000] train_loss: 0.007253\n",
      "[749/00000] train_loss: 0.007096\n",
      "[799/00000] train_loss: 0.006998\n",
      "[849/00000] train_loss: 0.006862\n",
      "[899/00000] train_loss: 0.006766\n",
      "[949/00000] train_loss: 0.006676\n",
      "[999/00000] train_loss: 0.006567\n",
      "[1049/00000] train_loss: 0.006429\n",
      "[1099/00000] train_loss: 0.006371\n",
      "[1149/00000] train_loss: 0.006317\n",
      "[1199/00000] train_loss: 0.006258\n",
      "[1249/00000] train_loss: 0.006216\n",
      "[1299/00000] train_loss: 0.006166\n",
      "[1349/00000] train_loss: 0.006113\n",
      "[1399/00000] train_loss: 0.006058\n",
      "[1449/00000] train_loss: 0.006025\n",
      "[1499/00000] train_loss: 0.005960\n",
      "[1549/00000] train_loss: 0.005900\n",
      "[1599/00000] train_loss: 0.005872\n",
      "[1649/00000] train_loss: 0.005849\n",
      "[1699/00000] train_loss: 0.005817\n",
      "[1749/00000] train_loss: 0.005785\n",
      "[1799/00000] train_loss: 0.005762\n",
      "[1849/00000] train_loss: 0.005737\n",
      "[1899/00000] train_loss: 0.005721\n",
      "[1949/00000] train_loss: 0.005689\n",
      "[1999/00000] train_loss: 0.005655\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "overfit_config = {\n",
    "    'experiment_name': '3_2_deepsdf_overfit',\n",
    "    'device': 'cuda:0',  # change this to cpu if you do not have a GPU\n",
    "    'is_overfit': True,\n",
    "    'num_sample_points': 40000,\n",
    "    'latent_code_length': 256,\n",
    "    'batch_size': 16,\n",
    "    'resume_ckpt': None,\n",
    "    'learning_rate_model': 0.0005,\n",
    "    'learning_rate_code': 0.001,\n",
    "    'lambda_code_regularization': 0.0001,\n",
    "    'max_epochs': 2000,\n",
    "    'print_every_n': 50,\n",
    "    'visualize_every_n': 250,\n",
    "}\n",
    "\n",
    "train_deepsdf.main(overfit_config)  # expected loss around 0.0062"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31b241bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2cdc3c1b4504d6cb76a91d13708f6b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overfit\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7691a864f06a470db3b19eda7153f4c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and visualize GT mesh of the overfit sample\n",
    "gt_mesh = ShapeImplicit.get_mesh('7e728818848f191bee7d178666aae23d')\n",
    "print('GT')\n",
    "visualize_mesh(gt_mesh.vertices, gt_mesh.faces, flip_axes=True)\n",
    "\n",
    "# Load and visualize reconstructed overfit sample; it's okay if they don't look visually exact, since we don't run \n",
    "# the training too long and have a learning rate decay while training \n",
    "mesh_path = \"runs/3_2_deepsdf_overfit/meshes/01999_000.obj\"\n",
    "overfit_output = trimesh.load(mesh_path)\n",
    "print('Overfit')\n",
    "visualize_mesh(overfit_output.vertices, overfit_output.faces, flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4773b00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "[000/00049] train_loss: 0.038442\n",
      "[000/00099] train_loss: 0.035935\n",
      "[000/00149] train_loss: 0.033375\n",
      "[000/00199] train_loss: 0.033340\n",
      "[000/00249] train_loss: 0.032919\n",
      "[000/00299] train_loss: 0.032582\n",
      "[000/00349] train_loss: 0.033365\n",
      "[000/00399] train_loss: 0.031029\n",
      "[000/00449] train_loss: 0.032137\n",
      "[000/00499] train_loss: 0.030671\n",
      "[000/00549] train_loss: 0.031336\n",
      "[000/00599] train_loss: 0.032829\n",
      "[000/00649] train_loss: 0.031796\n",
      "[000/00699] train_loss: 0.032844\n",
      "[000/00749] train_loss: 0.031459\n",
      "[000/00799] train_loss: 0.031331\n",
      "[000/00849] train_loss: 0.032159\n",
      "[000/00899] train_loss: 0.030964\n",
      "[000/00949] train_loss: 0.032007\n",
      "[000/00999] train_loss: 0.033122\n",
      "[000/01049] train_loss: 0.031459\n",
      "[000/01099] train_loss: 0.031270\n",
      "[000/01149] train_loss: 0.032139\n",
      "[000/01199] train_loss: 0.031048\n",
      "[001/00023] train_loss: 0.031830\n",
      "[001/00073] train_loss: 0.032459\n",
      "[001/00123] train_loss: 0.031237\n",
      "[001/00173] train_loss: 0.030809\n",
      "[001/00223] train_loss: 0.030694\n",
      "[001/00273] train_loss: 0.030893\n",
      "[001/00323] train_loss: 0.031369\n",
      "[001/00373] train_loss: 0.030377\n",
      "[001/00423] train_loss: 0.029839\n",
      "[001/00473] train_loss: 0.029747\n",
      "[001/00523] train_loss: 0.030789\n",
      "[001/00573] train_loss: 0.031745\n",
      "[001/00623] train_loss: 0.031660\n",
      "[001/00673] train_loss: 0.029712\n",
      "[001/00723] train_loss: 0.030220\n",
      "[001/00773] train_loss: 0.030241\n",
      "[001/00823] train_loss: 0.031500\n",
      "[001/00873] train_loss: 0.031146\n",
      "[001/00923] train_loss: 0.030319\n",
      "[001/00973] train_loss: 0.031335\n",
      "[001/01023] train_loss: 0.030745\n",
      "[001/01073] train_loss: 0.030691\n",
      "[001/01123] train_loss: 0.030537\n",
      "[001/01173] train_loss: 0.029853\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_deepsdf\n\u001b[0;32m      3\u001b[0m generalization_config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexperiment_name\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3_2_deepsdf_generalization\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# run this on a gpu for a reasonable training time\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvisualize_every_n\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m5000\u001b[39m,\n\u001b[0;32m     17\u001b[0m }\n\u001b[1;32m---> 19\u001b[0m \u001b[43mtrain_deepsdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeneralization_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\excercises\\adl4cv\\deepSDF\\training\\train_deepsdf.py:166\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m    163\u001b[0m Path(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/runs/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmkdir(exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    165\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[1;32m--> 166\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_vectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\excercises\\adl4cv\\deepSDF\\training\\train_deepsdf.py:43\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, latent_vectors, train_dataloader, device, config)\u001b[0m\n\u001b[0;32m     39\u001b[0m best_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m---> 43\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[0;32m     44\u001b[0m         \u001b[38;5;66;03m# Move batch to device\u001b[39;00m\n\u001b[0;32m     45\u001b[0m         ShapeImplicit\u001b[38;5;241m.\u001b[39mmove_batch_to_device(batch, device)\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;66;03m# TODO: Zero out previously accumulated gradients\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\adl4cv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\adl4cv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    572\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\adl4cv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\adl4cv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\Desktop\\excercises\\adl4cv\\deepSDF\\data\\shape_implicit.py:46\u001b[0m, in \u001b[0;36mShapeImplicit.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     42\u001b[0m sdf_samples_path \u001b[38;5;241m=\u001b[39m ShapeImplicit\u001b[38;5;241m.\u001b[39mdataset_path \u001b[38;5;241m/\u001b[39m item \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msdf.npz\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# read points and their sdf values from disk\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# TODO: Implement the method get_sdf_samples\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m sdf_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_sdf_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43msdf_samples_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m points \u001b[38;5;241m=\u001b[39m sdf_samples[:, :\u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m     49\u001b[0m sdf \u001b[38;5;241m=\u001b[39m sdf_samples[:, \u001b[38;5;241m3\u001b[39m:]\n",
      "File \u001b[1;32m~\\Desktop\\excercises\\adl4cv\\deepSDF\\data\\shape_implicit.py:94\u001b[0m, in \u001b[0;36mShapeImplicit.get_sdf_samples\u001b[1;34m(self, path_to_sdf)\u001b[0m\n\u001b[0;32m     92\u001b[0m pos_num_int \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(pos_num[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     93\u001b[0m neg_num_int \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_sample_points \u001b[38;5;241m-\u001b[39m pos_num_int\n\u001b[1;32m---> 94\u001b[0m idx_pos \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpos_tensor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_num_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m idx_neg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(neg_tensor)), neg_num_int, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat([pos_tensor[idx_pos], neg_tensor[idx_neg]],dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from training import train_deepsdf\n",
    "\n",
    "generalization_config = {\n",
    "    'experiment_name': '3_2_deepsdf_generalization',\n",
    "    'device': 'cuda:0',  # run this on a gpu for a reasonable training time\n",
    "    'is_overfit': False,\n",
    "    'num_sample_points': 4096, # you can adjust this such that the model fits on your gpu\n",
    "    'latent_code_length': 256,\n",
    "    'batch_size': 1,\n",
    "    'resume_ckpt': None,\n",
    "    'learning_rate_model': 0.0005,\n",
    "    'learning_rate_code': 0.001,\n",
    "    'lambda_code_regularization': 0.0001,\n",
    "    'max_epochs': 2000,  # not necessary to run for 2000 epochs if you're short on time, at 500 epochs you should start to see reasonable results\n",
    "    'print_every_n': 50,\n",
    "    'visualize_every_n': 5000,\n",
    "}\n",
    "\n",
    "train_deepsdf.main(generalization_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef38fae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference.infer_deepsdf import InferenceHandlerDeepSDF\n",
    "\n",
    "device = torch.device('cuda:0') \n",
    "\n",
    "inference_handler = InferenceHandlerDeepSDF(256, \"runs/3_2_deepsdf_generalization\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da7de2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations with negative SDF (inside)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f057fa8e59194a739ba238b79b6e6c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations with positive SDF (outside)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74df868963b94e73bd2fc1aaf1118377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "points, sdf = ShapeImplicit.get_all_sdf_samples(\"b351e06f5826444c19fb4103277a6b93\")\n",
    "\n",
    "inside_points = points[sdf[:, 0] < 0, :].numpy()\n",
    "outside_points = points[sdf[:, 0] > 0, :].numpy()\n",
    "\n",
    "# visualize observed points; you'll observe that the observations are very complete\n",
    "print('Observations with negative SDF (inside)')\n",
    "visualize_pointcloud(inside_points, 0.025, flip_axes=True)\n",
    "print('Observations with positive SDF (outside)')\n",
    "visualize_pointcloud(outside_points, 0.025, flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00cd11f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00000] optim_loss: 0.031894\n",
      "[00050] optim_loss: 0.008029\n",
      "[00100] optim_loss: 0.006347\n",
      "[00150] optim_loss: 0.005890\n",
      "[00200] optim_loss: 0.005879\n",
      "[00250] optim_loss: 0.005604\n",
      "[00300] optim_loss: 0.005261\n",
      "[00350] optim_loss: 0.005147\n",
      "[00400] optim_loss: 0.005209\n",
      "[00450] optim_loss: 0.005113\n",
      "[00500] optim_loss: 0.004998\n",
      "[00550] optim_loss: 0.004825\n",
      "[00600] optim_loss: 0.004784\n",
      "[00650] optim_loss: 0.004640\n",
      "[00700] optim_loss: 0.004755\n",
      "[00750] optim_loss: 0.004710\n",
      "Optimization complete.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21f5c3b24a79416ea68456aeba9037f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reconstruct\n",
    "vertices, faces = inference_handler.reconstruct(points, sdf, 800)\n",
    "# visualize\n",
    "visualize_mesh(vertices, faces, flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcb797ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations with negative SDF (inside)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "840af40003704b4b847ca49c3eafb170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations with positive SDF (outside)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f09105c28ef42409cf4fcfd3655f86b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get observed data\n",
    "points, sdf = ShapeImplicit.get_all_sdf_samples(\"b351e06f5826444c19fb4103277a6b93_incomplete\")\n",
    "\n",
    "inside_points = points[sdf[:, 0] < 0, :].numpy()\n",
    "outside_points = points[sdf[:, 0] > 0, :].numpy()\n",
    "\n",
    "# visualize observed points; you'll observe that the observations are incomplete\n",
    "# making this is a shape completion task\n",
    "print('Observations with negative SDF (inside)')\n",
    "visualize_pointcloud(inside_points, 0.025, flip_axes=True)\n",
    "print('Observations with positive SDF (outside)')\n",
    "visualize_pointcloud(outside_points, 0.025, flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f0b8a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00000] optim_loss: 0.032641\n",
      "[00050] optim_loss: 0.008166\n",
      "[00100] optim_loss: 0.005987\n",
      "[00150] optim_loss: 0.005718\n",
      "[00200] optim_loss: 0.005049\n",
      "[00250] optim_loss: 0.004744\n",
      "[00300] optim_loss: 0.004648\n",
      "[00350] optim_loss: 0.004559\n",
      "[00400] optim_loss: 0.004415\n",
      "[00450] optim_loss: 0.004512\n",
      "[00500] optim_loss: 0.004287\n",
      "[00550] optim_loss: 0.004618\n",
      "[00600] optim_loss: 0.004271\n",
      "[00650] optim_loss: 0.004155\n",
      "[00700] optim_loss: 0.004162\n",
      "[00750] optim_loss: 0.004096\n",
      "Optimization complete.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f61b4567cf4240e5945d8ed9b6a4dc29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reconstruct\n",
    "vertices, faces = inference_handler.reconstruct(points, sdf, 800)\n",
    "# visualize\n",
    "visualize_mesh(vertices, faces, flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f86f2a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Shape A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baris\\anaconda3\\envs\\adl4cv\\lib\\site-packages\\traittypes\\traittypes.py:97: UserWarning: Given trait value dtype \"uint32\" does not match required type \"uint32\". A coerced copy has been created.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e9a8746b25d412082e019cbe379b019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Shape B\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45611b2b5ce74ed3ab3769afeed6a71c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data.shape_implicit import ShapeImplicit\n",
    "from util.visualization import visualize_mesh\n",
    "\n",
    "mesh = ShapeImplicit.get_mesh(\"494fe53da65650b8c358765b76c296\")\n",
    "print('GT Shape A')\n",
    "visualize_mesh(mesh.vertices, mesh.faces, flip_axes=True)\n",
    "\n",
    "mesh = ShapeImplicit.get_mesh(\"5ca1ef55ff5f68501921e7a85cf9da35\")\n",
    "print('GT Shape B')\n",
    "visualize_mesh(mesh.vertices, mesh.faces, flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd890103",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference.infer_deepsdf import InferenceHandlerDeepSDF\n",
    "\n",
    "inference_handler = InferenceHandlerDeepSDF(256, \"runs/3_2_deepsdf_generalization\", torch.device('cuda:0'))\n",
    "# interpolate; also exports interpolated meshes to disk\n",
    "inference_handler.interpolate('494fe53da65650b8c358765b76c296', '5ca1ef55ff5f68501921e7a85cf9da35', 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bf4fe76",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyrender'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmesh_collection_to_gif\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m  meshes_to_gif\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_gif\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# create list of meshes (just exported) to be visualized\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\excercises\\adl4cv\\deepSDF\\util\\mesh_collection_to_gif.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyrender\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtrimesh\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvideo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mImageSequenceClip\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageSequenceClip\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyrender'"
     ]
    }
   ],
   "source": [
    "from util.mesh_collection_to_gif import  meshes_to_gif\n",
    "from util.misc import show_gif\n",
    "\n",
    "# create list of meshes (just exported) to be visualized\n",
    "mesh_paths = sorted([x for x in Path(\"/runs/3_2_deepsdf_generalization/interpolation\").iterdir() if int(x.name.split('.')[0].split(\"_\")[1]) == 0], key=lambda x: int(x.name.split('.')[0].split(\"_\")[0]))\n",
    "mesh_paths = mesh_paths + mesh_paths[::-1]\n",
    "\n",
    "# create a visualization of the interpolation process\n",
    "meshes_to_gif(mesh_paths, \"exercise_3/runs/3_2_deepsdf_generalization/latent_interp.gif\", 20)\n",
    "show_gif(\"exercise_3/runs/3_2_deepsdf_generalization/latent_interp.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe22e95b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

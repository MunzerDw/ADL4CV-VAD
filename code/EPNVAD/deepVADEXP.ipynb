{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "658cfe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import k3d\n",
    "import trimesh\n",
    "import torch\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec76e905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | Name         | Type             | Params  \n",
      "-----------------------------------------------------\n",
      "0  | bottleneck   | Sequential       | 263168  \n",
      "1  | bottleneck.0 | Linear           | 65792   \n",
      "2  | bottleneck.1 | ReLU             | 0       \n",
      "3  | bottleneck.2 | Linear           | 65792   \n",
      "4  | bottleneck.3 | ReLU             | 0       \n",
      "5  | bottleneck.4 | Linear           | 131584  \n",
      "6  | bottleneck.5 | ReLU             | 0       \n",
      "7  | decoder1     | Sequential       | 8389376 \n",
      "8  | decoder1.0   | ConvTranspose3d  | 8388864 \n",
      "9  | decoder1.1   | BatchNorm3d      | 512     \n",
      "10 | decoder1.2   | ReLU             | 0       \n",
      "11 | decoder2     | Sequential       | 2097536 \n",
      "12 | decoder2.0   | ConvTranspose3d  | 2097280 \n",
      "13 | decoder2.1   | BatchNorm3d      | 256     \n",
      "14 | decoder2.2   | ReLU             | 0       \n",
      "15 | decoder3     | Sequential       | 524480  \n",
      "16 | decoder3.0   | ConvTranspose3d  | 524352  \n",
      "17 | decoder3.1   | BatchNorm3d      | 128     \n",
      "18 | decoder3.2   | ReLU             | 0       \n",
      "19 | decoder4     | Sequential       | 4097    \n",
      "20 | decoder4.0   | ConvTranspose3d  | 4097    \n",
      "21 | TOTAL        | ThreeDEPNDecoder | 11278657\n",
      "torch.Size([16, 256])\n",
      "Output tensor shape:  torch.Size([16, 32, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "from exercise_3.model.threedepn import ThreeDEPNDecoder\n",
    "from exercise_3.util.model import summarize_model\n",
    "\n",
    "threedepn = ThreeDEPNDecoder()\n",
    "print(summarize_model(threedepn))  # Expected: Rows 0-34 and TOTAL = 52455681\n",
    "\n",
    "latent = torch.randn(16,256)\n",
    "print(latent.shape)\n",
    "predictions = threedepn(latent)\n",
    "\n",
    "print('Output tensor shape: ', predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6302227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train set: 153540\n",
      "Length of val set: 32304\n",
      "Length of overfit set: 64\n"
     ]
    }
   ],
   "source": [
    "from exercise_3.data.shapenet import ShapeNet\n",
    "\n",
    "# Create a dataset with train split\n",
    "train_dataset = ShapeNet('train')\n",
    "val_dataset = ShapeNet('val')\n",
    "overfit_dataset = ShapeNet('overfit')\n",
    "\n",
    "# Get length, which is a call to __len__ function\n",
    "print(f'Length of train set: {len(train_dataset)}')  # expected output: 153540\n",
    "# Get length, which is a call to __len__ function\n",
    "print(f'Length of val set: {len(val_dataset)}')  # expected output: 32304\n",
    "# Get length, which is a call to __len__ function\n",
    "print(f'Length of overfit set: {len(overfit_dataset)}')  # expected output: 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b9dc15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target DF: (32, 32, 32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32bebc357ac24f9e8a50c1329027e4f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from exercise_3.util.visualization import visualize_mesh\n",
    "from skimage.measure import marching_cubes\n",
    "\n",
    "train_sample = train_dataset[1]\n",
    "#print(f'Name: {train_sample[\"name\"]}')  # expected output: 03001627/798a46965d9e0edfcea003eff0268278__3__-03001627/798a46965d9e0edfcea003eff0268278__0__\n",
    "#print(f'Input SDF: {train_sample[\"input_sdf\"].shape}')  # expected output: (2, 32, 32, 32)\n",
    "print(f'Target DF: {train_sample[\"target_df\"].shape}')  # expected output: (32, 32, 32)\n",
    "\n",
    "input_mesh = marching_cubes(train_sample['target_df'], level=1)\n",
    "#print(input_mesh)\n",
    "visualize_mesh(input_mesh[0], input_mesh[1], flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e7a48ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target DF: (32, 32, 32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e9976b333174bdd9583eb91eca9efe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from exercise_3.util.visualization import visualize_mesh\n",
    "from skimage.measure import marching_cubes\n",
    "\n",
    "train_sample = overfit_dataset[60]\n",
    "#print(f'Name: {train_sample[\"name\"]}')  # expected output: 03001627/798a46965d9e0edfcea003eff0268278__3__-03001627/798a46965d9e0edfcea003eff0268278__0__\n",
    "#print(f'Input SDF: {train_sample[\"input_sdf\"].shape}')  # expected output: (2, 32, 32, 32)\n",
    "print(f'Target DF: {train_sample[\"target_df\"].shape}')  # expected output: (32, 32, 32)\n",
    "\n",
    "input_mesh = marching_cubes(train_sample['target_df'], level=1)\n",
    "#print(input_mesh)\n",
    "visualize_mesh(input_mesh[0], input_mesh[1], flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bf3e571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "[004/00001] train_loss: 0.603385 kl_loss: 0.474221 normal_loss: 0.129164\n",
      "[009/00001] train_loss: 0.461389 kl_loss: 0.422513 normal_loss: 0.038876\n",
      "[014/00001] train_loss: 0.397052 kl_loss: 0.376322 normal_loss: 0.020729\n",
      "[019/00001] train_loss: 0.348126 kl_loss: 0.335189 normal_loss: 0.012936\n",
      "[024/00001] train_loss: 0.315695 kl_loss: 0.306336 normal_loss: 0.009360\n",
      "[029/00001] train_loss: 0.297063 kl_loss: 0.289356 normal_loss: 0.007707\n",
      "[034/00001] train_loss: 0.279856 kl_loss: 0.273371 normal_loss: 0.006485\n",
      "[039/00001] train_loss: 0.263844 kl_loss: 0.258261 normal_loss: 0.005583\n",
      "[044/00001] train_loss: 0.252087 kl_loss: 0.247060 normal_loss: 0.005027\n",
      "[049/00001] train_loss: 0.244861 kl_loss: 0.240142 normal_loss: 0.004719\n",
      "[054/00001] train_loss: 0.237838 kl_loss: 0.233395 normal_loss: 0.004443\n",
      "[059/00001] train_loss: 0.231006 kl_loss: 0.226813 normal_loss: 0.004193\n",
      "[064/00001] train_loss: 0.225806 kl_loss: 0.221803 normal_loss: 0.004003\n",
      "[069/00001] train_loss: 0.222515 kl_loss: 0.218630 normal_loss: 0.003886\n",
      "[074/00001] train_loss: 0.219260 kl_loss: 0.215490 normal_loss: 0.003770\n",
      "[079/00001] train_loss: 0.216035 kl_loss: 0.212377 normal_loss: 0.003658\n",
      "[084/00001] train_loss: 0.213540 kl_loss: 0.209976 normal_loss: 0.003563\n",
      "[089/00001] train_loss: 0.211951 kl_loss: 0.208441 normal_loss: 0.003510\n",
      "[094/00001] train_loss: 0.210369 kl_loss: 0.206908 normal_loss: 0.003461\n",
      "[099/00001] train_loss: 0.208780 kl_loss: 0.205380 normal_loss: 0.003400\n"
     ]
    }
   ],
   "source": [
    "from exercise_3.training import train_3depn_vad\n",
    "config = {\n",
    "    'experiment_name': '3_1_3depn_overfitting',\n",
    "    'device': 'cuda:0',  # change this to cpu if you do not have a GPU\n",
    "    'is_overfit': True,\n",
    "    'batch_size': 32,\n",
    "    'resume_ckpt': None,\n",
    "    'learning_rate_model': 0.01,\n",
    "    'learning_rate_code': 0.01,\n",
    "    'learning_rate_log_var':0.01,\n",
    "    'max_epochs': 250,\n",
    "    'print_every_n': 10,\n",
    "    'validate_every_n': 250,\n",
    "    'latent_code_length' : 256,\n",
    "    'vad_free' : True,\n",
    "    'kl_weight': 1\n",
    "\n",
    "}\n",
    "train_3depn_vad.main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "758dd9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4780e+00,  1.8334e+00, -4.5796e-01, -1.5467e+00,  8.1558e-01,\n",
      "         -3.4728e+00,  4.2831e-01, -2.6861e+00,  1.2894e+00, -3.4587e-01,\n",
      "         -1.1912e+00,  7.7967e-01, -6.8007e-01, -1.7917e+00, -4.5616e-01,\n",
      "          6.6990e-01,  1.7780e-01,  1.3631e-01, -3.6798e-01, -2.1832e-01,\n",
      "         -1.6601e+00,  1.0758e+00, -2.6007e+00,  6.0293e-01, -7.6131e-01,\n",
      "          1.8696e+00, -1.0097e+00, -4.5246e-01, -3.8259e-01,  5.3534e-02,\n",
      "         -4.0509e-01, -1.7333e+00, -5.0495e-01, -5.3440e-01, -3.0962e+00,\n",
      "          9.0052e-01, -4.4318e-01, -5.2586e-01, -1.3770e+00,  3.6186e-01,\n",
      "          2.6785e+00, -1.8695e+00, -1.2665e+00, -6.0516e-01,  2.0079e+00,\n",
      "          1.2437e+00, -5.9270e-01,  1.9756e+00,  1.5126e+00, -9.0876e-02,\n",
      "          7.8496e-01, -1.5695e+00,  6.3331e-01,  1.6450e+00,  6.1957e-01,\n",
      "          1.6435e+00, -1.5387e+00, -4.4077e-02,  8.5214e-01,  1.0975e+00,\n",
      "         -5.5297e-01, -1.6584e+00,  1.2035e+00,  6.7995e-01, -1.3309e+00,\n",
      "          2.0231e+00, -2.7912e+00, -8.4536e-01, -1.3486e-01,  3.0253e+00,\n",
      "         -1.7851e+00, -9.4984e-01,  1.4989e+00,  9.7750e-01,  1.1964e+00,\n",
      "          4.1614e-01,  2.5503e+00,  3.4211e+00,  7.3268e-01, -2.6066e-01,\n",
      "         -2.6127e+00,  8.4597e-04, -1.3256e+00,  2.7273e+00, -2.5349e+00,\n",
      "         -3.4253e-01, -1.2291e+00,  8.6898e-01,  4.1500e-01,  1.5498e+00,\n",
      "          8.1705e-01, -1.2485e+00,  4.2027e-01, -1.6873e+00, -1.4843e+00,\n",
      "         -2.3678e+00,  1.4672e+00,  1.1243e-01,  1.7174e+00, -3.6757e-01,\n",
      "          1.0791e-01,  1.7477e+00,  1.3964e-01,  1.3543e+00,  5.1919e-01,\n",
      "         -4.2231e-01, -2.0130e+00, -1.4868e+00, -2.3850e+00,  1.2325e+00,\n",
      "         -1.7556e+00, -4.2337e-01, -1.9904e+00,  8.5771e-01, -2.5820e+00,\n",
      "         -1.3361e+00,  9.7219e-01, -1.0984e+00,  6.2801e-01,  4.8978e-01,\n",
      "         -1.4899e+00,  3.3197e-01, -5.9992e-01,  2.8851e+00, -3.8184e-01,\n",
      "          1.0452e+00,  1.2819e+00, -7.1695e-01, -1.6043e-01, -1.4815e-02,\n",
      "         -3.1057e+00,  1.6656e+00, -1.2367e+00, -3.5183e+00,  7.3900e-01,\n",
      "         -1.0566e+00,  3.4012e-01, -6.8234e-01, -1.3447e+00,  1.3372e+00,\n",
      "         -1.0691e+00,  5.2894e-01,  5.4655e-01, -9.7224e-01,  1.5701e-03,\n",
      "          9.0512e-01, -2.2877e+00,  9.0128e-01,  1.0354e+00, -2.2760e+00,\n",
      "         -2.7442e-01,  2.0699e+00,  1.3877e+00,  4.7349e-01, -1.2056e-01,\n",
      "          5.0211e-02, -8.7944e-01,  5.3856e-01,  5.0128e-01, -4.9657e-02,\n",
      "          5.2021e-01,  9.9382e-01,  9.3084e-01,  1.9213e+00, -8.9088e-01,\n",
      "          1.6235e+00, -6.3877e-01,  1.8735e+00,  5.4388e-01,  3.2837e+00,\n",
      "          1.2245e+00,  1.5988e+00, -9.9597e-01, -1.9041e+00,  4.9108e-01,\n",
      "         -3.9922e-01, -3.8408e-01,  1.5870e+00,  1.3415e+00, -4.1211e-02,\n",
      "         -1.2299e+00, -9.5270e-01,  1.8943e+00, -5.5559e-01, -1.0278e+00,\n",
      "          2.0315e+00,  3.6579e+00,  1.3908e+00, -2.2782e+00,  1.7758e+00,\n",
      "          1.7634e+00, -2.7264e-01, -1.2370e+00,  9.9840e-01, -1.1033e+00,\n",
      "         -7.8176e-01, -1.5409e-01,  1.5884e+00, -3.2076e+00,  3.2797e-01,\n",
      "          3.1540e+00, -1.8231e+00, -1.1759e+00, -2.7824e+00,  3.8660e-01,\n",
      "         -1.4382e+00, -2.5640e-01,  1.7058e-01,  2.9509e-01,  1.4169e+00,\n",
      "          1.7782e+00,  9.1267e-01, -1.1329e+00,  7.5715e-01,  2.5731e-01,\n",
      "         -1.1912e+00, -1.7236e+00, -1.1123e+00,  1.5729e+00,  1.0226e+00,\n",
      "          2.9063e-02, -5.4655e-02,  2.6830e+00,  1.0642e+00,  1.0882e+00,\n",
      "          1.0761e+00,  9.6497e-01,  1.6504e+00, -1.1598e+00,  7.2222e-01,\n",
      "         -5.0674e-01,  4.0250e-01,  4.6364e-01, -1.1373e-01,  1.9274e+00,\n",
      "         -1.2255e+00,  1.1700e-01,  1.2481e-01, -1.8887e+00,  6.3376e-01,\n",
      "          1.2095e+00, -7.0034e-01,  1.0768e+00,  1.3478e+00, -5.7125e-01,\n",
      "          5.7530e-01, -8.0646e-01, -2.7425e+00,  9.8468e-01,  2.3566e+00,\n",
      "         -5.7639e-01,  1.3064e+00,  8.1543e-01, -1.2217e+00,  1.5314e+00,\n",
      "         -1.2984e+00]], grad_fn=<UnsqueezeBackward0>)\n",
      "torch.Size([1, 32, 32, 32])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a1dbf5a2d634475a4440c4c469a4002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from exercise_3.util.visualization import visualize_mesh\n",
    "from skimage.measure import marching_cubes\n",
    "import torch.distributions as dist\n",
    "model = ThreeDEPNDecoder()\n",
    "model.load_state_dict(torch.load('exercise_3/runs/3_1_3depn_overfitting/' + \"model_best.ckpt\", map_location='cpu'))\n",
    "latent_vectors = torch.load('exercise_3/runs/3_1_3depn_overfitting/latent_best.ckpt', map_location = 'cpu')\n",
    "log_vars = torch.load('exercise_3/runs/3_1_3depn_overfitting/log_var_best.pt', map_location = 'cpu')\n",
    "Dist = dist.Normal(latent_vectors[0], torch.exp(log_vars[0]))\n",
    "x_vad = Dist.rsample().unsqueeze(0)\n",
    "print(x_vad)\n",
    "output_meshes = model(x_vad)\n",
    "print(output_meshes.shape)\n",
    "output_mesh = marching_cubes(output_meshes[0].detach().numpy(), level=1)\n",
    "visualize_mesh(output_mesh[0], output_mesh[1], flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6413c2db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "[000/00099] train_loss: 5.043805 kl_loss: 0.500034 normal_loss: 0.043467\n",
      "[000/00199] train_loss: 5.032662 kl_loss: 0.500567 normal_loss: 0.026997\n",
      "[000/00299] train_loss: 5.031036 kl_loss: 0.500432 normal_loss: 0.026718\n",
      "[000/00399] train_loss: 5.019615 kl_loss: 0.499309 normal_loss: 0.026521\n",
      "[000/00499] train_loss: 5.027519 kl_loss: 0.500075 normal_loss: 0.026773\n",
      "[000/00599] train_loss: 5.023463 kl_loss: 0.499668 normal_loss: 0.026786\n",
      "[000/00699] train_loss: 5.026794 kl_loss: 0.500020 normal_loss: 0.026598\n",
      "[000/00799] train_loss: 5.023679 kl_loss: 0.499737 normal_loss: 0.026304\n",
      "[000/00899] train_loss: 5.022270 kl_loss: 0.499591 normal_loss: 0.026356\n",
      "[000/00999] train_loss: 5.021141 kl_loss: 0.499511 normal_loss: 0.026030\n",
      "[000/01099] train_loss: 5.029538 kl_loss: 0.500373 normal_loss: 0.025806\n",
      "[000/01199] train_loss: 5.022107 kl_loss: 0.499605 normal_loss: 0.026054\n",
      "[000/01299] train_loss: 5.022349 kl_loss: 0.499677 normal_loss: 0.025584\n",
      "[000/01399] train_loss: 5.032252 kl_loss: 0.500563 normal_loss: 0.026624\n",
      "[000/01499] train_loss: 5.019293 kl_loss: 0.499245 normal_loss: 0.026839\n",
      "[000/01599] train_loss: 5.020547 kl_loss: 0.499482 normal_loss: 0.025724\n",
      "[000/01699] train_loss: 5.045469 kl_loss: 0.501898 normal_loss: 0.026484\n",
      "[000/01799] train_loss: 5.023959 kl_loss: 0.499754 normal_loss: 0.026423\n",
      "[000/01899] train_loss: 5.026786 kl_loss: 0.500044 normal_loss: 0.026349\n",
      "[000/01999] train_loss: 5.025082 kl_loss: 0.499888 normal_loss: 0.026205\n",
      "[000/02099] train_loss: 5.024884 kl_loss: 0.499905 normal_loss: 0.025832\n",
      "[000/02199] train_loss: 5.024167 kl_loss: 0.499737 normal_loss: 0.026798\n",
      "[000/02299] train_loss: 5.030193 kl_loss: 0.500326 normal_loss: 0.026935\n",
      "[000/02399] train_loss: 5.027794 kl_loss: 0.500169 normal_loss: 0.026106\n",
      "[000/02499] train_loss: 5.022805 kl_loss: 0.499643 normal_loss: 0.026379\n",
      "[000/02599] train_loss: 5.033121 kl_loss: 0.500661 normal_loss: 0.026515\n",
      "[000/02699] train_loss: 5.012503 kl_loss: 0.498592 normal_loss: 0.026586\n",
      "[000/02799] train_loss: 5.026384 kl_loss: 0.500011 normal_loss: 0.026275\n",
      "[000/02899] train_loss: 5.018386 kl_loss: 0.499195 normal_loss: 0.026439\n",
      "[000/02999] train_loss: 5.031149 kl_loss: 0.500432 normal_loss: 0.026825\n",
      "[000/03099] train_loss: 5.030419 kl_loss: 0.500407 normal_loss: 0.026352\n",
      "[000/03199] train_loss: 5.029804 kl_loss: 0.500377 normal_loss: 0.026034\n",
      "[000/03299] train_loss: 5.024431 kl_loss: 0.499877 normal_loss: 0.025656\n",
      "[000/03399] train_loss: 5.014558 kl_loss: 0.498857 normal_loss: 0.025986\n",
      "[000/03499] train_loss: 5.033374 kl_loss: 0.500704 normal_loss: 0.026335\n",
      "[000/03599] train_loss: 5.035091 kl_loss: 0.500897 normal_loss: 0.026124\n",
      "[000/03699] train_loss: 5.025986 kl_loss: 0.500011 normal_loss: 0.025872\n",
      "[000/03799] train_loss: 5.019681 kl_loss: 0.499338 normal_loss: 0.026303\n",
      "[000/03899] train_loss: 5.037830 kl_loss: 0.501145 normal_loss: 0.026385\n",
      "[000/03999] train_loss: 5.025112 kl_loss: 0.499944 normal_loss: 0.025669\n",
      "[000/04099] train_loss: 5.037915 kl_loss: 0.501173 normal_loss: 0.026181\n",
      "[000/04199] train_loss: 5.041818 kl_loss: 0.501642 normal_loss: 0.025394\n",
      "[000/04299] train_loss: 5.026254 kl_loss: 0.500007 normal_loss: 0.026185\n",
      "[000/04399] train_loss: 5.027272 kl_loss: 0.500076 normal_loss: 0.026511\n",
      "[000/04499] train_loss: 5.029202 kl_loss: 0.500337 normal_loss: 0.025829\n",
      "[000/04599] train_loss: 5.019492 kl_loss: 0.499285 normal_loss: 0.026642\n",
      "[000/04699] train_loss: 5.032617 kl_loss: 0.500649 normal_loss: 0.026126\n",
      "[001/00000] train_loss: 5.011825 kl_loss: 0.498533 normal_loss: 0.026491\n",
      "[001/00100] train_loss: 3.258085 kl_loss: 0.323181 normal_loss: 0.026278\n",
      "[001/00200] train_loss: 3.256711 kl_loss: 0.323075 normal_loss: 0.025966\n",
      "[001/00300] train_loss: 3.276470 kl_loss: 0.325006 normal_loss: 0.026407\n",
      "[001/00400] train_loss: 3.271502 kl_loss: 0.324545 normal_loss: 0.026055\n",
      "[001/00500] train_loss: 3.255795 kl_loss: 0.323042 normal_loss: 0.025372\n",
      "[001/00600] train_loss: 3.268606 kl_loss: 0.324226 normal_loss: 0.026347\n",
      "[001/00700] train_loss: 3.266445 kl_loss: 0.323967 normal_loss: 0.026777\n",
      "[001/00800] train_loss: 3.265742 kl_loss: 0.323983 normal_loss: 0.025916\n",
      "[001/00900] train_loss: 3.256395 kl_loss: 0.323043 normal_loss: 0.025967\n",
      "[001/01000] train_loss: 3.267490 kl_loss: 0.324134 normal_loss: 0.026152\n",
      "[001/01100] train_loss: 3.274272 kl_loss: 0.324831 normal_loss: 0.025961\n",
      "[001/01200] train_loss: 3.276260 kl_loss: 0.325012 normal_loss: 0.026145\n",
      "[001/01300] train_loss: 3.274635 kl_loss: 0.324802 normal_loss: 0.026613\n",
      "[001/01400] train_loss: 3.283070 kl_loss: 0.325679 normal_loss: 0.026278\n",
      "[001/01500] train_loss: 3.257524 kl_loss: 0.323134 normal_loss: 0.026186\n",
      "[001/01600] train_loss: 3.248021 kl_loss: 0.322193 normal_loss: 0.026091\n",
      "[001/01700] train_loss: 3.261188 kl_loss: 0.323533 normal_loss: 0.025862\n",
      "[001/01800] train_loss: 3.263670 kl_loss: 0.323732 normal_loss: 0.026346\n",
      "[001/01900] train_loss: 3.264932 kl_loss: 0.323855 normal_loss: 0.026382\n",
      "[001/02000] train_loss: 3.275287 kl_loss: 0.324847 normal_loss: 0.026814\n",
      "[001/02100] train_loss: 3.261967 kl_loss: 0.323546 normal_loss: 0.026505\n",
      "[001/02200] train_loss: 3.266379 kl_loss: 0.323980 normal_loss: 0.026582\n",
      "[001/02300] train_loss: 3.263703 kl_loss: 0.323757 normal_loss: 0.026129\n",
      "[001/02400] train_loss: 3.260587 kl_loss: 0.323443 normal_loss: 0.026152\n",
      "[001/02500] train_loss: 3.255386 kl_loss: 0.322913 normal_loss: 0.026255\n",
      "[001/02600] train_loss: 3.259764 kl_loss: 0.323418 normal_loss: 0.025588\n",
      "[001/02700] train_loss: 3.268265 kl_loss: 0.324215 normal_loss: 0.026116\n",
      "[001/02800] train_loss: 3.257617 kl_loss: 0.323112 normal_loss: 0.026498\n",
      "[001/02900] train_loss: 3.270912 kl_loss: 0.324504 normal_loss: 0.025871\n",
      "[001/03000] train_loss: 3.275458 kl_loss: 0.324982 normal_loss: 0.025638\n",
      "[001/03100] train_loss: 3.253768 kl_loss: 0.322732 normal_loss: 0.026445\n",
      "[001/03200] train_loss: 3.265645 kl_loss: 0.323984 normal_loss: 0.025806\n",
      "[001/03300] train_loss: 3.283000 kl_loss: 0.325687 normal_loss: 0.026134\n",
      "[001/03400] train_loss: 3.268631 kl_loss: 0.324269 normal_loss: 0.025938\n",
      "[001/03500] train_loss: 3.266062 kl_loss: 0.324019 normal_loss: 0.025876\n",
      "[001/03600] train_loss: 3.250359 kl_loss: 0.322404 normal_loss: 0.026316\n",
      "[001/03700] train_loss: 3.268009 kl_loss: 0.324179 normal_loss: 0.026217\n",
      "[001/03800] train_loss: 3.273049 kl_loss: 0.324683 normal_loss: 0.026218\n",
      "[001/03900] train_loss: 3.265794 kl_loss: 0.323881 normal_loss: 0.026979\n",
      "[001/04000] train_loss: 3.251786 kl_loss: 0.322577 normal_loss: 0.026014\n",
      "[001/04100] train_loss: 3.268313 kl_loss: 0.324210 normal_loss: 0.026213\n",
      "[001/04200] train_loss: 3.266606 kl_loss: 0.324019 normal_loss: 0.026414\n",
      "[001/04300] train_loss: 3.254942 kl_loss: 0.322875 normal_loss: 0.026188\n",
      "[001/04400] train_loss: 3.266607 kl_loss: 0.324089 normal_loss: 0.025719\n",
      "[001/04500] train_loss: 3.260841 kl_loss: 0.323440 normal_loss: 0.026439\n",
      "[001/04600] train_loss: 3.255673 kl_loss: 0.322989 normal_loss: 0.025782\n",
      "[001/04700] train_loss: 3.252289 kl_loss: 0.322612 normal_loss: 0.026169\n",
      "[002/00001] train_loss: 3.262591 kl_loss: 0.323667 normal_loss: 0.025917\n",
      "[002/00101] train_loss: 2.569271 kl_loss: 0.254311 normal_loss: 0.026164\n",
      "[002/00201] train_loss: 2.566513 kl_loss: 0.253993 normal_loss: 0.026581\n",
      "[002/00301] train_loss: 2.578392 kl_loss: 0.255237 normal_loss: 0.026024\n",
      "[002/00401] train_loss: 2.573759 kl_loss: 0.254776 normal_loss: 0.026002\n",
      "[002/00501] train_loss: 2.564812 kl_loss: 0.253857 normal_loss: 0.026247\n",
      "[002/00601] train_loss: 2.571960 kl_loss: 0.254594 normal_loss: 0.026020\n",
      "[002/00701] train_loss: 2.563037 kl_loss: 0.253716 normal_loss: 0.025873\n",
      "[002/00801] train_loss: 2.576061 kl_loss: 0.254982 normal_loss: 0.026245\n",
      "[002/00901] train_loss: 2.579573 kl_loss: 0.255289 normal_loss: 0.026683\n",
      "[002/01001] train_loss: 2.565124 kl_loss: 0.253816 normal_loss: 0.026963\n",
      "[002/01101] train_loss: 2.565592 kl_loss: 0.253912 normal_loss: 0.026475\n",
      "[002/01201] train_loss: 2.571231 kl_loss: 0.254485 normal_loss: 0.026380\n",
      "[002/01301] train_loss: 2.569069 kl_loss: 0.254313 normal_loss: 0.025938\n",
      "[002/01401] train_loss: 2.573856 kl_loss: 0.254766 normal_loss: 0.026193\n",
      "[002/01501] train_loss: 2.587436 kl_loss: 0.256136 normal_loss: 0.026075\n",
      "[002/01601] train_loss: 2.564966 kl_loss: 0.253944 normal_loss: 0.025521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[002/01701] train_loss: 2.579668 kl_loss: 0.255378 normal_loss: 0.025891\n",
      "[002/01801] train_loss: 2.565586 kl_loss: 0.254031 normal_loss: 0.025271\n",
      "[002/01901] train_loss: 2.571496 kl_loss: 0.254549 normal_loss: 0.026007\n",
      "[002/02001] train_loss: 2.571892 kl_loss: 0.254605 normal_loss: 0.025843\n",
      "[002/02101] train_loss: 2.568492 kl_loss: 0.254203 normal_loss: 0.026462\n",
      "[002/02201] train_loss: 2.574309 kl_loss: 0.254866 normal_loss: 0.025646\n",
      "[002/02301] train_loss: 2.571493 kl_loss: 0.254540 normal_loss: 0.026093\n",
      "[002/02401] train_loss: 2.578455 kl_loss: 0.255224 normal_loss: 0.026217\n",
      "[002/02501] train_loss: 2.572784 kl_loss: 0.254675 normal_loss: 0.026033\n",
      "[002/02601] train_loss: 2.574578 kl_loss: 0.254817 normal_loss: 0.026409\n",
      "[002/02701] train_loss: 2.568913 kl_loss: 0.254264 normal_loss: 0.026269\n",
      "[002/02801] train_loss: 2.573739 kl_loss: 0.254772 normal_loss: 0.026017\n",
      "[002/02901] train_loss: 2.576430 kl_loss: 0.255012 normal_loss: 0.026311\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexercise_3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_3depn_vad\n\u001b[0;32m      2\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexperiment_name\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3_1_3depn_generalization\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# change this to cpu if you do not have a GPU\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m }\n\u001b[1;32m---> 19\u001b[0m \u001b[43mtrain_3depn_vad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\excercises\\adl4cv\\03748560\\E3\\exercise_3\\training\\train_3depn_vad.py:163\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m    160\u001b[0m Path(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexercise_3/runs/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmkdir(exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    162\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[1;32m--> 163\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_vectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_log_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\excercises\\adl4cv\\03748560\\E3\\exercise_3\\training\\train_3depn_vad.py:74\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_dataloader, val_dataloader, latent_vectors, latent_log_var, device, config)\u001b[0m\n\u001b[0;32m     72\u001b[0m kl_loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(dist\u001b[38;5;241m.\u001b[39mkl_divergence(Dist, q_z))\n\u001b[0;32m     73\u001b[0m loss \u001b[38;5;241m=\u001b[39m init_loss \u001b[38;5;241m+\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkl_weight\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m kl_loss\n\u001b[1;32m---> 74\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# Logging\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\adl4cv\\lib\\site-packages\\torch\\_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\adl4cv\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from exercise_3.training import train_3depn_vad\n",
    "config = {\n",
    "    'experiment_name': '3_1_3depn_generalization',\n",
    "    'device': 'cuda:0',  # change this to cpu if you do not have a GPU\n",
    "    'is_overfit': False,\n",
    "    'batch_size': 32,\n",
    "    'resume_ckpt': None,\n",
    "    'learning_rate_model': 0.01,\n",
    "    'learning_rate_code': 0.01,\n",
    "    'learning_rate_log_var':0.01,\n",
    "    'max_epochs': 100,\n",
    "    'print_every_n': 100,\n",
    "    'validate_every_n': 250,\n",
    "    'latent_code_length' : 256,\n",
    "    'vad_free' : True,\n",
    "    'kl_weight': 10\n",
    "\n",
    "}\n",
    "train_3depn_vad.main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4cf355e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6584, -0.2321,  0.1266, -0.3753, -0.1055, -0.7185,  1.4486,  1.2286,\n",
      "          1.1191, -1.2339,  0.8722, -1.1335, -0.9018, -1.0980, -0.6786,  0.9741,\n",
      "          0.1818,  0.3132, -1.3102, -0.7462,  0.3455, -0.6517,  0.0623,  1.3077,\n",
      "          0.9696,  2.8295,  2.1062, -2.5235,  0.4273, -1.4153, -0.6763,  0.7307,\n",
      "         -0.2005,  1.4036,  0.3231, -0.4166, -2.8169, -0.8324, -0.0398, -0.8676,\n",
      "          1.3576, -1.2660,  0.6033,  1.1655,  0.2042, -0.6970, -0.9532, -0.4612,\n",
      "         -0.0757, -0.1920, -2.7722,  2.1989, -0.5961,  1.7815, -0.3403, -1.7410,\n",
      "          0.4649,  2.2596, -1.7369, -1.3083,  0.5284,  0.0738,  1.0796, -1.8512,\n",
      "         -1.2687, -1.0881,  0.8251, -0.4480, -2.3407,  1.7695,  0.1365,  0.3206,\n",
      "         -0.3523, -0.4566,  1.2336,  0.6753, -1.0943, -0.9837,  0.6526,  1.8047,\n",
      "         -0.0385, -0.8380,  0.9137, -1.4264, -0.9409, -0.6709,  0.3797, -0.7174,\n",
      "          0.9260, -1.5662, -0.8791,  1.1298, -0.8859, -0.3710, -0.7087,  0.9470,\n",
      "          1.2711,  2.3161, -0.8103, -1.8862,  0.4170,  0.6092,  0.3651, -0.3219,\n",
      "          1.3739, -0.5745,  1.6072, -2.1623, -0.6555, -0.3437,  0.0052, -0.8864,\n",
      "         -0.8530,  0.6788, -1.9486,  0.6531,  0.2795,  0.7046,  0.7063, -1.1116,\n",
      "         -0.0349,  0.2274, -3.3504,  0.2515,  0.9525,  0.6327, -0.4619, -0.3047,\n",
      "          0.0813, -0.1240, -1.1323, -0.8440, -0.6510, -2.0375, -1.1233,  2.1372,\n",
      "         -2.2291,  0.2582, -1.6342, -0.9950, -1.0569,  0.9833, -0.8928,  0.1851,\n",
      "          1.7064, -2.5291,  0.1725,  0.6479, -0.3481, -0.2409, -0.7433, -1.0568,\n",
      "          1.6502, -0.7101,  0.7323,  0.9275, -0.8650, -0.3761, -0.2017, -0.0326,\n",
      "          0.6007,  0.1411, -0.9443,  0.7873,  0.6191, -0.0197, -0.4220, -0.6062,\n",
      "         -1.3528,  0.8381, -0.6213, -1.9101,  0.1119, -0.7396,  0.3974, -0.0895,\n",
      "          0.1717,  0.2635,  0.0309, -2.3751, -2.4246, -0.8332,  0.6631,  0.6962,\n",
      "          1.6140,  0.1168, -1.1428, -0.6626,  0.3953, -0.4790,  1.1359, -0.3421,\n",
      "          0.9379, -0.4369, -1.1208, -0.5266,  0.6573,  0.5598,  0.5686,  0.0100,\n",
      "         -1.3891, -0.2595,  1.4420,  0.6121, -0.7741, -0.1485,  0.3278,  0.7193,\n",
      "         -0.7796, -0.0654, -1.4900, -0.6333,  1.4592,  0.8772,  0.0397,  0.5593,\n",
      "          0.0771,  1.0949, -0.1080, -0.9121, -0.5313, -1.0880,  0.4347,  0.2889,\n",
      "         -1.3276, -1.3781,  0.3602, -0.6262, -0.7562, -0.9939, -0.9483, -0.5614,\n",
      "         -1.5452,  0.7580, -0.4183,  0.0980, -0.4783, -0.8339,  0.2141, -0.6420,\n",
      "          0.5558,  0.7136, -2.2498,  0.3293,  0.4353,  0.3424,  0.9216,  1.7442,\n",
      "         -2.1925, -0.7469,  0.7369,  0.6265,  1.1528, -0.5219, -0.7299, -0.8214]],\n",
      "       grad_fn=<UnsqueezeBackward0>)\n",
      "torch.Size([1, 32, 32, 32])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4c1cf62baac4d589c13864f66b518f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from exercise_3.util.visualization import visualize_mesh\n",
    "from skimage.measure import marching_cubes\n",
    "import torch.distributions as dist\n",
    "model = ThreeDEPNDecoder()\n",
    "model.load_state_dict(torch.load('exercise_3/runs/3_1_3depn_generalization/' + \"model_best.ckpt\", map_location='cpu'))\n",
    "latent_vectors = torch.load('exercise_3/runs/3_1_3depn_generalization/latent_best.pt', map_location = 'cpu')\n",
    "log_vars = torch.load('exercise_3/runs/3_1_3depn_generalization/log_var_best.pt', map_location = 'cpu')\n",
    "Dist = dist.Normal(latent_vectors[100], torch.exp(log_vars[100]))\n",
    "x_vad = Dist.rsample().unsqueeze(0)\n",
    "print(x_vad)\n",
    "output_meshes = model(latent_vectors[1000].unsqueeze(0))\n",
    "print(output_meshes.shape)\n",
    "output_mesh = marching_cubes(output_meshes[0].detach().numpy(), level=1)\n",
    "visualize_mesh(output_mesh[0], output_mesh[1], flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecbe58b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
